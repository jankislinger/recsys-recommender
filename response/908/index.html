<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    


  

    <div class="item">
      <h3>deepseek-r1:32b</h3>
      <div class="ui segment">
        <h4>Prompt</h4>
        <pre><code>You are an intelligent assistant tasked with categorizing research articles to create a user-friendly, navigable interface. Your goal is to assign each article to multiple relevant categories to ensure that users can seamlessly explore and discover content.

Key Objectives:

    1. Categorization Accuracy: Ensure each article is placed in the most appropriate categories based on its content, themes, and relevance.
    2. Category Utility: Each category should contain a sufficient number of articles to be useful for navigation. Avoid creating categories with too few articles.
    3. User-Centric Design: Prioritize categories that align with user interests and search behaviors, making the interface intuitive and efficient.
    4. Consistency: Maintain consistent categorization logic across all articles to avoid confusion and ensure a cohesive user experience.

Guidelines:

    - Multiple Categories: Assign each article to at least 8-12 categories to enhance discoverability.
    - Balanced Distribution: Aim for a balanced distribution of articles across categories to prevent overcrowding in some and underrepresentation in others.
    - Dynamic Updates: Be prepared to adjust categories as new articles are added or user needs evolve.
    - Clear Labels: Use clear, descriptive, and user-friendly category names that accurately reflect the content within.

Example Workflow:

    - Analyze the article&#39;s title and abstract to identify its core themes.
    - Map the article to existing categories or propose new ones if necessary.
    - Ensure the article is placed in categories that are both specific and broad enough to be useful.
    - Review the categorization to confirm it aligns with user needs and interface goals.

Examples of Categories:

    - Family of algorithm (e.g., Matrix Factorization, Encoder, Multi-Armed Bandits, etc.).
    - Domain of the problem (e.g., Books, Movies, Healthcare, Education, etc.).
    - Something specific in the recommendation space (e.g. Cold Start)
    - Aspects of evaluation (e.g. Diversity of Recommendations, Beyond Accuracy)
    - Whether there are any real word applications (e.g. A/B Test, User Survey, etc.)
    - Any other type of categorization that seems relevant to the article.

Output:

    - Return just the list of categories.
    - The format should be a list of keywords separated by comma, e.g. &#34;Scalability, Web Systems, Implicit Feedback&#34;


Title: Large Language Model Augmented Narrative Driven Recommendations
Abstract:
Narrative-driven recommendation (NDR) presents an information access problem where users solicit recommendations with verbose descriptions of their preferences and context, for example, travelers soliciting recommendations for points of interest while describing their likes/dislikes and travel circumstances. These requests are increasingly important with the rise of natural language-based conversational interfaces for search and recommendation systems. However, NDR lacks abundant training data for models, and current platforms commonly do not support these requests. Fortunately, classical user-item interaction datasets contain rich textual data, e.g., reviews, which often describe user preferences and context â€” this may be used to bootstrap training for NDR models. In this work, we explore using large language models (LLMs) for data augmentation to train NDR models. We use LLMs for authoring synthetic narrative queries from user-item interactions with few-shot prompting and train retrieval models for NDR on synthetic queries and user-item interaction data. Our experiments demonstrate that this is an effective strategy for training small-parameter retrieval models that outperform other retrieval and LLM baselines for narrative-driven recommendation.
</code></pre>
      </div>
      <div class="ui segment">
        <h4>Response</h4>
        <pre><code>&lt;think&gt;
Okay, I&#39;m trying to categorize this research article titled &#34;Large Language Model Augmented Narrative Driven Recommendations.&#34; Let&#39;s break it down step by step.

First, the title mentions Large Language Models (LLMs), so that&#39;s definitely a key category. The abstract talks about narrative-driven recommendations (NDR), which is another specific area I should include. It discusses using LLMs for data augmentation, so &#34;Data Augmentation&#34; makes sense as a category too.

The article also focuses on recommendation systems in general, so &#34;Recommendation Systems&#34; should be included. They mention that NDR presents an information access problem, especially with verbose user descriptions. So categories like &#34;Natural Language Processing&#34; and &#34;User-Item Interaction&#34; are relevant since they deal with textual data and how users interact with items.

The abstract states that current platforms lack support for these narrative requests, pointing towards a gap in existing systems. That leads me to think about &#34;System Design&#34; as another category because the work is proposing a new approach to address this gap.

They use user-item interaction datasets like reviews, which are examples of &#34;Textual Data.&#34; So including &#34;Textual Data&#34; makes sense. The experiments show that using LLMs helps train retrieval models effectively, so &#34;Retrieval Models&#34; should be another category.

The paper also touches on challenges with sparse data in NDR and how they&#39;re addressing this with synthetic queries. Therefore, &#34;Sparse Data Handling&#34; is a good fit. Additionally, since they are creating synthetic narrative queries from user interactions, &#34;Synthetic Queries&#34; is relevant.

Lastly, the overall approach involves using LLMs to enhance recommendation systems through various methods like data augmentation, so &#34;Large Language Models (LLMs)&#34; as a broader category also applies.

Putting it all together, I should make sure each of these categories accurately reflects different aspects of the article without being too narrow or overlapping. This way, users can easily navigate and find related content based on their interests.
&lt;/think&gt;

Narrative-Driven Recommendations, Large Language Models (LLMs), Data Augmentation, Recommendation Systems, Natural Language Processing, User-Item Interaction, System Design, Textual Data, Retrieval Models, Sparse Data Handling, Synthetic Queries.</code></pre>
      </div>
    </div>

  


  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>