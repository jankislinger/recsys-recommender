<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reproducibility/">Reproducibility</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/real-world-applications/">Real-world Applications</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/e-commerce/">E-commerce</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reinforcement-learning/">Reinforcement Learning</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>A Unified Graph Transformer for Overcoming Isolations in Multi-modal Recommendation (2024)</h3>
    <p><strong>Authors:</strong> Zixuan Yi, Iadh Ounis</p>
    <p>With the rapid development of online multimedia services, especially in e-commerce platforms, there is a pressing need for personalised recommendation systems that can effectively encode the diverse multi-modal content associated with each item. However, we argue that existing multi-modal recommender systems typically use isolated processes for both feature extraction and modality modelling. Such isolated processes can harm the recommendation performance. Firstly, an isolated extraction process underestimates the importance of effective feature extraction in multi-modal recommendations, potentially incorporating non-relevant information, which is harmful to item representations. Second, an isolated modality modelling process produces disjointed embeddings for item modalities due to the individual processing of each modality, which leads to a suboptimal fusion of user/item representations for effective user preferences prediction. We hypothesise that the use of a unified model for addressing both aforementioned isolated processes will enable the consistent extraction and cohesive fusion of joint multi-modal features, thereby enhancing the effectiveness of multi-modal recommender systems. In this paper, we propose a novel model, called Unified Multi-modal Graph Transformer (UGT), which firstly leverages a multi-way transformer to extract aligned multi-modal features from raw data for top-k recommendation. Subsequently, we build a unified graph neural network in our UGT model to jointly fuse the user/item representations with their corresponding multi-modal features. Using the graph transformer architecture of our UGT model, we show that the UGT model can achieve significant effectiveness gains, especially when jointly optimised with the commonly-used multi-modal recommendation losses. Our extensive experiments conducted on three benchmark datasets demonstrate the superiority of our proposed UGT model over seven existing state-of-the-art recommendation approaches.</p>
    <p><strong>Categories:</strong> Graph Neural Networks, Transformer Models, Multi-Modal Recommendations, E-Commerce, Feature Extraction, Modality Modeling, Multi-Modal Fusion, Online Services, Multimedia, Benchmark Testing, Recommendation Systems, Model Architecture, Comparison Studies (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1023/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Self-Attentive Sequential Recommendations with Hyperbolic Representations (2024)</h3>
    <p><strong>Authors:</strong> Tatyana Matveeva, Evgeny Frolov, Ivan Oseledets, Leyla Mirvakhabova</p>
    <p>In recent years, self-attentive sequential learning models have surpassed conventional collaborative filtering techniques in next-item recommendation tasks. However, Euclidean geometry utilized in these models may not be optimal for capturing a complex structure of behavioral data. Building on recent advances in the application of hyperbolic geometry to collaborative filtering tasks, we propose a novel approach that leverages hyperbolic geometry in the sequential learning setting. Our approach replaces final output of the Euclidean models with a linear predictor in the non-linear hyperbolic space, which increases the representational capacity and improves recommendation quality.</p>
    <p><strong>Categories:</strong> Self-Attention, Transformer-Based Models, Hyperbolic Geometry, Sequential Recommendations, Recommendation Systems, Model Architecture, Representation Learning, Geometric Deep Learning, Output Layer Design, Recommendation Quality (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1113/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Equivariant Contrastive Learning for Sequential Recommendation (2023)</h3>
    <p><strong>Authors:</strong> Yueqi Xie, Yining Hua, Sunghun Kim, Jaeboum Kim, Shoujin Wang, Jingqi Gao, Qichen Ye, Peilin Zhou</p>
    <p>Contrastive learning (CL) benefits the training of sequential recommendation models with informative self-supervision signals. Existing solutions apply general sequential data augmentation strategies to generate positive pairs and encourage their representations to be invariant. However, due to the inherent properties of user behavior sequences, some augmentation strategies, such as item substitution, can lead to changes in user intent. Learning indiscriminately invariant representations for all augmentation strategies might be sub-optimal. Therefore, we propose Equivariant Contrastive Learning for Sequential Recommendation (ECL-SR), which endows SR models with great discriminative power, making the learned user behavior representations sensitive to invasive augmentations (e.g., item substitution) and insensitive to mild augmentations (e.g., feature-level dropout masking). In detail, we use the conditional discriminator to capture differences in behavior due to item substitution, which encourages the user behavior encoder to be equivariant to invasive augmentations. Comprehensive experiments on four benchmark datasets show that the proposed ECL-SR framework achieves competitive performance compared to state-of-the-art SR models. The source code will be released.</p>
    <p><strong>Categories:</strong> Contrastive Learning, Sequential Recommendation, Data Augmentation, Model Architecture, Recommendation Systems, Self-Supervised Learning, User Behavior Analysis, Discriminative Models, Performance Evaluation/Metrics, Sequential Modeling (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/862/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>M3REC: A Meta-based Multi-scenario Multi-task Recommendation Framework (2023)</h3>
    <p><strong>Authors:</strong> Zerong Lan, Yingyi Zhang, Xianneng Li</p>
    <p>Users in recommender systems exhibit multi-behavior in multiple business scenarios on real-world e-commerce platforms. A crucial challenge in such systems is to make recommendations for each business scenario at the same time. On top of this, multiple predictions (e.g., Click Through Rate and Conversion Rate) need to be made simultaneously in order to improve the platform revenue. Research focus on making recommendations for several business scenarios is in the field of Multi-Scenario Recommendation (MSR), and Multi-Task Recommendation (MTR) mainly attempts to solve the possible problems in collaboratively executing different recommendation tasks. However, existing researchers have paid attention to either MSR or MTR, ignoring the integration of MSR and MTR that faces the issue of conflict between scenarios and tasks. To address the above issue, we propose a Meta-based Multi-scenario Multi-task RECommendation framework (M3REC) to serve multiple tasks in multiple business scenarios by a unified model. However, integrating MSR and MTR in a proper manner is non-trivial due to: 1) Unified representation problem: Users’ and items’ representation behave Non-i.i.d in different scenarios and tasks which takes inconsistency into recommendations. 2) Synchronous optimization problem: Tasks distribution varies in different scenarios, and a unified optimization method is needed to optimize multi-tasks in multi-scenarios. Thus, to unified represent users and items, we design a Meta-Item-Embedding Generator (MIEG) and a User-Preference Transformer (UPT). The MIEG module can generate initialized item embedding using item features through meta-learning technology, and the UPT module can transfer user preferences in other scenarios. Besides, the M3REC framework uses a specifically designed backbone network together with a task-specific aggregate gate to promote all tasks to achieve the purpose of optimizing multiple tasks in multiple business scenarios within one model. Experiments on two public datasets have shown that M3REC outperforms those compared MSR and MTR state-of-the-art methods.</p>
    <p><strong>Categories:</strong> Meta-Learning, E-commerce, Multi-Scenario Recommendation, Multi-Task Learning, Cold Start, User Representation, Beyond Accuracy, Real-world Application, Model Architecture, Multi-Task Optimization (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/911/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>BRUCE – Bundle Recommendation Using Contextualized item Embeddings (2022)</h3>
    <p><strong>Authors:</strong> Amit Livne, Bracha Shapira, Oren Sar Shalom, Mark Last, Tzoof Avny Brosh</p>
    <p>A bundle is a pre-defined set of items that are collected together. In many domains, bundling is one of the most important marketing strategies for item promotion, commonly used in e-commerce. Bundle recommendation resembles the item recommendation task, where bundles are the recommended unit, but it poses additional challenges; while item recommendation requires only user and item understanding, bundle recommendation also requires modeling the connections between the various items in a bundle. Transformers have driven the state-of-the-art methods for set and sequence modeling in various natural language processing and computer vision tasks, emphasizing the understanding that the neighbors of an element are of crucial importance. Under some required adjustments, we believe the same applies for items in bundles, and better capturing the relations of an item with other items in the bundle may lead to improved recommendations. To address that, we introduce BRUCE - a novel model for bundle recommendation, in which we adapt Transformers to represent data on users, items, and bundles. This allows exploiting the self-attention mechanism to model the following: latent relations between the items in a bundle; and users’ preferences toward each of the items in the bundle and toward the whole bundle. Moreover, we examine various architectures to integrate the items’ and the users’ information and provide insights on architecture selection based on data characteristics. Experiments conducted on three benchmark datasets show that the proposed approach contributes to the accuracy of the recommendation and substantially outperforms state-of-the-art methods</p>
    <p><strong>Categories:</strong> Bundle Recommendation, E-commerce, Recommendation Systems, Transformers, Attention Mechanism, Item Relationships, User Preferences, Model Architecture, Embeddings, Neighbor Modeling, Recommendation Accuracy, Novel Methods, Real-world Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/750/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Effective and Efficient Training for Sequential Recommendation using Recency Sampling (2022)</h3>
    <p><strong>Authors:</strong> Aleksandr Petrov, Craig Macdonald</p>
    <p>Many modern sequential recommender systems use deep neural networks, which can effectively estimate the relevance of items but require a lot of time to train. Slow training increases expenses, hinders product development timescales and prevents the model from being regularly updated to adapt to changing user preferences. Training such sequential models involves appropriately sampling past user interactions to create a realistic training objective. The existing training objectives have limitations. For instance, next item prediction never uses the beginning of the sequence as a learning target, thereby potentially discarding valuable data. On the other hand, the item masking used by BERT4Rec is only weakly related to the goal of the sequential recommendation; therefore, it requires much more time to obtain an effective model. Hence, we propose a novel Recency-based Sampling of Sequences training objective that addresses both limitations. We apply our method to various recent and state-of-the-art model architectures – such as GRU4Rec, Caser, and SASRec. We show that the models enhanced with our method can achieve performances exceeding or very close to state-of-the-art BERT4Rec, but with much less training time.</p>
    <p><strong>Categories:</strong> Sequential Recommendations, Training Techniques, Recency Sampling, Model Architecture, Efficiency, Scalability, Algorithm Improvements, Optimization, Deep Learning, Real-World Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/764/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>MEANTIME: Mixture of Attention Mechanisms with Multi-temporal Embeddings for Sequential Recommendation (2020)</h3>
    <p><strong>Authors:</strong> Sung Min Cho, Eunhyeok Park, Sungjoo Yoo</p>
    <p>Recently, self-attention based models have achieved state-of-the-art performance in sequential recommendation task. Following the custom from language processing, most of these models rely on a simple positional embedding to exploit the sequential nature of the user’s history. However, there are some limitations regarding the current approaches. First, sequential recommendation is different from language processing in that timestamp information is available. Previous models have not made good use of it to extract additional contextual information. Second, using a simple embedding scheme can lead to information bottleneck since the same embedding has to represent all possible contextual biases. Third, since previous models use the same positional embedding in each attention head, they can wastefully learn overlapping patterns. To address these limitations, we propose MEANTIME (MixturE of AtteNTIon mechanisms with Multi-temporal Embeddings) which employs multiple types of temporal embeddings designed to capture various patterns from the user’s behavior sequence, and an attention structure that fully leverages such diversity. Experiments on real-world data show that our proposed method outperforms current state-of-the-art sequential recommendation methods, and we provide an extensive ablation study to analyze how the model gains from the diverse positional information.</p>
    <p><strong>Categories:</strong> Sequential Recommendation, Attention Mechanisms, Temporal Embeddings, User Behavior Analysis, Model Architecture, Cold Start Problem, Evaluation Metrics, Real-World Applications, Diversity of Recommendations, Novel Methods, Hybrid Models (<i>deepseek-r1:70b</i>)</p>
    <p><a href="/recsys-recommender/response/582/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Recommending What Video to Watch Next: A Multitask Ranking System (2019)</h3>
    <p><strong>Authors:</strong> Lichan Hong, Ed Chi, Maheswaran Sathiamoorthy, Li Wei, Aditee Kumthekar, Aniruddh Nath, Xinyang Yi, Zhe Zhao, Shawn Andrews, Jilin Chen</p>
    <p>In this paper, we introduce a large scale multi-objective ranking system for recommending what video to watch next on an industrial video sharing platform. The system faces many real-world challenges, including the presence of multiple competing ranking objectives, as well as implicit selection biases in user feedback. To tackle these challenges, we explored a variety of soft-parameter sharing techniques such as Multi-gate Mixture-of-Experts so as to efficiently optimize for multiple ranking objectives. Additionally, we mitigated the selection biases by adopting a Wide & Deep framework. We demonstrated that our proposed techniques can lead to substantial improvements on recommendation quality on one of the world’s largest video sharing platforms.</p>
    <p><strong>Categories:</strong> Video Recommendations, Multi-Objective Optimization, Implicit Feedback, Algorithm Design, Model Architecture, Real-World Applications, Recommendation Quality, Multi-Task Learning, Bias Mitigation, System Design, Platform-Specific (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/458/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>