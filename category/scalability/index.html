<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui primary button" style="margin: 5px;"
             href="/recsys-recommender/">Scalability</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/evaluation-metrics/">Evaluation Metrics</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/beyond-accuracy/">Beyond Accuracy</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/explainability/">Explainability</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/cold-start/">Cold Start</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reproducibility/">Reproducibility</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Toward 100TB Recommendation Models with Embedding Offloading (2024)</h3>
    <p><strong>Authors:</strong> Sarunya Pumma, Levy Zhao, Joshua Deng, Dennis Van Der Staay, Jian He, Intaik Park, Ehsan Ardestani, Damian Reeves, Yu Guo, Paul Zhang, Henry Tsang</p>
    <p>Training recommendation models become memory-bound with large embedding tables, and fast GPU memory is scarce. In this paper, we explore embedding caches and prefetch pipelines to effectively leverage large but slow host memory for embedding tables. We introduce Locality-Aware Sharding and iterative planning that automatically size caches optimally and produce effective sharding plans. Embedding Offloading, a system that combines all of these components and techniques, is implemented on top of Meta’s open-source libraries, FBGEMM GPU and TorchRec, and it is used to improve scalability and efficiency of industry-scale production models. Embedding Offloading achieved 37x model scale to 100TB model size with only 26% training speed regression.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Embedding, Scalability, Memory Optimization, System Design, Cache Management, Sharding, Production Systems, Industry Applications, System Performance, GPU Memory, Resource Management (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1178/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>RPAF: A Reinforcement Prediction-Allocation Framework for Cache Allocation in Large-Scale Recommender Systems (2024)</h3>
    <p><strong>Authors:</strong> Kaiqiao Zhan, Kun Gai, Xiaoshuang Chen, Yao Wang, Ziqiang Zhang, Ben Wang, Yulin Wu, Shuo Su</p>
    <p>Modern recommender systems are built upon computation-intensive infrastructure, and it is challenging to perform real-time computation for each request, especially in peak periods, due to the limited computational resources. Recommending by user-wise result caches is widely used when the system cannot afford a real-time recommendation. However, it is challenging to allocate real-time and cached recommendations to maximize the users’ overall engagement. This paper shows two key challenges to cache allocation, i.e., the temporal dependency and the streaming allocation. Then, we propose a reinforcement prediction-allocation framework (RPAF) to address these issues. RPAF is a reinforcement-learning-based two-stage framework containing prediction and allocation stages. The prediction stage estimates the values of the cache choices considering the strategy and value dependencies, while the allocation stage determines the cache choices for each request. We show that the challenge of training RPAF includes globality and the strictness of budget constraints, and a relaxed local allocator (RLA) is proposed to address this issue. Moreover, a PoolRank algorithm is used in the allocation stage to deal with the streaming allocation problem. Experiments show that RPAF significantly improves users’ engagement under computational budget constraints.</p>
    <p><strong>Categories:</strong> Reinforcement Learning, Cache Management, Recommender Systems, Real-time Recommendations, Scalability, Streaming Allocation, Optimization, Computational Constraints, Algorithm Design, Evaluation Metrics, Temporal Dependency, Recommendation Strategies (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1058/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>A Novel Evaluation Perspective on GNNs-based Recommender Systems through the Topology of the User-Item Graph (2024)</h3>
    <p><strong>Authors:</strong> Alberto Carlo Maria Mancino, Vito Walter Anelli, Claudio Pomo, Tommaso Di Noia, Eugenio Di Sciascio, Daniele Malitesta</p>
    <p>Recently, graph neural networks (GNNs)-based recommender systems have encountered great success in recommendation. As the number of GNNs approaches rises, some works have started questioning the theoretical and empirical reasons behind their superior performance. Nevertheless, this investigation still disregards that GNNs treat the recommendation data as a topological graph structure. Building on this assumption, in this work, we provide a novel evaluation perspective on GNNs-based recommendation, which investigates the impact of the graph topology on the recommendation performance. To this end, we select some (topological) properties of the recommendation data and three GNNs-based recommender systems (i.e., LightGCN, DGCF, and SVD-GCN). Then, starting from three popular recommendation datasets (i.e., Yelp2018, Gowalla, and Amazon-Book) we sample them to obtain 1,800 size-reduced datasets that still resemble the original ones but can encompass a wider range of topological structures. We use this procedure to build a large pool of samples for which data characteristics and recommendation performance of the selected GNNs models are measured. Through an explanatory framework, we find strong correspondences between graph topology and GNNs performance, offering a novel evaluation perspective on these models.</p>
    <p><strong>Categories:</strong> Graph Neural Networks, GNN-based Recommender Systems, Recommendation Systems, Real-World Applications, Evaluation Framework, Graph Topology Analysis, Data Characteristics, Recommendation Performance, Scalability, Robustness, Model Interpretability, Beyond Accuracy, Evaluation Metrics, Novel Evaluation Perspective (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1116/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Co-optimize Content Generation and Consumption in a Large Scale Video Recommendation System (2024)</h3>
    <p><strong>Authors:</strong> Yuening Li, Mingyan Gao, Qingyun Liu, Sourabh Bansod, Shuchao Bi, Liang Liu, Yaping Zhang, Zhen Zhang</p>
    <p>Multi-task prediction models and value models are the de-facto standard ranking components in modern large-scale content recommendation systems. However, they are typically optimized to model users’ passive consumption behaviors, and rank content in a way to grow only consumption-centric values. In this talk, we discuss the key insight that it is possible to model sparse participatory content-generation actions as well and grow ecosystem value through a new ranking system. We made the following key technical contributions in this system: (1) introducing ranking for content generation based on a categorization of user participation actions of different sparsity, including proxy intent action or access point clicks. (2) improving sparse task prediction quality and stability by causal task relationship modeling, conditional loss modeling and ResNet based shared bottom network. (3) personalizing the value model to minimize conflicts between different values, through e.g. ranking inspiring content higher for users who actively generate content. (4) conducting systematic evaluation of proposed approach in a large short-form video UGC (User-Generated Content) platform.</p>
    <p><strong>Categories:</strong> Multi-Task Learning, Video Recommendation, User-Generated Content, Content Generation, Large-Scale Systems, Evaluation Metrics, Causal Modeling, Network Architecture, User Participation, Scalability, Content Creation, User-Centric Design (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1156/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Effective Off-Policy Evaluation and Learning in Contextual Combinatorial Bandits (2024)</h3>
    <p><strong>Authors:</strong> Yuta Saito, Tatsuhiro Shimizu, Ren Kishimoto, Masahiro Nomura, Koichi Tanaka, Haruka Kiyohara</p>
    <p>We explore off-policy evaluation and learning in contextual combinatorial bandits (CCB), where a policy selects a subset in the action space. For example, it might choose a set of furniture pieces (a bed and a drawer) from available items (bed, drawer, chair, etc.) for interior design sales. This setting is widespread in fields such as recommender systems and healthcare, yet OPE/L of CCB remains unexplored in the relevant literature. Standard OPE methods typically employ regression and importance sampling in the action subset space. However, they often face significant challenges due to high bias or variance, exacerbated by the exponential growth in the number of available subsets. To address these challenges, we introduce a concept of factored action space, which allows us to decompose each subset into binary indicators. These indicators signify whether each action is included in the selected subset. This formulation allows us to distinguish between the “main effect” derived from the main actions, and the “residual effect”, originating from the supplemental actions, facilitating more effective OPE. Specifically, our estimator, called OPCB, leverages an importance sampling-based approach to unbiasedly estimate the main effect, while employing regression-based approach to deal with the residual effect with low variance. OPCB achieves substantial variance reduction compared to conventional importance sampling methods and bias reduction relative to regression methods under certain conditions, as illustrated in our theoretical analysis. Experiments on both synthetic and real-world datasets demonstrate OPCB’s superior performance over the typical methods, particularly when navigating the complexities of a large action subset space.</p>
    <p><strong>Categories:</strong> Combinatorial Bandits, Contextual Bandits, Off-Policy Evaluation, Importance Sampling, Regression Methods, Recommender Systems, Healthcare, Scalability, Evaluation Metrics, Multi-Armed Bandits, Real-World Applications, Theoretical Analysis. (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1040/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>MLoRA: Multi-Domain Low-Rank Adaptive Network for CTR Prediction (2024)</h3>
    <p><strong>Authors:</strong> Libin Yang, Haining Gao, Wei Ning, Luwei Yang, Zhiming Yang, Dehong Gao, Guannan Zhang, Xiaoyan Cai</p>
    <p>Click-through rate (CTR) prediction is one of the fundamental tasks in the industry, especially in e-commerce, social media, and streaming media. It directly impacts website revenues, user satisfaction, and user retention. However, real-world production platforms often encompass various domains to cater for diverse customer needs. Traditional CTR prediction models struggle in multi-domain recommendation scenarios, facing challenges of data sparsity and disparate data distributions across domains. Existing multi-domain recommendation approaches introduce specific-domain modules for each domain, which partially address these issues but often significantly increase model parameters and lead to insufficient training. In this paper, we propose a Multi-domain Low-Rank Adaptive network (MLoRA) for CTR prediction, where we introduce a specialized LoRA module for each domain. This approach enhances the model’s performance in multi-domain CTR prediction tasks and is able to be applied to various deep-learning models. We evaluate the proposed method on several multi-domain datasets. Experimental results demonstrate our MLoRA approach achieves a significant improvement compared with state-of-the-art baselines. Furthermore, we deploy it in a real-world e-commerce production website. The online A/B testing results indicate the superiority and flexibility in real-world production environments.</p>
    <p><strong>Categories:</strong> Multi-Domain, Click-Through Rate Prediction, Recommendation Systems, Deep Learning Models, Low-Rank Adaptive Methods, Real-World Applications, A/B Testing, Data Sparsity, Cross-Domain, Scalability (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1041/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Ranking Across Different Content Types: The Robust Beauty of Multinomial Blending (2024)</h3>
    <p><strong>Authors:</strong> Jan Malte Lichtenberg, Giuseppe Di Benedetto, Matteo Ruffini</p>
    <p>An increasing number of media streaming services have expanded their offerings to include entities of multiple content types. For instance, audio streaming services that started by offering music only, now also offer podcasts, merchandise items, and (music) videos. Ranking items across different content types into a single slate poses a significant challenge for traditional learning-to-rank (LTR) algorithms due to differing feature sets and user engagement patterns for different content types. We explore a simple method, called multinomial blending (MB), which can be used in conjunction with most existing LTR algorithms. We compare MB to a range of baselines not only in terms of ranking quality but also from other industry-relevant perspectives such as interpretability, ease-of-use, and stability in dynamic online-learning environments.</p>
    <p><strong>Categories:</strong> Learning-to-Rank, Multinomial Blending, Media Streaming Services, Content Types, Ranking Across Different Content Types, Cross-Content Type Recommendations, Real-World Applications, Beyond Accuracy, Scalability, Online Learning, Heterogeneous Data, User Engagement Patterns, Feature Engineering, Experimental Evaluation (<i>deepseek-r1:70b</i>)</p>
    <p><a href="/recsys-recommender/response/1180/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>RePlay: a Recommendation Framework for Experimentation and Production Use (2024)</h3>
    <p><strong>Authors:</strong> Denis Kulandin, Tatiana Bysheva, Alexey Vasilev, Anton Klenitskiy, Anna Volodkevich</p>
    <p>Using a single tool to build and compare recommender systems significantly reduces the time to market for new models. In addition, the comparison results when using such tools look more consistent. This is why many different tools and libraries for researchers in the field of recommendations have recently appeared. Unfortunately, most of these frameworks are aimed primarily at researchers and require modification for use in production due to the inability to work on large datasets or an inappropriate architecture. In this demo, we present our open-source toolkit RePlay – a framework containing an end-to-end pipeline for building recommender systems, which is ready for production use. RePlay also allows you to use a suitable stack for the pipeline on each stage: Pandas, Polars, or Spark. This allows the library to scale computations and deploy to a cluster. Thus, RePlay allows data scientists to easily move from research mode to production mode using the same interfaces.</p>
    <p><strong>Categories:</strong> Recommender Systems, Research to Production, Model Comparison, Scalability, End-to-End Pipeline, Evaluation Pipelines, Open Source Tools, Multi-Stack Solutions, Data Science Workflow, Experimentation (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1209/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Scalable Cross-Entropy Loss for Sequential Recommendations with Large Item Catalogs (2024)</h3>
    <p><strong>Authors:</strong> Gleb Mezentsev, Danil Gusak, Ivan Oseledets, Evgeny Frolov</p>
    <p>Scalability issue plays a crucial role in productionizing modern recommender systems. Even lightweight architectures may suffer from high computational overload due to intermediate calculations, limiting their practicality in real-world applications. Specifically, applying full Cross-Entropy (CE) loss often yields state-of-the-art performance in terms of recommendations quality. Still, it suffers from excessive GPU memory utilization when dealing with large item catalogs. This paper introduces a novel Scalable Cross-Entropy (SCE) loss function in the sequential learning setup. It approximates the CE loss for datasets with large-size catalogs, enhancing both time efficiency and memory usage without compromising recommendations quality. Unlike traditional negative sampling methods, our approach utilizes a selective GPU-efficient computation strategy, focusing on the most informative elements of the catalog, particularly those most likely to be false positives. This is achieved by approximating the softmax distribution over a subset of the model outputs through the maximum inner product search. Experimental results on multiple datasets demonstrate the effectiveness of SCE in reducing peak memory usage by a factor of up to 100 compared to the alternatives, retaining or even exceeding their metrics values. The proposed approach also opens new perspectives for large-scale developments in different domains, such as large language models.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Loss Functions, Scalability, Sequential Recommendations, GPU Memory Optimization, Large Item Catalogs, Efficiency and Performance, False Positives Handling, Max Inner Product Search (MIPS), Large Language Models (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1059/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Powerful A/B-Testing Metrics and Where to Find Them (2024)</h3>
    <p><strong>Authors:</strong> Shubham Baweja, Aleksei Ustimenko, Neeti Pokharna, Olivier Jeunen</p>
    <p>Online controlled experiments, colloquially known as A/B-tests, are the bread and butter of real-world recommender system evaluation. Typically, end-users are randomly assigned some system variant, and a plethora of metrics are then tracked, collected, and aggregated throughout the experiment. A North Star metric (e.g. long-term growth or revenue) is used to assess which system variant should be deemed superior. As a result, most collected metrics are <i>supporting</i> in nature, and serve to either (i) provide an understanding of how the experiment impacts user experience, or (ii) allow for confident decision-making when the North Star metric moves insignificantly (i.e. a false negative or type-II error). The latter is not straightforward: suppose a treatment variant leads to fewer but longer sessions, with more views but fewer engagements; should this be considered a positive or negative outcome? The question then becomes: how do we assess a supporting metric’s utility when it comes to decision-making using A/B-testing?Online platforms typically run dozens of experiments at any given time. This provides a wealth of information about interventions and treatment effects that can be used to evaluate metrics’ utility for online evaluation. We propose to collect this information and leverage it to quantify type-I, type-II, and type-III errors for the metrics of interest, alongside a distribution of measurements of their statistical power (e.g. $z$-scores and $p$-values). We present results and insights from building this pipeline at scale for two large-scale short-video platforms: ShareChat and Moj; leveraging hundreds of past experiments to find online metrics with high statistical power.</p>
    <p><strong>Categories:</strong> A/B Testing, Evaluation Metrics, Statistical Analysis, Recommender Systems, Real-World Applications, Experimentation, Decision-Making Under Uncertainty, Metrics Analysis and Evaluation, Statistical Power, Scalability, Historical Data Analysis (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1173/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Bootstrapping Conditional Retrieval for User-to-Item Recommendations (2024)</h3>
    <p><strong>Authors:</strong> Jiajing Xu, Jaewon Yang, Hongtao Lin, Haoyu Chen</p>
    <p>User-to-item retrieval has been an active research area in recommendation system, and two tower models are widely adopted due to model simplicity and serving efficiency. In this work, we focus on a variant called conditional retrieval, where we expect retrieved items to be relevant to a condition (e.g. topic). We propose a method that uses the same training data as standard two tower models but incorporates item side information as conditions in query. This allows us to bootstrap new conditional retrieval use cases and encourages feature interactions between user and condition. Experiments show that our method can retrieve highly relevant items and out-performed standard two tower models with filters on engagement metrics. The proposed model is deployed to power a topic-based notification feed at Pinterest and led to +0.26% weekly active users.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Conditional Retrieval, Two-Tower Models, Item Side Information, Query-Based Recommendations, Feature Interaction, Performance Comparison, Real-World Applications, User Growth, Engagement Metrics, Scalability (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1151/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>LLMs for User Interest Exploration: A Hybrid Approach (2024)</h3>
    <p><strong>Authors:</strong> He Ma, Haokai Lu, Yueqi Wang, Yifan Liu, Ed H. Chi, Lexi Baugher, Ningren Han, Shuzhou Zhang, Yang Gu, Jianling Wang, Minmin Chen, Shuchao Bi</p>
    <p>Traditional recommendation systems are subject to a strong feedback loop by learning from and reinforcing past user-item interactions, which in turn limits the discovery of novel user interests. To address this, we introduce a hybrid hierarchical framework combining Large Language Models (LLMs) and classic recommendation models for user interest exploration. The framework controls the interfacing between the LLMs and the classic recommendation models through “interest clusters”, the granularity of which can be explicitly determined by algorithm designers. It recommends the next novel interests by first representing “interest clusters” using language, and employs a fine-tuned LLM to generate novel interest descriptions that are strictly within these predefined clusters. At the low level, it grounds these generated interests to an item-level policy by restricting classic recommendation models, in this case a transformer-based sequence recommender to return items that fall within the novel clusters generated at the high level. We showcase the efficacy of this approach on an industrial-scale commercial platform serving billions of users. Live experiments show a significant increase in both exploration of novel interests and overall user enjoyment of the platform.</p>
    <p><strong>Categories:</strong> Hybrid Models, Large Language Models (LLMs), Recommendation Systems, User Interest Exploration, Transformer-Based Recommenders, Content Generation, Interest Clustering, Real-World Applications, Live Experiments, User Behavior, Hierarchical Structures, Industrial Application, Scalability, Exploration vs Exploitation (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1092/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Multi-Objective Recommendation via Multivariate Policy Learning (2024)</h3>
    <p><strong>Authors:</strong> Ivan Potapov, Sourabh Vaid, Wenzhe Shi, Nakul Agarwal, Olivier Jeunen, Jatin Mandav, Aleksei Ustimenko</p>
    <p>Real-world recommender systems often need to balance multiple objectives when deciding which recommendations to present to users. These include behavioural signals (e.g. clicks, shares, dwell time), as well as broader objectives (e.g. diversity, fairness). Scalarisation methods are commonly used to handle this balancing task, where a weighted average of per-objective reward signals determines the final score used for ranking. Naturally, <i>how</i> these weights are computed exactly, is key to success for any online platform. We frame this as a decision-making task, where the scalarisation weights are <i>actions</i> taken to maximise an overall North Star reward (e.g. long-term user retention or growth). We extend existing policy learning methods to the continuous multivariate action domain, proposing to maximise a pessimistic lower bound on the North Star reward that the learnt policy will yield. Typical lower bounds based on normal approximations suffer from insufficient coverage, and we propose an efficient and effective policy-dependent correction for this. We provide guidance to design stochastic data collection policies, as well as highly sensitive reward signals. Empirical observations from simulations, offline and online experiments highlight the efficacy of our deployed approach.</p>
    <p><strong>Categories:</strong> Multi-Objective Optimization, Fairness in Recommendations, Diversity of Recommendations, Policy Learning, Reinforcement Learning in Recommender Systems, Implicit Feedback, Real-World Applications, A/B Testing, Scalarization Methods, Evaluation Methods, Scalability (<i>deepseek-r1:70b</i>)</p>
    <p><a href="/recsys-recommender/response/1051/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Multimodal Representation Learning for high-quality Recommendations in Cold-start and Beyond-Accuracy (2024)</h3>
    <p><strong>Authors:</strong> Marta Moscati</p>
    <p>Recommender systems (RS) traditionally leverage the large amount of user–item interaction data. This exposes RS to a lower recommendation quality in cold-start scenarios, as well as to a low recommendation quality in terms of beyond-accuracy evaluation metrics. State-of-the-art (SotA) models for cold-start scenarios rely on the use of side information on the items or the users, therefore relating recommendation to multimodal machine learning (ML). However, the most recent techniques from multimodal ML are often not applied to the domain of recommendation. Additionally, the evaluation of SotA multimodal RS often neglects beyond-accuracy aspects of recommendation. In this work, we outline research into designing novel multimodal RS based on SotA multimodal ML architectures for cold-start recommendation, and their evaluation and benchmark with preexisting multimodal RS in terms of accuracy and beyond-accuracy aspects of recommendation quality.</p>
    <p><strong>Categories:</strong> Multimodal Representation Learning, Cold Start, Beyond Accuracy, Recommender Systems, Machine Learning, Evaluation Metrics, Scalability, Architecture Design, Benchmarking, Side Information (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1144/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>DNS-Rec: Data-aware Neural Architecture Search for Recommender Systems (2024)</h3>
    <p><strong>Authors:</strong> Zijian Zhang, Xiangyu Zhao, Ruocheng Guo, Sheng Zhang, Chenyi Zhuang, Jinjie Gu, Yao Zhao, Hongzhi Yin, Maolin Wang</p>
    <p>In the era of data proliferation, efficiently sifting through vast information to extract meaningful insights has become increasingly crucial. This paper addresses the computational and resource inefficiencies prevalent in existing Sequential Recommender Systems (SRSs). However, existing SRSs are often plagued by significant computational overhead and resource inefficiency during the inference stage. To address these challenges, we introduce an innovative approach combining pruning methods with advanced model designs. Furthermore, we delve into resource-constrained Neural Architecture Search (NAS), an emerging technique in recommender systems, to optimize models in terms of FLOPs, latency, and energy consumption while maintaining or enhancing accuracy. Our principal contribution is the development of a Data-aware Neural Architecture Search for Recommender System (DNS-Rec). DNS-Rec is specifically designed to tailor compact network architectures for attention-based SRS models, thereby ensuring accuracy retention. It incorporates data-aware gates to enhance the performance of the recommendation network by learning information from historical user-item interactions. Moreover, DNS-Rec employs a dynamic resource constraint strategy, stabilizing the search process and yielding more suitable architectural solutions. We demonstrate the effectiveness of our approach through rigorous experiments conducted on three benchmark datasets, which highlight the superiority of DNS-Rec in SRSs. Our findings set a new standard for future research in efficient and accurate recommendation systems, marking a significant step forward in this rapidly evolving field.</p>
    <p><strong>Categories:</strong> Neural Architecture Search, Recommender Systems, Sequential Recommender Systems (SRSs), Computational Efficiency, Resource Optimization, Attention-Based Models, Data-Aware Methods, Pruning Techniques, Scalability, Energy Efficiency, Dynamic Resource Allocation, Model Design (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1027/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Self-Auxiliary Distillation for Sample Efficient Learning in Google-Scale Recommenders (2024)</h3>
    <p><strong>Authors:</strong> Ruoxi Wang, Tiansheng Yao, Ed H. Chi, Andrew Evdokimov, Yuan Gao, Jerry Zhang, Evan Ettinger, Derek Zhiyuan Cheng, Yin Zhang, Jonathan Valverde, Xiang Li</p>
    <p>Industrial recommendation systems process billions of daily user feedback which are complex and noisy. Efficiently uncovering user preference from these signals becomes crucial for high-quality recommendation. We argue that those signals are not inherently equal in terms of their informative value and training ability, which is particularly salient in industrial applications with multi-stage processes (e.g., augmentation, retrieval, ranking). Considering that, in this work, we propose a novel self-auxiliary distillation framework that prioritizes training on high-quality labels, and improves the resolution of low-quality labels through distillation by adding a bilateral branch-based auxiliary task. This approach enables flexible learning from diverse labels without additional computational costs, making it highly scalable and effective for Google-scale recommenders. Our framework consistently improved both offline and online key business metrics across three Google major products. Notably, self-auxiliary distillation proves to be highly effective in addressing the severe signal loss challenge posed by changes such as Apple iOS policy. It further delivered significant improvements in both offline (+17\% AUC) and online metrics for a Google Apps recommendation system. This highlights the opportunities of addressing real-world signal loss problems through self-auxiliary distillation techniques.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Self-Auxiliary Distillation, Large Scale Recommenders, Sample Efficient Learning, Noise Handling, Signal Loss Problems, Offline Evaluation, Online Evaluation, A/B Test, Scalability, User Feedback (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1179/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>