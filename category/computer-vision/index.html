<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui primary button" style="margin: 5px;"
             href="/recsys-recommender/">Computer Vision</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/offline-evaluation/">Offline Evaluation</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reproducibility/">Reproducibility</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/cold-start/">Cold Start</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Using Learnable Physics for Real-Time Exercise Form Recommendations (2023)</h3>
    <p><strong>Authors:</strong> Gautam Chauhan, Abhishek Jaiswal, Nisheeth Srivastava</p>
    <p>Good posture and form are essential for safe and productive exercising. Even in gym settings, trainers may not be readily available for feedback. Rehabilitation therapies and fitness workouts can thus benefit from recommender systems that provide real-time evaluation. In this paper, we present an algorithmic pipeline that can diagnose problems in exercises technique and offer corrective recommendations, with high sensitivity and specificity, in real-time. We use MediaPipe for pose recognition, count repetitions using peak-prominence detection, and use a learnable physics simulator to track motion evolution for each exercise. A test video is diagnosed based on deviations from the prototypical learned motion using statistical learning. The system is evaluated on six full and upper body exercises. These real-time interactive suggestions counseled via low-cost equipment like smartphones will allow exercisers to rectify potential mistakes making self-practice feasible while reducing the risk of workout injuries.</p>
    <p><strong>Categories:</strong> Machine Learning, Computer Vision, Exercise, Fitness, Real-Time Processing, Statistical Learning, Signal Processing, Physics, Simulation, Wearable Technology, Rehabilitation, Health and Wellness (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/895/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Learning Users’ Preferred Visual Styles in an Image Marketplace (2022)</h3>
    <p><strong>Authors:</strong> Alessandra Sala, Raul Gomez Bruballa, Lauren Burnham-King</p>
    <p>Providing meaningful recommendations in a content marketplace is challenging due to the fact that users are not the final content consumers. Instead, most users are creatives whose interests, linked to the projects they work on, change rapidly and abruptly. To address the challenging task of recommending images to content creators, we design a RecSys that learns visual styles preferences transversal to the semantics of the projects users work on. We analyze the challenges of the task compared to content-based recommendations driven by semantics, propose an evaluation setup, and explain its applications in a global image marketplace.</p>
    <p><strong>Categories:</strong> Computer Vision, Image Processing, Recommendation Systems, Content-Based Recommendations, Context-Aware Recommendations, Cold Start Problems, Creativity, Image Marketplace, User Preferences, Dynamic Preferences, Evaluation Setup, Beyond Accuracy, A/B Test, User Survey (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/824/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>EntityBot: Supporting Everyday Digital Tasks with Entity Recommendations (2021)</h3>
    <p><strong>Authors:</strong> Salvatore Andolina, Tung Vuong, Samuel Kaski, Tuukka Ruotsalo, Mats Sjöberg, Giulio Jacucci, Khalil Klouche, Pedram Daee</p>
    <p>Everyday digital tasks can highly benefit from systems that recommend the right information to use at the right time. However, existing solutions typically support only specific applications and tasks. In this demo, we showcase EntityBot, a system that captures context across application boundaries and recommends information entities related to the current task. The user’s digital activity is continuously monitored by capturing all content on the computer screen using optical character recognition. This includes all applications and services being used and specific to individuals’ computer usages such as instant messaging, emailing, web browsing, and word processing. A linear model is then applied to detect the user’s task context to retrieve entities such as applications, documents, contact information, and several keywords determining the task. The system has been evaluated with real-world tasks, demonstrating that the recommendation had an impact on the tasks and led to high user satisfaction.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Productivity Tools, Instant Messaging, Email, Computer Vision, User Interaction, Context-Aware Systems, Cross-Application, Task Detection Models, Real-World Applications, User Satisfaction, Evaluation Methods (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/697/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Tops, Bottoms, and Shoes: Building Capsule Wardrobes via Cross-Attention Tensor Network (2021)</h3>
    <p><strong>Authors:</strong> Hao Yang, Fei Wang, Yusan Lin, Huiyuan Chen</p>
    <p>Fashion is more than Paris runways. Fashion is about how people express their interests, identity, mood, and cultural influences. Given an inventory of candidate garments from different categories, how to assemble them together would most improve their fashionability? This question presents an intriguing visual recommendation challenge to automatically create capsule wardrobes. Capsule wardrobe generation is a complex combinatorial problem that requires the understanding of how multiple visual items interact. The generative process often needs fashion experts to manually tease the combinations out, making it hard to scale.<br>We introduce TensorNet, an approach that captures the key ingredients of visual compatibility among tops, bottoms, and shoes. TensorNet aims to provide actionable advice for full-body clothing outfits that mix and match well. Our TensorNet consists of two core modules: a Cross-Attention Message Passing module and a Wide&Deep Tensor Interaction module. As such, TensorNet is able to characterize the local region-based patterns as well as the global compatibility of the entire outfits. Our experimental results on the real-word datasets indicate that the proposed method is capable of learning visual compatibility and outperforms all the baselines. TensorNet opens up opportunities for fashion designers to narrow down the search space for multi-clothes combinations.</p>
    <p><strong>Categories:</strong> Neural Networks, Attention Mechanisms, Multi-Item Recommendation, Fashion, Cross-Attention, Retail, Computer Vision, Capsule Wardrobes, Visual Compatibility, Empirical Validation, Wide&amp;Deep Models, Personal Style Assistant (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/671/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Audio-Visual Encoding of Multimedia Content to Enhance Movie Recommendations (2018)</h3>
    <p><strong>Authors:</strong> Markus Schedl, Bogdan Ionescu, Paolo Cremonesi, Yashar Deldjoo, Mihai Gabriel Constantin, Hamid Eghbal-zadeh</p>
    <p>We propose a multi-modal content-based movie recommender system that replaces human-generated metadata by content descriptions automatically extracted from the visual and audio channels of a video. Content descriptors improve over traditional metadata in terms of both richness (it is possible to extract hundreds of meaningful features covering various modalities) and quality (content features are consistent across different systems and immune to human errors). Our recommender system integrates state-of-the-art aesthetic and deep visual features as well as block-level and i-vector audio features. For fusing the different modalities, we propose a rank aggregation strategy extending the Borda count approach. We evaluate the proposed multi-modal recommender system comprehensively against metadata-based baselines. To this end, we conduct two empirical studies: (i) a system-centric study to measure the offline quality of recommendations in terms of accuracy-related and beyond-accuracy performance measures (novelty, diversity, and coverage), and (ii) a user-centric online experiment, measuring different subjective metrics, including relevance, satisfaction, and diversity. In both studies, we use a dataset of more than 4,000 movie trailers, which makes our approach versatile. Our results shed light on the accuracy and beyond-accuracy performance of audio, visual, and textual features in content-based movie recommender systems.</p>
    <p><strong>Categories:</strong> Audio Features, Visual Features, Computer Vision, Speech Processing, Content-Based Recommendations, Multi-Modal Data, Movie Recommendations, Multi-Modal Recommender Systems, Rank Aggregation, Accuracy Metrics, Beyond Accuracy, User Survey (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/367/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Aesthetic Features for Personalized Photo Recommendation (2018)</h3>
    <p><strong>Authors:</strong> Putra Manggala, Ga Wu, Yu Qing Zhou, Scott Sanner</p>
    <p>Many photography websites such as Flickr, 500px, Unsplash, and Adobe Behance are used by amateur and professional photography enthusiasts. Unlike content-based image search, such users of photography websites are not just looking for photos with certain content, but more generally for photos with a certain photographic “aesthetic”. In this context, we explore personalized photo recommendation and propose two aesthetic feature extraction methods based on (i) color space and (ii) deep style transfer embeddings. Using a dataset from 500px, we evaluate how these features can be best leveraged by collaborative filtering methods and show that (ii) provides a significant boost in photo recommendation performance.</p>
    <p><strong>Categories:</strong> Personalized Recommendation, Photography, Computer Vision, Collaborative Filtering, Aesthetic Features, Deep Learning, Feature Extraction, Recommender Systems, User Preferences, Image Processing (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/410/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Surveying User Reactions to Recommendations Based on Inferences Made by Face Detection Technology (2017)</h3>
    <p><strong>Authors:</strong> Jason Wiese, Jennifer Marlow</p>
    <p>It is increasingly possible to use cameras and sensors to detect and analyze human appearance for the purposes of personalizing user experiences. Such systems are already deployed in some public places to personalize advertisements and recommend items. However, since these technologies are not yet widespread, we do not have a good sense of the perceived benefits and drawbacks of public display systems that use face detection as an input for personalized recommendations. We conducted a user study with a system that inferred a user’s gender and age from a facial detection and analysis algorithm and used this to present recommendations in two scenarios (finding stores to visit in a mall and finding a pair of sunglasses to buy).  This work provides an initial step towards understanding user reactions to a new and emerging form of implicit recommendation based on physical appearance.</p>
    <p><strong>Categories:</strong> Face Detection, Personalized Recommendations, Retail, User Perception, Privacy Concerns, Beyond Accuracy, User Study, Computer Vision, Implicit Feedback (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/297/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Do you have a Pop face? Here is a Pop song. Using profile pictures to mitigate the cold-start problem in Music Recommender Systems. (2015)</h3>
    <p><strong>Authors:</strong> Eugenio Tacchini, Ramon Morros, Enrique Sañoso, Veronica Vilaplana</p>
    <p>When a new user registers to a recommender system service, the system does not know her taste and cannot propose meaningful suggestions (cold-start problem). This preliminary work attempts to mitigate the cold-start problem using the profile picture of the user as a sole information, following the intuition that a correspondence may exist between the pictures that people use to represent themselves and their taste. We proved that, at least in the small music community we used for our experiments, our method can improve the precision of both a classifier and a Top-N music recommender system in a cold-start condition.</p>
    <p><strong>Categories:</strong> Cold Start Problem, Music, Recommendation Systems, User Profiling, Computer Vision, Top-N Recommendations, Image Processing, Applied Research, Experimental Methods, Real-World Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/146/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>