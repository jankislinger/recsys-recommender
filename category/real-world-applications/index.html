<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui primary button" style="margin: 5px;"
             href="/recsys-recommender/">Real-World Applications</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/cold-start/">Cold Start</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/beyond-accuracy/">Beyond Accuracy</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/evaluation-metrics/">Evaluation Metrics</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reinforcement-learning/">Reinforcement Learning</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Analyzing User Preferences and Quality Improvement on Bing’s WebPage Recommendation Experience with Large Language Models (2024)</h3>
    <p><strong>Authors:</strong> Jialin Liu, Gang Luo, Hongzhi Li, Chuck Wang, Fan Wu, Amey Barapatre, Jaidev Shah</p>
    <p>Explore Further @ Bing (Web Recommendations) is a web-scale query independent webpage-to-webpage recommendation system with an index size of over 200 billion webpages. Due to the significant variability in webpage quality across the web and the reliance of our system on learning soleley user behavior (clicks), our production system was susceptible to serving clickbait and low-quality recommendations. Our team invested several months in developing and shipping several improvements that utilize LLM-generated recommendation quality labels to enhance our ranking stack to improve the nature of the recommendations we show to our users. Another key motivation behind our efforts was to go beyond merely surfacing relevant webpages, focusing instead on prioritizing more useful and authoritative content that delivers value to users based on their implied intent. We demonstrate how large language models (LLMs) offer a powerful tool for product teams to gain deeper insights into shifts in product experience and user behavior following significant improvements or changes to a production system. In this work, to enable our analysis, we also showcase the use of a small language model (SLM) to generate better-quality webpage text features and summaries at scale and describe our approach to mitigating position bias in user interaction logs.</p>
    <p><strong>Categories:</strong> Web Recommendations, Large Language Models, Quality Improvement, Clickbait Detection, Ranking Algorithms, User Behavior Analysis, Position Bias Mitigation, Content Quality, Webpage Summarization, Authoritative Content, Real-world Applications, Beyond Accuracy (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1152/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Optimizing for Participation in Recommender System (2024)</h3>
    <p><strong>Authors:</strong> Sourabh Bansod, Yaping Zhang, Bibang Liu, Mingyan Gao, Yuan Shao, Arnab Bhadury</p>
    <p>The traditional recommender system has been designed to mostly optimize for viewer consumption, and with the rise of short form videos, the boundaries between consumption and participation have blurred. This shift presents an opportunity to optimize recommender systems not only for passive consumption, but also for active participation in content creation. In this paper, we document the development of a recommender system that provides inspiration to existing content uploaders and new future content uploaders to encourage participation. Our contributions are two-fold: 1) Inspiration Framework: We present a novel framework for building a recommender system that goes beyond traditional consumption-focused metrics, specifically addressing the need for creative inspiration to lower barriers for participation. This framework is adaptable in the design of large-scale recommender systems in other domains. 2) Empirical Evaluation: We conduct systematic evaluation via live experiments to prove the values of the proposed system in increasing daily participation and participants.</p>
    <p><strong>Categories:</strong> Recommender Systems, Content Creation, Video Recommendation, Beyond Accuracy, User Engagement, Real-World Applications, Cold Start, Framework Design (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1167/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>ConFit: Improving Resume-Job Matching using Data Augmentation and Contrastive Learning (2024)</h3>
    <p><strong>Authors:</strong> Zhou Yu, Jinzhong Zhang, Xiao Yu</p>
    <p>A reliable resume-job matching system helps a company find suitable candidates from a pool of resumes, and helps a job seeker find relevant jobs from a list of job posts. However, since job seekers apply only to a few jobs, interaction records in resume-job datasets are sparse. Different from many prior work that use complex modeling techniques, we tackle this sparsity problem using data augmentations and a simple contrastive learning approach. ConFit first formulates resume-job datasets as a sparse bipartite graph, and creates an augmented dataset by paraphrasing specific sections in a resume or a job post. Then, ConFit finetunes pre-trained encoders with contrastive learning to further increase training samples from B pairs per batch to O(B^2) per batch. We evaluate ConFit on two real-world datasets and find it outperforms prior methods (including BM25 and OpenAI text-ada-002) by up to 19% and 31% absolute in nDCG@10 for ranking jobs and ranking resumes, respectively. We believe ConFit’s simple yet highly performant approach lays a strong foundation for future research in modeling person-job fit.</p>
    <p><strong>Categories:</strong> Job Matching, Recruitment Systems, Data Augmentation, Contrastive Learning, Bipartite Graphs, Recommendation Systems, Sparse Interaction Records, Transfer Learning, Ranking Performance, Real-World Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1032/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Pareto Front Approximation for Multi-Objective Session-Based Recommender Systems (2024)</h3>
    <p><strong>Authors:</strong> Timo Wilm, Philipp Normann, Felix Stepprath</p>
    <p>This work introduces MultiTRON, an approach that adapts Pareto front approximation techniques to multi-objective session-based recommender systems using a transformer neural network. Our approach optimizes trade-offs between key metrics such as click-through and conversion rates by training on sampled preference vectors. A significant advantage is that after training, a single model can access the entire Pareto front, allowing it to be tailored to meet the specific requirements of different stakeholders by adjusting an additional input vector that weights the objectives. We validate the model’s performance through extensive offline and online evaluation. For broader application and research, the source code is made available. The results confirm the model’s ability to manage multiple recommendation objectives effectively, offering a flexible tool for diverse business needs.</p>
    <p><strong>Categories:</strong> Multi-objective optimization, Session-based recommendations, Pareto front approximation, Transformer neural networks, Offline evaluation, Online evaluation, Recommendation systems, Real-world applications, Evaluation techniques, Deep learning approaches (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1166/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Fair Augmentation for Graph Collaborative Filtering (2024)</h3>
    <p><strong>Authors:</strong> Gianni Fenu, Ludovico Boratto, Giacomo Medda, Mirko Marras, Francesco Fabbri</p>
    <p>Recent developments in recommendation have harnessed the collaborative power of graph neural networks (GNNs) in learning users’ preferences from user-item networks. Despite emerging regulations addressing fairness of automated systems, unfairness issues in graph collaborative filtering remain underexplored, especially from the consumer’s perspective. While the recommendation literature has seen numerous contributions in the form of mitigation algorithms and comprehensive evaluation studies on consumer unfairness, only a few of these works have delved into GNNs. A notable gap exists in the formalization of the latest mitigation algorithms, as well as in their effectiveness and reliability on cutting-edge models. In this paper, we conduct an extensive analysis of one of the latest mitigation methods tailored for consumer fairness in GNN-based recommendation. The reproduced technique adjusts the system fairness level by learning a fair graph augmentation. Our study serves as a solid response to recent research highlighting unfairness issues in graph collaborative filtering. Under an experimental setup based on 11 GNNs, 5 non-GNN models, and 5 real-world networks across diverse domains, our investigation reveals that fair graph augmentation is consistently effective on high-utility models and large datasets. Experiments on the transferability of the fair augmented graph open new issues for future recommendation~studies.</p>
    <p><strong>Categories:</strong> Fairness, Graph Collaborative Filtering, Algorithm Family - GNNs, Mitigation Algorithms, Evaluation Studies, Consumer Unfairness, Recommendation Systems, Real-World Applications, Model Transferability (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1122/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>From Clicks to Carbon: The Environmental Toll of Recommender Systems (2024)</h3>
    <p><strong>Authors:</strong> Alan Said, Tobias Vente, Lukas Wegmeth, Joeran Beel</p>
    <p>As global warming soars, evaluating the environmental impact of research is more critical now than ever before. However, we find that few to no recommender systems research papers document their impact on the environment. Consequently, in this paper, we conduct a comprehensive analysis of the environmental impact of recommender system research papers by reproducing a characteristic recommender systems experimental pipeline. We focus on estimating the carbon footprint of recommender systems research papers, highlighting the evolution of the environmental impact of recommender systems research experiments over time. We evaluated all 79 full papers from the ACM RecSys 2013 and 2023 conferences to analyze representative experimental pipelines for papers utilizing traditional, so-called good old-fashioned AI algorithms and deep learning algorithms, respectively. We reproduced these representative experimental pipelines, measured electricity consumption using a hardware energy meter, and converted the measured energy consumption into CO2 equivalents to estimate the environmental impact. Our results show that a recommender systems research paper utilizing deep learning algorithms emits approximately 42 times more CO2 equivalents than a paper utilizing traditional algorithms. Furthermore, such a paper produces, on average, 3,297 kilograms of CO2 equivalents, which is more than one person produces by flying from New York City to Melbourne or the amount one tree sequesters in 300 years.</p>
    <p><strong>Categories:</strong> Deep Learning, Recommender Systems, Environmental Impact, Carbon Footprint, Energy Consumption, CO2 Emissions, Traditional Algorithms, Real-World Applications, Sustainability (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1123/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Promoting Two-sided Fairness with Adaptive Weights for Providers and Customers in Recommendation (2024)</h3>
    <p><strong>Authors:</strong> Wayne Xin Zhao, Ji-Rong Wen, Lanling Xu, Sheng Chen, Zihan Lin, Jinpeng Wang</p>
    <p>At present, most recommender systems involve two stakeholders, providers and customers. Apart from maximizing the recommendation accuracy, the fairness issue for both sides should also be considered. However, there is a trade-off for multi-objective optimization problems, where optimizing one objective (e.g. provider-side fairness) may degrade the performance of others (e.g. accuracy). Most of previous studies try to improve two-sided fairness with post-processing algorithms or fairness-aware loss constraints, which are highly dependent on the heuristic adjustments without respect to the optimization goal of accuracy. In contrast, we propose a novel training framework, adaptive weighting  towards two-sided fairness-aware recommendation (named Ada2Fair), which lies in the extension of the accuracy-focused objective to a controllable preference learning loss over the interaction data. Specifically, we adjust the optimization scale of an interaction sample with an adaptive weight generator, and estimate the two-sided fairness-aware weights within model training. During the training process, the recommender is trained with two-sided fairness-aware weights to boost the utility of niche providers and inactive customers in a unified way. Extensive experiments on three public datasets verify the effectiveness of Ada2Fair, which can achieve Pareto improvements in two-sided fairness-aware recommendation. Our code implementation is available at https://anonymous.4open.science/r/Ada2Fair.</p>
    <p><strong>Categories:</strong> Adaptive Weights, Recommender Systems, Fairness, Two-sided Fairness, Multi-objective Optimization, Recommendation Frameworks, Provider-Customer Dynamics, User-Centric Design, Real-world Applications, Adaptive Learning, Evaluation Metrics (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1112/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Sliding Window Training – Utilizing Historical Recommender Systems Data for Foundation Models (2024)</h3>
    <p><strong>Authors:</strong> Ko-Jen Hsiao, Yesu Feng, Sudarshan Lamkhede, Swanand Joshi, Zhe Zhang</p>
    <p>Long-lived recommender systems (RecSys) often encounter lengthy user-item interaction histories that span many years. To effectively learn long term user preferences, Large RecSys foundation models (FM) need to encode this information in pretraining. Usually, this is done by either generating a long enough sequence length to take all history sequences as input at the cost of large model input dimension or by dropping some parts of the user history to accommodate model size and latency requirements on the production serving side. In this paper, we introduce a sliding window training technique to incorporate long user history sequences during training time without increasing the model input dimension. We show the quantitative \& qualitative improvements this technique brings to the RecSys FM in learning user long term preferences. We additionally show that the average quality of items in the catalog learnt in pretraining also improves.</p>
    <p><strong>Categories:</strong> Recommender Systems (RecSys), Foundation Models, Training Techniques, Sliding Window, Historical Data Utilization, Model Optimization, User Preferences Learning, Catalog Quality, Pretraining Methods, Scalability, Time Series Analysis, Model Efficiency, Evaluation Metrics, Real-World Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1176/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Discerning Canonical User Representation for Cross-Domain Recommendation (2024)</h3>
    <p><strong>Authors:</strong> Sherry Sahebi, Siqian Zhao</p>
    <p>Cross-domain recommender systems have emerged, to address the cold-start problem and enhance recommendation outcomes by leveraging information transfer across different domains. Existing cross-domain recommender systems have investigated the learning of both domain-specific and domain-shared user preferences to enhance recommendation performance. However, these models typically allow the disparities between shared and distinct user preferences to emerge freely in any space, lacking sufficient constraints to identify differences between two domains and ensure that both domains are considered simultaneously. Canonical Correlation Analysis (CCA) has shown promise for transferring information between domains, by mapping their user representations into the same space. But, CCA only models domain similarities, and fails to capture the potential differences between user preferences in different domains. In this paper, we propose Discerning Canonical User Representation Learning for Cross-Domain Recommendation (DICUCDR), a generative adversarial networks (GAN) based method that learns both domain-shared and domain-specific user representations. DICUCDR introduces Discerning Canonical Correlation User Representation Learning (DCCRL), a novel design of non-linear Canonical Correlation mappings that creates a shared transformation for simultaneously mapping similarities between different domains and separating domain differences from domains. We compare DICUCDR against several state-of-the-art approaches using two real-world datasets. Our extensive experiments demonstrate the superiority of separately learning shared and specific user representations via DCCRL.</p>
    <p><strong>Categories:</strong> Cross-Domain Recommendation, Cold Start Problem, Transfer Learning, Multi-Domain, Canonical Correlation Analysis (CCA), Generative Adversarial Networks (GANs), Deep Learning, Representation Learning, Domain Adaptation, Real-World Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1033/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>End-to-End Cost-Effective Incentive Recommendation under Budget Constraint with Uplift Modeling (2024)</h3>
    <p><strong>Authors:</strong> Yunpeng Weng, Xiuqiang He, Hao Yang, Dugang Liu, Xing Tang, Zexu Sun</p>
    <p>In modern online platforms, incentive (<i>e.g</i>., discounts, bonus) are essential factors that enhance user engagement and increase platform revenue. Over recent years, uplift modeling has been introduced as a strategic approach to assign incentive to individual customers. Especially, in many real-world applications, online platforms can only incentivize customers with specific budget constraints. This problem can be reformulated as the multi-choice knapsack problem (MCKP). The objective of this optimization is to select the optimal incentive for each customer in order to maximize the return-on-investment (ROI). Recent works in this field frequently tackle the problem of budget allocation using a two-stage approach. %: the first stage utilizes causal inference algorithms to estimate the individual treatment effect or uplift, while the second stage employs integer programming techniques to determine the optimal solution for budget allocation. However, this solution is confronted with the following challenges: (1) The commonly used causal inference methods often ignore the domain knowledge in online marketing, where the expected response curve of a customer should be monotonic and smooth as the incentive increases. (2) There is an optimality gap between the two stages, resulting in inferior sub-optimal allocation performance, which is due to the loss of the incentive recommendation information for the uplift prediction under the limited budget constraint. To address these challenges, we propose a novel <u>E</u>nd-to-<u>E</u>nd Cost-<u>E</u>ffective <u>I</u>ncentive <u>R</u>ecommendation (E$^3$IR) model under the budget constraint. Specifically, our methods consist of two modules: the uplift prediction module and the differentiable allocation module. In the uplift prediction module, we construct prediction heads to capture the incremental improvement between adjacent treatments with the marketing domain constraints (<i>i.e.</i>, monotonic and smooth). %To obtain a monotonic user response curve, we constrain the output of each prediction head to be non-negative. In the differentiable allocation module, we incorporate integer linear programming (ILP) as a differentiable layer input. Furthermore, we conduct extensive experiments on both public and real product datasets, which demonstrate that our E$^3$IR improves allocation performance compared to existing two-stage approaches.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Marketing Strategies, E-commerce, Uplift Modeling, Resource Management, Optimization, Causal Inference, Integer Linear Programming, Real-World Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1038/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Enhancing Cross-Domain Recommender Systems with LLMs: Evaluating Bias and Beyond-Accuracy Measures (2024)</h3>
    <p><strong>Authors:</strong> Thomas Elmar Kolb</p>
    <p>The research domain of recommender systems is rapidly evolving. Initially, optimization efforts focused primarily on accuracy. However, recent research has highlighted the importance of addressing bias and beyond-accuracy measures such as novelty, diversity, and serendipity. With the rise of multi-domain recommender systems, the need to re-examine bias and beyond-accuracy measures in cross-domain settings has become crucial. Traditional methods face challenges such as cold-start problems, which can potentially be mitigated by leveraging LLMs. This proposed work investigates how LLM-based recommendation methods can enhance cross-domain recommender systems, focusing on identifying, measuring, and mitigating bias while evaluating the impact of beyond-accuracy measures. We aim to provide new insights by comparing traditional and LLM-based systems within a real-world environment encompassing the domains of news, books, and various lifestyle areas. Our research seeks to address the outlined gaps and develop effective evaluation strategies for the unique challenges posed by LLMs in cross-domain recommender systems.</p>
    <p><strong>Categories:</strong> Cross-Domain Recommender Systems, Large Language Models (LLMs), Bias, Novelty, Diversity, Serendipity, Beyond Accuracy, Cold Start Problem, News Domain, Books Domain, Lifestyle Domain, Real-World Applications, Traditional Recommenders, Neural Networks, Multi-Domain Evaluation, Enhancing Recommender Systems (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1137/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>AIE: Auction Information Enhanced Framework for CTR Prediction in Online Advertising (2024)</h3>
    <p><strong>Authors:</strong> Chenxu Zhu, Muyu Zhang, Yang Yang, Huifeng Guo, Menghui Zhu, Bo Chen, Ruiming Tang, Zhenhua Dong, Xinyi Dai</p>
    <p>Click-Through Rate (CTR) prediction is a fundamental technique for online advertising recommendation and the complex online competitive auction process also brings many difficulties to CTR optimization. Recent studies have shown that introducing posterior auction information contributes to the performance of CTR prediction. However, existing work doesn’t fully capitalize on the benefits of auction information and overlooks the data bias brought by the auction, leading to biased and suboptimal results. To address these limitations, we propose Auction Information Enhanced Framework (AIE) for CTR prediction in online advertising, which delves into the problem of insufficient utilization of auction signals and first reveals the auction bias. Specifically, AIE introduces two pluggable modules, namely Adaptive Market-price AuxiliaryModule (AM2) and Bid Calibration Module (BCM), which work collaboratively to excavate the posterior auction signals better and enhance the performance of CTR prediction. Furthermore, the two proposed modules are lightweight, model-agnostic and friendly to inference latency. Extensive experiments are conducted on a public dataset and an industrial dataset to demonstrate the effectiveness and compatibility of AIE. Besides, a one-month online A/B test in a large-scale advertising platform shows that AIE improves the base model by 5.76% and 2.44% in terms of eCPM and CTR, respectively.</p>
    <p><strong>Categories:</strong> Algorithm Design, Online Advertising, Recommendation Systems, Auction Mechanisms, CTR Prediction, Model Performance, Bias Mitigation, A/B Test, Evaluation Metrics, Scalability, Real-World Applications, Beyond Accuracy (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1021/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>One-class recommendation systems  with  the hinge pairwise distance loss and orthogonal representations (2024)</h3>
    <p><strong>Authors:</strong> Ramin Raziperchikolaei, Young-joo Chung</p>
    <p>In one-class recommendation systems, the goal is to learn a model from a small set of interacted users and items and then identify the positively-related (i.e., similar) user-item pairs among a large number of pairs with unknown interactions. Most loss functions in the literature rely on dissimilar pairs of users and items, which are selected from the ones with unknown interactions, to obtain better prediction performance. The main issue of this strategy is that it needs a large number of dissimilar pairs, which increases the training time significantly. In this paper, the goal is to only use the similar set to train the models and discard the dissimilar set.  We highlight three trivial solutions that the models converge to when they are trained only on similar pairs: collapsed, dimensional collapsed, and shrinking solutions. We propose a hinge pairwise loss and an orthogonality term that can be added to the objective functions in the literature to avoid these trivial solutions. We conduct experiments on various tasks on public and real-world datasets, which show that our approach using only similar pairs can be trained several times faster than the state-of-the-art methods while achieving competitive results.</p>
    <p><strong>Categories:</strong> Recommendation Systems, One-class Learning, Algorithm Design, Loss Function Design, Optimization Techniques, User-Item Interaction, Similarity-based Recommendations, Cold Start Problem, Efficiency, Real-world Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1102/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Revisiting BPR: A Replicability Study of a Common Recommender System Baseline (2024)</h3>
    <p><strong>Authors:</strong> Aleksandr Milogradskii, Oleg Lashinin, Sergey Kolesnikov, Alexander P, Marina Ananyeva</p>
    <p>Bayesian Personalized Rank (BPR), a collaborative filtering approach based on matrix factorization, frequently serves as a benchmark for recommender systems research. However, numerous studies often overlook the nuances of BPR implementation, claiming that it performs worse than newly proposed methods across various tasks. In this paper, we thoroughly examine the features of the BPR model, indicating their impact on its performance, and investigate open-source BPR implementations. Our analysis reveals inconsistencies between these implementations and the original BPR paper, leading to a significant decrease in performance of up to 50% for specific implementations. Furthermore, through extensive experiments on real-world datasets under modern evaluation settings, we demonstrate that with proper tuning of its hyperparameters, the BPR model can achieve performance levels close to state-of-the-art methods on the top-n recommendation tasks and even outperform them on specific datasets. Specifically, on the Million Song Dataset, the BPR model with hyperparameters tuning statistically significantly outperforms Mult-VAE by 10% in NDCG@100 with binary relevance function.</p>
    <p><strong>Categories:</strong> Matrix Factorization, Bayesian Personalized Ranking (BPR), Recommender Systems, Replicability Study, Performance Evaluation, Real-World Applications, Evaluation Metrics, Benchmarking, Hyperparameter Tuning, State-of-the-Art Methods, Methodology Improvement, Top-N Recommendations (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1131/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Scale-Invariant Learning-to-Rank (2024)</h3>
    <p><strong>Authors:</strong> Ye-Sheen Lim, Alessio Petrozziello, Xiaoke Liu, Christian Sommeregger</p>
    <p>At Expedia, learning-to-rank (LTR) models plays a key role on our website in sorting and presenting information more relevant to users, such as search filters, property rooms, amenities, and images. A major challenge in deploying these models is ensuring consistent feature scaling between training and production data, as discrepancies can lead to unreliable rankings when deployed. Normalization techniques like feature standardization and batch normalization could address these issues but are impractical in production due to latency impacts and the difficulty of distributed real-time inference. To address consistent feature scaling issue, we introduce a scale-invariant LTR framework which combines a deep and a wide neural network to mathematically guarantee scale-invariance in the model at both training and prediction time.</p>
    <p><strong>Categories:</strong> Learning-to-Rank, E-commerce, Travel, Model Scaling, Feature Engineering, Production Systems, Scale-Invariant Methods, Ranking Algorithms, Web Systems, Real-World Applications, Model Robustness, Algorithm Design (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1174/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Scene-wise Adaptive Network for Dynamic Cold-start Scenes Optimization in CTR Prediction (2024)</h3>
    <p><strong>Authors:</strong> Chao Tang, Wenhao Li, Jie Zhou, Shixiong Zhao, Chuan Luo, Kun Zhang</p>
    <p>In the realm of modern mobile E-commerce, providing users with nearby commercial service recommendations through location-based online services has become increasingly vital. While machine learning approaches have shown promise in multi-scene recommendation, existing methodologies often struggle to address cold-start problems in unprecedented scenes: the increasing diversity of commercial choices, along with the short online lifespan of scenes, give rise to the complexity of effective recommendations in online and dynamic scenes. In this work, we propose Scene-wise Adaptive Network (SwAN), a novel approach that emphasizes high-performance cold-start online recommendations for new scenes. Our approach introduces several crucial capabilities, including scene similarity learning, user-specific scene transition cognition, scene-specific information construction for the new scene, and enhancing the diverged logical information between scenes. We demonstrate SwAN’s potential to optimize dynamic multi-scene recommendation problems by effectively online handling cold-start recommendations for any newly arrived scenes. More encouragingly, SwAN has been successfully deployed in Company M’s online catering recommendation service, which serves millions of customers per day, and SwAN has achieved a 5.64% CTR index improvement relative to the baselines and a 5.19% increase in daily order volume proportion.</p>
    <p><strong>Categories:</strong> Scene-wise Adaptive Network (SwAN), Neural Networks, Cold Start, Multi-scene Recommendations, Dynamic Scenarios, Recommendation Systems, Mobile E-commerce, Catering Services, Location-based Services, Evaluation Metrics, Beyond Accuracy, Real-world Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1063/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>