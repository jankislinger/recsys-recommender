<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/bias-mitigation/">Bias Mitigation</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/real-world-applications/">Real-world Applications</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/explainability/">Explainability</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reproducibility/">Reproducibility</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Stalactite: toolbox for fast prototyping of vertical federated learning systems (2024)</h3>
    <p><strong>Authors:</strong> Maria Khodorchenko, Anastasiia Zakharova, Dmitriy Alexandrov, Alexey Vasilev, Maxim Savchenko, Nikolay Butakov, Alexander Grigorievskiy</p>
    <p>Machine learning (ML) models trained on datasets owned by different organizations and physically located in remote databases offer benefits in many real-world use cases. State regulations or business requirements often prevent data transfer to a central location, making it difficult to utilize standard machine learning algorithms. Federated Learning (FL) is a technique that enables models to learn from distributed datasets without revealing the original data. Vertical Federated learning (VFL) is a type of FL where data samples are divided by features across several data owners. For instance, in a recommendation task, a user can interact with various sets of items, and the logs of these interactions are stored by different organizations. In this demo paper, we present Stalactite – an open-source framework for VFL that provides the necessary functionality for building prototypes of VFL systems. It has several advantages over the existing frameworks. In particular, it allows researchers to focus on the algorithmic side rather than engineering and to easily deploy learning in a distributed environment. It implements several VFL algorithms and has a built-in homomorphic encryption layer. We demonstrate its use on a real-world recommendation datasets.</p>
    <p><strong>Categories:</strong> Federated Learning, Vertical Federated Learning (VFL), Recommendation Systems, Machine Learning Frameworks, Algorithm Implementation, Homomorphic Encryption, Security and Privacy, Distributed Systems, Multi-Party Computation, Rapid Prototyping, Real-World Applications, Data Privacy, Open Source Tools (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1208/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Exploring Unlearning Methods to Ensure the Privacy, Security, and Usability of Recommender Systems (2023)</h3>
    <p><strong>Authors:</strong> Jens Leysen</p>
    <p>Machine learning algorithms have proven highly effective in analyzing large amounts of data and identifying complex patterns and relationships. One application of machine learning that has received significant attention in recent years is recommender systems, which are algorithms that analyze user behavior and other data to suggest items or content that a user may be interested in. However useful, these systems may unintentionally retain sensitive, outdated, or faulty information. Posing a risk to user privacy, system security, and limiting a system’s usability. In this research proposal, we aim to address these challenges by investigating methods for machine “unlearning”, which would allow information to be efficiently “forgotten” or “unlearned” from machine learning models. The main objective of this proposal is to develop the foundation for future machine unlearning methods. We first evaluate current unlearning methods and explore novel adversarial attacks on these methods’ verifiability, efficiency, and accuracy to gain new insights and further develop the theory of machine unlearning. Using our gathered insights, we seek to create novel unlearning methods that are verifiable, efficient, and limit unnecessary accuracy degradation. Through this research, we seek to make significant contributions to the theoretical foundations of machine unlearning while also developing unlearning methods that can be applied to real-world problems.</p>
    <p><strong>Categories:</strong> Unlearning Methods, Privacy, Security, Recommender Systems, Machine Learning, Data Privacy, User Behavior, Adversarial Attacks, Theoretical Foundations, Applications, Efficiency (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/981/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>FR-FMSS: Federated Recommendation via Fake Marks and Secret Sharing (2021)</h3>
    <p><strong>Authors:</strong> Zhaohao Lin, Weike Pan, Zhong Ming</p>
    <p>With the implementation of privacy protection laws such as GDPR, it is increasingly difficult for organizations to legally collect user data. However, a typical recommendation algorithm based on machine learning requires user data to learn user preferences. In order to protect user privacy, a lot of recent works turn to develop federated learning-based recommendation algorithms. However, some of these works can only protect the users’ rating values, some can only protect the users’ rating behavior (i.e., the engaged items), and only a few works can protect the both types of privacy at the same time. Moreover, most of them can only be applied to a specific algorithm or a class of similar algorithms. In this paper, we propose a generic cross-user federated recommendation framework called FR-FMSS. Our FR-FMSS can not only protect the two types of user privacy, but can also be applied to most recommendation algorithms for rating prediction, item ranking, and sequential recommendation. Specifically, we use fake marks and secret sharing to modify the data uploaded by the clients to the server, which protects user privacy without loss of model accuracy. We take three representative recommendation algorithms, i.e., MF-MPC, eALS, and Fossil, as examples to show how to apply our FR-FMSS to a specific algorithm.</p>
    <p><strong>Categories:</strong> Federated Learning, Matrix Factorization, Recommendation Systems, Privacy Preservation, Cross-User Federated Recommendations, Fake Marks, Secret Sharing, User Privacy Protection, Model Accuracy, A/B Testing, Data Privacy, Cold Start, User-Centric (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/688/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>A Method to Anonymize Business Metrics to Publishing Implicit Feedback Datasets (2020)</h3>
    <p><strong>Authors:</strong> Takanori Maehara, Yoshifumi Seki</p>
    <p>This paper shows a method for building and publishing datasets in commercial services. Datasets contribute to the development of research in machine learning and recommender systems. In particular, because recommender systems play a central role in many commercial services, publishing datasets from the services are in great demand from the recommender system community. However, the publication of datasets by commercial services may have some business risks to those companies. To publish a dataset, this must be approved by a business manager of the service. Because many business managers are not specialists in machine learning or recommender systems, the researchers are responsible for explaining to them the risks and benefits.<br>We first summarize three challenges in building datasets from commercial services: (1) anonymize the business metrics, (2) maintain fairness, and (3) reduce the popularity bias. Then, we formulate the problem of building and publishing datasets as an optimization problem that seeks the sampling weight of users, where the challenges are encoded as appropriate loss functions. We applied our method to build datasets from the raw data of our real-world mobile news delivery service. The raw data has more than 1,000,000 users with 100,000,000 interactions. Each dataset was built in less than 10 minutes. We discussed the properties of our method by checking the statistics of the datasets and the performances of typical recommender system algorithms.</p>
    <p><strong>Categories:</strong> Anonymization Techniques, Data Privacy, Recommender Systems, Real-World Applications, Fairness, Optimization Techniques, Loss Functions, Machine Learning Datasets, Scalability, Evaluation Metrics, Stakeholder Communication (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/521/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>PDMFRec: A Decentralised Matrix Factorisation with Tunable User-centric Privacy (2019)</h3>
    <p><strong>Authors:</strong> James Geraci, Aonghus Lawlor, Francisco J. Peña, Panagiotis Symeonidis, Barry Smyth, Elias Z. Tragos, Erika Duriakova, Neil Hurley</p>
    <p>Conventional approaches to matrix factorisation (MF) typically rely on a centralised collection of user data for building a MF model. This approach introduces an increased risk when it comes to user privacy. In this short paper we propose an alternative, user-centric, privacy enhanced, decentralised approach to MF. Our method pushes the computation of the recommendation model to the user’s device, and eliminates the need to exchange sensitive personal information; instead only the loss gradients of local device-based) MF models need to be shared. Moreover, users can select the amount and type of information to be shared, for enhanced privacy. We demonstrate the effectiveness of this approach by considering different levels of user privacy in comparison with state-of-the-art alternatives. i>Presentation: Tuesday Poster Lunch</i</p>
    <p><strong>Categories:</strong> Matrix Factorisation, Recommendation Systems, Decentralised Computing, Privacy Preservation, Data Privacy, Edge Computing, Secure Communication, User-Centric Design, Evaluation Methods, Benchmarking, Privacy-Preserving Machine Learning (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/489/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Exploring Recommendations Under User-Controlled Data Filtering (2018)</h3>
    <p><strong>Authors:</strong> Longqi Yang, Deborah Estrin, Michael Sobolev, Hongyi Wen</p>
    <p>Traditionally, recommendation systems are built on the assumption that each service provider has full access to all user data generated on its platform. However, with increasing data privacy concerns and personal data protection regulation, service providers, such as Google, Twitter, and Facebook, are enabling their users to revisit, erase, and rectify their historical profiles. Future recommendation systems need to be robust to such profile modifications and user-controlled data filtering. In this paper, we explore how recommendation performance may be affected by time-sensitive user data filtering, i.e., users choosing to share only recent “N days” of data. Using the MovieLens dataset as a testbed, we evaluate three state-of-the-art collaborative filtering algorithms. Our experiments demonstrate that filtering out historical user data does not significantly affect the overall recommendation performance, but its impact on individual users may vary. These findings challenge the common belief that more data produces better performance, and suggest a potential win-win solution for services and end users.</p>
    <p><strong>Categories:</strong> Data Privacy, Recommendation Systems, User Control, Collaborative Filtering, Matrix Factorization, Time-Sensitive Data, Movie Domain, Evaluation Metrics, Beyond Accuracy, Real-World Applications, Individual Impact (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/375/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>