<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui primary button" style="margin: 5px;"
             href="/recsys-recommender/">Online evaluation</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/offline-evaluation/">Offline Evaluation</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reproducibility/">Reproducibility</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/performance-evaluation/">Performance Evaluation</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Self-Auxiliary Distillation for Sample Efficient Learning in Google-Scale Recommenders (2024)</h3>
    <p><strong>Authors:</strong> Ruoxi Wang, Tiansheng Yao, Ed H. Chi, Andrew Evdokimov, Yuan Gao, Jerry Zhang, Evan Ettinger, Derek Zhiyuan Cheng, Yin Zhang, Jonathan Valverde, Xiang Li</p>
    <p>Industrial recommendation systems process billions of daily user feedback which are complex and noisy. Efficiently uncovering user preference from these signals becomes crucial for high-quality recommendation. We argue that those signals are not inherently equal in terms of their informative value and training ability, which is particularly salient in industrial applications with multi-stage processes (e.g., augmentation, retrieval, ranking). Considering that, in this work, we propose a novel self-auxiliary distillation framework that prioritizes training on high-quality labels, and improves the resolution of low-quality labels through distillation by adding a bilateral branch-based auxiliary task. This approach enables flexible learning from diverse labels without additional computational costs, making it highly scalable and effective for Google-scale recommenders. Our framework consistently improved both offline and online key business metrics across three Google major products. Notably, self-auxiliary distillation proves to be highly effective in addressing the severe signal loss challenge posed by changes such as Apple iOS policy. It further delivered significant improvements in both offline (+17\% AUC) and online metrics for a Google Apps recommendation system. This highlights the opportunities of addressing real-world signal loss problems through self-auxiliary distillation techniques.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Self-Auxiliary Distillation, Large Scale Recommenders, Sample Efficient Learning, Noise Handling, Signal Loss Problems, Offline Evaluation, Online Evaluation, A/B Test, Scalability, User Feedback (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1179/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Multi-Preview Recommendation via Reinforcement Learning (2024)</h3>
    <p><strong>Authors:</strong> Kuan-Ting Lai, Pengcheng Xiong, Zhong Wu, Yang Xu</p>
    <p>Preview recommendations serve as a crucial shortcut for attracting users’ attention on various systems, platforms, and webpages, significantly boosting user engagement. However, the variability of preview types and the flexibility of preview duration make it challenging to use an integrated framework for multi-preview recommendations under resource constraints. In this paper, we present an approach that incorporates constrained Q-learning into a notification recommendation system, effectively handling both multi-preview ranking and duration orchestration by targeting long-term user retention. Our method bridges the gap between combinatorial reinforcement learning, which often remains too theoretical for practical use, and segmented modules in production, where model performance is typically compromised due to over-simplification. We demonstrate the superiority of our approach through off-policy evaluation and online A/B testing using Microsoft data.</p>
    <p><strong>Categories:</strong> Reinforcement Learning, Recommendation Systems, Multi-Preview, Notifications, User Engagement, Resource Constraints, Q-Learning, Combinatorial Optimization, Online Evaluation, A/B Testing, Microsoft Data, Production Systems (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1207/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Pareto Front Approximation for Multi-Objective Session-Based Recommender Systems (2024)</h3>
    <p><strong>Authors:</strong> Timo Wilm, Philipp Normann, Felix Stepprath</p>
    <p>This work introduces MultiTRON, an approach that adapts Pareto front approximation techniques to multi-objective session-based recommender systems using a transformer neural network. Our approach optimizes trade-offs between key metrics such as click-through and conversion rates by training on sampled preference vectors. A significant advantage is that after training, a single model can access the entire Pareto front, allowing it to be tailored to meet the specific requirements of different stakeholders by adjusting an additional input vector that weights the objectives. We validate the model’s performance through extensive offline and online evaluation. For broader application and research, the source code is made available. The results confirm the model’s ability to manage multiple recommendation objectives effectively, offering a flexible tool for diverse business needs.</p>
    <p><strong>Categories:</strong> Multi-objective optimization, Session-based recommendations, Pareto front approximation, Transformer neural networks, Offline evaluation, Online evaluation, Recommendation systems, Real-world applications, Evaluation techniques, Deep learning approaches (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1166/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Do Not Wait: Learning Re-Ranking Model Without User Feedback At Serving Time in E-Commerce (2024)</h3>
    <p><strong>Authors:</strong> Sirui Chen, Changshuo Zhang, Zhiyu Li, Quan Lin, Xiao Zhang, Yuan Wang, Jun Xu</p>
    <p>Recommender systems have been widely used in e-commerce, and re-ranking models are playing an increasingly significant role in the domain, which leverages the inter-item influence and determines the final recommendation lists. Online learning methods keep updating a deployed model with the latest available samples to capture the shifting of the underlying data distribution in e-commerce. However, they depend on the availability of real user feedback, which may be delayed by hours or even days, such as item purchases, leading to a lag in model enhancement.  In this paper, we propose a novel extension of online learning methods for re-ranking modeling, which we term LAST, an acronym for Learning At Serving Time. It circumvents the requirement of user feedback by using a surrogate model to provide the instructional signal needed to steer model improvement. Upon receiving an online request, LAST finds and applies a model modification on the fly before generating a recommendation result for the request. The modification is request-specific and transient. It means the modification is tailored to and only to the current request to capture the specific context of the request. After a request, the modification is discarded, which helps to prevent error propagation and stabilizes the online learning procedure since the predictions of the surrogate model may be inaccurate. Most importantly, as a complement to feedback-based online learning methods, LAST can be seamlessly integrated into existing online learning systems to create a more adaptive and responsive recommendation experience. Comprehensive experiments, both offline and online, affirm that LAST outperforms state-of-the-art re-ranking models.</p>
    <p><strong>Categories:</strong> Recommender Systems, E-Commerce, Re-ranking Models, Online Learning, Without User Feedback at Serving Time, Surrogate Model, Comprehensive Experiments, Offline Evaluation, Online Evaluation, Novel Method (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1080/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>AI-assisted Coding with Cody: Lessons from Context Retrieval and Evaluation for Code Recommendations (2024)</h3>
    <p><strong>Authors:</strong> Quinn Slack, Jan Hartman, Dominic Cooney, Rishabh Mehrotra, Hitesh Sagtani, Olaf Geirsson, Beyang Liu, Rafal Gajdulewicz, Julie Tibshirani</p>
    <p>In this work, we discuss a recently popular type of recommender system: an LLM-based coding assistant. Connecting the task of providing code recommendations in multiple formats to traditional RecSys challenges, we outline several similarities and differences due to domain specifics. We emphasize the importance of providing relevant context to an LLM for this use case and discuss lessons learned from context enhancements & offline and online evaluation of such AI-assisted coding systems.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Code Recommendations, Machine Learning, AI-assisted Coding, Context Retrieval, Evaluation Methods, Offline Evaluation, Online Evaluation, Recommender Systems, Recommendation Effectiveness, Coding Assistants, Context Enhancement (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1153/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Towards Understanding The Gaps of Offline And Online Evaluation Metrics: Impact of Series vs. Movie Recommendations (2024)</h3>
    <p><strong>Authors:</strong> Ashok Chandrashekar, Puja Das, Bora Edizel, Tim Sweetser, Kamilia Ahmadi</p>
    <p>In the realm of recommender systems research, offline evaluation metrics like NDCG, Recall, or Precision are often used to measure the impact. On the other hand, common industry practices suggest evaluating new ideas/models through A/B tests where decisions are made based on business metrics like the overall engagement of users. A new model may show improvement in offline metrics but performance loss in online metrics. One reason that leads to this phenomenon is the counterfactual nature of the recommendation problem which can be addressed by off-policy evaluation methods. Another reason is the degree of causal connection between offline evaluation metrics and observed online metrics. In this work, we will share our learnings from two sets of A/B tests that we conducted at Max1 where we observed a mismatch between online and offline metrics due to a weak causal connection between online and offline metrics. Thanks to learnings from A/B tests, we discovered and quantified the impact of series to movie ratio at recommendations. Our experiments show that there is an optimal amount of series to movies ratio that provides the best possible results for user engagement</p>
    <p><strong>Categories:</strong> Evaluation Metrics, Offline Evaluation, Online Evaluation, Recommender Systems, A/B Testing, User Engagement, Content Types, Causal Inference, Business Metrics, Movie Recommendations, Series Recommendations (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1182/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Interpretable User Retention Modeling in Recommendation (2023)</h3>
    <p><strong>Authors:</strong> Leyu Lin, Xiaochun Yang, Ruobing Xie, Kaikai Ge, Xu Zhang, Xiaobo Hao, Jie Zhou, Rui Ding</p>
    <p>Recommendation usually focuses on immediate accuracy metrics like CTR as training objectives. User retention rate, which reflects the percentage of today’s users that will return to the recommender system in the next few days, should be paid more attention to in real-world systems. User retention is the most intuitive and accurate reflection of user long-term satisfaction. However, most existing recommender systems are not focused on user retention-related objectives, since their complexity and uncertainty make it extremely hard to discover why a user will or will not return to a system and which behaviors affect user retention. In this work, we conduct a series of preliminary explorations on discovering and making full use of the reasons for user retention in recommendation. Specifically, we make a first attempt to design a rationale contrastive multi-instance learning framework to explore the rationale and improve the interpretability of user retention. Extensive offline and online evaluations with detailed analyses of a real-world recommender system verify the effectiveness of our user retention modeling. We further reveal the real-world interpretable factors of user retention from both user surveys and explicit negative feedback quantitative analyses to facilitate future model designs.</p>
    <p><strong>Categories:</strong> User Retention, Recommendation Systems, Interpretable Models, Model Interpretability, Multi-Instance Learning, A/B Testing, Offline Evaluation, Online Evaluation, Real-World Applications, User Surveys, Explicit Negative Feedback, Long-term User Satisfaction (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/931/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>An Industrial Framework for Personalized Serendipitous Recommendation in E-commerce (2023)</h3>
    <p><strong>Authors:</strong> Sulong Xu, Anyu Dai, Zhuoye Ding, Linfang Hou, Mian Ma, Luobao Zou, Yanyan Zou, Zongyi Wang, Nan Qiao</p>
    <p>Classical recommendation methods typically face the filter bubble problem where users likely receive recommendations of their familiar items, making them bored and dissatisfied. To alleviate such an issue, this applied paper introduces a novel framework for personalized serendipitous recommendation in an e-commerce platform (i.e., JD.com), which allows to present user unexpected and satisfying items deviating from user’s prior behaviors, considering both accuracy and novelty. To achieve such a goal, it is crucial yet challenging to recognize when a user is willing to receive serendipitous items and how many novel items are expected. To address above two challenges, a two-stage framework is designed. Firstly, a DNN-based scorer is deployed to quantify the novelty degree of a product category based on user behavior history. Then, we resort to a potential outcome framework to decide the optimal timing to recommend a user serendipitous items and the novelty degree of the recommendation. Online A/B test on the e-commerce recommender platform in JD.com demonstrates that our model achieves significant gains on various metrics, 0.54% relative increase of impressive depth, 0.8% of average user click count, 3.23%  and 1.38% of number of novel impressive and clicked items individually.</p>
    <p><strong>Categories:</strong> Personalized Serendipitous Recommendation, E-commerce, Filter Bubble, Deep Learning (DNN), User Behavior Analysis, Real-world Applications, A/B Testing, Industrial Framework, Personalization, Novelty, Accuracy, Online Evaluation, User Satisfaction, Recommendation Systems, Scalability, Web Systems (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/991/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Scalable Linear Shallow Autoencoder for Collaborative Filtering (2022)</h3>
    <p><strong>Authors:</strong> Vojtěch Vančura, Petr Kasalicky, Pavel Kordík, Rodrigo Alves</p>
    <p>Recently, the RS research community has witnessed a surge in popularity for shallow autoencoder-based CF methods. Due to its straightforward implementation and high accuracy on item retrieval metrics, EASE is potentially the most prominent of these models. Despite its accuracy and simplicity, EASE cannot be employed in some real-world recommender system applications due to its inability to scale to huge interaction matrices. In this paper, we proposed ELSA, a scalable shallow autoencoder method for implicit feedback recommenders. ELSA is a scalable autoencoder in which the hidden layer is factorizable into a low-rank plus sparse structure, thereby drastically lowering memory consumption and computation time. We conducted a comprehensive offline experimental section that combined synthetic and several real-world datasets. We also validated our strategy in an online setting by comparing ELSA to baselines in a live recommender system using an A/B test. Experiments demonstrate that ELSA is scalable and has competitive performance. Finally, we demonstrate the explainability of ELSA by illustrating the recovered latent space.</p>
    <p><strong>Categories:</strong> Scalable Linear Shallow Autoencoder, Collaborative Filtering, Recommender Systems, Matrix Factorization, Implicit Feedback, Autoencoder, Offline Evaluation, Online Evaluation, Scalability, Explainability (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/796/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Recommending the Video to Watch Next: An Offline and Online Evaluation at YOUTV.de (2020)</h3>
    <p><strong>Authors:</strong> Markus Zanker, Daniel Morandini, Ludovik Coba, Panagiotis Symeonidis, Andrea Janes, Dmitry Chaltsev, Andreas Unterhuber, Philip Giuliani</p>
    <p>The task “recommend a video to watch next?” has been in the focus of recommender systems’ research for a long time. However, adequately exploiting the clues hidden in the sequences of actions of user sessions in order to reveal users’ short-term intentions moved only recently into the focus of research. Based on a real-world application scenario, in this paper, we propose a Markov Chain-based transition probability matrix to efficiently reveal the short-term preferences of individuals. We experimentally evaluated our proposed method by comparing it against state-of-the-art algorithms in an offline as well as a live evaluation setting. In both cases our method not only demonstrated its superiority over its competitors, but exposed a clearly stronger engagement of users on the platform. In the online setting, our method improved the click-through rate by up to 93.61%. This paper therefore contributes real-world evidence for improving the recommendation effectiveness, by considering sequence-awareness, since capturing the short-term preferences of users is crucial in the light of items with a short life span such as tv programs (news, tv shows, etc.).</p>
    <p><strong>Categories:</strong> Markov Chain, Media/TV, Sequence-Aware Recommendations, Recommendation Systems, Offline Evaluation, Online Evaluation, Real-World Application, Click-Through Rate (CTR), User Engagement, State-of-the-Art Comparison, Probabilistic Models, Cold Start Problem (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/552/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Progressive Layered Extraction (PLE): A Novel Multi-Task Learning (MTL) Model for Personalized Recommendations (2020)</h3>
    <p><strong>Authors:</strong> Ming Zhao, Hongyan Tang, Junning Liu, Xudong Gong</p>
    <p>Multi-task learning (MTL) has been successfully applied to many recommendation applications. However, MTL models often suffer from performance degeneration with negative transfer due to the complex and competing task correlation in real-world recommender systems. Moreover, through extensive experiments across SOTA MTL models, we have observed an interesting seesaw phenomenon that performance of one task is often improved by hurting the performance of some other tasks. To address these issues, we propose a Progressive Layered Extraction (PLE) model with a novel sharing structure design. PLE separates shared components and task-specific components explicitly and adopts a progressive routing mechanism to extract and separate deeper semantic knowledge gradually, improving efficiency of joint representation learning and information routing across tasks in a general setup. We apply PLE to both complicatedly correlated and normally correlated tasks, ranging from two-task cases to multi-task cases on a real-world Tencent video recommendation dataset with 1 billion samples, and results show that PLE outperforms state-of-the-art MTL models significantly under different task correlations and task-group size. Furthermore, online evaluation of PLE on a large-scale content recommendation platform at Tencent manifests 2.23% increase in view-count and 1.84% increase in watch time compared to SOTA MTL models, which is a significant improvement and demonstrates the effectiveness of PLE. Finally, extensive offline experiments on public benchmark datasets demonstrate that PLE can be applied to a variety of scenarios besides recommendations to eliminate the seesaw phenomenon. PLE now has been deployed to the online video recommender system in Tencent successfully.</p>
    <p><strong>Categories:</strong> Multi-Task Learning (MTL), Personalized Recommendations, Recommender Systems, Video, Media, Sharing Structure, Progressive Routing, Seesaw Phenomenon, Negative Transfer, Real-World Applications, A/B Test, Online Evaluation (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/543/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Predicting Online Performance of Job Recommender Systems With Offline Evaluation (2019)</h3>
    <p><strong>Authors:</strong> Adrien Mogenet, Tuan Anh Nguyen Pham, Masahiro Kazama, Jialin Kong</p>
    <p>Recommender systems can be used to recommend jobs. In this context, implicit and explicit feedback signals we can collect are rare events, making the task of evaluation more complex. Online evaluation (A-B testing) is usually the most reliable way to measure the results from our experiments, but it is a slow process. In contrast, the offline evaluation process is faster, but it is critical to make it reliable as it informs our decision to roll out new improvements in production. In this paper, we review the comparative offline and online performances of three recommendations models, we describe the evaluation metrics we use and analyze how the offline performance metrics correlate with online metrics to understand how an offline evaluation process can be leveraged to inform the decisions. i>Presentation: Wednesday Poster Lunch</i</p>
    <p><strong>Categories:</strong> Job Recommendations, Recommendation Models, Offline Evaluation, Online Evaluation, Evaluation Metrics, Model Comparison, Performance Prediction, Decision-Making, Methodology (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/487/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Educational Question Routing in Online Student Communities (2017)</h3>
    <p><strong>Authors:</strong> Ivan Srba, Jakub Macina, Joseph Jay Williams, Maria Bielikova</p>
    <p>Students’ performance in Massive Open Online Courses (MOOCs) is enhanced by high quality discussion forums or recently emerging educational Community Question Answering (CQA) systems. Nevertheless, only a small number of students answer questions asked by their peers. This results in instructor overload, and many unanswered questions. To increase students’ participation, we present an approach for recommendation of new questions to students who are likely to provide answers. Existing approaches to such question routing proposed for non-educational CQA systems tend to rely on a few experts, which is not suitable because we want students to be engaged as it positively influences their learning outcomes. In tackling this novel educational question routing problem, our method (1) goes beyond previous question-answering data as it incorporate additional non-QA data from the course (to improve prediction accuracy and to involve a larger part of community) and (2) applies constraints on users’ workload (to prevent user overloading). We use an ensemble classifier for predicting students’ willingness to answer a question, as well as the students’ expertise for answering. We conducted an online evaluation of the proposed method using an A/B test in our CQA system deployed at an edX MOOC. The proposed method outperformed a baseline method (non-educational question routing enhanced with workload restriction) in recommendation accuracy, involving more community members, and average number of contributions.</p>
    <p><strong>Categories:</strong> Education, Online Learning, Educational Technology, Community Building, Question Routing, Recommender Systems, Student Engagement, Collaboration, Feature Engineering, User Experience, Real World Application, A/B Test, Online Evaluation, Method Comparison, Ensemble Methods. (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/262/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Contrasting Offline and Online Results when Evaluating Recommendation Algorithms (2016)</h3>
    <p><strong>Authors:</strong> Marco Rossetti, Fabio Stella, Markus Zanker</p>
    <p>Most evaluations of novel algorithmic contributions assess their accuracy in predicting what was withheld in an offline evaluation scenario. However, several doubts have been raised that standard offline evaluation practices are not appropriate to select the best algorithm for field deployment. The goal of this work is therefore to compare the offline and the online evaluation methodology with the same study participants, i.e. a within users experimental design. This paper presents empirical evidence that the ranking of algorithms based on offline accuracy measurements clearly contradicts the results from the online study with the same set of users. Thus the external validity of the most commonly applied evaluation methodology is not guaranteed.</p>
    <p><strong>Categories:</strong> Offline Evaluation, Online Evaluation, Algorithmic Evaluation Methods, Recommendation Algorithms, External Validity, User-Centered Evaluation, Evaluation Methodology, Algorithm Selection, Empirical Evidence, Deployment Considerations, User Study, Recommendation Systems (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/199/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Comparing offline and online recommender system evaluations on long-tail distributions (2015)</h3>
    <p><strong>Authors:</strong> Adilson Cunha, Gabriel de Souza Pereira Moreira, Gilmar Alves de Souzaand</p>
    <p>In this investigation, we conduct a comparison between offline and online accuracy evaluation of different algorithms and settings in a real-world content recommender system. By focusing on recommendations of long-tail items, which are usually more interesting for users, it was possible to reduce the bias caused by extremely popular items and to observe a better alignment of accuracy results in offline and online evaluations.</p>
    <p><strong>Categories:</strong> Evaluation Methods, Long-Tail Recommendations, Accuracy Metrics, Offline Evaluation, Online Evaluation, Real-World Applications, Recommendation Bias, Content Recommendations (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/145/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Offline and Online Evaluation of News Recommender Systems at swissinfo.ch (2014)</h3>
    <p><strong>Authors:</strong> Olivier Donatsch, Amr Huber, Florent Garcin, Boi Faltings, Ayar Alazzawi, Christophe Bruttin</p>
    <p>We report on the live evaluation of various news recommender systems conducted on the website swissinfo.ch. We demonstrate that there is a major difference between offline and online accuracy evaluations. In an offline setting, recommending most popular stories is the best strategy, while in a live environment this strategy is the poorest. For online setting, context-tree recommender systems which profile the users in real-time improve the click-through rate by up to 35%. The visit length also increases by a factor of 2.5. Our experience holds important lessons for the evaluation of recommender systems with offline data as well as for the use of the click-through rate as a performance indicator.</p>
    <p><strong>Categories:</strong> Offline Evaluation, Online Evaluation, News Recommender Systems, Real-Time Profiling, Click-Through Rate, User Engagement, A/B Testing, Offline Data Evaluation, Performance Improvement, Recommendation Strategies, Dynamic User Profiling, Evaluation Settings (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/30/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>