<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui primary button" style="margin: 5px;"
             href="/recsys-recommender/">Deep Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/explainability/">Explainability</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/real-world-applications/">Real-world Applications</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/offline-evaluation/">Offline Evaluation</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reproducibility/">Reproducibility</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Multi-Behavioral Sequential Recommendation (2024)</h3>
    <p><strong>Authors:</strong> Shereen Elsayed, Lars Schmidt-Thieme, Ahmed Rashed</p>
    <p>Sequential recommendation models are crucial for next-item prediction tasks in various online platforms, yet many focus on a single behavior, neglecting valuable implicit interactions. While multi-behavioral models address this using graph-based approaches, they often fail to capture sequential patterns simultaneously. Our proposed Multi-Behavioral Sequential Recommendation framework (MBSRec) captures the multi-behavior dependencies between the heterogeneous historical interactions via multi-head self-attention. Furthermore, we utilize a weighted binary cross-entropy loss for precise behavior control. Experimental results on four datasets demonstrate MBSRec’s significant outperformance of state-of-the-art approaches. The implementation code is available here (https://drive.google.com/drive/folders/1EGRQutc9xtVYbsbXswUcTb9nvT1Tc9cZ?usp=sharing) during the review and will be added to GitHub upon acceptance.</p>
    <p><strong>Categories:</strong> Multi-Behavioral Models, Sequential Recommendation, Implicit Feedback, Attention Mechanism, Recommender Systems, Loss Function Optimization, Deep Learning, Evaluation Metrics, Implementation Details, Cross-Entropy Loss, Multi-Head Self Attention, Heterogeneous Interactions (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1101/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Joint Modeling of Search and Recommendations Via an Unified Contextual Recommender (UniCoRn) (2024)</h3>
    <p><strong>Authors:</strong> Sudarshan Lamkhede, Vito Ostuni, Moumita Bhattacharya</p>
    <p>Search and recommendation systems are essential in many services,and they are often developed separately, leading to complex maintenance and technical debt. In this paper, we present a unified deep learning model that efficiently handles key aspects of both tasks</p>
    <p><strong>Categories:</strong> Search, Recommendation Systems, Unified Models, Deep Learning, Efficiency, Contextual Recommendations, System Integration, Technical Debt Reduction (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1168/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>From Clicks to Carbon: The Environmental Toll of Recommender Systems (2024)</h3>
    <p><strong>Authors:</strong> Alan Said, Tobias Vente, Lukas Wegmeth, Joeran Beel</p>
    <p>As global warming soars, evaluating the environmental impact of research is more critical now than ever before. However, we find that few to no recommender systems research papers document their impact on the environment. Consequently, in this paper, we conduct a comprehensive analysis of the environmental impact of recommender system research papers by reproducing a characteristic recommender systems experimental pipeline. We focus on estimating the carbon footprint of recommender systems research papers, highlighting the evolution of the environmental impact of recommender systems research experiments over time. We evaluated all 79 full papers from the ACM RecSys 2013 and 2023 conferences to analyze representative experimental pipelines for papers utilizing traditional, so-called good old-fashioned AI algorithms and deep learning algorithms, respectively. We reproduced these representative experimental pipelines, measured electricity consumption using a hardware energy meter, and converted the measured energy consumption into CO2 equivalents to estimate the environmental impact. Our results show that a recommender systems research paper utilizing deep learning algorithms emits approximately 42 times more CO2 equivalents than a paper utilizing traditional algorithms. Furthermore, such a paper produces, on average, 3,297 kilograms of CO2 equivalents, which is more than one person produces by flying from New York City to Melbourne or the amount one tree sequesters in 300 years.</p>
    <p><strong>Categories:</strong> Deep Learning, Recommender Systems, Environmental Impact, Carbon Footprint, Energy Consumption, CO2 Emissions, Traditional Algorithms, Real-World Applications, Sustainability (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1123/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Discerning Canonical User Representation for Cross-Domain Recommendation (2024)</h3>
    <p><strong>Authors:</strong> Sherry Sahebi, Siqian Zhao</p>
    <p>Cross-domain recommender systems have emerged, to address the cold-start problem and enhance recommendation outcomes by leveraging information transfer across different domains. Existing cross-domain recommender systems have investigated the learning of both domain-specific and domain-shared user preferences to enhance recommendation performance. However, these models typically allow the disparities between shared and distinct user preferences to emerge freely in any space, lacking sufficient constraints to identify differences between two domains and ensure that both domains are considered simultaneously. Canonical Correlation Analysis (CCA) has shown promise for transferring information between domains, by mapping their user representations into the same space. But, CCA only models domain similarities, and fails to capture the potential differences between user preferences in different domains. In this paper, we propose Discerning Canonical User Representation Learning for Cross-Domain Recommendation (DICUCDR), a generative adversarial networks (GAN) based method that learns both domain-shared and domain-specific user representations. DICUCDR introduces Discerning Canonical Correlation User Representation Learning (DCCRL), a novel design of non-linear Canonical Correlation mappings that creates a shared transformation for simultaneously mapping similarities between different domains and separating domain differences from domains. We compare DICUCDR against several state-of-the-art approaches using two real-world datasets. Our extensive experiments demonstrate the superiority of separately learning shared and specific user representations via DCCRL.</p>
    <p><strong>Categories:</strong> Cross-Domain Recommendation, Cold Start Problem, Transfer Learning, Multi-Domain, Canonical Correlation Analysis (CCA), Generative Adversarial Networks (GANs), Deep Learning, Representation Learning, Domain Adaptation, Real-World Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1033/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Repeated Padding for Sequential Recommendation (2024)</h3>
    <p><strong>Authors:</strong> Jianzhe Zhao, Linying Jiang, Yuting Liu, Yizhou Dang, Xingwei Wang, Guibing Guo, Enneng Yang</p>
    <p>Sequential recommendation aims to provide users with personalized suggestions based on their historical interactions. When training sequential models, padding is a widely adopted technique for two main reasons: 1) The vast majority of models can only handle fixed-length sequences; 2) Batch-based training needs to ensure that the sequences in each batch have the same length. The special value 0 is usually used as the padding content, which does not contain the actual information and is ignored in the model calculations. This common-sense padding strategy leads us to a problem that has never been explored in the recommendation field: Can we utilize this idle input space by padding other content to improve model performance and training efficiency further? In this paper, we propose a simple yet effective padding method called Repeated Padding (RepPad). Specifically, we use the original interaction sequences as the padding content and fill it to the padding positions during model training. This operation can be performed a finite number of times or repeated until the input sequences’ length reaches the maximum limit. Our RepPad can be considered as a sequence-level data augmentation strategy. Unlike most existing works, our method contains no trainable parameters or hyperparameters and is a plug-and-play data augmentation operation. Extensive experiments on various categories of sequential models and five real-world datasets demonstrate the effectiveness and efficiency of our approach. The average recommendation performance improvement is up to 60.3% on GRU4Rec and 24.3% on SASRec. We also provide in-depth analysis and explanation of what makes RepPad effective from multiple perspectives. The source code will be released to ensure the complete reproducibility of our experiments.</p>
    <p><strong>Categories:</strong> Sequential Models, Recommendation Systems, Data Augmentation, Sequence Padding, Model Performance, Training Efficiency, Real-World Datasets, Reproducibility, Deep Learning, Beyond Accuracy (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1061/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Improving Adversarial Robustness for Recommendation Model via Cross-Domain Distributional Adversarial Training (2024)</h3>
    <p><strong>Authors:</strong> Ning Yang, Lilin Zhang, Jingyu Chen</p>
    <p>Recommendation models based on deep learning are fragile when facing adversarial examples (AE). Adversarial training (AT) is the existing mainstream method to promote the adversarial robustness of recommendation models. However, these AT methods often have two drawbacks. First, they may be ineffective due to the ubiquitous sparsity of interaction data. Second, point-wise perturbation used by these AT methods leads to suboptimal adversarial robustness, because not all examples are equally susceptible to such perturbations. To overcome these issues, we propose a novel method called Cross-domain Distributional Adversarial Training (CDAT) which utilizes a richer auxiliary domain to improve the adversarial robustness of a sparse target domain. CDAT comprises a Domain adversarial network (Dan) and a Cross-domain adversarial example generative network (Cdan). Dan learns a domain-invariant preference distribution which is obtained by aligning user embeddings from two domains and paves the way to leverage the knowledge from another domain for the target domain. Then, by adversarially perturbing the domain-invariant preference distribution under the guidance of a discriminator, Cdan captures an aggressive and imperceptible AE distribution. In this way, CDAT can transfer distributional adversarial robustness from the auxiliary domain to the target domain. The extensive experiments conducted on real datasets demonstrate the remarkable superiority of the proposed CDAT in improving the adversarial robustness of the sparse domain.</p>
    <p><strong>Categories:</strong> Adversarial Machine Learning, Recommendation Systems, Deep Learning, Robustness in Recommendations, Cross-Domain Methods, Transfer Learning, Real-World Applications, Distributional Adversarial Training, Sparse Data Handling (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1042/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Power Loss Function in Neural Networks for Predicting Click-Through Rate (2023)</h3>
    <p><strong>Authors:</strong> Ergun Biçici</p>
    <p>Loss functions guide machine learning models towards concentrating on the error most important to improve upon.  We introduce power loss functions for neural networks and apply them on imbalanced click-through rate datasets. Power loss functions decrease the loss for confident predictions and increase the loss for error-prone predictions. They improve both AUC and F1 and produce better calibrated results.  We obtain improvements in the results on four different classifiers and on two different datasets. We obtain significant improvements in AUC that reach $0.44\%$ for DeepFM on the Avazu dataset.</p>
    <p><strong>Categories:</strong> Neural Networks, Click-Through Rate, Deep Learning, Loss Functions, Imbalanced Data, Recommendation Systems, AUC, F1 Score, Evaluation Metrics, Digital Advertising (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/963/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Deep Situation-Aware Interaction Network for Click-Through Rate Prediction (2023)</h3>
    <p><strong>Authors:</strong> Yongkang Wang, Dong Wang, Yisong Yu, Beihong Jin, Yapeng Zhang, Jian Dong, Xingxing Wang, Shuli Wang, Yimin Lv</p>
    <p>User behavior sequence modeling plays a significant role in Click-Through Rate (CTR) prediction on e-commerce platforms. Except for the interacted items, user behaviors contain rich interaction information, such as the behavior type, time, location, etc. However, so far, the information related to user behaviors has not yet been fully exploited. In the paper, we propose the concept of a situation and situational features for distinguishing interaction behaviors and then design a CTR model named Deep Situation-Aware Interaction Network (DSAIN). DSAIN first adopts the reparameterization trick to reduce noise in the original user behavior sequences. Then it learns the embeddings of situational features by feature embedding parameterization and tri-directional correlation fusion. Finally, it obtains the embedding of behavior sequence via heterogeneous situation aggregation. We conduct extensive offline experiments on three real-world datasets. Experimental results demonstrate the superiority of the proposed DSAIN model. More importantly, DSAIN has increased the CTR by 2.70\%, the CPM by 2.62\%, and the GMV by 2.16\% in the online A/B test. Now, DSAIN has been deployed on the Meituan food delivery platform and serves the main traffic of the Meituan takeout app. Our source code is available at https://github.com/W-void/DSAIN</p>
    <p><strong>Categories:</strong> Deep Learning, Matrix Factorization, Interaction Network, E-commerce, Food Delivery, Click-Through Rate Prediction, Situational Awareness, User Behavior Modeling, Contextual Features, Sequence Modeling, A/B Test, Performance Improvement, User Interaction Analysis (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/849/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Beyond Labels: Leveraging Deep Learning and LLMs for Content Metadata (2023)</h3>
    <p><strong>Authors:</strong> Jaya Kawale, Saurabh Agrawal, John Trenkle</p>
    <p>Content metadata plays a very important role in movie recommender systems as it provides valuable information about various aspects of a movie such as genre, cast, plot synopsis, box office summary, etc. Analyzing the metadata can help understand the user preferences and generate personalized recommendations catering to the niche tastes of the users. It can also help with content cold starting when the recommender system has little or no interaction data available to perform collaborative filtering. In this talk, we will focus on one particular type of metadata – genre labels. Genre labels associated with a movie or a TV series such as “horror” or “comedy” or “romance” help categorize a collection of movies into different themes and correspondingly setting up the audience expectation for a title. We present some of the challenges associated with using genre label information via traditional methods and propose a new way of examining the genre information that we call as the Genre Spectrum. The Genre Spectrum helps capture the various nuanced genres in a title and our offline and online experiments corroborate the effectiveness of the approach.</p>
    <p><strong>Categories:</strong> Deep Learning, Large Language Models (LLMs), Recommendation Systems, Content Metadata, Genre Analysis, Cold Start Problem, Personalized Recommendations, User Preferences, Offline Experiments, Online Experiments (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/993/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Enhanced Privacy Preservation for Recommender Systems (2023)</h3>
    <p><strong>Authors:</strong> Ziqing Wu</p>
    <p>My research focuses on privacy preservation for recommender systems specifically in the following aspects: first, how to better address users’ realistic privacy concerns and offer enhanced privacy control by considering what and with whom to share sensitive information for decentralized recommender systems; second, how to enhance the privacy preservation capability of LLM-based recommender systems; last, how to formulate uniform metrics to compare the privacy-preservation efficacy of the recommender system.</p>
    <p><strong>Categories:</strong> Privacy Preservation, Recommender Systems, User-Centric Design, Decentralized Systems, Large Language Models, Machine Learning, Deep Learning, Evaluation Metrics, Performance Measurement, Algorithm Evaluation, Data Security, Trust (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/976/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Contrastive Learning with Frequency-Domain Interest Trends for Sequential Recommendation (2023)</h3>
    <p><strong>Authors:</strong> Guisheng Yin, Yuxin Dong, Yichi Zhang</p>
    <p>Recently, contrastive learning for sequential recommendation has demonstrated its powerful ability to learn high-quality user representations. However, constructing augmented samples in the time domain poses challenges due to various reasons, such as fast-evolving trends, interest shifts, and system factors. Furthermore, the F-principle indicates that deep learning preferentially fits the low-frequency part, resulting in poor performance on high-frequency tasks. The complexity of time series and the low-frequency preference limit the utility of sequence encoders. To address these challenges, we need to construct augmented samples from the frequency domain, thus improving the ability to accommodate events of different frequency sizes. To this end, we propose a novel Contrastive Learning with Frequency-Domain Interest Trends for Sequential Recommendation (CFIT4SRec). We treat the embedding representations of historical interactions as “images” and introduce the second-order Fourier transform to construct augmented samples. The components of different frequency sizes reflect the interest trends between attributes and their surroundings in the hidden space. We introduce three data augmentation operations to accommodate events of different frequency sizes: low-pass augmentation, high-pass augmentation, and band-stop augmentation. Extensive experiments on four public benchmark datasets demonstrate the superiority of CFIT4SRec over the state-of-the-art baselines. The implementation code is available at https://github.com/zhangyichi1Z/CFIT4SRec.</p>
    <p><strong>Categories:</strong> Contrastive Learning, Sequential Recommendation, Frequency-Domain Analysis, Data Augmentation, User Representation Learning, Recommendation Algorithms, Time Series Analysis, Deep Learning, Signal Processing Techniques, Interest Evolution Modeling (<i>deepseek-r1:70b</i>)</p>
    <p><a href="/recsys-recommender/response/855/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Track Mix Generation on Music Streaming Services using Transformers (2023)</h3>
    <p><strong>Authors:</strong> Thomas Bouabça, Walid Bendada, Benjamin Chapus, Thibault Cador, Théo Bontempelli, Mathieu Morlon, Guillaume Salha-Galvan</p>
    <p>This paper introduces Track Mix, a personalized playlist generation system released in 2022 on the music streaming service Deezer. Track Mix automatically generates “mix” playlists inspired by initial music tracks, allowing users to discover music similar to their favorite content. To generate these mixes, we consider a Transformer model trained on millions of track sequences from user playlists. In light of the growing popularity of Transformers in recent years, we analyze the advantages, drawbacks, and technical challenges of using such a model for mix generation on the service, compared to a more traditional collaborative filtering approach. Since its release, Track Mix has been generating playlists for millions of users daily, enhancing their music discovery experience on Deezer.</p>
    <p><strong>Categories:</strong> Transformer Models, Music Streaming, Recommendation Systems, Deep Learning, Personalization, Language Modeling, Collaborative Filtering, Real-World Applications, User Engagement, Playlist Generation, Neural Networks, Music Domain, Scalability, Model Evaluation (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1016/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>ADRNet: A Generalized Collaborative Filtering Framework Combining Clinical and Non-Clinical Data for Adverse Drug Reaction Prediction (2023)</h3>
    <p><strong>Authors:</strong> Xiao-Hua Zhou, Zetong Xiong, Taojun Hu, Chunyuan Zheng, Haoxuan Li, Fuli Feng, Xiangnan He</p>
    <p>Adverse drug reaction (ADR) prediction plays a crucial role in both health care and drug discovery for reducing patient mortality and enhancing drug safety. Recently, many studies have been devoted to effectively predict the drug-ADRs incidence rates. However, these methods either did not effectively utilize non-clinical data, i.e., physical, chemical, and biological information about the drug, or did little to establish a link between content-based and pure collaborative filtering during the training phase. In this paper, we first formulate the prediction of multi-label ADRs as a drug-ADR collaborative filtering problem, and to the best of our knowledge, this is the first work to provide extensive benchmark results of previous collaborative filtering methods on two large publicly available clinical datasets. Then, by exploiting the easy accessible drug characteristics from non-clinical data, we propose ADRNet, a generalized collaborative filtering framework combining clinical and non-clinical data for drug-ADR prediction. Specifically, ADRNet has a shallow collaborative filtering module and a deep drug representation module, which can exploit the high-dimensional drug descriptors to further  guide the learning of low-dimensional ADR latent embeddings, which incorporates both the benefits of collaborative filtering and representation learning. Extensive experiments are conducted on two publicly available real-world drug-ADR clinical datasets and two non-clinical datasets to demonstrate the accuracy and efficiency of the proposed ADRNet.</p>
    <p><strong>Categories:</strong> Collaborative Filtering, Deep Learning, Multi-Label Classification, Healthcare, Drug Safety, Non-Clinical Data, Real-World Application, Drug Discovery (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/893/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>CR-SoRec: BERT driven Consistency Regularization for Social Recommendation (2023)</h3>
    <p><strong>Authors:</strong> Raksha Jalan, Naoyuki Onoe, Tushar Prakash, Brijraj Singh</p>
    <p>In the real world, when we seek our friends’ opinions on various items or events, we request verbal social recommendations. It has been observed that we often turn to our friends for recommendations on a daily basis. The emergence of online social platforms has enabled users to share their opinion with their social connections. Therefore, we should consider users’ social connections to enhance online recommendation performance. The social recommendation aims to fuse social links with user-item interactions to offer more relevant recommendations. Several efforts have been made to develop an effective social recommendation system. However, there are two significant limitations to current methods: First, they haven’t thoroughly explored the intricate relationships between the diverse influences of neighbours on users’ preferences. Second, existing models are vulnerable to overfitting due to the relatively low number of user-item interaction records in the interaction space. For the aforementioned problems,  this paper offers a novel framework called CR-SoRec, an effective recommendation model based on BERT and Consistency Regularization. This model incorporates Bidirectional Encoder Representations from Transformer(BERT) to learn bidirectional context-aware user and item embeddings with neighbourhood sampling. The neighbourhood Sampling technique samples the most influential neighbours for all the users/ items. Further, to effectively use the available user-item interaction data and social ties, we leverage diverse perspectives via consistency regularisation to harness the underlying information. The main objective of our model is to predict the next item that a user would interact with based on its interaction behaviour and social connections. Experimental results show that our model defines a new state-of-the-art on various datasets and outperforms previous work by a significant margin. Extensive experiments are conducted to analyse the method. We release the source code of our model at https://anonymous.4open.science/r/CR-SoRec-68F4</p>
    <p><strong>Categories:</strong> BERT, Social Recommendation, Consistency Regularization, Recommendation Systems, Neighborhood Sampling, Overfitting Mitigation, User-Item Interactions, State-of-the-Art Model, Deep Learning, Experimental Analysis, Collaborative Filtering, Context-Aware Recommendations (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/925/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>MCM: A Multi-task Pre-trained Customer Model for Personalization (2023)</h3>
    <p><strong>Authors:</strong> Tianxin Wang, Peng Wan, Rui Luo, Jingyuan Deng</p>
    <p>Personalization plays a critical role in helping customers discover the products and contents they prefer for e-commerce stores.Personalized recommendations differ in contents, target customers, and UI. However, they require a common core capability – the ability to deeply understand customers’ preferences and shopping intents. In this paper, we introduce the MLCM (Multi-task Large pre-trained Customer Model), a large pre-trained BERT-based multi-task customer model with 10 million trainable parameters for e-commerce stores. This model aims to empower all personalization projects by providing commonly used preference scores for recommendations, customer embeddings for transfer learning, and a pre-trained model for fine-tuning. In this work, we improve the SOTA BERT4Rec framework to handle heterogeneous customer signals and multi-task training as well as innovate new data augmentation method that is suitable for recommendation task. Experimental results show that MLCM outperforms the original BERT4Rec by 17% on preference prediction tasks. Additionally, we demonstrate that the model can be easily fine-tuned to assist a specific recommendation task. For instance, after fine-tuning MLCM for an incentive based recommendation project, performance improves by 60% on the conversion prediction task and 25% on the click-through prediction task compared to the production baseline model.</p>
    <p><strong>Categories:</strong> Personalization, Recommendation Systems, Multi-Task Learning, Deep Learning, E-Commerce, Customer Modeling, Natural Language Processing, Transfer Learning, Data Augmentation, Model Fine-Tuning, Performance Improvement, Incentive-Based Recommendations, Conversion Prediction, Click-Through Rate, Real-World Applications. (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1004/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Nonlinear Bandits Exploration for Recommendations (2023)</h3>
    <p><strong>Authors:</strong> Minmin Chen, Yi Su</p>
    <p>The paradigm of framing recommendations as (sequential) decision-making processes has gained significant interest. To achieve long-term user satisfaction, these interactive systems need to strikes a balance between exploitation (recommending high-reward items) and exploration (exploring uncertain regions for potentially better items). Classical bandit algorithms like Upper-Confidence-Bound and Thompson Sampling, and their contextual extensions with linear payoffs have exhibited strong theoretical guarantees and empirical success in managing the exploration-exploitation trade-off. Building efficient exploration-based systems for deep neural network powered real-world, large-scale industrial recommender systems remains under studied. In addition, these systems are often multi-stage, multi-objective and response time sensitive.  In this talk, we share our experience in addressing these challenges in building exploration based industrial recommender systems. Specifically, we adopt the Neural Linear Bandit algorithm, which effectively combines the representation power of deep neural networks, with the simplicity of linear bandits to incorporate exploration in DNN based recommender systems. We introduce  exploration capability to both the nomination and ranking stage of the industrial recommender system.  In the context of the ranking stage, we delve into the extension of this algorithm to accommodate the multi-task setup, enabling exploration in systems with multiple objectives. Moving on to the nomination stage, we will address the development of efficient bandit algorithms tailored to factorized bi-linear models. These algorithms play a crucial role in facilitating maximum inner product search, which is commonly employed in large-scale retrieval systems. We validate our algorithms and present findings from real-world live experiments.</p>
    <p><strong>Categories:</strong> Multi-Armed Bandits, Recommendation Systems, Deep Learning, Exploration, Exploitation, Neural Linear Bandit, Industrial Recommender Systems, Nomination Stage, Ranking Stage, Multi-Task Learning, Large Scale Systems, Real World Applications, Efficiency, Beyond Accuracy, Evaluation Metrics, Performance Evaluation, Algorithm Performance (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1012/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>