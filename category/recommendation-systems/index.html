<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui primary button" style="margin: 5px;"
             href="/recsys-recommender/">Recommendation Systems</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/explainability/">Explainability</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reproducibility/">Reproducibility</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/real-world-applications/">Real-world Applications</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Pareto Front Approximation for Multi-Objective Session-Based Recommender Systems (2024)</h3>
    <p><strong>Authors:</strong> Timo Wilm, Philipp Normann, Felix Stepprath</p>
    <p>This work introduces MultiTRON, an approach that adapts Pareto front approximation techniques to multi-objective session-based recommender systems using a transformer neural network. Our approach optimizes trade-offs between key metrics such as click-through and conversion rates by training on sampled preference vectors. A significant advantage is that after training, a single model can access the entire Pareto front, allowing it to be tailored to meet the specific requirements of different stakeholders by adjusting an additional input vector that weights the objectives. We validate the model’s performance through extensive offline and online evaluation. For broader application and research, the source code is made available. The results confirm the model’s ability to manage multiple recommendation objectives effectively, offering a flexible tool for diverse business needs.</p>
    <p><strong>Categories:</strong> Multi-objective optimization, Session-based recommendations, Pareto front approximation, Transformer neural networks, Offline evaluation, Online evaluation, Recommendation systems, Real-world applications, Evaluation techniques, Deep learning approaches (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1166/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Scene-wise Adaptive Network for Dynamic Cold-start Scenes Optimization in CTR Prediction (2024)</h3>
    <p><strong>Authors:</strong> Chao Tang, Wenhao Li, Jie Zhou, Shixiong Zhao, Chuan Luo, Kun Zhang</p>
    <p>In the realm of modern mobile E-commerce, providing users with nearby commercial service recommendations through location-based online services has become increasingly vital. While machine learning approaches have shown promise in multi-scene recommendation, existing methodologies often struggle to address cold-start problems in unprecedented scenes: the increasing diversity of commercial choices, along with the short online lifespan of scenes, give rise to the complexity of effective recommendations in online and dynamic scenes. In this work, we propose Scene-wise Adaptive Network (SwAN), a novel approach that emphasizes high-performance cold-start online recommendations for new scenes. Our approach introduces several crucial capabilities, including scene similarity learning, user-specific scene transition cognition, scene-specific information construction for the new scene, and enhancing the diverged logical information between scenes. We demonstrate SwAN’s potential to optimize dynamic multi-scene recommendation problems by effectively online handling cold-start recommendations for any newly arrived scenes. More encouragingly, SwAN has been successfully deployed in Company M’s online catering recommendation service, which serves millions of customers per day, and SwAN has achieved a 5.64% CTR index improvement relative to the baselines and a 5.19% increase in daily order volume proportion.</p>
    <p><strong>Categories:</strong> Scene-wise Adaptive Network (SwAN), Neural Networks, Cold Start, Multi-scene Recommendations, Dynamic Scenarios, Recommendation Systems, Mobile E-commerce, Catering Services, Location-based Services, Evaluation Metrics, Beyond Accuracy, Real-world Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1063/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Dynamic Stage-aware User Interest Learning for Heterogeneous Sequential Recommendation (2024)</h3>
    <p><strong>Authors:</strong> Zhong Ming, Weixin Li, Xiaolin Lin, Weike Pan</p>
    <p>Sequential recommendation has been widely used to predict users’ potential preferences by learning their dynamic user interests, for which most previous works focus on capturing item-level dependencies. Despite the great success, they often overlook the stage-level interest dependencies. In real-world scenarios, user interests tend to be staged, e.g., following an item purchase, a user’s interests may undergo a transition into the subsequent phase. And there are intricate dependencies across different stages. Meanwhile, users’ behaviors are usually heterogeneous, including auxiliary behaviors (e.g., examinations) and target behaviors (e.g., purchases), which imply more fine-grained user interests. However, existing works have limitations in explicitly modeling the relationships between auxiliary behaviors and target behaviors. To address the above issues, we propose a novel framework, i.e., dynamic stage-aware user interest learning (DSUIL), for heterogeneous sequential recommendation, which is the first solution to model user interests in a cross-stage manner. Specifically, our DSUIL consists of three modules: a dynamic graph convolution module that dynamically learns item representations in each stage, a behavior-aware subgraph representation learning module that learns heterogeneous dependencies between behaviors and aggregates item representations to represent the user interests for each stage, and a sequence decoder to capture the evolving pattern of user interests and make item prediction. Extensive experimental results on two public datasets show that our DSUIL performs significantly better than the state-of-the-art methods.</p>
    <p><strong>Categories:</strong> Sequential Recommendation, Stage-aware Interest Modeling, Heterogeneous Behaviors, User Interest Evolution, Dynamic Learning, Cross-Stage Dependencies, Auxiliary Behaviors, Target Behaviors, Behavior Relationships, Recommendation Systems, State-of-the-Art Methods, User Behavior Analysis (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1039/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Stalactite: toolbox for fast prototyping of vertical federated learning systems (2024)</h3>
    <p><strong>Authors:</strong> Maria Khodorchenko, Anastasiia Zakharova, Dmitriy Alexandrov, Alexey Vasilev, Maxim Savchenko, Nikolay Butakov, Alexander Grigorievskiy</p>
    <p>Machine learning (ML) models trained on datasets owned by different organizations and physically located in remote databases offer benefits in many real-world use cases. State regulations or business requirements often prevent data transfer to a central location, making it difficult to utilize standard machine learning algorithms. Federated Learning (FL) is a technique that enables models to learn from distributed datasets without revealing the original data. Vertical Federated learning (VFL) is a type of FL where data samples are divided by features across several data owners. For instance, in a recommendation task, a user can interact with various sets of items, and the logs of these interactions are stored by different organizations. In this demo paper, we present Stalactite – an open-source framework for VFL that provides the necessary functionality for building prototypes of VFL systems. It has several advantages over the existing frameworks. In particular, it allows researchers to focus on the algorithmic side rather than engineering and to easily deploy learning in a distributed environment. It implements several VFL algorithms and has a built-in homomorphic encryption layer. We demonstrate its use on a real-world recommendation datasets.</p>
    <p><strong>Categories:</strong> Federated Learning, Vertical Federated Learning (VFL), Recommendation Systems, Machine Learning Frameworks, Algorithm Implementation, Homomorphic Encryption, Security and Privacy, Distributed Systems, Multi-Party Computation, Rapid Prototyping, Real-World Applications, Data Privacy, Open Source Tools (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1208/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>LyricLure: Mining Catchy Hooks in Song Lyrics to Enhance Music Discovery and Recommendation (2024)</h3>
    <p><strong>Authors:</strong> Tarun Sharma, Siddharth Sharma, Joaquin Delgado, Ajinkya Walimbe, Akshay Shukla</p>
    <p>Amazon Music encounters a significant challenge as users increasingly rely on catchy lines from lyrics to search for both new releases and other popular songs. Integrating lyrics into existing lexical search index or using lyrics vector index pose difficulties due to lyrics text length. While lexical scoring mechanisms like BM25 are inadequate and necessitates complex query planning and index schema for long text, text embedding similarity based techniques often retrieve noisy near-similar meaning lyrics, resulting in low precision. This paper introduces a proactive approach to extract catchy phrases from song lyrics, overcoming the limitations of conventional graph-based phrase extractors and deep learning models, which are primarily designed for extractive summarization or task-specific key phrase extraction from domain-specific corpora. Additionally, we employ a multi-step mechanism to mine search query logs for potential unresolved user queries containing catchy phrases from lyrics. This involves creation of word and character k-gram index for lyric chunks, careful query and lyrics domain-centric normalization (and expansion) and a re-ranking layer incorporating lexical and well as semantic similarity. Together these strategies helped us create a high retrieval source specifically for serving lyrics intent queries with high recall.</p>
    <p><strong>Categories:</strong> Music, Recommendation Systems, Text Mining, Natural Language Processing, Phrase Extraction, Query Log Analysis, Indexing Techniques, Text Preprocessing, Re-ranking Mechanisms, Search Algorithms (BM25, Similarity), Retrieval Optimization, Lyrics Analysis, Lexical Search, Multi-Step Processing (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1170/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Instructing and Prompting Large Language Models for Explainable Cross-domain Recommendations (2024)</h3>
    <p><strong>Authors:</strong> Alessandro Petruzzelli, Cataldo Musto, Pasquale Lops, Marco de Gemmis, Ivan Rinaldi, Giovanni Semeraro, Lucrezia Laraspata</p>
    <p>In this paper, we present a strategy to provide users with explainable cross-domain recommendations (CDR) that exploits large language models (LLMs). Generally speaking, cross-domain recommender systems typically suffer of data sparsity issues, since they require a large amount of data labeled in both base and target domains, which are not easy to collect. Accordingly, our approach relies on the intuition that the knowledge that is already encoded in LLMs can be used to bridge the domains and seamlessly provide users with personalized cross-domain suggestions. To this end, we designed a pipeline to: (a) instruct a LLM to handle a CDR task; (b) design a personalized prompt, based on the preferences of the user in a base domain, in both zero-shot and one-shot settings; (c) feed the LLM with the prompt, and process the answer in order to extract the recommendations in a target domain, together with a natural language explanation supporting the suggestion. As shown in the experimental evaluation, our approach beats several established state-of-the-art baselines for CDR in most of the experimental settings, thus showing the effectiveness of LLMs also in this novel and scarcely investigated scenario.</p>
    <p><strong>Categories:</strong> Large Language Models (LLMs), Cross-domain Recommendations, Explainable Recommendations, Recommendation Systems, Personalization, Zero-shot Learning, One-shot Learning, Data Sparsity, Natural Language Processing (NLP), Instruction Following (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1049/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Enhancing Performance and Scalability of Large-Scale Recommendation Systems with Jagged Flash Attention (2024)</h3>
    <p><strong>Authors:</strong> Hong Li, Mingwei Tang, Meng Liu, Junjie Yang, Dai Li, Xing Liu, Tunhou Zhang, Arnold Overwijk, Haoci Zhang, Rengan Xu, Sijia Chen, Sri Reddy, Devashish Shankar, Jiaqi Zhai, Bill Zhu, Boyang Li, Zehua Zhang, Yifan Xu, Yuxi Hu</p>
    <p>The integration of hardware accelerators has significantly advanced the capabilities of modern recommendation systems, enabling the exploration of complex ranking paradigms previously deemed impractical. However, the GPU-based computational costs present substantial challenges. In this paper, we demonstrate our development of an efficiency-driven approach to explore these paradigms, moving beyond traditional reliance on native PyTorch modules. We address the specific challenges posed by ranking models’ dependence on categorical features, which vary in length and complicate GPU utilization. We introduce Jagged Feature Interaction Kernels, a novel method designed to extract fine-grained insights from long categorical features through efficient handling of dynamically sized tensors. We further enhance the performance of attention mechanisms by integrating Jagged tensors with Flash Attention. As the feature length grows, the Jagged Flash Attention is able to scale memory linearly rather than quadratically. Our experimental results demonstrate that Jagged Flash Attention achieves speedups of 2.4× to 5.6× over dense attention and reduces memory usage by up to 21.8×. This allows to scale the recommendation systems with longer features and more complex model architecture.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Scalability, GPU Usage, Categorical Features, Efficient Algorithms, Flash Attention, Memory Efficiency, Hardware Acceleration, Performance Optimization, Large-Scale Systems, Attention Mechanisms, Novel Methods, Efficiency-Driven Approaches, Complex Model Architectures. (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1163/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>ReChorus2.0: A Modular and Task-Flexible Recommendation Library (2024)</h3>
    <p><strong>Authors:</strong> Peijie Sun, Hanyu Li, Zhiyu He, Weizhi Ma, Shaoping Ma, Min Zhang, Jiayu Li</p>
    <p>With the applications of recommendation systems rapidly expanding, an increasing number of studies have focused on every aspect of recommender systems with different data inputs, models, and task settings. Therefore, a flexible library is needed to help researchers implement the experimental strategies they require. Existing open libraries for recommendation scenarios have enabled reproducing various recommendation methods and provided standard implementations. However, these libraries often impose certain restrictions on data and seldom support the same model to perform different tasks and input formats, limiting users from customized explorations. To fill the gap, we propose ReChorus2.0, a modular and task-flexible library for recommendation researchers. Based on ReChorus, we upgrade the supported input formats, models, and training\&evaluation strategies to help realize more recommendation tasks with more data types. The main contributions of ReChorus2.0 include:    (1) Realization of complex and practical tasks, including reranking and CTR prediction tasks;   (2) Inclusion of various context-aware and rerank recommenders;   (3) Extension of existing and new models to support different tasks with the same models;   (4) Support of highly-customized input with impression logs, negative items, or click labels, as well as user, item, and situation contexts.   To summarize, ReChorus2.0 serves as a comprehensive and flexible library better aligning with the practical problems in the recommendation scenario and catering to more diverse research needs. The implementation and detailed tutorials of ReChorus2.0 can be found at https://github.com/THUwangcy/ReChorus.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Libraries/Tools, Modular Design, Task Flexibility, Data Handling, Context-Aware Recommendations, Customization, Evaluation Strategies, Reranking, CTR Prediction (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1125/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Not All Videos Become Outdated: Short-Video Recommendation by Learning to Deconfound Release Interval Bias (2024)</h3>
    <p><strong>Authors:</strong> Aixin Sun, Guoxiu He, Lulu Dong</p>
    <p>Short-video recommender systems often exhibit a biased preference to recently released videos. However, not all videos become outdated; certain classic videos can still attract user’s attention. Such bias along temporal dimension can be further aggravated by the matching model between users and videos, because the model learns from preexisting interactions. From real data, we observe that different videos have varying sensitivities to recency in attracting users’ attention. Our analysis, based on a causal graph modeling short-video recommendation, suggests that the release interval serves as a confounder, establishing a backdoor path between users and videos. To address this confounding effect, we propose a model-agnostic causal architecture called Learning to Deconfound the Release Interval Bias (LDRI). LDRI enables jointly learning of the matching model and the video recency sensitivity perceptron. In the inference stage, we apply a backdoor adjustment, effectively blocking the backdoor path by intervening on each video. Extensive experiments on two benchmarks demonstrate that LDRI consistently outperforms backbone models and exhibits superior performance against state-of-the-art models. Additional comprehensive analyses confirm the deconfounding capability of LDRI. Our code is available online: https://anonymous.4open.science/r/LDRI/.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Short-Video Recommendations, Bias Mitigation, Temporal Dynamics, Model Agnostic, Causal Inference, User Modeling, Evaluation Methods, Matching Models, Confounding Variables, Recency Sensitivity (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1053/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>MAWI Rec: Leveraging Severe Weather Data in Recommendation (2024)</h3>
    <p><strong>Authors:</strong> Taylor Berg-Kirkpatrick, Surya Kallumadi, Julian Mcauley, Brendan Duncan</p>
    <p>Inferring user intent in recommender systems can help performance but is difficult because intent is personal and not directly observable. Previous work has leveraged signals to stand as a proxy for intent (e.g. user interactions with resource pages), but such signals are not always available. In this paper, we instead recognize that certain events, which are observable, directly influence user intent. For example, after a flood, home improvement customers are more likely to undertake a renovation project to dry out their basement. We introduce MAWI Rec, a recommender system that leverages severe weather data to improve recommendation. Our weather-aware system achieves a significant improvement over a state-of-the-art baseline for online and in-store datasets of home improvement customers. This gain is most significant for weather-related product categories such as roof panels and flashings.</p>
    <p><strong>Categories:</strong> Recommendation Systems, External Signals, User Intent Inference, Event-Based Recommendations, Context-Aware Recommendations, Natural Disasters/Weather Events, Real-World Applications, Performance Evaluation, Impact Analysis (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1093/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Biased User History Synthesis for Personalized Long-Tail Item Recommendation (2024)</h3>
    <p><strong>Authors:</strong> Elan Markowitz, Greg Ver Steeg, Abdulla Alshabanah, Keshav Balasubramanian, Murali Annavaram</p>
    <p>Recommendation systems connect users to items and create value chains in the internet economy. Recommendation systems learn from past user-item interaction histories. As such, items that have short interaction histories, either because they are new or not popular, are disproportionately under-recommended. This long-tail item problem can exacerbate model bias, and reinforce poor recommendation of tail items. In this paper, we propose a novel training algorithm, <i>biased user history synthesis</i>, to not only address this problem but also achieve better personalization in recommendation systems. As a result, we concurrently improve tail and head item recommendation performance. Our approach is built on a tail item biased User Interaction History (UIH) sampling strategy and a synthesis model that produces an augmented user representation from the sampled user history. We provide a theoretical justification for our approach using information theory and demonstrate through extensive experimentation, that our model outperforms state-of-the-art baselines on tail, head, and overall recommendation. the source code is available at https://github.com/lkp411/BiasedUserHistorySynthesis.</p>
    <p><strong>Categories:</strong> Algorithm, Personalization, Long-Tail Item Recommendation, Cold Start Problem, User Interaction History, Data Augmentation, Recommendation Systems, Evaluation Metrics, Theoretical Justification, Scalability and Performance (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1026/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>A Novel Evaluation Perspective on GNNs-based Recommender Systems through the Topology of the User-Item Graph (2024)</h3>
    <p><strong>Authors:</strong> Alberto Carlo Maria Mancino, Vito Walter Anelli, Claudio Pomo, Tommaso Di Noia, Eugenio Di Sciascio, Daniele Malitesta</p>
    <p>Recently, graph neural networks (GNNs)-based recommender systems have encountered great success in recommendation. As the number of GNNs approaches rises, some works have started questioning the theoretical and empirical reasons behind their superior performance. Nevertheless, this investigation still disregards that GNNs treat the recommendation data as a topological graph structure. Building on this assumption, in this work, we provide a novel evaluation perspective on GNNs-based recommendation, which investigates the impact of the graph topology on the recommendation performance. To this end, we select some (topological) properties of the recommendation data and three GNNs-based recommender systems (i.e., LightGCN, DGCF, and SVD-GCN). Then, starting from three popular recommendation datasets (i.e., Yelp2018, Gowalla, and Amazon-Book) we sample them to obtain 1,800 size-reduced datasets that still resemble the original ones but can encompass a wider range of topological structures. We use this procedure to build a large pool of samples for which data characteristics and recommendation performance of the selected GNNs models are measured. Through an explanatory framework, we find strong correspondences between graph topology and GNNs performance, offering a novel evaluation perspective on these models.</p>
    <p><strong>Categories:</strong> Graph Neural Networks, GNN-based Recommender Systems, Recommendation Systems, Real-World Applications, Evaluation Framework, Graph Topology Analysis, Data Characteristics, Recommendation Performance, Scalability, Robustness, Model Interpretability, Beyond Accuracy, Evaluation Metrics, Novel Evaluation Perspective (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1116/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Revisiting LightGCN: Unexpected Inflexibility, Inconsistency, and A Remedy Towards Improved Recommendation (2024)</h3>
    <p><strong>Authors:</strong> Geon Lee, Kijung Shin, Kyungho Kim</p>
    <p>Graph Neural Networks (GNNs) have emerged as effective tools in recommender systems. Among various GNN models, LightGCN is distinguished by its simplicity and outstanding performance. Its efficiency has led to widespread adoption across different domains, including social, bundle, and multimedia recommendations. In this paper, we thoroughly examine the mechanisms of LightGCN, focusing on its strategies for scaling embeddings, aggregating neighbors, and pooling embeddings across layers. Our analysis reveals that, contrary to expectations based on its design, LightGCN suffers from inflexibility and inconsistency when applied to real-world data. We introduce LightGCN++, an enhanced version of LightGCN designed to address the identified limitations. LightGCN++ incorporates flexible scaling of embedding norms and neighbor weighting, along with a tailored approach for pooling layer-wise embeddings to resolve the identified inconsistencies. Despite its remarkably simple remedy, extensive experimental results demonstrate that LightGCN++ significantly outperforms LightGCN, achieving an improvement of up to 17.81% in terms of NDCG@20. Furthermore, state-of-the-art models utilizing LightGCN as a backbone for item, bundle, multimedia, and knowledge-graph-based recommendations exhibit improved performance when equipped with LightGCN++.</p>
    <p><strong>Categories:</strong> Graph Neural Networks (GNNs), Recommendation Systems, LightGCN, Algorithm Design, Evaluation Metrics, Embedding Techniques, Social Recommendations, Bundle Recommendations, Multimedia Recommendations, Model Limitations, Algorithm Optimization, Recommendation Quality (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1110/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Repeated Padding for Sequential Recommendation (2024)</h3>
    <p><strong>Authors:</strong> Jianzhe Zhao, Linying Jiang, Yuting Liu, Yizhou Dang, Xingwei Wang, Guibing Guo, Enneng Yang</p>
    <p>Sequential recommendation aims to provide users with personalized suggestions based on their historical interactions. When training sequential models, padding is a widely adopted technique for two main reasons: 1) The vast majority of models can only handle fixed-length sequences; 2) Batch-based training needs to ensure that the sequences in each batch have the same length. The special value 0 is usually used as the padding content, which does not contain the actual information and is ignored in the model calculations. This common-sense padding strategy leads us to a problem that has never been explored in the recommendation field: Can we utilize this idle input space by padding other content to improve model performance and training efficiency further? In this paper, we propose a simple yet effective padding method called Repeated Padding (RepPad). Specifically, we use the original interaction sequences as the padding content and fill it to the padding positions during model training. This operation can be performed a finite number of times or repeated until the input sequences’ length reaches the maximum limit. Our RepPad can be considered as a sequence-level data augmentation strategy. Unlike most existing works, our method contains no trainable parameters or hyperparameters and is a plug-and-play data augmentation operation. Extensive experiments on various categories of sequential models and five real-world datasets demonstrate the effectiveness and efficiency of our approach. The average recommendation performance improvement is up to 60.3% on GRU4Rec and 24.3% on SASRec. We also provide in-depth analysis and explanation of what makes RepPad effective from multiple perspectives. The source code will be released to ensure the complete reproducibility of our experiments.</p>
    <p><strong>Categories:</strong> Sequential Models, Recommendation Systems, Data Augmentation, Sequence Padding, Model Performance, Training Efficiency, Real-World Datasets, Reproducibility, Deep Learning, Beyond Accuracy (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1061/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Is It Really Complementary? Revisiting Behavior-based Labels for Complementary Recommendation (2024)</h3>
    <p><strong>Authors:</strong> Kazushi Okamoto, Kai Sugahara, Chihiro Yamasaki</p>
    <p>Complementary recommendation is a type of item-to-item recommendation that recommends what should be purchased together for an item. Previous studies have traditionally used behavior-based labels (BBLs) that are constructed from the co-purchase logs of users for training and evaluation because rigorous label construction for complements is inefficient. However, the fact that many item pairs in BBLs are not functionally complementary, even though they are frequently co-purchased, has been overlooked. This study aimed to re-evaluate the validity of BBLs through functional relationships and provide directions for their improvement. Quantitative analysis using manually annotated function-based labels (FBLs) as correct labels revealed that the accuracy of the complementary recommendations generated by BBLs was below 50%, suggesting potential functional incompatibility within BBLs. Existing models that were trained on BBLs were similarly inaccurate, indicating the unreliability of the evaluations in existing studies. Finally, we proposed a label correction method for BBLs using a small set of FBLs, thereby providing a direction for reliable complementary recommendations.</p>
    <p><strong>Categories:</strong> Complementary Recommendations, Behavior-based Labels (BBLs), Item-to-Item Recommendations, Functional Relationships, Evaluation Metrics, Label Correction, Data Annotation, Recommendation Systems, E-commerce, Reliability. (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1196/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>MARec: Metadata Alignment for cold-start Recommendation (2024)</h3>
    <p><strong>Authors:</strong> Anirban Majumder, Wentao Lu, Julien Monteil, Volodymyr Vaskovych, Anton van den Hengel</p>
    <p>For many recommender systems the primary data source is a historical record of user clicks. The associated click matrix which is often very sparse, however, as the number of users x products can be far larger than the number of clicks, and such sparsity is accentuated in cold-start settings. The sparsity of the click matrix is the reason matrix factorization and autoencoders techniques remain highly competitive across collaborative filtering datasets. In this work, we propose a simple approach to address cold-start recommendations by leveraging content metadata, Metadata Alignment for cold-start Recommendation (MARec). we show that this approach can readily augment existing matrix factorization and autoencoder approaches, enabling a smooth transition to top performing algorithms in warmer set-ups. Our experimental results indicate three separate contributions: first, we show that our proposed framework largely beats SOTA results on 4 cold-start datasets with different sparsity and scale characteristics, with gains ranging from +8.4% to +53.8% on reported ranking metrics; second, we provide an ablation study on the utility of semantic features, and proves the additional gain obtained by leveraging such features ranges between +46.8% and +105.5%; and third, our approach is by construction highly competitive in warm set-ups, and we propose a closed-form solution outperformed by SOTA results by only 0.8% on average.</p>
    <p><strong>Categories:</strong> Cold Start, Metadata Alignment, Matrix Factorization, Collaborative Filtering, Data Sparsity, State of the Art, Ablation Study, Beyond Accuracy, Real-World Applications, Recommendation Systems, Novel Approach, Content-Based Filtering (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1044/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>