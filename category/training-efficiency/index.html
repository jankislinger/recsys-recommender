<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui primary button" style="margin: 5px;"
             href="/recsys-recommender/">Training Efficiency</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reproducibility/">Reproducibility</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/evaluation-metrics/">Evaluation Metrics</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/e-commerce/">E-commerce</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reinforcement-learning/">Reinforcement Learning</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Repeated Padding for Sequential Recommendation (2024)</h3>
    <p><strong>Authors:</strong> Jianzhe Zhao, Linying Jiang, Yuting Liu, Yizhou Dang, Xingwei Wang, Guibing Guo, Enneng Yang</p>
    <p>Sequential recommendation aims to provide users with personalized suggestions based on their historical interactions. When training sequential models, padding is a widely adopted technique for two main reasons: 1) The vast majority of models can only handle fixed-length sequences; 2) Batch-based training needs to ensure that the sequences in each batch have the same length. The special value 0 is usually used as the padding content, which does not contain the actual information and is ignored in the model calculations. This common-sense padding strategy leads us to a problem that has never been explored in the recommendation field: Can we utilize this idle input space by padding other content to improve model performance and training efficiency further? In this paper, we propose a simple yet effective padding method called Repeated Padding (RepPad). Specifically, we use the original interaction sequences as the padding content and fill it to the padding positions during model training. This operation can be performed a finite number of times or repeated until the input sequences’ length reaches the maximum limit. Our RepPad can be considered as a sequence-level data augmentation strategy. Unlike most existing works, our method contains no trainable parameters or hyperparameters and is a plug-and-play data augmentation operation. Extensive experiments on various categories of sequential models and five real-world datasets demonstrate the effectiveness and efficiency of our approach. The average recommendation performance improvement is up to 60.3% on GRU4Rec and 24.3% on SASRec. We also provide in-depth analysis and explanation of what makes RepPad effective from multiple perspectives. The source code will be released to ensure the complete reproducibility of our experiments.</p>
    <p><strong>Categories:</strong> Sequential Models, Recommendation Systems, Data Augmentation, Sequence Padding, Model Performance, Training Efficiency, Real-World Datasets, Reproducibility, Deep Learning, Beyond Accuracy (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1061/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Exploring Coresets for Efficient Training and Consistent Evaluation of Recommender Systems (2024)</h3>
    <p><strong>Authors:</strong> Zheng Ju, Neil Hurley, Honghui Du, Elias Tragos, Aonghus Lawlor</p>
    <p>Recommender systems have achieved remarkable success in various web applications, such as e-commerce, online advertising, and social media, harnessing the power of big data. To attain optimal model performance, recommender systems are typically trained on very large datasets, with substantial numbers of users and items. However, large datasets often present challenges in terms of processing time and computational resources. Coreset selection offers a method for obtaining a reduced yet representative subset from vast datasets, thereby enhancing the efficiency of training machine learning algorithms. Nevertheless, little research has been conducted to explore the practical implications of different coreset selection approaches on the performance of recommender systems algorithms. In this paper, we systematically investigate the impact of various coreset selection techniques. We evaluate the performance of the resulting coresets using inductive recommendation models which allow for consistent evaluations to be performed. The experimental results demonstrate that coreset methods are a powerful and useful approach for obtaining reduced datasets which preserve the properties of the large original dataset and have competitive performance compared to the time required to train with the full dataset.</p>
    <p><strong>Categories:</strong> Coreset Selection, Recommender Systems, Algorithm Optimization, Evaluation Metrics, Data Reduction Techniques, Machine Learning, Big Data, Inductive Models, Web Applications, Computational Resources, Training Efficiency (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1191/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>gSASRec: Reducing Overconfidence in Sequential Recommendation Trained with Negative Sampling (2023)</h3>
    <p><strong>Authors:</strong> Craig Macdonald, Aleksandr V. Petrov</p>
    <p>Large catalogue size is one of the central challenges in training recommendation models: a large number of items makes it infeasible to compute scores for all items during training, forcing models to deploy negative sampling. However, negative sampling increases the proportion of positive interactions in the training data. Therefore models trained with negative sampling tend to overestimate the probabilities of positive interactions — a phenomenon we call overconfidence. While the absolute values of the predicted scores/probabilities are unimportant for ranking retrieved recommendations, overconfident models may fail to estimate nuanced differences in the top-ranked items, resulting in degraded performance. This paper shows that overconfidence explains why the popular SASRec model underperforms when compared to BERT4Rec (contrary to the BERT4Rec authors’ attribution to the bi-directional attention mechanism). We propose a novel Generalised Binary Cross-Entropy Loss function (gBCE) to mitigate overconfidence and theoretically prove that it can mitigate overconfidence. We further propose the gSASRec model, an improvement over SASRec that deploys an increased number of negatives and gBCE loss. We show through detailed experiments on three datasets that gSASRec does not exhibit the overconfidence problem. As a result, gSASRec can outperform BERT4Rec (e.g.\ +9.47\% NDCG on MovieLens-1M), while requiring less training time (e.g.\ -73\% training time on MovieLens-1M). Moreover, in contrast to BERT4Rec, gSASRec is suitable for large datasets that contain more than 1 million items.</p>
    <p><strong>Categories:</strong> Sequential Recommendation, Negative Sampling, Cross-Entropy Loss, Overconfidence, Recommendation Systems, Movies, Diversity of Recommendations, Beyond Accuracy, Scalability, Training Efficiency (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/864/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Scaling Session-Based Transformer Recommendations using Optimized Negative Sampling and Loss Functions (2023)</h3>
    <p><strong>Authors:</strong> Philipp Normann, Timo Wilm, Paul-Vincent Kobow, Sophie Baumeister</p>
    <p>This work introduces TRON, a scalable session-based Transformer Recommender using Optimized Negative-sampling. Motivated by the scalability and performance limitations of prevailing models such as SASRec and GRU4Rec+, TRON integrates top-k negative sampling and listwise loss functions to enhance its recommendation accuracy. Evaluations on relevant large-scale e-commerce datasets show that TRON improves upon the recommendation quality of current methods while maintaining training speeds similar to SASRec. A live A/B test yielded an 18.14% increase in click-through rate over SASRec, highlighting the potential of TRON in practical settings. For further research, we provide access to our source code and an anonymized dataset.</p>
    <p><strong>Categories:</strong> Transformer-Based Recommenders, Session-Based Recommendations, Negative Sampling, Listwise Loss Functions, E-commerce, Scalability, Recommender Systems Evaluation, A/B Testing, Real-World Applications, Training Efficiency, Recommendation Accuracy (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1007/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Turning Dross Into Gold Loss: is BERT4Rec really better than SASRec? (2023)</h3>
    <p><strong>Authors:</strong> Alexey Vasilev, Anton Klenitskiy</p>
    <p>Recently sequential recommendations and next-item prediction task has become increasingly popular in the field of recommender systems. Currently, two state-of-the-art baselines are Transformer-based models SASRec and BERT4Rec. Over the past few years, there have been quite a few publications comparing these two algorithms and proposing new state-of-the-art models. In most of the publications, BERT4Rec achieves better performance than SASRec. But BERT4Rec uses cross-entropy over softmax for all items, while SASRec uses negative sampling and calculates binary cross-entropy loss for one positive and one negative item. In our work, we show that if both models are trained with the same loss, which is used by BERT4Rec, then SASRec will significantly outperform BERT4Rec both in terms of quality and training speed. In addition, we show that SASRec could be effectively trained with negative sampling and still outperform BERT4Rec, but the number of negative examples should be much larger than one.</p>
    <p><strong>Categories:</strong> Sequential Recommendations, Transformer-Based Models, BERT4Rec, SASRec, Algorithm Comparison, Loss Functions, Evaluation Metrics, State-of-the-Art Models, Training Efficiency, Model Performance, Recommender Systems, Negative Sampling, Cross-Entropy Loss, Binary Cross-Entropy Loss (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/966/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Recommending in changing times (2020)</h3>
    <p><strong>Authors:</strong> Manoj Nambiar, Amey Pandit, Rekha Singhal, Shruti Kunde, Shashank Gupta, Mayank Mishra, Gautam Shroff</p>
    <p>Recommender systems today face major challenges in keeping up with dynamic customer preferences. Disruptions or sudden changes in the environment affect customer preferences drastically and render historical data ineffective for modeling. With businesses relying heavily on Machine Learning(ML) based recommender systems for catering to customer preferences, the accuracy of timely recommendations gains prime significance. To address these challenges, we propose a novel concept, LDT (Labeled Data Threshold), a newly defined parameter to determine the sufficiency of available labeled training data. Our proposed scheme, using LDT leads to a significant reduction (  50X) in the training time for a model, thus enabling recommender systems to adapt quickly to disruptions. We illustrate the efficacy of our proposed scheme, by conducting extensive experimental analysis on six well known, structured data sets from various public domains.</p>
    <p><strong>Categories:</strong> Machine Learning, Recommendation Systems, Dynamic Environments, Adaptability, Scalability, Empirical Evaluation, Training Efficiency, Novel Concepts (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/613/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>