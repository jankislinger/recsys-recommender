<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui primary button" style="margin: 5px;"
             href="/recsys-recommender/">Performance Prediction</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reinforcement-learning/">Reinforcement Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/real-world-applications/">Real-world Applications</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/bias-mitigation/">Bias Mitigation</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reproducibility/">Reproducibility</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Generative Learning Plan Recommendation for Employees: A Performance-aware Reinforcement Learning Approach (2023)</h3>
    <p><strong>Authors:</strong> Ying Sun, Xin Song, Hengshu Zhu, Hui Xiong, Zhi Zheng</p>
    <p>With the rapid development of enterprise Learning Management Systems (LMS), more and more companies are trying to build enterprise training and course learning platforms for promoting the career development of employees. Indeed, through course learning, many employees have the opportunity to improve their knowledge and skills. For these systems, a major issue is how to recommend learning plans, i.e., a set of courses arranged in the order they should be learned, that can help employees improve their work performance. Existing studies mainly focus on recommending courses that users are most likely to click on by capturing their learning preferences. However, the learning preference of employees may not be the right fit for their career development, and thus it may not necessarily mean their work performance can be improved accordingly. Furthermore, how to capture the mutual correlation and sequential effects between courses, and ensure the rationality of the generated results, is also a major challenge. To this end, in this paper, we propose the Generative Learning plAn recommenDation (GLAD) framework, which can generate personalized learning plans for employees to help them improve their work performance. Specifically, we first design a performance predictor and a rationality discriminator, which have the same transformer-based model architecture, but with totally different parameters and functionalities. In particular, the performance predictor is trained for predicting the work performance of employees based on their work profiles and historical learning records, while the rationality discriminator aims to evaluate the rationality of the generated results. Then, we design a learning plan generator based on the gated transformer and the cross-attention mechanism for learning plan generation. We calculate the weighted sum of the output from the performance predictor and the rationality discriminator as the reward, and we use Self-Critical Sequence Training (SCST) based policy gradient methods to train the generator following the Generative Adversarial Network (GAN) paradigm. Finally, extensive experiments on real-world data clearly validate the effectiveness of our GLAD framework compared with state-of-the-art baseline methods and reveal some interesting findings for talent management</p>
    <p><strong>Categories:</strong> Employee Training, Career Development, Learning Plan Generation, Reinforcement Learning, Sequence Modeling, Performance Prediction, Rationality Evaluation, Dual-Model Framework, Algorithm Design, Policy Gradient Methods, GAN-based Models, Practical Applications, Performance Comparison (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/868/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Predicting Online Performance of Job Recommender Systems With Offline Evaluation (2019)</h3>
    <p><strong>Authors:</strong> Adrien Mogenet, Tuan Anh Nguyen Pham, Masahiro Kazama, Jialin Kong</p>
    <p>Recommender systems can be used to recommend jobs. In this context, implicit and explicit feedback signals we can collect are rare events, making the task of evaluation more complex. Online evaluation (A-B testing) is usually the most reliable way to measure the results from our experiments, but it is a slow process. In contrast, the offline evaluation process is faster, but it is critical to make it reliable as it informs our decision to roll out new improvements in production. In this paper, we review the comparative offline and online performances of three recommendations models, we describe the evaluation metrics we use and analyze how the offline performance metrics correlate with online metrics to understand how an offline evaluation process can be leveraged to inform the decisions. i>Presentation: Wednesday Poster Lunch</i</p>
    <p><strong>Categories:</strong> Job Recommendations, Recommendation Models, Offline Evaluation, Online Evaluation, Evaluation Metrics, Model Comparison, Performance Prediction, Decision-Making, Methodology (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/487/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>A Novel Recommender System for Helping Marathoners to Achieve a New Personal-Best (2017)</h3>
    <p><strong>Authors:</strong> Barry Smyth, Padraig Cunningham</p>
    <p>We describe a novel application of recommender systems, helping marathon runners to run a new personal-best race-time, by predicting a challenging, but achievable, target-time and by recommending a race-plan to achieve this time that is tailored to their ability and the course. A comprehensive evaluation of prediction accuracy and race-plan quality is provided using a large-scale dataset with almost 400,000 runners from the last 12 years of the Chicago marathon.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Sports, Running, Performance Prediction, User-Centered Design, Evaluation Methods, Large-Scale Data Analysis, Target Setting/Goal Setting, Race Planning/Strategy (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/284/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Predicting Online Performance of News Recommender Systems Through Richer Evaluation Metrics (2015)</h3>
    <p><strong>Authors:</strong> Boi Faltings, Florent Garcin, Andrii Maksai</p>
    <p>We investigate how metrics that can be measured offine can be used to predict the online performance of recommender systems, thus avoiding costly A-B testing. In addition to accuracy metrics, we combine diversity, coverage, and serendipity metrics to create a new performance model. Using the model, we quantify the trade-off between different metrics and propose to use it to tune the parameters of recommender algorithms without the need for online testing. Another application for the model is a self-adjusting algorithm blend that optimizes a recommenderâ€™s parameters over time. We evaluate our findings on data and experiments from news websites.</p>
    <p><strong>Categories:</strong> News, Recommender Systems, Evaluation Metrics, Diversity of Recommendations, Coverage, Serendipity, Richer Evaluation Metrics, Algorithm Optimization, Performance Prediction, Real World Applications, A/B Test (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/105/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>