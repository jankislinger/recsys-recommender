<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui primary button" style="margin: 5px;"
             href="/recsys-recommender/">Neural Collaborative Filtering</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/explainability/">Explainability</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/real-world-applications/">Real-world Applications</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reinforcement-learning/">Reinforcement Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Reenvisioning the comparison between Neural Collaborative Filtering and Matrix Factorization (2021)</h3>
    <p><strong>Authors:</strong> Alejandro Bellogin, Claudio Pomo, Vito Walter Anelli, Tommaso Di Noia Polytechnic</p>
    <p>Collaborative filtering models based on matrix factorization and learned similarities using Artificial Neural Networks (ANNs) have gained significant attention in recent years. This is, in part, because ANNs have demonstrated very good results in a wide variety of recommendation tasks. However, the introduction of ANNs within the recommendation ecosystem has been recently questioned, raising several comparisons in terms of efficiency and effectiveness. One aspect most of these comparisons have in common is their focus on accuracy, neglecting other evaluation dimensions important for the recommendation, such as novelty, diversity, or accounting for biases. In this work, we replicate experiments from three different papers that compare Neural Collaborative Filtering (NCF) and Matrix Factorization (MF), to extend the analysis to other evaluation dimensions. First, our contribution shows that the experiments under analysis are entirely reproducible, and we extend the study including other accuracy metrics and two statistical hypothesis tests. Second, we investigated the Diversity and Novelty of the recommendations, showing that MF provides a better accuracy also on the long tail, although NCF provides a better item coverage and more diversified recommendation lists. Lastly, we discuss the bias effect generated by the tested methods. They show a relatively small bias, but other recommendation baselines, with competitive accuracy performance, consistently show to be less affected by this issue. This is the first work, to the best of our knowledge, where several complementary evaluation dimensions have been explored for an array of state-of-the-art algorithms covering recent adaptations of ANNs and MF. Hence, we aim to show the potential these techniques may have on beyond-accuracy evaluation while analyzing the effect on reproducibility these complementary dimensions may spark. The code to reproduce the experiments is publicly available on GitHub at https://tny.sh/Reenvisioning.</p>
    <p><strong>Categories:</strong> Neural Collaborative Filtering, Matrix Factorization, Artificial Neural Networks, Recommendation Systems, Evaluation Metrics, Diversity of Recommendations, Novelty of Recommendations, Bias in Recommendations, Reproducibility, Beyond Accuracy, State-of-the-Art Algorithms, Experimental Design, Real-World Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/677/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>ProtoCF: Prototypical Collaborative Filtering for Few-shot Item Recommendation (2021)</h3>
    <p><strong>Authors:</strong> Aravind Sankar, Hari Sundaram, Junting Wang, Adit Krishnan</p>
    <p>In recent times, deep learning methods have supplanted conventional collaborative filtering approaches as the backbone of modern recommender systems. However, their gains are skewed towards popular items with a drastic performance drop for the vast collection of long-tail items with sparse interactions. Moreover, we empirically show that prior neural recommenders lack the resolution power to accurately rank relevant items within the long-tail. In this paper, we formulate long-tail item recommendations as a few-shot learning problem of learning-to-recommend few-shot items with very few interactions. We propose a novel meta-learning framework ProtoCF that learns-to-compose robust prototype representations for few-shot items. ProtoCF utilizes episodic few-shot learning to extract meta-knowledge across a collection of diverse meta-training tasks designed to mimic item ranking within the tail. To further enhance discriminative power, we propose a novel architecture-agnostic technique based on knowledge distillation to extract, relate, and transfer knowledge from neural base recommenders. Our experimental results demonstrate that ProtoCF consistently outperforms state-of-art approaches on overall recommendation (by 5% Recall@50) while achieving significant gains (of 60-80% Recall@50) for tail items with less than 20 interactions.</p>
    <p><strong>Categories:</strong> Collaborative Filtering, Few-shot Learning, Long-tail Problem, Recommendation Systems, Meta-Learning, Knowledge Distillation, Neural Collaborative Filtering, Scalability, Experimental Results, Real-world Applications, Beyond Accuracy, Prototypical Networks, Recommendation Quality, Evaluation Metrics, Architecture-Agnostic (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/653/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Neural Collaborative Filtering vs. Matrix Factorization Revisited (2020)</h3>
    <p><strong>Authors:</strong> John Anderson, Steffen Rendle, Walid Krichene, Li Zhang</p>
    <p>Embedding based models have been the state of the art in collaborative filtering for over a decade. Traditionally, the dot product or higher order equivalents have been used to combine two or more embeddings, e.g., most notably in matrix factorization. In recent years, it was suggested to replace the dot product with a learned similarity e.g. using a multilayer perceptron (MLP). This approach is often referred to as neural collaborative filtering (NCF). In this work, we revisit the experiments of the NCF paper that popularized learned similarities using MLPs. First, we show that with a proper hyperparameter selection, a simple dot product substantially outperforms the proposed learned similarities. Second, while a MLP can in theory approximate any function, we show that it is non-trivial to learn a dot product with an MLP. Finally, we discuss practical issues that arise when applying MLP based similarities and show that MLPs are too costly to use for item recommendation in production environments while dot products allow to apply very efficient retrieval algorithms. We conclude that MLPs should be used with care as embedding combiner and that dot products might be a better default choice.</p>
    <p><strong>Categories:</strong> Neural Collaborative Filtering, Matrix Factorization, Algorithm Comparison, Hyperparameters, Recommendation Systems, Evaluation Metrics, Production Systems, Efficiency, Cost Analysis, Traditional Methods vs. Neural Methods, Practical Recommendations (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/590/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Deep Language-based Critiquing for Recommender Systems (2019)</h3>
    <p><strong>Authors:</strong> Ga Wu, Scott Sanner, Harold Soh, Kai Luo</p>
    <p>Critiquing is a method for conversational recommendation that adapts recommendations in response to user preference feedback regarding item attributes.  Historical critiquing methods were largely based on constraint- and utility-based methods for modifying recommendations w.r.t. these critiqued attributes.  In this paper, we revisit the critiquing approach from the lens of deep learning based recommendation methods and language-based interaction.  Concretely, we propose an end-to-end deep learning framework with two variants that extend the Neural Collaborative Filtering architecture with explanation and critiquing components.  These architectures not only predict personalized keyphrases for a user and item but also embed language-based feedback in the latent space that in turn modulates subsequent critiqued recommendations. We evaluate the proposed framework on two recommendation datasets containing user reviews.  Empirical results show that our modified NCF approach not only provides a strong baseline recommender and high-quality personalized item keyphrase suggestions, but that it also properly suppresses items predicted to have a critiqued keyphrase. In summary, this paper provides a first step to unify deep recommendation and language-based feedback in what we hope to be a rich space for future research in deep critiquing for conversational recommendation.</p>
    <p><strong>Categories:</strong> Neural Collaborative Filtering, Deep Learning, Recommendation Systems, Critiquing, User Feedback, Natural Language Processing, Beyond Accuracy, Diversity of Recommendations (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/435/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Context-Regularized Neural Collaborative Filtering for Game App Recommendation (2019)</h3>
    <p><strong>Authors:</strong> Shonosuke Harada, Kazuki Taniguchi, Makoto Yamada, Hisashi Kashima</p>
    <p>People spend a substantial amount of time playing games on their smartphones. Owing to growth in the number of newly released games, it is getting more difficult for people to identify which of the broad selection of games they want to play. In this paper, we introduce context-aware recommendation for game apps that combines neural collaborative filtering and item embedding. We find that some contexts special to games are effective in representing item embeddings in implicit feedback situations. Experimental results show that our proposed method outperforms conventional methods.</p>
    <p><strong>Categories:</strong> Context Regularization, Game Apps, Neural Collaborative Filtering, Item Embedding, Mobile Apps, Implicit Feedback, Recommendation Systems, Evaluation Methods (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/513/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>