<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/explainability/">Explainability</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/real-world-applications/">Real-world Applications</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/offline-evaluation/">Offline Evaluation</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/bias-mitigation/">Bias Mitigation</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reproducibility/">Reproducibility</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Merlin HugeCTR: GPU-accelerated Recommender System Training and Inference (2022)</h3>
    <p><strong>Authors:</strong> Xu Guo, Matthias Langer, Yingcan Wei, Kunlun Li, Jie Liu, Jianbing Dong, Minseok Lee, Ji Shi, Zehuan Wang, Shijie Liu, Fan Yu, Daniel G. Abel</p>
    <p>In this talk, we introduce Merlin HugeCTR. Merlin HugeCTR is an open source, GPU-accelerated integration framework for click-through rate estimation. It optimizes both training and inference, whilst enabling model training at scale with model-parallel embeddings and data-parallel neural networks. In particular, Merlin HugeCTR combines a high-performance GPU embedding cache with an hierarchical storage architecture, to realize low-latency retrieval of embeddings for online model inference tasks. In the MLPerf v1.0 DLRM model training benchmark, Merlin HugeCTR achieves a speedup of up to 24.6x on a single DGX A100 (8x A100) over PyTorch on 4x4-socket CPU nodes (4x4x28 cores). Merlin HugeCTR can also take advantage of multi-node environments to accelerate training even further. Since late 2021, Merlin HugeCTR additionally features a hierarchical parameter server (HPS) and supports deployment via the NVIDIA Triton server framework, to leverage the computational capabilities of GPUs for high-speed recommendation model inference. Using this HPS, Merlin HugeCTR users can achieve a 5~62x speedup (batch size dependent) for popular recommendation models over CPU baseline implementations, and dramatically reduce their end-to-end inference latency.</p>
    <p><strong>Categories:</strong> GPU Acceleration, Recommender Systems, Click-Through Rate Estimation, Training Optimization, Inference Optimization, Model-Parallel Embeddings, Data-Parallel Neural Networks, High-Performance Computing, MLPerf Benchmark, Distributed Computing, Hierarchical Storage Architecture, Hierarchical Parameter Server (HPS), NVIDIA Triton Server, Real-World Applications, Big Data, Performance Benchmarks (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/839/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>BETA-Rec: Build, Evaluate and Tune Automated Recommender Systems (2020)</h3>
    <p><strong>Authors:</strong> Iadh Ounis, Yaxiong Wu, Shangsong Liang, Zaiqiao Meng, Craig Macdonald, Guangtao Zeng, Richard McCreadie, Siwei Liu, Yucheng Liang, Qiang Zhang, Junhua Liang</p>
    <p>The field of recommender systems has rapidly evolved over the last few years, with significant advances made due to the in-flux of deep learning techniques. However, as a result of this rapid progress, escalating barriers-to-entry for new researchers is emerging. In particular, state-of-the-art approaches have fragmented into a large number of code-bases, often requiring different input formats, pre-processing stages and evaluating with different metric packages. Hence, it is time-consuming for new researchers to reach the point of having both an effective baseline set and a sound comparative environment. As a step towards elevating this problem, we have developed BETA-Rec, an open source project for Building, Evaluating and Tuning Automated Recommender Systems. BETA-Rec aims to provide a practical data toolkit for building end-to-end recommendation systems in a standardized way. It provides means for dataset preparation and splitting using common strategies, a generalized model engine for implementing recommender models using Pytorch with 9 models available out-of-the-box, as well as a unified training, validation, tuning and testing pipeline. Furthermore, BETA-Rec is designed to be both modular and extensible, enabling new models to be quickly added to the framework. It is deployable in a wide range of environments via pre-built docker containers and supports distributed parameter tuning using Ray. In this demo, we will illustrate the deployment and use of BETA-Rec for researchers and practitioners on a number of standard recommendation datasets. The source code of the project is available at github: https://github.com/beta-team/beta-recsys.</p>
    <p><strong>Categories:</strong> Recommender Systems, Machine Learning Methods, Open Source Tools, Pre-trained Models, Hyperparameter Optimization, Deployment, Practical Applications, Modular Frameworks, Distributed Computing, Data Preprocessing, Benchmarking (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/594/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Efficient Similarity Computation for Collaborative Filtering in Dynamic Environments (2019)</h3>
    <p><strong>Authors:</strong> Olivier Jeunen, Bart Goethals, Koen Verstrepen</p>
    <p>The problem of computing all pairwise similarities in a large collection of vectors is a well-known and common data mining task. As the number and dimensionality of these vectors keeps increasing, however, currently existing approaches are often unable to meet the strict efficiency requirements imposed by the environments they need to perform in. Real-time neighbourhood-based collaborative filtering (CF) is one example of such an environment in which performance is critical. In this work, we present a novel algorithm for efficient and exact similarity computation between sparse, high-dimensional vectors. Our approach exploits the sparsity that is inherent to implicit feedback data-streams, entailing significant gains compared to other methods. Furthermore, as our model learns incrementally, it is naturally suited for dynamic real-time CF environments. We propose a MapReduce-inspired parallellisation procedure along with our method, and show how even more speed-up can be achieved. Additionally, in many real-world systems, many items are actually not recommendable at any given time, due to recency, stock, seasonality, or enforced business rules. We exploit this fact to further improve the computational efficiency of our approach. Experimental evaluation on both real-world and publicly available datasets shows that our approach scales up to millions of processed user-item interactions per second, and well advances the state-of-the-art. ,</p>
    <p><strong>Categories:</strong> Collaborative Filtering, Recommendation Systems, Algorithm Efficiency, High-Dimensional Data, Dynamic Environments, Distributed Computing, Real-World Applications, Performance Evaluation (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/443/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Guided Walk: A Scalable Recommendation Algorithm for Complex Heterogeneous Social Networks (2016)</h3>
    <p><strong>Authors:</strong> Uzi Cohen, Roy Levin, Hassan Abassi</p>
    <p>Online social networks have become predominant in recent years and have grown to encompass massive scales of data. In addition to data scale, these networks can be heterogeneous and contain complex structures between different users, between social entities and various interactions between users and social entities. This is especially true in enterprise social networks where hierarchies explicitly exist between employees as well. In such networks, producing the best recommendations for each user is a very challenging problem for two main reasons. First, the complex structures in the social network need to be properly mined and exploited by the algorithm. Second, these networks contain millions or even billions of edges making the problem very difficult computationally. In this paper we present Guided Walk, a supervised graph based algorithm that learns the significance of different network links for each user and then produces entity recommendations based on this learning phase. We compare the algorithm with a set of baseline algorithms using offline evaluation techniques as well as a user survey. The offline results show that the algorithm outperforms the next best algorithm by a factor of 3.6. The user survey further confirms that the recommendation are not only relevant but also rank high in terms of personal relevance for each user. To deal with large scale social networks, the Guided Walk algorithm is formulated as a Pregel program which allows us to utilize the power of distributed parallel computing. This would allow horizontally scaling the algorithm for larger social networks by simply adding more compute nodes to the cluster.</p>
    <p><strong>Categories:</strong> Social Networks, Recommendation Systems, Scalability, Graph-Based Algorithms, Enterprise Social Networks, Offline Evaluation Techniques, User Surveys, Personalization, Distributed Computing (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/184/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Scalable Audience Targeted Models for Brand Advertising on Social Networks (2014)</h3>
    <p><strong>Authors:</strong> Kunpeng Zhang</p>
    <p>People are using social media to generate, share, and communicate information with each other. Finding actionable insights from such big data has attracted a lot of research attentions on, for example, finding targeted user groups based on their historical on-line activities. However, existing machine learning algorithms fail to keep up with the increasing large data volume. In this paper, we develop a scalable regression-based algorithm called distributed iterative shrinkage-thresholding algorithm (DISTA) that can identify potential users. Our experiments conducted on Facebook data containing billions of users and associated activities show that DISTA with feature selection not only enables on-line audience-targeted approach for precise marketing but also performs efficiently on parallel computers.</p>
    <p><strong>Categories:</strong> Scalability, Social Media, Advertising, Machine Learning Algorithms, Distributed Computing, Feature Selection, Parallel Computing, Big Data Analysis, Audience Targeting, Real World Application (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/56/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>GASGD: Stochastic Gradient Descent for Distributed Asynchronous Matrix Completion via Graph Partitioning (2014)</h3>
    <p><strong>Authors:</strong> Fabio Petroni, Leonardo Querzoni</p>
    <p>Matrix completion latent factors models are known to be an effective method to build recommender systems. Currently, stochastic gradient descent (SGD) is considered one of the best latent factor-based algorithm for matrix completion. In this paper we discuss GASGD, a distributed asynchronous variant of SGD for large-scale matrix completion, that (i) leverages data partitioning schemes based on graph partitioning techniques, (ii) exploits specific characteristics of the input data and (iii) introduces an explicit parameter to tune synchronization frequency among the computing nodes. We empirically show how, thanks to these features, GASGD achieves a fast convergence rate incurring in smaller communication cost with respect to current asynchronous distributed SGD implementations.</p>
    <p><strong>Categories:</strong> Matrix Completion, Stochastic Gradient Descent (SGD), Recommender Systems, Distributed Computing, Asynchronous Algorithms, Graph Partitioning, Parallel Processing, Large-Scale Data, Communication Efficiency, Performance Analysis (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/22/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>