<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reproducibility/">Reproducibility</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/e-commerce/">E-commerce</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/performance-evaluation/">Performance Evaluation</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reinforcement-learning/">Reinforcement Learning</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>MMGCL: Meta Knowledge-Enhanced Multi-view Graph Contrastive Learning for Recommendations (2024)</h3>
    <p><strong>Authors:</strong> Wentao Zhang, Peng Jiang, Gaode Chen, Qi Zhang, Jingjian Lin, Changyu Li, Yuezihan Jiang, Peiyi Li, Fei Sun</p>
    <p>Multi-view Graph Learning is popular in recommendations due to its ability to capture relationships and connections across multiple views. Existing multi-view graph learning methods generally involve constructing graphs of views and performing information aggregation on view representations. Despite their effectiveness, they face two data limitations: Multi-focal Multi-source data noise and multi-source Data Sparsity. The former arises from the combination of noise from individual views and conflicting edges between views when information from all views is combined. The latter occurs because multi-view learning exacerbate the negative influence of data sparsity because these methods require more model parameters to learn more view information. Motivated by these issues, we propose MMGCL, a meta knowledge-enhanced multi-view graph contrastive learning framework for recommendations. To tackle the data noise issue, MMGCL extract meta knowledge to preserve important information from all views to form a meta view representation. It then rectifies every view in multi-learning frameworks, thus simultaneously removing the view-private noisy edges and conflicting edges across different views. To address the data sparsity issue, MMGCL performs meta knowledge transfer contrastive learning optimization on all views to reduce the searching space for model parameters and add more supervised signal. Besides, we have deployed MMGCL in a real industrial recommender system in China, and we further evaluate it on four benchmark datasets and a practical industry online application. Extensive experiments on these datasets demonstrate the state-of-the-art recommendation performance of MMGCL.</p>
    <p><strong>Categories:</strong> Recommendation Algorithms, Multi-View Graph Learning, Meta Knowledge Enhancement, Data Noise, Data Sparsity, Recommendations Domain, Challenges in Recommendations, Multi-View Learning, Real-World Applications, Industrial Applications, Unsupervised Learning, Beyond Accuracy (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1050/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Multiple Connectivity Views for Session-based Recommendation (2023)</h3>
    <p><strong>Authors:</strong> Zheng Miao, Yujing Wang, Yaming Yang, Jieyu Zhang, Yunhai Tong</p>
    <p>Session-based recommendation (SBR), which makes the next-item recommendation based on previous anonymous actions, has drawn increasing attention. The last decade has seen multiple deep learning-based modeling choices applied on SBR successfully, e.g., recurrent neural networks (RNNs), convolutional neural networks (CNNs), graph neural networks (GNNs), and each modeling choice has its intrinsic superiority and limitation. We argue that these modeling choices differentiate from each other by (1) the way they capture the interactions between items within a session and (2) the operators they adopt for composing the neural network, e.g., convolutional operator or self-attention operator. In this work, we dive deep into the former as it is relatively unique to the SBR scenario, while the latter is shared by general neural network modeling techniques. We first introduce the concept of connectivity view to describe the different item interaction patterns at the input level. Then, we develop the Multiple Connectivity Views for Session-based Recommendation (MCV-SBR), a unified framework that incorporates different modeling choices in a single model through the lens of connectivity view. In addition, MCV-SBR allows us to effectively and efficiently explore the search space of the combinations of connectivity views by the Tree-structured Parzen Estimator Approach (TPE) algorithm. Finally, on three widely used SBR datasets, we verify the superiority of MCV-SBR by comparing the searched models with state-of-the-art baselines. We also conduct a series of studies to demonstrate the efficacy and practicability of the proposed connectivity view search algorithm, as well as other components in MCV-SBR.</p>
    <p><strong>Categories:</strong> Session-based Recommendation, Neural Networks, Connectivity Views, Modeling Choices in SBR, Tree-structured Parzen Estimator (TPE), Deep Learning, Unsupervised Learning, Evaluation Studies, Recommendation Algorithms (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/938/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Semi-Supervised Visual Representation Learning for Fashion Compatibility (2021)</h3>
    <p><strong>Authors:</strong> Deepthi Sharma, Ambareesh Revanur, Vijay Kumar</p>
    <p>We consider the problem of complementary fashion prediction. Existing approaches focus on learning an embedding space where fashion items from different categories that are visually compatible are closer to each other. However, creating such labeled outfits is intensive and also not feasible to generate all possible outfit combinations, especially with large fashion catalogs. In this work, we propose a semi-supervised learning approach where we leverage large unlabeled fashion corpus to create pseudo positive and negative outfits on the fly during training. For each labeled outfit in a training batch, we obtain a pseudo-outfit by matching each item in the labeled outfit with unlabeled items. Additionally, we introduce consistency regularization to ensure that representation of the original images and their transformations are consistent to implicitly incorporate colour and other important attributes through self-supervision. We conduct extensive experiments on Polyvore, Polyvore-D and our newly created large-scale Fashion Outfits datasets, and show that our approach with only a fraction of labeled examples performs on-par with completely supervised methods.</p>
    <p><strong>Categories:</strong> Semi-Supervised Learning, Visual Representation Learning, Fashion Compatibility, Unsupervised Learning, Self-Supervision, Consistency Regularization, Dataset Creation, Evaluation Metrics, Real-World Applications, Scalability, Transfer Learning, Image Processing, Item Compatibility, Visual Similarity, Recommendation Systems (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/660/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Conversational Recommendation System with Unsupervised Learning (2016)</h3>
    <p><strong>Authors:</strong> Roger Jin, Yi Zhang, Yueming Sun, Yunfei Chen</p>
    <p>We will demonstrate a conversational products recommendation agent. This system shows how we combine research in personalized recommendation systems with research in dialogue systems to build a virtual sales agent. Based on new deep learning technologies we developed, the virtual agent is capable of learning how to interact with users, how to answer user questions, what is the next question to ask, and what to recommend when chatting with a human user. Normally a descent conversational agent for a particular domain requires tens of thousands of hand labeled conversational data or hand written rules. This is a major barrier when launching a conversation agent for a new domain. We will explore and demonstrate the effectiveness of the learning solution even when there is no hand written rules or hand labeled training data.</p>
    <p><strong>Categories:</strong> Conversational Recommendation, Unsupervised Learning, Deep Learning, Dialogue Systems, E-commerce/Retail, Personalization, Recommendation Systems, Domain Adaptation (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/235/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Deep Auto-Encoding for Context-Aware Inference of Preferred Items’ Categories (2016)</h3>
    <p><strong>Authors:</strong> Moshe Unger, Lior Rokach, Bracha Shapira, Ariel Bar</p>
    <p>Context-aware systems enable the sensing and analysis of user context in order to provide personalized services to users. We observed that it is possible to automatically learn contextual factors and behavioral patterns when users interact with the system. We later utilize the learned patterns to infer contextual user interests within a recommender system. We present a novel context-aware model for detecting users’ preferred items’ categories using an unsupervised deep learning technique applied to mobile sensor data. We train an auto-encoder for each item genre, using contextual data that was obtained when users interacted with the system. Given new contextual sensor data from a user, the discovered patterns from each auto-encoder are used to predict the category of items that should be recommended to the user in the given context. In order to collect rich contextual data, we conducted an extensive field study over a period of four weeks with a group of ninety users. The analysis reveals significant insights regarding the inference of different granularity levels of categories that are available within the data.</p>
    <p><strong>Categories:</strong> Autoencoder, Deep Learning, Unsupervised Learning, Context-Aware Recommendations, User Preference Inference, Mobile Systems, Recommender Systems, Real-World Applications, Beyond Accuracy, Field Study (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/227/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Assisting Emergent Readers in Finding Books to Read (2014)</h3>
    <p><strong>Authors:</strong> Maria Pera, Yiu-Kai Ng</p>
    <p>It is imperative to motivate children to read by offering them appealing books so that they can gradually establish a reading habit during their formative years. However, with the huge volume of existing and newly-published books, it is a challenge to find the right ones that match children’s interests and readability levels. In response to the needs, we have developed K3Rec, an unsupervised recommender, which suggests books that match the interests/preferences and reading abilities of emergent (i.e., K-3) readers.</p>
    <p><strong>Categories:</strong> Unsupervised Learning, Emergent Readers, Education, Elementary School, Readability, Age-Appropriate Content, Children&#39;s Education, Educational Recommender Systems, Reading Habits, Implicit Feedback, K3Rec, Personalization, Book Discovery (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/71/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>