<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/user-centric-design/">User-Centric Design</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reproducibility/">Reproducibility</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/beyond-accuracy/">Beyond Accuracy</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/evaluation-methods/">Evaluation Methods</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Personal Values and Community-Centric Environmental Recommender Systems: enhancing Sustainability through User Engagement (2024)</h3>
    <p><strong>Authors:</strong> Bianca Maria Deconcini</p>
    <p>The concept of sustainability has become a central focus across multiple sectors, driven by the urgent need to address climate change and protect the environment. Technological advancements and capabilities, together with the emergence of new ecological issues, are leading to growing awareness and influencing shifts in multiple areas such as energy, transportation, and waste management. Within this context, the roles of recommender systems represent a promising solution, since people need guidance and occasionally a gentle push to translate their intentions into actions or to bring goals to life. However, existing literature reveals a fragmented landscape, with solutions often addressing specific aspects or recommendation contribution in isolation. Many sustainability interventions focus solely on providing consumption data and environmental insights, while others emphasize learning and behavior change strategies. My doctoral project aims to address this gap by leveraging various approaches to recommender systems and applying them in sustainability contexts, with the goal to build a holistic system that maximizes the contributions of these diverse methods, also integrating user-centric and value-driven perspectives. This research project delves into two distinct facets: energy sustainability and sustainable mobility. The first case centers on enhancing energy efficiency within energy communities through personalized recommendations and engagement strategies. The second facet focuses on reshaping user commuting patterns towards sustainable alternatives, by recommending suitable and more sustainable modes of transportation, such as cycling, carpooling, and public transportation. Both cases share the same objective: align user behaviors with sustainability goals, thereby reducing individual environmental impact and enhancing the sense of belonging to a community, whether this is confined to a group of individuals or pertains to society at large. An innovative comprehensive recommendation system approach is highly beneficial since it can take advantage of all the existing contributions combined in a framework that makes at the same time different types of recommendations: explainable, educative, behavioral and social-aware, addressing the complexities of this multifaceted domain.</p>
    <p><strong>Categories:</strong> Environmental Sustainability, Sustainable Mobility, Energy Efficiency, Community Engagement, User-Centric Design, Value-Driven Approaches, Recommender Systems, Integrated Frameworks, Explainable Recommendations, Educative Recommendations, Behavioral Change, Social-Aware Recommendations, Fragmented Approaches (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1148/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>A New Perspective in Health Recommendations: Integration of Human Pose Estimation (2024)</h3>
    <p><strong>Authors:</strong> Gaetano Dibenedetto</p>
    <p>In recent years, there has been a growing interest in multimodal and multi-source data due to their ability to introduce heterogeneous information. Studies have demonstrated that combining such information enhances the performance of Recommender Systems across various scenarios. In the context of Health Recommendation Systems (HRS), different types of data are utilized, primarily focusing on patient-based information, but data from Pose Estimations (PE) are not incorporated. The objective of my Ph.D. is to investigate methods to design and develop HRS that treat the PE as one of the input sources, taking into account aspects such as privacy concerns and balancing the trade-off between system quality and responsiveness. By leveraging the combination of diverse information sources, I intend to create a new model in the area of HRS capable of providing more precise and explainable recommendations.</p>
    <p><strong>Categories:</strong> Healthcare, Recommender Systems, Human Pose Estimation, Multimodal Data, Explainable Recommendations, Precision, Privacy Concerns, Beyond Accuracy, Multi-Source Fusion, Cross-Modality, Machine Learning (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1126/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Instructing and Prompting Large Language Models for Explainable Cross-domain Recommendations (2024)</h3>
    <p><strong>Authors:</strong> Alessandro Petruzzelli, Cataldo Musto, Pasquale Lops, Marco de Gemmis, Ivan Rinaldi, Giovanni Semeraro, Lucrezia Laraspata</p>
    <p>In this paper, we present a strategy to provide users with explainable cross-domain recommendations (CDR) that exploits large language models (LLMs). Generally speaking, cross-domain recommender systems typically suffer of data sparsity issues, since they require a large amount of data labeled in both base and target domains, which are not easy to collect. Accordingly, our approach relies on the intuition that the knowledge that is already encoded in LLMs can be used to bridge the domains and seamlessly provide users with personalized cross-domain suggestions. To this end, we designed a pipeline to: (a) instruct a LLM to handle a CDR task; (b) design a personalized prompt, based on the preferences of the user in a base domain, in both zero-shot and one-shot settings; (c) feed the LLM with the prompt, and process the answer in order to extract the recommendations in a target domain, together with a natural language explanation supporting the suggestion. As shown in the experimental evaluation, our approach beats several established state-of-the-art baselines for CDR in most of the experimental settings, thus showing the effectiveness of LLMs also in this novel and scarcely investigated scenario.</p>
    <p><strong>Categories:</strong> Large Language Models (LLMs), Cross-domain Recommendations, Explainable Recommendations, Recommendation Systems, Personalization, Zero-shot Learning, One-shot Learning, Data Sparsity, Natural Language Processing (NLP), Instruction Following (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1049/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Explainable and Faithful Educational Recommendations through Causal Language Modelling via Knowledge Graphs (2024)</h3>
    <p><strong>Authors:</strong> Neda Afreen</p>
    <p>The rapid expansion of digital education has significantly increased the need for recommender systems to help learners navigate the extensive variety of available learning resources. Recent advancements in these systems have notably improved the personalization of course recommendations. However, many existing systems fail to provide clear explanations for their recommendations, making it difficult for learners to understand why a particular suggestion was made. This lack of transparency can negatively impact trust and acceptance of the system. Researchers have emphasized the importance of explanations in various other domains such as ecommerce, media, and entertainment, demonstrating how explanations can enhance system transparency, foster user trust, and improve decision-making processes. Despite these insights, such approaches have been rarely applied to the educational domain, and their effectiveness in practical use remains largely unexamined. My research focuses on developing explainable recommender systems for digital education. First, I aim to design knowledge graphs that can support high-quality recommendations in the context of education. Second, I will create models backed by these knowledge graphs that not only deliver accurate recommendations but also provide faithful explanations for each suggestion, helping learners make informed decisions. Third, I will evaluate the effectiveness of these explainable recommender systems in real-world scenarios.</p>
    <p><strong>Categories:</strong> Causal Language Modeling, Knowledge Graphs, Explainable Recommendations, Faithful Explanations, Transparency in Recommendations, Trust in Systems, Real-World Evaluation, Education Domain, User-Centric Design, Personalization (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1138/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Who do you think I am? Interactive User Modelling with Item Metadata (2022)</h3>
    <p><strong>Authors:</strong> Bart Goethals, Koen Ruymbeek, Joey De Pauw</p>
    <p>Recommender systems are used in many different applications and contexts, however their main goal can always be summarised as “connecting relevant content to interested users”. Explanations have been found to help recommender systems achieve this goal by giving users a look under the hood that helps them understand why they are recommended certain items. Furthermore, explanations can be considered to be the first step towards interacting with the system. Indeed, for a user to give feedback and guide the system towards better understanding her preferences, it helps if the user has a better idea of what the system has already learned.<br>To this end, we propose a linear collaborative filtering recommendation model that builds user profiles within the domain of item metadata. Our method is hence inherently transparent and explainable. Moreover, since recommendations are computed as a linear function of item metadata and the interpretable user profile, our method seamlessly supports interactive recommendation. In other words, users can directly tweak the weights of the learned profile for more fine-grained browsing and discovery of content based on their current interests. We demonstrate the interactive aspect of this model in an online application for discovering cultural events in Belgium.</p>
    <p><strong>Categories:</strong> Explainable Recommendations, Transparency, Collaborative Filtering, Item Metadata, Interactive Recommendation, User Profiling, User Feedback, Real World Application, Usability, Dynamic Adaptation, A/B Test, Core Recommendation. (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/802/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>ProtoMF: Prototype-based Matrix Factorization for Effective and Explainable Recommendations (2022)</h3>
    <p><strong>Authors:</strong> Christian Ganhör, Alessandro B. Melchiorre, Navid Rekabsaz, Markus Schedl</p>
    <p>Recent studies show the benefits of reformulating common machine learning models through the concept of prototypes – representatives of the underlying data, used to calculate the prediction score as a linear combination of similarities of a data point to prototypes. Such prototype-based formulation of a model, in addition to preserving (sometimes enhancing) the performance, enables explainability of the model’s decisions, as the prediction can be linearly broken down into the contributions of distinct definable prototypes. Following this direction, we extend the idea of prototypes to the recommender system domain by introducing ProtoMF, a novel collaborative filtering algorithm. ProtoMF learns sets of user/item prototypes that represent the general consumption characteristics of users/items in the underlying dataset. Using these prototypes, ProtoMF then represents users and items as vectors of similarities to the corresponding prototypes. These user/item representations are ultimately leveraged to make recommendations that are both effective in terms of accuracy metrics, and explainable through the interpretation of prototypes’ contributions to the affinity scores. We conduct experiments on three datasets to assess both the effectiveness and the explainability of ProtoMF. Addressing the former, we show that ProtoMF exhibits higher Hit Ratio and NDCG compared to other relevant collaborative filtering approaches. As for the latter, we qualitatively show how ProtoMF can provide explainable recommendations and how its explanation capabilities can expose the existence of statistical biases in the learned representations, which we exemplify for the case of gender bias.</p>
    <p><strong>Categories:</strong> Matrix Factorization, Explainability, Collaborative Filtering, Recommendation Systems, Evaluation Metrics, Fairness, Explainable Recommendations, Prototype-based Models, Collaborative Filtering Techniques, Transparency (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/773/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Local Factor Models for Large-Scale Inductive Recommendation (2021)</h3>
    <p><strong>Authors:</strong> Longqi Yang, Tobias Schnabel, Susan Dumais, Paul N. Bennett</p>
    <p>In many domains, user preferences are similar locally within like-minded subgroups of users, but typically differ globally between those subgroups. Local recommendation models were shown to substantially improve top-K recommendation performance in such settings. However, existing local models do not scale to large-scale datasets with an increasing number of subgroups and do not support inductive recommendations for users not appearing in the training set. Key reasons for this are that subgroup detection and recommendation get implemented as separate steps in the model or that local models are explicitly instantiated for each subgroup. In this paper, we propose an End-to-end Local Factor Model (Elfm) which overcomes these limitations by combining both steps and incorporating local structures through an inductive bias. Our model can be optimized end-to-end and supports incremental inference, does not require a full separate model for each subgroup, and has overall small memory and computational costs for incorporating local structures. Empirical results show that our method substantially improves recommendation performance on large-scale datasets with millions of users and items with considerably smaller model size. Our user study also shows that our approach produces coherent item subgroups which could aid in the generation of explainable recommendations.</p>
    <p><strong>Categories:</strong> Recommendation Algorithms, Factor Models, Large-Scale Recommendations, Subgroup Detection, Cold Start, Scalability, Top-K Performance, Explainable Recommendations, Incremental Inference, User Study. (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/652/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Explainable Recommendations via Attentive Multi-Persona Collaborative Filtering (2020)</h3>
    <p><strong>Authors:</strong> Avi Caciularu, Oren Barkan, Noam Koenigstein, Yonatan Fuchs</p>
    <p>Two main challenges in recommender systems are modeling users with heterogeneous taste, and providing explainable recommendations. In this paper, we propose the neural Attentive Multi-Persona Collaborative Filtering (AMP-CF) model as a unified solution for both problems. AMP-CF breaks down the user to several latent ‘personas’ (profiles) that identify and discern the different tastes and inclinations of the user. Then, the revealed personas are used to generate and explain the final recommendation list for the user. AMP-CF models users as an attentive mixture of personas, enabling a dynamic user representation that changes based on the item under consideration. We demonstrate AMP-CF on five collaborative filtering datasets from the domains of movies, music, video games and social networks. As an additional contribution, we propose a novel evaluation scheme for comparing the different items in a recommendation list based on the distance from the underlying distribution of “tastes” in the user’s historical items. Experimental results show that AMP-CF is competitive with other state-of-the-art models. Finally, we provide qualitative results to showcase the ability of AMP-CF to explain its recommendations.</p>
    <p><strong>Categories:</strong> Explainable Recommendations, Collaborative Filtering, User Modeling, Multi-Persona Models, Domain-Specific Recommendations (Movies, Music, Video Games, Social Networks), Evaluation Metrics, Attention Mechanisms, Deep Learning, Performance Comparison, Beyond Accuracy, User-Centric Design (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/576/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Explainable Entity-based Recommendations with Knowledge Graphs (2017)</h3>
    <p><strong>Authors:</strong> William Cohen, Maxine Eskenazi, Rose Catherine, Kathryn Mazaitis</p>
    <p>Explainable recommendation is an important task. Many methods have been proposed which generate explanations from the content and reviews written for items. When review text is unavailable, generating explanations is still a hard problem. In this paper, we illustrate how explanations can be generated in such a scenario by leveraging external knowledge in the form of knowledge graphs. Our method jointly ranks items and knowledge graph entities using a Personalized PageRank procedure to produce recommendations together with their explanations.</p>
    <p><strong>Categories:</strong> Explainable Recommendations, Knowledge Graphs, Entity-based Methods, Personalized PageRank, Recommendation Systems, External Knowledge Integration, Algorithm Development, Graph-based Methods (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/307/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>