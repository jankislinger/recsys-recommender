<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/explainability/">Explainability</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reproducibility/">Reproducibility</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reinforcement-learning/">Reinforcement Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/evaluation-metrics/">Evaluation Metrics</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Integrating Matrix Factorization with Graph based Models (2024)</h3>
    <p><strong>Authors:</strong> Rachana Mehta</p>
    <p>Graph based Recommender models make use of user-item rating and user-user social relationships to elicit recommendation performance by extracting inherent geometrical knowledge. In a social graph scenario, user-user trust plays a significant role in reducing sparsity and has varied characteristics that can be exploited. Existing models limit themselves to learning from either a high order interaction graph of user-item ratings or a user-user social graph from trust value. They explore other trust characteristics in a very limited setting. The graph based model, designed using entire user-user social information, impacts performance and escalates complexities in model learning. To alleviate these issues of graph learning, graph recommender seeks assistance from matrix factorization techniques. Incorporating graph based model with matrix factorization brings its own set of challenges of model integration, leveraging trust, graph learning, and optimization. This article presents the existing work in that line and future possibilities and challenges to be catered to through novel developments</p>
    <p><strong>Categories:</strong> Matrix Factorization, Graph-Based Recommendations, Recommendation Systems, Trust, Collaborative Filtering, Social Networks, Algorithm Integration, Evaluation Methods, Performance Analysis, Future Directions (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1145/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Acknowledging dynamic aspects of trust in recommender systems (2023)</h3>
    <p><strong>Authors:</strong> Imane Akdim</p>
    <p>Trust-based recommender systems emerged as a solution to different limitations of traditional recommender systems. These systems rely on the assumption that users will adopt the preferences of users they deem trustworthy in an online social setting. However, most trust-based recommender systems consider trust to be a static notion, thereby disregarding crucial dynamic factors that influence the value of trust between users and the performance of the recommender system. In this work, we intend to address several challenges regarding the dynamics of trust within a trust-based recommender system. These issues include the temporal evolution of trust between users and change detection and prediction in users’ interactions. By exploring the factors that influence the evolution of human trust, a complex and abstract concept, this work will contribute to a better understanding of how trust operates in recommender systems.</p>
    <p><strong>Categories:</strong> Trust, Recommender Systems, Dynamic Trust, Temporal Evolution of Trust, Change Detection, Human Factors in Trust, Evaluation Metrics, Theory Development, Conceptual Frameworks (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/969/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Enhanced Privacy Preservation for Recommender Systems (2023)</h3>
    <p><strong>Authors:</strong> Ziqing Wu</p>
    <p>My research focuses on privacy preservation for recommender systems specifically in the following aspects: first, how to better address users’ realistic privacy concerns and offer enhanced privacy control by considering what and with whom to share sensitive information for decentralized recommender systems; second, how to enhance the privacy preservation capability of LLM-based recommender systems; last, how to formulate uniform metrics to compare the privacy-preservation efficacy of the recommender system.</p>
    <p><strong>Categories:</strong> Privacy Preservation, Recommender Systems, User-Centric Design, Decentralized Systems, Large Language Models, Machine Learning, Deep Learning, Evaluation Metrics, Performance Measurement, Algorithm Evaluation, Data Security, Trust (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/976/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Combining Text Summarization and Aspect-based Sentiment Analysis of Users’ Reviews to Justify Recommendations (2019)</h3>
    <p><strong>Authors:</strong> Pasquale Lops, Giovanni Semeraro, Marco de Gemmis, Cataldo Musto, Gaetano Rossiello</p>
    <p>In this paper we present a methodology to justify recommendations that relies on the information extracted from users’ reviews discussing the available items. The intuition behind the approach is to conceive the justification as a summary of the most relevant and distinguishing aspects ofthe item, automatically obtained by analyzing the available reviews. To this end, we designed a pipeline of natural language processing techniques based on aspect extraction, sentiment analysis and text summarization to gather the reviews, process the relevant excerpts,and generate a unique synthesis presenting the main characteristics of the item. Such a summary is finally presented to the target user as justification of the recommendation she received. In the experimental evaluation we carried out a user study in the movie domain (N=141) and the results showed that our approach is able to make the recommendation process more transparent, engaging and trustful for the users. Moreover, the proposed method also beat another review-based explanation technique, thus confirming the validity of our intuition. i>Presentation: Monday Poster Lunch</i</p>
    <p><strong>Categories:</strong> Recommendation Systems, Natural Language Processing, Text Summarization, Aspect-Based Sentiment Analysis, Movie Domain, User Study, Explainability, Trust, Experimental Results, Evaluation Methodology, Pipeline Design, Transparency in AI, User Feedback, Sentiment Analysis, Aspect Extraction, User-Centered Design (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/469/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Using Explainability for Constrained Matrix Factorization (2017)</h3>
    <p><strong>Authors:</strong> Olfa Nasraoui, Behnoush Abdollahi</p>
    <p>Accurate model-based Collaborative Filtering (CF) approaches tend to be black-box machine learning models, such as Matrix Factorization (MF), that lack interpretability and do not provide a straightforward explanation for their outputs. Yet explanations can improve the transparency of a recommender system by justifying recommendations, and this in turn can enhance the user’s trust in the recommendations. Hence, one main challenge in designing a recommender system is mitigating the trade-off between an explainable technique with moderate prediction accuracy and a more accurate technique with no explainable recommendations. In this paper, we focus on MF and further assume the absence of any additional data source, such as item content or user attributes. We propose an explainability constrained MF technique that computes the top-n recommendation list from items that are explainable. Experimental results show that our method is effective in generating accurate and explainable recommendations.</p>
    <p><strong>Categories:</strong> Matrix Factorization, Collaborative Filtering, Explainable AI, Transparency, Trust, User Trust, Recommendation Systems, Algorithmic Transparency, Interpretability, Evaluation Metrics, Performance Analysis (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/309/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>A Hybrid Explanations Framework for Collaborative Filtering Recommender Systems (2014)</h3>
    <p><strong>Authors:</strong> Shay Ben Elazar, Noam Koenigstein</p>
    <p>Augmenting personalized recommendations with explanations is believed to improve users' trust, loyalty, satisfaction, and recommender's persuasiveness. We present a flexible explanations framework for collaborative filtering recom-mender systems. Our algorithms utilizes item tags to automatically generate personalized explanations in a natural language format. Given a specific user and a recommended item, the algorithm utilizes the user's personal information as well as global information (e.g., item similarities, metadata) in order to rank item tags based on their "explanatory power". The top tags are chosen to construct a personalized explanation sentence which helps shed light on the underlying recommender. Our system has been well received by both focus groups as well as in expert evaluations and is scheduled to be evaluated in an online experiment.</p>
    <p><strong>Categories:</strong> Collaborative Filtering, Recommender Systems, Explanations, Transparency, A/B Testing, User Surveys, Trust, Real World Application, Matrix Factorization, Natural Language Processing, Content-Based Filtering (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/66/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>