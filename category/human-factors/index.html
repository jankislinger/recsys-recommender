<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui primary button" style="margin: 5px;"
             href="/recsys-recommender/">Human Factors</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/bias-mitigation/">Bias Mitigation</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/offline-evaluation/">Offline Evaluation</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reproducibility/">Reproducibility</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Impact of Item Consumption on Assessment of Recommendations in User Studies (2018)</h3>
    <p><strong>Authors:</strong> Jürgen Ziegler, Tim Donkers, Benedikt Loepp, Timm Kleemann</p>
    <p>In user studies of recommender systems, participants typically cannot consume the recommended items. Still, they are asked to assess recommendation quality and other aspects related to user experience by means of questionnaires. Without having listened to recommended songs or watched suggested movies, however, this might be an error-prone task, possibly limiting validity of results obtained in these studies. In this paper, we investigate the effect of actually consuming the recommended items. We present two user studies conducted in different domains showing that in some cases, differences in the assessment of recommendations and in questionnaire results occur. Apparently, it is not always possible to adequately measure user experience without allowing users to consume items. On the other hand, depending on domain and provided information, participants sometimes seem to approximate the actual value of recommendations reasonably well.</p>
    <p><strong>Categories:</strong> Recommendation Systems, User Behavior, Human Factors, Evaluation Methods, Measurement Validity, Domain Analysis, User Experience, Contextual Factors, Assessment Accuracy, User Studies (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/380/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Memory Priming and User Preferences (2016)</h3>
    <p><strong>Authors:</strong> Efthimios Bothos, Babis Magoutas, Evagelia Anagnostopoulou, Gregoris Mentzas</p>
    <p>In this paper we provide a preliminary analysis of the effects of priming on user preferences and we describe two experiments that show such effects in test environments. Our first results show that small stimuli which primes the process of item rating leads to varying average ratings.</p>
    <p><strong>Categories:</strong> Psychology/Cognitive Science, Experimental Design and Analysis, User Behavior, Recommendation Systems, Evaluation Methods, User Preferences, Memory Priming, Rating Systems, Methodology, Human Factors (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/246/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>User Segmentation for Controlling Recommendation Diversity (2016)</h3>
    <p><strong>Authors:</strong> Farzad Eskandanian, Bamshad Mobasher, Robin Burke</p>
    <p>The quality of recommendations is known to be affected by diversity and novelty in addition to accuracy. Recent work has focused on methods that increase diversity of recommendation lists. However, these methods assume the user preference for diversity is constant across all users. In this paper, we show that users’ propensity towards diversity varies greatly and argue that the diversity of recommendation lists should be consistent with the level of user interest in diverse recommendations. We introduce a user segmentation approach in order to personalize recommendation according to user preference for diversity. We show that recommendations generated using these segments match the diversity preferences of users in each segment. We also discuss the impact of this segmentation on the novelty of recommendations.</p>
    <p><strong>Categories:</strong> User Segmentation, Recommendation Diversity, Personalization, Clustering, Recommendation Quality, Beyond Accuracy, Real World Applications, User-Centric Design, Human Factors, Evaluation Metrics, User Behavior Analysis (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/248/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Merging Latent Factors and Tags to Increase Interactive Control of Recommendations (2015)</h3>
    <p><strong>Authors:</strong> Jürgen Ziegler, Tim Donkers, Benedikt Loepp</p>
    <p>We describe a novel approach that integrates user-generated tags with standard Matrix Factorization to allow users to interactively control recommendations. The tag information is incorporated during the learning phase and relates to the automatically derived latent factors. Thus, the system can change an item’s score whenever the user adjusts a tag’s weight. We implemented a prototype and performed a user study showing that this seems to be a promising way for users to interactively manipulate the set of items recommended based on their user profile or in cold-start situations.</p>
    <p><strong>Categories:</strong> Matrix Factorization, User-Generated Tags, Interactive Recommendations, Cold Start, Real-World Application, Human Factors, Methodology Innovation, Recommendation Systems, User Study (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/157/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Dynamics of Human Trust in Recommender Systems (2014)</h3>
    <p><strong>Authors:</strong> Tarek Abdelzahe, Cleotilde Gonzalez, Jason Harman, John O’Donovan</p>
    <p>The trust that humans place on recommendations is key to the success of recommender systems. The formation and decay of trust in recommendations is a dynamic process influenced by context, human preferences, accuracy of recommendations, and the interactions of these factors. This paper describes two psychological experiments (N=400) that evaluate the evolution of trust in recommendations over time, under personalized and non-personalized recommendations by matching or not matching a participant’s profile. Main findings include: Humans trust inaccurate recommendations more than they should; when recommendations are personalized, they lose trust in inaccurate recommendations faster than when recommendations are not personalized; and participants learn to select the options that provide best outcomes increasingly over time when they use personalized recommendations, while they are unable to learn if the recommendations are not personalized. We make connections to the possible implications that these psychological findings to the design of recommender systems.</p>
    <p><strong>Categories:</strong> Trust Dynamics, User Behavior, Psychology of Recommendations, Recommendation Accuracy, Personalization in Recommendations, Human Factors, Recommender Systems Design, User Trust, Learning from Recommendations, Evaluation Methods, Psychological Experiments (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/48/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>