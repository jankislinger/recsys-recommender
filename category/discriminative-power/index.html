<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui primary button" style="margin: 5px;"
             href="/recsys-recommender/">Discriminative Power</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/popularity-bias/">Popularity Bias</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reinforcement-learning/">Reinforcement Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reproducibility/">Reproducibility</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/performance-evaluation/">Performance Evaluation</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>On the Consistency, Discriminative Power and Robustness of Sampled Metrics in Offline Top-N Recommender System Evaluation (2023)</h3>
    <p><strong>Authors:</strong> Dorota Glowacka, Yang Liu, Alan Medlar</p>
    <p>Negative item sampling in offline top-n recommendation evaluation has become increasingly wide-spread, but remains controversial. While several studies have warned against using sampled evaluation metrics on the basis of being a poor approximation of the full ranking (i.e.~using all negative items), others have highlighted their improved discriminative power and potential to make evaluation more robust. Unfortunately, empirical studies on negative item sampling are based on relatively few methods (between 3-12) and, therefore, lack the statistical power to assess the impact of negative item sampling in practice. In this article, we present preliminary findings from a comprehensive benchmarking study of negative item sampling based on 52 recommendation algorithms and 3 benchmark data sets. We show how the number of sampled negative items and different sampling strategies affect the consistency and discriminative power of sampled evaluation metrics. Furthermore, we investigate the impact of sparsity bias and popularity bias on the robustness of these metrics. In brief, we show that the optimal parameterizations for negative item sampling are dependent on data set characteristics and the goals of the investigator, suggesting a need for greater transparency in related experimental design decisions.</p>
    <p><strong>Categories:</strong> Evaluation Metrics, Offline Evaluation, Negative Item Sampling, Recommendation Algorithms, Consistency in Metrics, Discriminative Power, Robustness of Metrics, Sparsity Bias, Popularity Bias (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/961/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>On the Robustness and Discriminative Power of IR Metrics for Top-N Recommendation (2018)</h3>
    <p><strong>Authors:</strong> Alejandro Bellogin, Daniel Valcarce, Pablo Castells, Javier Parapar</p>
    <p>The evaluation of Recommender Systems is still an open issue in the field. Despite its limitations, offline evaluation usually constitutes the first step in assessing recommendation methods due to its reduced costs and high reproducibility. Selecting the appropriate metric is a central issue in offline evaluation. Among the properties of recommendation systems, ranking accuracy attracts the most attention nowadays. In this paper, we aim to shed light on the advantages of different ranking metrics which were previously used in Information Retrieval and are now typically used for assessing top-N recommender systems. We propose methodologies for comparing the robustness and the discriminative power of different metrics. On the one hand, we study the influence of cut-offs and we find that deeper cut-offs offer greater robustness and discriminative power. On the other hand, we find that precision offers high robustness and Normalised Discounted Cumulative Gain provides the best discriminative power.</p>
    <p><strong>Categories:</strong> Recommender Systems, Evaluation Metrics, Ranking Accuracy, Robustness, Discriminative Power, Top-N Recommendations, Information Retrieval, Evaluation Cutoffs, Methodologies (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/351/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Improving The Discriminative Power Of Inferred Content Information Using Segmented Virtual Profile (2014)</h3>
    <p><strong>Authors:</strong> Trevor Walker, Anmol Bhasin, Anuj Goyal, Haishan Liu</p>
    <p>We present a novel component of a hybrid recommender system at LinkedIn, where item features are augmented by a virtual profile based on observed user-item interactions. The concept of virtual profiles is generating a representation of an item in the user feature space by leveraging the over-represented user features from users that interacted with the item. It is a way to think about Collaborative Filtering with content features. The core principle is that if the feature occurs with high probability for the users who interacted with an item (henceforth termed as relevant users) versus those who did not (henceforth termed non-relevant users), then that feature is a good candidate to be included in the virtual profile of the item in question. However this scheme suffers from the data imbalance problem, given that observed relevant users are usually an extremely small minority group compared to the whole user base. Feature selection in this skewed setting is prone to noise from the overwhelming non-relevant examples that belong to the majority class. To alleviate the problem, we propose a method to select the most relevant non-relevant examples from the majority class by segmenting users on certain intelligently selected feature dimensions. The resulting virtual profile from the method is called the segmented virtual profile. Empirical evaluation on real-world large scale recommender system at LinkedIn shows that simple strategies for the segmentation yield significantly better performance.</p>
    <p><strong>Categories:</strong> Virtual Profiles, Collaborative Filtering, Content-Based Filtering, Feature Selection, Hybrid Recommender Systems, Segmentation, Imbalanced Data, Real-World Applications, Industry-Specific, Recommendation Systems, Performance Evaluation, Discriminative Power, User Interaction Analysis (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/18/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>