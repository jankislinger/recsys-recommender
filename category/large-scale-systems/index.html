<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reinforcement-learning/">Reinforcement Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/scalability/">Scalability</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/real-world-applications/">Real-world Applications</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/deep-learning/">Deep Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/evaluation-methods/">Evaluation Methods</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Co-optimize Content Generation and Consumption in a Large Scale Video Recommendation System (2024)</h3>
    <p><strong>Authors:</strong> Yuening Li, Mingyan Gao, Qingyun Liu, Sourabh Bansod, Shuchao Bi, Liang Liu, Yaping Zhang, Zhen Zhang</p>
    <p>Multi-task prediction models and value models are the de-facto standard ranking components in modern large-scale content recommendation systems. However, they are typically optimized to model users’ passive consumption behaviors, and rank content in a way to grow only consumption-centric values. In this talk, we discuss the key insight that it is possible to model sparse participatory content-generation actions as well and grow ecosystem value through a new ranking system. We made the following key technical contributions in this system: (1) introducing ranking for content generation based on a categorization of user participation actions of different sparsity, including proxy intent action or access point clicks. (2) improving sparse task prediction quality and stability by causal task relationship modeling, conditional loss modeling and ResNet based shared bottom network. (3) personalizing the value model to minimize conflicts between different values, through e.g. ranking inspiring content higher for users who actively generate content. (4) conducting systematic evaluation of proposed approach in a large short-form video UGC (User-Generated Content) platform.</p>
    <p><strong>Categories:</strong> Multi-Task Learning, Video Recommendation, User-Generated Content, Content Generation, Large-Scale Systems, Evaluation Metrics, Causal Modeling, Network Architecture, User Participation, Scalability, Content Creation, User-Centric Design (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1156/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Bridging the Gap: Unpacking the Hidden Challenges in Knowledge Distillation for Online Ranking Systems (2024)</h3>
    <p><strong>Authors:</strong> Shuo Yang, Yang Liu, Nikhil Khani, Li Wei, Pendo Abbo, Aniruddh Nath, Shawn Andrews</p>
    <p>Knowledge Distillation (KD) is a powerful approach for compressing large models into smaller, more efficient models, particularly beneficial for latency-sensitive applications like recommender systems. However, current KD research predominantly focuses on Computer Vision (CV) and NLP tasks, overlooking unique data characteristics and challenges inherent to recommender systems.  This paper addresses these overlooked challenges, specifically: (1) mitigating data distribution shifts between teacher and student models, (2) efficiently identifying optimal teacher configurations within time and budgetary constraints, and (3) enabling computationally efficient and rapid sharing of teacher labels to support multiple students. We present a robust KD system developed and rigorously evaluated on multiple large-scale personalized video recommendation systems within Google. Our live experiment results demonstrate significant improvements in student model performance while ensuring consistent and reliable generation of high-quality teacher labels from continuous data streams.</p>
    <p><strong>Categories:</strong> Knowledge Distillation, Recommender Systems, Online Ranking, Data Distribution Shifts, Teacher-Student Models, Model Compression, Optimization Techniques, Efficient Label Sharing, Multi-Teacher Settings, Video Recommendations, Large-Scale Systems, Performance Improvement, Real-World Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1158/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Enhancing Performance and Scalability of Large-Scale Recommendation Systems with Jagged Flash Attention (2024)</h3>
    <p><strong>Authors:</strong> Hong Li, Mingwei Tang, Meng Liu, Junjie Yang, Dai Li, Xing Liu, Tunhou Zhang, Arnold Overwijk, Haoci Zhang, Rengan Xu, Sijia Chen, Sri Reddy, Devashish Shankar, Jiaqi Zhai, Bill Zhu, Boyang Li, Zehua Zhang, Yifan Xu, Yuxi Hu</p>
    <p>The integration of hardware accelerators has significantly advanced the capabilities of modern recommendation systems, enabling the exploration of complex ranking paradigms previously deemed impractical. However, the GPU-based computational costs present substantial challenges. In this paper, we demonstrate our development of an efficiency-driven approach to explore these paradigms, moving beyond traditional reliance on native PyTorch modules. We address the specific challenges posed by ranking models’ dependence on categorical features, which vary in length and complicate GPU utilization. We introduce Jagged Feature Interaction Kernels, a novel method designed to extract fine-grained insights from long categorical features through efficient handling of dynamically sized tensors. We further enhance the performance of attention mechanisms by integrating Jagged tensors with Flash Attention. As the feature length grows, the Jagged Flash Attention is able to scale memory linearly rather than quadratically. Our experimental results demonstrate that Jagged Flash Attention achieves speedups of 2.4× to 5.6× over dense attention and reduces memory usage by up to 21.8×. This allows to scale the recommendation systems with longer features and more complex model architecture.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Scalability, GPU Usage, Categorical Features, Efficient Algorithms, Flash Attention, Memory Efficiency, Hardware Acceleration, Performance Optimization, Large-Scale Systems, Attention Mechanisms, Novel Methods, Efficiency-Driven Approaches, Complex Model Architectures. (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1163/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Loss Harmonizing for Multi-Scenario CTR Prediction (2023)</h3>
    <p><strong>Authors:</strong> Congcong Liu, Zhangang Lin, Changping Peng, Jingping Shao, Fei Teng, Xue Jiang, Pei Wang, Liang Shi</p>
    <p>Large-scale industrial systems often include multiple scenarios to satisfy diverse user needs. The common approach of using one model per scenario does not scale well and not suitable for minor scenarios with limited samples. An solution is to train a model on all scenarios, which can introduce domination and bias from the main scenario. MMoE-like structures have been proposed for multi-scenario prediction, but they do not explicitly address the issue of gradient unbalancing. This work proposes an adaptive loss harmonizing (ALH) algorithm for multi-scenario CTR prediction. It balances training by dynamically adjusting the learning speed, resulting in improved prediction performance. Experiments conducted on real production dataset and a rigorous A/B test prove the superiority of our method.</p>
    <p><strong>Categories:</strong> Click-Through Rate (CTR) Prediction, Multi-Scenario Prediction, Machine Learning Optimization, Large-Scale Systems, Recommendation Systems, Real-World Applications, Model Efficiency, Multi-Task Learning, Adaptive Algorithms (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1003/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>InTune: Reinforcement Learning-based Data Pipeline Optimization for Deep Recommendation Models (2023)</h3>
    <p><strong>Authors:</strong> Pablo Delgado, Kabir Nagrecha, Lingyi Liu, Prasanna Padmanabhan</p>
    <p>Deep learning-based recommendation models (DLRMs) have become an essential component of many modern recommender systems. Several companies are now building large compute clusters reserved only for DLRM training, driving new interest in cost- & time- saving optimizations. The systems challenges faced in this setting are unique; while typical deep learning (DL) training jobs are dominated by model execution times, the most important factor in DLRM training performance is often online data ingestion. In this paper, we explore the unique characteristics of this data ingestion problem and provide insights into the specific bottlenecks and challenges of the DLRM training pipeline at scale. We study real-world DLRM data processing pipelines taken from our compute cluster to both observe the performance impacts of online ingestion and to identify shortfalls in existing data pipeline optimizers. We find that current tooling either yields sub-optimal performance, frequent crashes, or else requires impractical cluster re-organization to adopt. Our studies lead us to design and build a new solution for data pipeline optimization, InTune. InTune employs a reinforcement learning (RL) agent to learn how to distribute CPU resources across a DLRM data pipeline to more effectively parallelize data-loading and improve throughput. Our experiments show that InTune can build an optimized data pipeline configuration within only a few minutes, and can easily be integrated into existing training workflows. By exploiting the responsiveness and adaptability of RL, InTune achieves significantly higher online data ingestion rates than existing optimizers, thus reducing idle times in model execution and increasing efficiency. We apply InTune to our real-world cluster, and find that it increases data ingestion throughput by as much as 2.29X versus current state-of-the-art data pipeline optimizers while also improving both CPU & GPU utilization.</p>
    <p><strong>Categories:</strong> Reinforcement Learning, Deep Learning Recommender Models, Data Pipeline Optimization, Resource Allocation, Performance Optimization, Real-World Applications, Large-Scale Systems, Compute Clusters, Resource Utilization, Deep Learning, Scalability (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/873/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Unleash the Power of Context: Enhancing Large-Scale Recommender Systems with Context-Based Prediction Models (2023)</h3>
    <p><strong>Authors:</strong> Davorin Kopič, Jan Hartman, Assaf Klein, Natalia Silberstein</p>
    <p>In this work, we introduce the notion of Context-Based Prediction Models. A Context-Based Prediction Model determines the probability of a user’s action (such as a click or a conversion) solely by relying on user and contextual features, without considering any specific features of the item itself. We have identified numerous valuable applications for this modeling approach, including training an auxiliary context-based model to estimate click probability and incorporating its prediction as a feature in CTR prediction models.Our experiments indicate that this enhancement brings significant improvements in offline and online business metrics while having minimal impact on the cost of serving. Overall, our work offers a simple and scalable, yet powerful approach for enhancing the performance of large-scale commercial recommender systems, with broad implications for the field of personalized recommendations.</p>
    <p><strong>Categories:</strong> Context-Aware Recommendations, Recommender Systems, Personalized Recommendations, Recommendation Techniques, Large-Scale Systems, Evaluation Metrics, Click-Through Rate Prediction, Scalability (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1017/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Nonlinear Bandits Exploration for Recommendations (2023)</h3>
    <p><strong>Authors:</strong> Minmin Chen, Yi Su</p>
    <p>The paradigm of framing recommendations as (sequential) decision-making processes has gained significant interest. To achieve long-term user satisfaction, these interactive systems need to strikes a balance between exploitation (recommending high-reward items) and exploration (exploring uncertain regions for potentially better items). Classical bandit algorithms like Upper-Confidence-Bound and Thompson Sampling, and their contextual extensions with linear payoffs have exhibited strong theoretical guarantees and empirical success in managing the exploration-exploitation trade-off. Building efficient exploration-based systems for deep neural network powered real-world, large-scale industrial recommender systems remains under studied. In addition, these systems are often multi-stage, multi-objective and response time sensitive.  In this talk, we share our experience in addressing these challenges in building exploration based industrial recommender systems. Specifically, we adopt the Neural Linear Bandit algorithm, which effectively combines the representation power of deep neural networks, with the simplicity of linear bandits to incorporate exploration in DNN based recommender systems. We introduce  exploration capability to both the nomination and ranking stage of the industrial recommender system.  In the context of the ranking stage, we delve into the extension of this algorithm to accommodate the multi-task setup, enabling exploration in systems with multiple objectives. Moving on to the nomination stage, we will address the development of efficient bandit algorithms tailored to factorized bi-linear models. These algorithms play a crucial role in facilitating maximum inner product search, which is commonly employed in large-scale retrieval systems. We validate our algorithms and present findings from real-world live experiments.</p>
    <p><strong>Categories:</strong> Multi-Armed Bandits, Recommendation Systems, Deep Learning, Exploration, Exploitation, Neural Linear Bandit, Industrial Recommender Systems, Nomination Stage, Ranking Stage, Multi-Task Learning, Large Scale Systems, Real World Applications, Efficiency, Beyond Accuracy, Evaluation Metrics, Performance Evaluation, Algorithm Performance (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1012/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Two-Layer Bandit Optimization for Recommendations (2022)</h3>
    <p><strong>Authors:</strong> Humeyra Topcu Altintas, Puja Das, Aaron Chen, Sofia Maria Nikolakaki, Siyong Ma</p>
    <p>Online commercial app marketplaces serve millions of apps to billions of users in an efficient manner. Bandit optimization algorithms are used to ensure that the recommendations are relevant, and converge to the best performing content over time. However, directly applying bandits to real-world systems, where the catalog of items is dynamic and continuously refreshed, is not straightforward. One of the challenges we face is the existence of several competing content surfacing components, a phenomenon not unusual in large-scale recommender systems. This often leads to challenging scenarios, where improving the recommendations in one component can lead to performance degradation of another, i.e., “cannibalization”. To address this problem we introduce an efficient two-layer bandit approach which is contextualized to user cohorts of similar taste. We mitigate cannibalization at runtime within a single multi-intent content surfacing platform by formalizing relevant offline evaluation metrics, and by involving the cross-component interactions in the bandit rewards. The user engagement in our proposed system has more than doubled as measured by online A/B testings.</p>
    <p><strong>Categories:</strong> Multi-Armed Bandits, Recommendation Systems, App Marketplaces, Cannibalization, Cross-Component Interactions, Offline Evaluation, A/B Test, User Cohorts, User Engagement, Large-Scale Systems (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/846/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>An Incremental Learning framework for large-scale CTR prediction (2022)</h3>
    <p><strong>Authors:</strong> Dimitrios Mallis, Vassilis Pitsikalis, Stavros Theodorakis, Nikiforos Mandilaras, Petros Katsileros, Gil Chamiel</p>
    <p>In this work we introduce an incremental learning framework for Click-Through-Rate (CTR) prediction and demonstrate its effectiveness for Taboola’s massive-scale recommendation service. Our approach enables rapid capture of emerging trends through warm-starting from previously deployed models and fine tuning on “fresh” data only. Past knowledge is maintained via a teacher-student paradigm, where the teacher acts as a distillation technique, mitigating the catastrophic forgetting phenomenon. Our incremental learning framework enables significantly faster training and deployment cycles (x12 speedup). We demonstrate a consistent Revenue Per Mille (RPM) lift over multiple traffic segments and a significant CTR increase on newly introduced items.</p>
    <p><strong>Categories:</strong> Incremental Learning, CTR Prediction, Large-Scale Systems, Teacher-Student Paradigm, Catastrophic Forgetting Mitigation, Rapid Deployment, Revenue Per Mille (RPM) Lift, Real-Time Application (<i>deepseek-r1:70b</i>)</p>
    <p><a href="/recsys-recommender/response/816/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Jointly Optimize Capacity, Latency and Engagement in Large-scale Recommendation Systems (2021)</h3>
    <p><strong>Authors:</strong> Hitesh Khandelwal</p>
    <p>As the recommendation systems behind commercial services scale up and apply more and more sophisticated machine learning models, it becomes important to optimize computational cost (capacity) and runtime latency, besides the traditional objective of user engagement. Caching recommended results and reusing them later is a common technique used to reduce capacity and latency. However, the standard caching approach negatively impacts user engagement. To overcome the challenge, this paper presents an approach to optimizing capacity, latency and engagement simultaneously. We propose a smart caching system including a lightweight adjuster model to refresh the cached ranking scores, achieving significant capacity savings without impacting ranking quality. To further optimize latency, we introduce a prefetching strategy which leverages the smart cache. Our production deployment on Facebook Marketplace demonstrates that the approach reduces capacity demand by 50% and p75 end-to-end latency by 35%. While Facebook Marketplace is used as a case study, the approach is applicable to other industrial recommendation systems as well.</p>
    <p><strong>Categories:</strong> System Optimization, Technical Challenges, Caching Strategies, Large-scale Systems, Recommendation Algorithms, Machine Learning Models, Real-World Applications, A/B Testing, Production Systems, User Engagement, Scalability, Industrial Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/727/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Automatic Collection Creation and Recommendation (2021)</h3>
    <p><strong>Authors:</strong> Manjeet Dahiya, Piyush Singh, Sanidhya Singal</p>
    <p>We present a collection recommender system that can automatically create and recommend collections of items at a user level. Unlike regular recommender systems, which output top-N relevant items, a collection recommender system outputs collections of items such that the items in the collections are relevant to a user, and the items within a collection follow a specific theme. Our system builds on top of the user-item representations learnt by item recommender systems. We employ dimensionality reduction and clustering techniques along with intuitive heuristics to create collections with their ratings and titles. We test these ideas in a real-world setting of music recommendation, within a popular music streaming service. We find that there is a 2.3x increase in recommendation-driven consumption when recommending collections over items. Further, it results in effective utilization of real estate and leads to recommending a more and diverse set of items. To our knowledge, these are first of its kind experiments at such a large scale.</p>
    <p><strong>Categories:</strong> Recommender Systems, Collection Recommendations, Music, Entertainment, Dimensionality Reduction, Clustering, User-Level Analysis, Top-N Recommendations, A/B Testing, Large-Scale Systems, Real-World Applications, Recommendation-Driven Consumption, Diversity of Recommendations, User-Item Representations, Heuristics. (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/685/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Tuning Word2vec for Large Scale Recommendation Systems (2020)</h3>
    <p><strong>Authors:</strong> Suvash Sedhain, Ben Chamberlain, Dan Shiebler, Emanuele Rossi, Michael Bronstein</p>
    <p>Word2vec is a powerful machine learning tool that emerged from Natural Language Processing (NLP) and is now applied in multiple domains, including recommender systems, forecasting, and network analysis. As Word2vec is often used off the shelf, we address the question of whether the default hyperparameters are suitable for recommender systems. The answer is emphatically no. In this paper, we first elucidate the importance of hyperparameter optimization and show that unconstrained optimization yields an average 221% improvement in hit rate over the default parameters. However, unconstrained optimization leads to hyperparameter settings that are very expensive and not feasible for large scale recommendation tasks. To this end, we demonstrate 138% average improvement in hit rate with a runtime budget-constrained hyperparameter optimization. Furthermore, to make hyperparameter optimization applicable for large scale recommendation problems where the target dataset is too large to search over, we investigate generalizing hyperparameters settings from samples. We show that applying constrained hyperparameter optimization using only a 10% sample of the data still yields a 91% average improvement in hit rate over the default parameters when applied to the full datasets. Finally, we apply hyperparameters learned using our method of constrained optimization on a sample to the Who To Follow recommendation service at Twitter and are able to increase follow rates by 15%.</p>
    <p><strong>Categories:</strong> Recommender Systems, Word2vec, Hyperparameter Optimization, Large Scale Systems, Evaluation Metrics, Real-World Applications, NLP, Social Networks. (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/615/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Building a reciprocal recommendation system at scale from scratch: Learnings from one of Japan’s prominent dating applications (2020)</h3>
    <p><strong>Authors:</strong> R. Ramanathan</p>
    <p>Online dating platforms have changed the paradigm of how people seek potential relationships. In this context, reciprocal recommendation systems consider the mutual ’match’ potential between users, i.e users who are likely to interact and potentially ’like’ each other. We present our experiences on how we devised algorithms to overcome data specific nuances, built and deployed the system from scratch in a relatively short time-span for one of the prominent dating applications in Japan.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Dating Applications, Reciprocal Recommendations, Real-World Applications, Scalability, Algorithm Design, User Interaction, Deployment, User Behavior Analysis, Matchmaking Algorithms, Large-Scale Systems (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/618/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Smart Targeting: A Relevance-driven and Configurable Targeting Framework for Advertising System (2020)</h3>
    <p><strong>Authors:</strong> Yafei Yao, Changping Peng, Weipeng Yan, Kui Ma, Yongjun Bao, Zhiwei Fang, Yong Li, Zihao Zhao</p>
    <p>Targeting system is an essential part of computational advertising. It allows advertisers to select and reach their targeted users. Due to various advertising goals and the demand for making budget plans, advertisers have a strong will to configure the final targeting results, or they can become very cautious in spending money on advertising campaigns. Meanwhile, to guarantee the advertising performance, the targeted users should also be relevant to the ads of the advertisers. Recent targeting methods are mainly based on tags produced by the Data Management Platform (DMP) which is easy for the advertisers to configure the targeting results. However, in such methods, the relevance between the targeted users and ads is not technically evaluated and cannot be guaranteed. The biggest challenge is that it is hard for a machine learning model to both model the relevance and take account of the advertiser’s configuration demands. In this paper, we propose a novel relevance-driven and configurable targeting framework called Smart Targeting to solve the problem. Specifically, different from Tag-wise Targeting, we first use a relevance model to retrieve the most relevant users for the ads. To further enable the advertisers to configure the final results, we develop a Delay Intervention Mechanism to leverage the power of DMP. As far as we know, this is the first attempt of combining relevance modeling and advertiser intervention into a unified targeting system. We implement and evaluate our framework on JD.com platform with over 300 million users and the results show that it can bring significant improvements to the core indicators such as CTR and eCPM. The long term monitoring also demonstrates that Smart Targeting gradually becomes the most popular targeting tool after its release.</p>
    <p><strong>Categories:</strong> Computational Advertising, Targeting Frameworks, Relevance Modeling, Configuration Mechanisms, User Relevance, Machine Learning Models, Performance Evaluation, Large-Scale Systems, Real-World Applications, Hybrid Systems (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/609/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>LORE: A Large-Scale Offer Recommendation Engine with Eligibility and Capacity Constraints (2019)</h3>
    <p><strong>Authors:</strong> Dale Struble, Shreya Chakrabarti, Yi Liu, Rahul Makhijani</p>
    <p>Businesses, such as Amazon, department store chains, home furnishing store chains, Uber, and Lyft, frequently offer deals, product discounts and incentives to drive sales, increase new product acceptance and engage with users. In order to appeal to diverse user groups, these businesses typically design more than one promotion offer but market different ones to different users. For instance, Uber offers a percentage discount in the rides to some users and a low fixed price to others. In this paper, we propose solutions to optimally recommend promotions and items to maximize user conversion constrained by user eligibility and item or offer capacity (limited quantity of items or offers) simultaneously. We achieve this through an offer recommendation model based on Min-Cost Flow network optimization, which enables us to satisfy the constraints within the optimization itself and solve it in polynomial time. We present two approaches that can be used in various settings: single period solution and sequential time period offering. We evaluate these approaches against competing methods using counterfactual evaluation in offline mode. We also discuss three practical aspects that may affect the online performance of constrained optimization: capacity determination, traffic arrival pattern and clustering for large scale setting.</p>
    <p><strong>Categories:</strong> Large-Scale Systems, Offer Recommendation, Optimization-based Algorithms, E-commerce, Eligibility Constraints, Capacity Constraints, Resource Allocation, Cold Start, Evaluation Methods (Counterfactual), Real-World Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/448/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Ghosting: Contextualized Inline Query Completion in Large Scale Retail Search (2019)</h3>
    <p><strong>Authors:</strong> Uma Murthy, Lakshmi Ramachandran</p>
    <p>Query auto-completion presents a ranked list of queries as suggestions for a user-entered prefix. Ghosting is the process of auto-completing a search recommendation by highlighting the suggested text inline within the search box. We propose the use of a behavior-based recommendation model along with customer search context to ghost on high-confidence queries. We tested ghosting on a retail production system, on over 140 million search sessions. We found that session-context based ghosting significantly increased the acceptance of offered suggestions by 6.18%, reduced misspellings among searches by 4.42%, and improved net sales by 0.14%.</p>
    <p><strong>Categories:</strong> Retail, E-commerce, Search Systems, Recommendation Systems, Real-World Application, Context-Aware, Large-Scale Systems, Behavioral Analysis, Sales Optimization, User Experience, Business Impact, Scalability (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/470/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>