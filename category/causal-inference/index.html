<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/bias-mitigation/">Bias Mitigation</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/e-commerce/">E-commerce</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reinforcement-learning/">Reinforcement Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reproducibility/">Reproducibility</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Country-diverted experiments for mitigation of network effects (2024)</h3>
    <p><strong>Authors:</strong> Ningren Han, Lina Lin, Jean Pouget-Abadie, Jennifer Brennan, Yajun Peng, Changping Meng, Shuchao Bi</p>
    <p>We describe the process of conducting a country-diverted experiment on a major content platform to mitigate the interference often observed in user-diverted A/B experiments. In particular, we propose a heuristic measure of leakage based on cosine similarity between treatment and control groups, which is used to select suitable country diversions, paired with a synthetic control approach to estimate the total treatment effect. We demonstrate the success of our approach through a live experiment on a key user engagement metric, as compared to a previous user-diverted experiment.</p>
    <p><strong>Categories:</strong> A/B Testing, Experimentation Methods, Network Effects Mitigation, Country-Diverted Experiments, Heuristic Measure of Leakage, Synthetic Control Approach, User Engagement Metrics, Recommendation Systems, Causal Inference (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1155/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Not All Videos Become Outdated: Short-Video Recommendation by Learning to Deconfound Release Interval Bias (2024)</h3>
    <p><strong>Authors:</strong> Aixin Sun, Guoxiu He, Lulu Dong</p>
    <p>Short-video recommender systems often exhibit a biased preference to recently released videos. However, not all videos become outdated; certain classic videos can still attract user’s attention. Such bias along temporal dimension can be further aggravated by the matching model between users and videos, because the model learns from preexisting interactions. From real data, we observe that different videos have varying sensitivities to recency in attracting users’ attention. Our analysis, based on a causal graph modeling short-video recommendation, suggests that the release interval serves as a confounder, establishing a backdoor path between users and videos. To address this confounding effect, we propose a model-agnostic causal architecture called Learning to Deconfound the Release Interval Bias (LDRI). LDRI enables jointly learning of the matching model and the video recency sensitivity perceptron. In the inference stage, we apply a backdoor adjustment, effectively blocking the backdoor path by intervening on each video. Extensive experiments on two benchmarks demonstrate that LDRI consistently outperforms backbone models and exhibits superior performance against state-of-the-art models. Additional comprehensive analyses confirm the deconfounding capability of LDRI. Our code is available online: https://anonymous.4open.science/r/LDRI/.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Short-Video Recommendations, Bias Mitigation, Temporal Dynamics, Model Agnostic, Causal Inference, User Modeling, Evaluation Methods, Matching Models, Confounding Variables, Recency Sensitivity (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1053/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>End-to-End Cost-Effective Incentive Recommendation under Budget Constraint with Uplift Modeling (2024)</h3>
    <p><strong>Authors:</strong> Yunpeng Weng, Xiuqiang He, Hao Yang, Dugang Liu, Xing Tang, Zexu Sun</p>
    <p>In modern online platforms, incentive (<i>e.g</i>., discounts, bonus) are essential factors that enhance user engagement and increase platform revenue. Over recent years, uplift modeling has been introduced as a strategic approach to assign incentive to individual customers. Especially, in many real-world applications, online platforms can only incentivize customers with specific budget constraints. This problem can be reformulated as the multi-choice knapsack problem (MCKP). The objective of this optimization is to select the optimal incentive for each customer in order to maximize the return-on-investment (ROI). Recent works in this field frequently tackle the problem of budget allocation using a two-stage approach. %: the first stage utilizes causal inference algorithms to estimate the individual treatment effect or uplift, while the second stage employs integer programming techniques to determine the optimal solution for budget allocation. However, this solution is confronted with the following challenges: (1) The commonly used causal inference methods often ignore the domain knowledge in online marketing, where the expected response curve of a customer should be monotonic and smooth as the incentive increases. (2) There is an optimality gap between the two stages, resulting in inferior sub-optimal allocation performance, which is due to the loss of the incentive recommendation information for the uplift prediction under the limited budget constraint. To address these challenges, we propose a novel <u>E</u>nd-to-<u>E</u>nd Cost-<u>E</u>ffective <u>I</u>ncentive <u>R</u>ecommendation (E$^3$IR) model under the budget constraint. Specifically, our methods consist of two modules: the uplift prediction module and the differentiable allocation module. In the uplift prediction module, we construct prediction heads to capture the incremental improvement between adjacent treatments with the marketing domain constraints (<i>i.e.</i>, monotonic and smooth). %To obtain a monotonic user response curve, we constrain the output of each prediction head to be non-negative. In the differentiable allocation module, we incorporate integer linear programming (ILP) as a differentiable layer input. Furthermore, we conduct extensive experiments on both public and real product datasets, which demonstrate that our E$^3$IR improves allocation performance compared to existing two-stage approaches.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Marketing Strategies, E-commerce, Uplift Modeling, Resource Management, Optimization, Causal Inference, Integer Linear Programming, Real-World Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1038/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Why the Shooting in the Dark Method Dominates Recommender Systems Practice (2024)</h3>
    <p><strong>Authors:</strong> David Rohde</p>
    <p>The introduction of A/B Testing represented a great leap forward in recommender systems research. Like the randomized control trial for evaluating drug efficacy; A/B Testing has equipped recommender systems practitioners with a protocol for measuring performance as defined by actual business metrics and with minimal assumptions. While A/B testing provided a way to measure the performance of two or more candidate systems, it provides no guide for determining what policy we should test. The focus of this industry talk is to better understand, why the development of A/B testing was the last great leap forward in the development of reward optimizing recommender systems despite more than a decade of efforts in both industry and academia. The talk will survey: industry best practice, standard theories and tools including: collaborative filtering (MovieLens RecSys), contextual bandits, attribution, off-policy estimation, causal inference, click through rate models and will explain why we have converged on a fundamentally heuristic solution or guess and check type method. The talk will offer opinions about which of these theories are useful, and which are not and make a concrete proposal to make progress based on a non-standard use of deep learning tools.</p>
    <p><strong>Categories:</strong> A/B Testing, Evaluation Methods, Industry Practices, Challenges, Collaborative Filtering, Contextual Bandits, Attribution, Off-Policy Estimation, Causal Inference, Click-Through Rate Models, Methodologies, Theory Application, Future Directions (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1183/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Towards Understanding The Gaps of Offline And Online Evaluation Metrics: Impact of Series vs. Movie Recommendations (2024)</h3>
    <p><strong>Authors:</strong> Ashok Chandrashekar, Puja Das, Bora Edizel, Tim Sweetser, Kamilia Ahmadi</p>
    <p>In the realm of recommender systems research, offline evaluation metrics like NDCG, Recall, or Precision are often used to measure the impact. On the other hand, common industry practices suggest evaluating new ideas/models through A/B tests where decisions are made based on business metrics like the overall engagement of users. A new model may show improvement in offline metrics but performance loss in online metrics. One reason that leads to this phenomenon is the counterfactual nature of the recommendation problem which can be addressed by off-policy evaluation methods. Another reason is the degree of causal connection between offline evaluation metrics and observed online metrics. In this work, we will share our learnings from two sets of A/B tests that we conducted at Max1 where we observed a mismatch between online and offline metrics due to a weak causal connection between online and offline metrics. Thanks to learnings from A/B tests, we discovered and quantified the impact of series to movie ratio at recommendations. Our experiments show that there is an optimal amount of series to movies ratio that provides the best possible results for user engagement</p>
    <p><strong>Categories:</strong> Evaluation Metrics, Offline Evaluation, Online Evaluation, Recommender Systems, A/B Testing, User Engagement, Content Types, Causal Inference, Business Metrics, Movie Recommendations, Series Recommendations (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1182/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Online Evaluation Methods for the Causal Effect of Recommendations (2021)</h3>
    <p><strong>Authors:</strong> Masahiro Sato</p>
    <p>Evaluating the causal effect of recommendations is an important objective because the causal effect on user interactions can directly leads to an increase in sales and user engagement. To select an optimal recommendation model, it is common to conduct A/B testing to compare model performance. However, A/B testing of causal effects requires a large number of users, making such experiments costly and risky. We therefore propose the first interleaving methods that can efficiently compare recommendation models in terms of causal effects. In contrast to conventional interleaving methods, we measure the outcomes of both items on an interleaved list and items not on the interleaved list, since the causal effect is the difference between outcomes with and without recommendations. To ensure that the evaluations are unbiased, we either select items with equal probability or weight the outcomes using inverse propensity scores. We then verify the unbiasedness and efficiency of online evaluation methods through simulated online experiments. The results indicate that our proposed methods are unbiased and that they have superior efficiency to A/B testing.</p>
    <p><strong>Categories:</strong> Causal Effect Evaluation, Recommendation Systems, Online Experiments, Interleaving Methods, A/B Testing, Causal Inference, Algorithm Comparison, User Engagement, Efficiency Optimization, Unbiased Evaluation (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/648/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Debiasing Item-to-Item Recommendations With Small Annotated Datasets (2020)</h3>
    <p><strong>Authors:</strong> Tobias Schnabel, Paul N. Bennett</p>
    <p>Item-to-item recommendation (e.g., “People who like this also like...”) is a ubiquitous and important type of recommendation in real-world systems. Observational data from historical interaction logs abound in these settings. However, since virtually all observational data exhibit biases, such as time-in-inventory or interface biases, it is crucial that recommender algorithms account for these biases. In this paper, we develop a principled approach for item-to-item recommendation based on causal inference and present a practical and highly effective method for estimating the causal parameters from a small annotated dataset. Empirically, we find that our approach substantially improves upon existing methods while requiring only small amounts of annotated data.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Bias Mitigation, Fairness, Item-to-Item Recommendations, Causal Inference, Beyond Accuracy, Empirical Evaluation, Practical Applications, Ethics, Robustness, Small Datasets, Evaluation Methods (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/530/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Causal Inference on Recommender Systems (2020)</h3>
    <p><strong>Authors:</strong> David Blei, Yixin Wang, Laurent Charlin, Dawen Liang</p>
    <p>Recommender systems have become crucial in information filtering nowadays. Existing recommender systems extract user preferences based on the correlation in data, such as behavioral correlation in collaborative filtering, feature-feature, or feature-behavior correlation in click-through rate prediction. However, unfortunately, the real world is driven by causality, not just correlation, and correlation does not imply causation. For instance, recommender systems might recommend a battery charger to a user after buying a phone, where the latter can serve as the cause of the former; such a causal relation cannot be reversed. Recently, to address this, researchers in recommender systems have begun utilizing causal inference to extract causality, thereby enhancing the recommender system. In this survey, we offer a comprehensive review of the literature on causal inference-based recommendation. Initially, we introduce the fundamental concepts of both recommender system and causal inference as the foundation for subsequent content. We then highlight the typical issues faced by non-causality recommender system. Following that, we thoroughly review the existing work on causal inference-based recommender systems, based on a taxonomy of three-aspect challenges that causal inference can address. Finally, we discuss the open problems in this critical research area and suggest important potential future works.</p>
    <p><strong>Categories:</strong> Causal Inference, Recommender Systems, Correlation vs Causation, Non-Causality Issues, Survey Paper, Recommendation Systems, Literature Review, Causal Methods in Recommendations, Open Problems, Future Directions (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/566/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Unbiased Learning for the Causal Effect of Recommendation (2020)</h3>
    <p><strong>Authors:</strong> Janmajay Singh, Masahiro Sato, Tomoko Ohkuma, Sho Takemori</p>
    <p>Increasing users’ positive interactions, such as purchases or clicks, is an important objective of recommender systems. Recommenders typically aim to select items that users will interact with. If the recommended items are purchased, an increase in sales is expected. However, the items could have been purchased even without recommendation. Thus, we want to recommend items that results in purchases caused by recommendation. This can be formulated as a ranking problem in terms of the causal effect. Despite its importance, this problem has not been well explored in the related research. It is challenging because the ground truth of causal effect is unobservable, and estimating the causal effect is prone to the bias arising from currently deployed recommenders. This paper proposes an unbiased learning framework for the causal effect of recommendation. Based on the inverse propensity scoring technique, the proposed framework first constructs unbiased estimators for ranking metrics. Then, it conducts empirical risk minimization on the estimators with propensity capping, which reduces variance under finite training samples. Based on the framework, we develop an unbiased learning method for the causal effect extension of a ranking metric. We theoretically analyze the unbiasedness of the proposed method and empirically demonstrate that the proposed method outperforms other biased learning methods in various settings.</p>
    <p><strong>Categories:</strong> Causal Inference, Recommender Systems, E-commerce, Unbiased Learning, Ranking Metrics, Causal Effect, Empirical Risk Minimization, Propensity Score, Bias in Recommendations, Theoretical Analysis, Unbiased Evaluation (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/562/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Uplift-based Evaluation and Optimization of Recommenders (2019)</h3>
    <p><strong>Authors:</strong> Sho Takemori, Qian Zhang, Masahiro Sato, Takashi Sonoda, Janmajay Singh, Tomoko Ohkuma</p>
    <p>Recommender systems aim to increase user actions such as clicks and purchases. Typical evaluations of recommenders regard the purchase of a recommended item as a success. However, the item may have been purchased even without the recommendation. An uplift is defined as an increase in user actions caused by recommendations. Situations with and without a recommendation cannot both be observed for a specific user-item pair at a given time instance, making uplift-based evaluation and optimization challenging. This paper proposes new evaluation metrics and optimization methods for the uplift in a recommender system. We apply a causal inference framework to estimate the average uplift for the offline evaluation of recommenders. Our evaluation protocol leverages both purchase and recommendation logs under a currently deployed recommender system, to simulate the cases both with and without recommendations. This enables the offline evaluation of the uplift for newly generated recommendation lists. For optimization, we need to define positive and negative samples that are specific to an uplift-based approach. For this purpose, we deduce four classes of items by observing purchase and recommendation logs. We derive the relative priorities among these four classes in terms of the uplift and use them to construct both pointwise and pairwise sampling methods for uplift optimization. Through dedicated experiments with three public datasets, we demonstrate the effectiveness of our optimization methods in improving the uplift.</p>
    <p><strong>Categories:</strong> Uplift Modeling, Causal Inference, Recommendation Systems, Evaluation Metrics, Offline Evaluation, Beyond Accuracy, Optimization Methods, Real World Data (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/457/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>