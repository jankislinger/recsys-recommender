<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reinforcement-learning/">Reinforcement Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/e-commerce/">E-commerce</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reproducibility/">Reproducibility</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/beyond-accuracy/">Beyond Accuracy</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/evaluation-methods/">Evaluation Methods</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Scale-Invariant Learning-to-Rank (2024)</h3>
    <p><strong>Authors:</strong> Ye-Sheen Lim, Alessio Petrozziello, Xiaoke Liu, Christian Sommeregger</p>
    <p>At Expedia, learning-to-rank (LTR) models plays a key role on our website in sorting and presenting information more relevant to users, such as search filters, property rooms, amenities, and images. A major challenge in deploying these models is ensuring consistent feature scaling between training and production data, as discrepancies can lead to unreliable rankings when deployed. Normalization techniques like feature standardization and batch normalization could address these issues but are impractical in production due to latency impacts and the difficulty of distributed real-time inference. To address consistent feature scaling issue, we introduce a scale-invariant LTR framework which combines a deep and a wide neural network to mathematically guarantee scale-invariance in the model at both training and prediction time.</p>
    <p><strong>Categories:</strong> Learning-to-Rank, E-commerce, Travel, Model Scaling, Feature Engineering, Production Systems, Scale-Invariant Methods, Ranking Algorithms, Web Systems, Real-World Applications, Model Robustness, Algorithm Design (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1174/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Ranking Across Different Content Types: The Robust Beauty of Multinomial Blending (2024)</h3>
    <p><strong>Authors:</strong> Jan Malte Lichtenberg, Giuseppe Di Benedetto, Matteo Ruffini</p>
    <p>An increasing number of media streaming services have expanded their offerings to include entities of multiple content types. For instance, audio streaming services that started by offering music only, now also offer podcasts, merchandise items, and (music) videos. Ranking items across different content types into a single slate poses a significant challenge for traditional learning-to-rank (LTR) algorithms due to differing feature sets and user engagement patterns for different content types. We explore a simple method, called multinomial blending (MB), which can be used in conjunction with most existing LTR algorithms. We compare MB to a range of baselines not only in terms of ranking quality but also from other industry-relevant perspectives such as interpretability, ease-of-use, and stability in dynamic online-learning environments.</p>
    <p><strong>Categories:</strong> Learning-to-Rank, Multinomial Blending, Media Streaming Services, Content Types, Ranking Across Different Content Types, Cross-Content Type Recommendations, Real-World Applications, Beyond Accuracy, Scalability, Online Learning, Heterogeneous Data, User Engagement Patterns, Feature Engineering, Experimental Evaluation (<i>deepseek-r1:70b</i>)</p>
    <p><a href="/recsys-recommender/response/1180/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>A Probabilistic Position Bias Model for Short-Video Recommendation Feeds (2023)</h3>
    <p><strong>Authors:</strong> Olivier Jeunen</p>
    <p>Modern web-based platforms often show ranked lists of recommendations to users, in an attempt to maximise user satisfaction or business metrics. Typically, the goal of such systems boils down to maximising the exposure probability — conversely, minimising the rank— for items that are deemed “reward-maximising” according to some metric of interest. This general framing comprises music or movie streaming applications, as well as e-commerce, restaurant or job recommendations, and even web search. Position bias or user models can be used to estimate exposure probabilities for each use-case, specifically tailored to how users interact with the presented rankings. A unifying factor in these diverse problem settings is that typically only one or several items will be engaged with (clicked, streamed, purchased, et cetera) before a user leaves the ranked list.  Short-video feeds on social media platforms diverge from this general framing in several ways, most notably that users do not tend to leave the feed after, for example, liking a post. Indeed, seemingly infinite feeds invite users to scroll further down the ranked list. For this reason, existing position bias or user models tend to fall short in such settings, as they do not accurately capture users’ interaction modalities. In this work, we propose a novel and probabilistically sound personalised position bias model for feed recommendations. We focus on a 1st-level feed in a hierarchical structure, where users may enter a 2nd-level feed via any given 1st-level item. We posit that users come to the platform with a given scrolling budget that is drawn according to a discrete power-law distribution, and show how the survival function of said distribution can be used to obtain closed-form estimates for personalised exposure probabilities. Empirical insights gained through data from a large-scale social media platform show how our probabilistic position bias model more accurately captures empirical exposure than existing models, and paves the way for improved unbiased evaluation and learning-to-rank.</p>
    <p><strong>Categories:</strong> Probabilistic Models, Short-Video Recommendations, Social Media Platforms, Position Bias, Recommendation Systems, Learning to Rank, Exposure Probability, Personalized Recommendations, User Engagement, Real-World Applications, Hierarchical Feed Structures, Empirical Analysis, User Interaction Patterns (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/894/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Adaptive Pointwise-Pairwise Learning-to-Rank for Content-based Personalized Recommendation (2020)</h3>
    <p><strong>Authors:</strong> Jean-Michel Renders, Yagmur Gizem Cinar</p>
    <p>This paper extends the standard pointwise and pairwise paradigms for learning-to-rank in the context of personalized recommendation, by considering these two approaches as two extremes of a continuum of possible strategies. It basically consists of a surrogate loss that models how to select and combine these two approaches adaptively, depending on the context (query or user, pair of items, etc.). In other words, given a training instance, which is typically a triplet (a query/user and two items with different preferences or relevance grades), the strategy adaptively determines whether it is better to focus on the “most preferred” item (pointwise - positive instance), on the “less preferred” one (pointwise - negative instance) or on the pair (pairwise), or on anything else in between these 3 extreme alternatives. We formulate this adaptive strategy as minimizing a particular loss function that generalizes simultaneously the traditional pointwise and pairwise loss functions (negative log-likelihood) through a mixture coefficient. This coefficient is formulated as a learnable function of the features associated to the triplet. Experimental results on several real-world news recommendation datasets show clear improvements over several pointwise, pairwise, and listwise approaches.</p>
    <p><strong>Categories:</strong> Learning-to-Rank, Personalized Recommendation, Pointwise Learning, Pairwise Learning, Adaptive Methods, Contextual Modeling, Loss Functions, Triplet Learning, News Recommendations, Relevance Ranking, Preference Modeling, Beyond Accuracy, Evaluation Metrics, Content-Based Recommendation (<i>deepseek-r1:70b</i>)</p>
    <p><a href="/recsys-recommender/response/565/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Online Learning to Rank for Sequential Music Recommendation (2019)</h3>
    <p><strong>Authors:</strong> Alberto Ueda, Nivio Ziviani, Bruno L. Pereira, Gustavo Penha, Rodrygo L. T. Santos</p>
    <p>The prominent success of music streaming services has brought increasingly complex challenges for music recommendation. In particular, in a streaming setting, songs are consumed sequentially within a listening session, which should cater not only for the user’s historical preferences, but also for eventual preference drifts, triggered by a sudden change in the user’s context. In this paper, we propose a novel online learning to rank approach for music recommendation aimed to continuously learn from the user’s listening feedback. In contrast to existing online learning approaches for music recommendation, we leverage implicit feedback as the only signal of the user’s preference. Moreover, to adapt rapidly to preference drifts over millions of songs, we represent each song in a lower dimensional feature space and explore multiple directions in this space as duels of candidate recommendation models. Our thorough evaluation using listening sessions from Last.fm demonstrates the effectiveness of our approach at learning faster and better compared to state-of-the-art online learning approaches.</p>
    <p><strong>Categories:</strong> Music Recommendations, Online Learning, Implicit Feedback, Streaming Music, Sequential Recommendations, Preference Drift, Real-World Applications, Learning to Rank, Feature Engineering, Model Comparison, Recommendation Systems, Dynamic Recommendations, Evaluation Metrics (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/449/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Get Me The Best: Predicting Best Answerers in Community Question Answering Sites (2018)</h3>
    <p><strong>Authors:</strong> Manisha Dubey, Maunendra Sankar Desarkar, Rohan Ravindra Tondulkar</p>
    <p>There has been a massive rise in the use of Community Question and Answering (CQA) forums to get solutions to various technical and non-technical queries. One common problem faced in CQA is the small number of experts, which leaves many questions unanswered. This paper addresses the challenging problem of predicting the best answerer for a new question and thereby recommending the best expert for the same. Although there are work in the literature that aim to find possible answerers for questions posted in CQA, very few algorithms exist for finding the best answerer whose answer will satisfy the information need of the original Poster. For finding answerers, existing approaches mostly use features based on content and tags associated with the questions. There are few approaches that additionally consider the users’ history. In this paper, we propose an approach that considers a comprehensive set of features including but not limited to text representation, tag based similarity as well as multiple user-based features that target users’ availability, agility as well as expertise for predicting the best answerer for a given question. We also include features that give incentives to users who answer less but more important questions over those who answer a lot of questions of less importance. A learning to rank algorithm is used to find the weight for each feature. Experiments conducted on a real dataset from Stack Exchange show the efficacy of the proposed method in terms of multiple evaluation metrics for accuracy, robustness and real time performance.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Community Question Answering, Expert Finding, Learning to Rank, User Behavior Modeling, Text Representation, Tag-Based Similarity, Performance Evaluation, Real-Time Performance, User Incentives (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/340/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Practical Lessons from Developing a Large-Scale Recommender System at Zalando (2017)</h3>
    <p><strong>Authors:</strong> Antonino Freno</p>
    <p>Developing a real-world recommender system, i.e. for use in large-scale online retail, poses a number of different challenges. Interestingly, only a small part of these challenges are of algorithmic nature, such as how to select the most accurate model for a given use case. Instead, most technical problems usually arise from operational constraints, such as: adaptation to novel use cases; cost and complexity of system maintenance; capability of reusing pre-existing signal and integrating heterogeneous data sources. In this paper, we describe the system we developed in order to address those constraints at Zalando, which is one of the most popular online fashion retailers in Europe. In particular, we explain how moving from a collaborative filtering approach to a learning-to-rank model helped us to effectively tackle the challenges mentioned above, while improving at the same time the quality of our recommendations. A fairly detailed description of our software architecture is provided, along with an overview of the algorithmic approach. On the other hand, we present some of the offline and online experiments that we ran in order to validate our models.</p>
    <p><strong>Categories:</strong> Recommender Systems, Online Retail, Fashion, Collaborative Filtering, Learning-to-Rank, System Architecture, Real-World Applications, Scalability, Operational Challenges, Model Validation, A/B Test, Data Integration, Recommendation Quality, Evaluation Metrics, Model Selection (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/271/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Controlling Popularity Bias in Learning-to-Rank Recommendation (2017)</h3>
    <p><strong>Authors:</strong> Bamshad Mobasher, Himan Abdollahpouri, Robin Burke</p>
    <p>Many recommendation algorithms suffer from popularity bias in their output: popular items are recommended frequently and less popular ones rarely, if at all. However, less popular, long-tail items are precisely those that are desirable for increased user satisfaction. In this paper, we introduce a flexible regularization-based framework to enhance the longtail coverage of recommendation lists in a learning-to-rank algorithm. We show that regularization provides a tunable mechanism for controlling the trade-off between accuracy and coverage. Moreover, the experimental results using two data sets show that it is possible to achieve higher coverage of long tail items without substantial sacrifice of ranking performance.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Popularity Bias, Long-tail Items, Learning-to-Rank, Regularization, Coverage, Accuracy vs Coverage, User Satisfaction (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/281/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>entity2rec: Learning User-Item Relatedness from Knowledge Graphs for Top-N Item Recommendation (2017)</h3>
    <p><strong>Authors:</strong> Raphaël Troncy, Enrico Palumbo, Giuseppe Rizzo</p>
    <p>Knowledge Graphs have proven to be extremely valuable to recommender systems, as they enable hybrid graph-based recommendation models encompassing both collaborative and content information. Leveraging this wealth of heterogeneous information for top-N item recommendation is a challenging task, as it requires the ability of effectively encoding a diversity of semantic relations and connectivity patterns. In this work, we propose a novel approach to learning user-item relatedness from knowledge graphs for top-N item recommendations. We start from a knowledge graph modeling user-item and item-item relations and we learn property-specific vector representations of users and items applying neural language models on the network. These representations are used to create property-specific user-item relatedness features, which are in turn fed into learning to rank algorithms to learn a global relatedness model that optimizes top-N item recommendations. We evaluate the proposed approach in terms of ranking quality on the MovieLens 1M dataset, outperforming two state-of-the-art recommender systems, and we assess the importance of property-specific relatedness scores on the overall ranking quality.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Hybrid Models, Top-N Recommendation, Deep Learning, Learning to Rank, Knowledge Graphs, Movies, Ranking Quality, Beyond Accuracy, User-Item Embeddings, Hybrid Approaches (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/287/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Learning to Rank with Trust and Distrust in Recommender Systems (2017)</h3>
    <p><strong>Authors:</strong> Dimitrios Rafailidis, Fabio Crestani</p>
    <p>The sparsity of users’ preferences can significantly degrade the quality of recommendations in the collaborative filtering strategy. To account for the fact that the selections of social friends and foes may improve the recommendation accuracy, we propose a learning to rank model that exploits users’ trust and distrust relationships. Our learning to rank model focusses on the performance at the top of the list, with the recommended items that end-users will actually see. In our model, we try to push the relevant items of users and their friends at the top of the list, while ranking low those of their foes. Furthermore, we propose a weighting strategy to capture the correlations of users’ preferences with friends’ trust and foes’ distrust degrees in two intermediate trust- and distrust-preference user latent spaces, respectively. Our experiments on the Epinions dataset show that the proposed learning to rank model significantly outperforms other state-of-the-art methods in the presence of sparsity in users’ preferences and when a part of trust and distrust relationships is not available. Furthermore, we demonstrate the crucial role of our weighting strategy in our model, to balance well the influences of friends and foes on users’ preferences.</p>
    <p><strong>Categories:</strong> Learning to Rank, Recommender Systems, Trust and Distrust, Collaborative Filtering, Sparsity Handling, Top-N Recommendations, Beyond Accuracy, Social Networks, Latent Factor Models (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/269/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>WMRB: Learning to Rank in a Scalable Batch Training Approach (2017)</h3>
    <p><strong>Authors:</strong> Kuan Liu, Prem Natarajan</p>
    <p>We propose a new learning to rank algorithm, named Weighted Margin-Rank Batch loss (WMRB), to extend the popular Weighted Approximate-Rank Pairwise loss (WARP). WMRB uses a new rank estimator and an efficient batch training algorithm. The approach allows more accurate item rank approximation and explicit utilization of parallel computation to accelerate training. In three item recommendation tasks, WMRB consistently outperforms WARP and other baselines. Moreover, WMRB shows clear time efficiency advantages as data scale increases.</p>
    <p><strong>Categories:</strong> Learning to Rank, Recommendation Systems, Scalability, Batch Training, Optimization, Ranking Methods, Real-World Applications, Evaluation Metrics, Machine Learning Techniques, Algorithmic Extensions (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/303/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>On Parallelizing SGD for Pairwise Learning to Rank in Collaborative Filtering Recommender Systems (2017)</h3>
    <p><strong>Authors:</strong> Fikret Gurgen, Murat Yagci, Tevfik Aytekin</p>
    <p>Learning to rank with pairwise loss functions has been found useful in collaborative filtering recommender systems. At web scale, the optimization is often based on stochastic gradient descent (SGD) which has a sequential nature. We investigate two different shared memory lock-free parallel SGD schemes based on block partitioning and no partitioning for use with pairwise loss functions. To speed up convergence to a solution, we extrapolate simple practical algorithms from their application to pointwise learning to rank. Experimental results show that the proposed algorithms are quite useful regarding their ranking ability and speedup patterns in comparison to their sequential counterpart.</p>
    <p><strong>Categories:</strong> Collaborative Filtering, Recommender Systems, Learning to Rank, Pairwise Loss Functions, Stochastic Gradient Descent (SGD), Parallelization, Web Scale Applications, Optimization Algorithms, Recommendation Accuracy, Scalability (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/293/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>MPR: Multi-Objective Pairwise Ranking (2017)</h3>
    <p><strong>Authors:</strong> Rasaq Otunba, Jessica Lin, Raimi A. Rufai</p>
    <p>The recommendation challenge can be posed as the problem of predicting either item ratings or item rankings. The latter approach has proven more effective. Pairwise learning-to-rank techniques have been relatively successful. Hence, they are popularly used for learning recommender model parameters such as those in collaborative filtering (CF) models. The model parameters are learned by optimizing close smooth approximations of the non-smooth information retrieval (IR) metrics such as Mean Area Under ROC curve (AUC). Targeted campaigns are an alternative to item recommendations for increasing conversion. The user ranking task is referred to as audience retrieval. It is used in targeted campaigns to rank push campaign recipients based on their potential to convert. In this work, we consider the task of efficiently learning a ranking model that provides item recommendations and user rankings simultaneously.  We adopt pairwise learning for this task. We refer to our novel approach as multi-objective pairwise ranking (MPR). We describe our approach and evaluate its performance by experiments.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Pairwise Ranking, Multi-Objective Optimization, Collaborative Filtering, Learning-to-Rank, Audience Retrieval, Targeted Campaigns, Evaluation Metrics, Ranking Models, Information Retrieval (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/273/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Context-Aware Event Recommendation in Event-based Social Networks (2015)</h3>
    <p><strong>Authors:</strong> Leandro B. Marinho, Rodrygo L. T. Santos, Augusto Q. Macedo</p>
    <p>The Web has grown into one of the most important channels to communicate social events nowadays. However, the sheer volume of events available in event-based social networks (EBSNs) often undermines the users’ ability to choose the events that best fit their interests. Recommender systems appear as a natural solution for this problem, but differently from classic recommendation scenarios (e.g. movies, books), the event recommendation problem is intrinsically cold-start. Indeed, events published in EBSNs are typically short-lived and, by definition, are always in the future, having little or no trace of historical attendance. To overcome this limitation, we propose to exploit several contextual signals available from EBSNs. In particular, besides content-based signals based on the events’ description and collaborative signals derived from users’ RSVPs, we exploit social signals based on group memberships, location signals based on the users’ geographical preferences, and temporal signals derived from the users’ time preferences. Moreover, we combine the proposed signals for learning to rank events for personalized recommendation. Thorough experiments using a large crawl of Meetup.com demonstrate the effectiveness of our proposed contextual learning approach in contrast to state-of-the-art event recommenders from the literature.</p>
    <p><strong>Categories:</strong> Event Recommendation, Social Networks, Cold Start, Contextual Signals, Content-Based Signals, Collaborative Filtering, Social Signals, Location-Based Recommendations, Temporal Signals, Learning to Rank, Evaluation of Recommendation Systems, Real-World Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/89/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Beyond Clicks: Dwell Time for Personalization (2014)</h3>
    <p><strong>Authors:</strong> Liangjie Hong, Suju Rajan, Xing Yi, Nathan Liu, Erheng Zhong</p>
    <p>Many internet companies, such as Yahoo, Facebook, Google and Twitter, rely on content recommendation systems to deliver the most relevant content items to individual users through personalization. Delivering such personalized user experiences is believed to increase the long term engagement of users. While there has been a lot of progress in designing effective personalized recommender systems, by exploiting user interests and historical interaction data through implicit (item click) or explicit (item rating) feedback, directly optimizing for users satisfaction with the system remains challenging. In this paper, we explore the idea of using item-level dwell time as a proxy to quantify how likely a content item is relevant to a particular user. We describe a novel method to compute accurate dwell time based on client-side and server-side logging and demonstrate how to normalize dwell time across different devices and contexts. In addition, we demonstrate how to incorporate dwell time into state-of-the-art learning to rank techniques and collaborative filtering models and obtain competitive performances in both offline and online settings. This paper is the first work to go beyond “clicks” for optimizing for large-scale content recommendation, and outlines a number of interesting future research directions.</p>
    <p><strong>Categories:</strong> Personalization, Recommendation Systems, Implicit Feedback, User Engagement, Learning to Rank, Collaborative Filtering, Dwell Time, Large-Scale Content Recommendation, Real World Applications, Evaluation Metrics. (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/9/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Towards a Dynamic Top-N Recommendation Framework (2014)</h3>
    <p><strong>Authors:</strong> Xin Liu</p>
    <p>Real world large-scale recommender systems are always dynamic: new users and items continuously enter the system, and the status of old ones (e.g., users’ preference and items’ popularity) evolve over time. In order to handle such dynamics, we propose a recommendation framework consisting of an online component and an offline component, where the newly arrived items are processed by the online component such that users are able to get suggestions for fresh information, and the influence of longstanding items is captured by the offline component. Based on individual users’ past rating behavior, recommendations from the two components are combined to provide top-N recommendation. We formulate recommendation problem as a ranking problem where learning to rank is applied to extend upon a latent factor model to optimize recommendation rankings by minimizing a pairwise loss function. Furthermore, to more accurately model interactions between users and items, Latent Dirichlet Allocation is incorporated to fuse rating information and textual information. Real data based experiments demonstrate that our approach outperforms the state-of-the-art models by at least 61.21% and 50.27% in terms of mean average precision (MAP) and normalized discounted cumulative gain (NDCG) respectively.</p>
    <p><strong>Categories:</strong> Dynamic Recommendations, Top-N Recommendations, Online Algorithms, Offline Processing, Latent Factor Models, Learning to Rank, Textual Information Fusion, Mean Average Precision (MAP), Normalized Discounted Cumulative Gain (NDCG), Real Data Experiments (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/36/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>