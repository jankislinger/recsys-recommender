<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reinforcement-learning/">Reinforcement Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reproducibility/">Reproducibility</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/e-commerce/">E-commerce</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/cold-start/">Cold Start</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Fairness Matters: A look at LLM-generated group recommendations (2024)</h3>
    <p><strong>Authors:</strong> Antonela Tommasel</p>
    <p>Recommender systems play a crucial role in how users consume information, with group recommendation receiving considerable attention. Ensuring fairness in group recommender systems entails providing recommendations that are useful and relevant to all group members rather than solely reflecting the majority’s preferences, while also addressing fairness concerns related to sensitive attributes (e.g., gender). Recently, the advancements on Large Language Models (LLMs) have enabled the development of new kinds of recommender systems. However, LLMs can perpetuate social biases present in training data, posing risks of unfair outcomes and harmful impacts. We investigated LLMs impact on group recommendation fairness, establishing and instantiating a framework that encompasses group definition, sensitive attribute combinations, and evaluation methodology. Our findings revealed the interactions patterns between sensitive attributes and LLMs and how they affected recommendation. This study advances the understanding of fairness considerations in group recommendation systems, laying the groundwork for future research.</p>
    <p><strong>Categories:</strong> Recommender Systems, Fairness, Group Recommendations, Large Language Models (LLMs), Sensitive Attributes, Bias Mitigation, Natural Language Processing (NLP), Evaluation Methodology, Social Biases, Societal Impact (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1089/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Long-term fairness for Group Recommender Systems with Large Groups (2022)</h3>
    <p><strong>Authors:</strong> Patrik Dokoupil</p>
    <p>Group recommender systems (GRS) focus on recommending items to groups of users. GRS need to tackle the heterogeneity of group members’ preferences and produce recommendations of high overall utility while also considering some sense of fairness among group members. This work plans to aim for novel applications of GRS involving construction of large-scale groups of users and focusing on the long-term fairness of these groups which is in contrast with current research that concentrates on small groups of ephemeral nature. We believe that these directions could bring results of significant societal impact and scope of the effect expanding beyond currently considered GRS domains, e.g., helping to mitigate the filter bubble problem</p>
    <p><strong>Categories:</strong> Group Recommender Systems, Fairness in Recommendations, Large-scale Groups, Long-term Effects, Societal Impact, Scalability, Real-World Applications, Personalization, Diversity of Recommendations, Beyond Accuracy (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/808/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Algorithms Aside: Recommendation As The Lens Of Life (2016)</h3>
    <p><strong>Authors:</strong> Marko Tkalcic, Paolo Cremonesi, Anna Zacchi, Ayse Göker, Daniel Kohlsdorf, Davide Malagoli, Jean-Yves Le Moine, Martha Larson, Francesco Ricci, Domonkos Tikk, Andreas Lommatzsch, Thuy Ngoc Nguyen, Tamas Motajcsek, Jasminko Novak, Kristaps Dobrajs, Franca Garzotto, Omar Alonso, Andrew Demetriou, Frank Hopfgartner, Mario Scriminaci</p>
    <p>In this position paper, we take the experimental approach of putting algorithms aside, and reflect on what recommenders would be for people if they were not tied to technology. By looking at some of the shortcomings that current recommenders have fallen into and discussing their limitations from a human point of view, we ask the question: if freed from all limitations, what should, and what could, RecSys be? We then turn to the idea that life itself is the best recommender system, and that people themselves are the query. By looking at how life brings people in contact with options that suit their needs or match their preferences, we hope to shed further light on what current RecSys could be doing better. Finally, we look at the forms that RecSys could take in the future. By formulating our vision beyond the reach of usual considerations and current limitations, including business models, algorithms, data sets, and evaluation methodologies, we attempt to arrive at fresh conclusions that may inspire the next steps taken by the community of researchers working on RecSys.</p>
    <p><strong>Categories:</strong> Future Directions, Human-Centered Design, Ethical Considerations, Philosophy of Recommendations, Personalization Beyond Algorithms, Visionary Concepts, Societal Impact, Business Models in Recommendations, Reflections on Recommender Systems (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/217/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>