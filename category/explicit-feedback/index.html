<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui primary button" style="margin: 5px;"
             href="/recsys-recommender/">Explicit Feedback</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reinforcement-learning/">Reinforcement Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/multi-armed-bandits/">Multi-Armed Bandits</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/user-behavior/">User Behavior</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/offline-evaluation/">Offline Evaluation</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Calibrating the Predictions for Top-N Recommendations (2024)</h3>
    <p><strong>Authors:</strong> Masahiro Sato</p>
    <p>Well-calibrated predictions of user preferences are essential for many applications. Since recommender systems typically select the top-N items for users, calibration for those top-N items, rather than for all items, is important.  We show that previous calibration methods result in miscalibrated predictions for the top-N items, despite their excellent calibration performance when evaluated on all items.  In this work, we address the miscalibration in the top-N recommended items. We first define evaluation metrics for this objective and then propose a generic method to optimize calibration models focusing on the top-N items. It groups the top-N items by their ranks and optimizes distinct calibration models for each group with rank-dependent training weights.  We verify the effectiveness of the proposed method for both explicit and implicit feedback datasets, using diverse classes of recommender models.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Top-N Recommendations, Calibration of Predictions, Evaluation Metrics, Optimization Methods, Explicit Feedback, Implicit Feedback, Diverse Recommenders, Accuracy of Recommendations, Matrix Factorization, Multi-Armed Bandits, Algorithm Evaluation, Item Ranking (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1082/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>The Effect of Feedback Granularity on Recommender Systems Performance (2022)</h3>
    <p><strong>Authors:</strong> Ladislav Peska, Stepan Balcar</p>
    <p>The main source of knowledge utilized in recommender systems (RS) is users’ feedback. While the usage of implicit feedback (i.e. user’s behavior statistics) is gaining in prominence, the explicit feedback (i.e. user’s ratings) remain an important data source. This is true especially for domains, where evaluation of an object does not require an extensive usage and users are well motivated to do so (e.g., video-on-demand services or library archives).<br>So far, numerous rating schemes for explicit feedback have been proposed, ranging both in granularity and presentation style. There are several works studying the effect of rating’s scale and presentation on user’s rating behavior, e.g. willingness to provide feedback or various biases in rating behavior. Nonetheless, the effect of ratings granularity on RS performance remain largely under-researched.<br>In this paper, we studied the combined effect of ratings granularity and supposed probability of feedback existence on various performance statistics of recommender systems. Results indicate that decreasing feedback granularity may lead to changes in RS’s performance w.r.t. nDCG for some recommending algorithms. Nonetheless, in most cases the effect of feedback granularity is surpassed by even a small decrease in feedback’s quantity. Therefore, our results corroborate the policy of many major real-world applications, i.e. preference of simpler rating schemes with the higher chance of feedback reception instead of finer-grained rating scenarios.</p>
    <p><strong>Categories:</strong> Explicit Feedback, Implicit Feedback, Recommender Systems, Evaluation Metrics, Rating Granularity, User Behavior, Real-World Applications, Video-on-Demand Services, Library Archives, Beyond Accuracy. (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/797/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Denoising User-aware Memory Network for Recommendation (2021)</h3>
    <p><strong>Authors:</strong> Zhenqi Sun, Xiaolong Li, Kaikui Liu, Junjie Tang, Zhi Bian, Hao Fu, Qihong Yang, Shaojun Zhou, Guiquan Liu</p>
    <p>For better user satisfaction and business effectiveness, more and more attention has been paid to the sequence-based recommendation system, which is used to infer the evolution of users’ dynamic preferences, and recent studies have noticed that the evolution of users’ preferences can be better understood from the implicit and explicit feedback sequences. However, most of the existing recommendation techniques do not consider the noise contained in implicit feedback, which will lead to the biased representation of user interest and a suboptimal recommendation performance. Meanwhile, the existing methods utilize item sequence for capturing the evolution of user interest. The performance of these methods is limited by the length of the sequence, and can not effectively model the long-term interest in a long period of time. Based on this observation, we propose a novel CTR model named denoising user-aware memory network (DUMN). Specifically, the framework: (i) proposes a feature purification module based on orthogonal mapping, which use the representation of explicit feedback to purify the representation of implicit feedback, and effectively denoise the implicit feedback; (ii) designs a user memory network to model the long-term interests in a fine-grained way by improving the memory network, which is ignored by the existing methods; and (iii) develops a preference-aware interactive representation component to fuse the long-term and short-term interests of users based on gating to understand the evolution of unbiased preferences of users. Extensive experiments on two real e-commerce user behavior datasets show that DUMN has a significant improvement over the state-of-the-art baselines.</p>
    <p><strong>Categories:</strong> Deep Learning, Matrix Factorization, Sequence-based Recommendations, E-commerce, Hybrid Recommendation, Implicit Feedback, Explicit Feedback, Long-term Recommendations, Short-term Recommendations, Denoising Techniques, Memory Networks, Personalized Recommendations, User Modeling, Cold Start Problem, Accuracy Metrics, Beyond Accuracy, A/B Test. (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/634/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Combining Rating and Review Data by Initializing Latent Factor Models with Topic Models for Top-N Recommendation (2020)</h3>
    <p><strong>Authors:</strong> Barry Smyth, Aonghus Lawlor, Francisco J. Peña, Diarmuid O’Reilly-Morgan, Elias Z. Tragos, Erika Duriakova, Neil Hurley</p>
    <p>Nowadays we commonly have multiple sources of data associated with items. Users may provide numerical ratings, or implicit interactions, but may also provide textual reviews. Although many algorithms have been proposed to jointly learn a model over both interactions and textual data, there is room to improve the many factorization models that are proven to work well on interactions data, but are not designed to exploit textual information. Our focus in this work is to propose a simple, yet easily applicable and effective, method to incorporate review data into such factorization models. In particular, we propose to build the user and item embeddings within the topic space of a topic model learned from the review data. This has several advantages: we observe that initializing the user and item embeddings in topic space leads to faster convergence of the factorization algorithm to a model that out-performs models initialized randomly, or with other state-of-the-art initialization strategies. Moreover, constraining user and item factors to topic space allows for the learning of an interpretable model that users can visualise.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Explicit Feedback, Implicit Feedback, Latent Factor Models, Topic Models, User/Item Embeddings, Textual Data, Initialization Strategies, Model Convergence, Model Interpretability, Hybrid Models, Top-N Recommendations (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/575/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Style Conditioned Recommendations (2019)</h3>
    <p><strong>Authors:</strong> Kamelia Aryafar, Murium Iqbal, Timothy Anderton</p>
    <p>We propose Style Conditioned Recommendations (SCR) and introduce style injection as a method to diversify recommendations. We use Conditional Variational Autoencoder (CVAE) architecture, where both the encoder and decoder are conditioned on a user profile learned from item content data. This allows us to apply style transfer methodologies to the task of recommendations, which we refer to as injection. To enable style injection, user profiles are learned to be interpretable such that they express users’ propensities for specific predefined styles. These are learned via label-propagation from a dataset of item content, with limited labeled points. To perform injection, the condition on the encoder is learned while the condition on the decoder is selected per explicit feedback. Explicit feedback can be taken either from a user’s response to a style or interest quiz, or from item ratings. In the absence of explicit feedback, the condition at the encoder is applied to the decoder. We show a 12% improvement on NDCG@20 over the traditional VAE based approach on the task of recommendations. We show an average 22% improvement on AUC across all classes for predicting user style profiles against our best performing baseline. After injecting styles we compare the user style profile to the style of the recommendations and show that injected styles have an average +133% increase in presence. Our results show that style injection is a powerful method to diversify recommendations while maintaining personal relevance. Our main contribution is an application of a semi-supervised approach that extends item labels to interpretable user profiles.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Variational Autoencoders, Diversification of Recommendations, Explicit Feedback, Content-Based Filtering, Semi-Supervised Learning, Evaluation of Recommendation Systems, Personalization, Beyond Accuracy, Style/Theme, Interpretability, Diversity of Recommendations, Conditional Generative Models, Performance Metrics, User Feedback Mechanisms, Novelty in Recommendations (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/453/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Word2vec applied to Recommendation: Hyperparameters Matter (2018)</h3>
    <p><strong>Authors:</strong> Jimena Royo-Letelier, Hugo Caselles-Dupré, Florian Lesaint</p>
    <p>Skip-gram with negative sampling, a popular variant of Word2vec originally designed and tuned to create word embeddings for Natural Language Processing, has been used to create item embeddings with successful applications in recommendation. While these fields do not share the same type of data, neither evaluate on the same tasks, recommendation applications tend to use the same already tuned hyperparameters values, even if optimal hyperparameters values are often known to be data and task dependent. We thus investigate the marginal importance of each hyperparameter in a recommendation setting through large hyperparameter grid searches on various datasets. Results reveal that optimizing neglected hyperparameters, namely negative sampling distribution, number of epochs, subsampling parameter and window-size, significantly improves performance on a recommendation task, and can increase it by an order of magnitude. Importantly, we find that optimal hyperparameters configurations for Natural Language Processing tasks and Recommendation tasks are noticeably different.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Word Embeddings, Collaborative Filtering, Algorithm Performance, Hyperparameter Optimization, Item Embeddings, Cross-Domain Applications, Beyond Accuracy, Explicit Feedback, Implicit Feedback, Domain Adaptation (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/407/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Item Recommendation on Monotonic Behavior Chains (2018)</h3>
    <p><strong>Authors:</strong> Mengting Wan, Julian McAuley</p>
    <p>‘Explicit’ and ‘implicit’ feedback in recommender systems have been studied for many years, as two relatively isolated areas. However many real-world systems involve a spectrum of both implicit and explicit signals, ranging from clicks and purchases, to ratings and reviews. A natural question is whether implicit signals (which are dense but noisy) might help to predict explicit signals (which are sparse but reliable), or vice versa. Thus in this paper, we propose an item recommendation framework which jointly models this spectrum of interactions. Our main observation is that in many settings, feedback signals exhibit monotonic dependency structures, i.e., any signal necessarily implies the presence of a weaker (or more implicit) signal (a ‘review’ action implies a ‘purchase’ action, which implies a ‘click’ action, etc.). We refer to these structures as ‘monotonic behavior chains,’ for which we develop new algorithms that exploit these dependencies. Using several new and existing datasets that exhibit a variety of feedback types, we demonstrate the quantitative performance of our approaches. We also perform qualitative analysis to uncover the relationships between different stages of implicit vs. explicit signals.</p>
    <p><strong>Categories:</strong> Recommender Systems, Explicit Feedback, Implicit Feedback, Monotonic Behavior Chains, Algorithm Development, Model-Based Recommendations, E-Commerce, Evaluation Metrics, Performance Analysis, Real-World Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/332/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Intent-Aware Diversification using Item-Based SubProfiles (2017)</h3>
    <p><strong>Authors:</strong> Mesut Kaya, Derek Bridge</p>
    <p>In many approaches to recommendation diversification, a recommender scores items for relevance and then re-ranks them to balance relevance with diversity. In intent-aware diversification, diversity is formulated in terms of coverage of aspects, where aspects are either explicit such as movie genres or implicit such as the latent factors found during matrix factorization. Typically, the same set of aspects is used across all users. In this paper, we propose a form of personalized intent-aware diversification, which we call SPAD (SubProfile-Aware Diversification). The aspects we use in SPAD are subprofiles of the user’s profile. They are not defined in terms of explicit or implicit features. We compare SPAD to other forms of intent-aware diversification. We present empirical results in support of SPAD.</p>
    <p><strong>Categories:</strong> Intent-Aware Diversification, Recommendation Diversity, Beyond Accuracy, Personalization Techniques, Explicit Feedback, Implicit Feedback, Matrix Factorization, Experimental Methods, Recommendation Systems, Evaluation Metrics (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/306/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Behaviorism is Not Enough (2016)</h3>
    <p><strong>Authors:</strong> Martijn C Willemsen, Michael D Ekstrand</p>
    <p>Behaviorism is the currently-dominant paradigm for building and evaluating recommender systems. Both the operation and the evaluation of recommender system applications are most often driven by analyzing the behavior of users. In this paper, we argue that listening to what users say — about the items and recom-mendations they like, the control they wish to exert on the output, and the ways in which they perceive the system — and not just observing what they do will enable important developments in the future of recommender systems. We provide both philosophi-cal and pragmatic motivations for this idea, describe the various points in the recommendation and evaluation processes where explicit user input may be considered, and discuss benefits that may result from considered incorporation of user preferences at each of these points. In particular, we envision recommender applications that aim to support users’ better selves: helping them live the life that they desire to lead. For example, recommender-assisted behavior change requires algorithms to predict not what users choose or do now, inferable from behavioral data, but what they should choose or do in the future to become healthier, fitter, more sustainable, or culturally aware. We hope that our work will spur useful discussion and many new ideas for recommenders that empower their users.</p>
    <p><strong>Categories:</strong> Recommender Systems, Explicit Feedback, Evaluation Methods, User-Centered Design, Behavior Change, Empowerment, Ethical Considerations, Interdisciplinary Approaches (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/213/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Implicit vs. Explicit Trust in Social Matrix Factorization (2014)</h3>
    <p><strong>Authors:</strong> Alejandro Bellogin, Peter Sloep, Hendrik Drachsler, Babak Loni, Soude Fazeli</p>
    <p>Incorporating social trust in Matrix Factorization (MF) methods demonstrably improves accuracy of rating prediction. Such approaches mainly use the trust scores explicitly expressed by users. However, it is often challenging to have users provide explicit trust scores of each other. There exist quite a few works, which propose Trust Metrics (TM) to compute and predict trust scores between users based on their interactions. In this paper, we first evaluate several TMs to find out which one can best predict trust scores compared to the actual trust scores explicitly expressed by users. And, second, we propose to incorporate these trust scores inferred from the candidate implicit TMs into social matrix factorization (MF). We investigate if incorporating the implicit trust scores in MF can make rating prediction as accurate as the MF on explicit trust scores. The reported results support the idea of employing implicit trust into MF whenever explicit trust is not available, since the performance of both models is similar.</p>
    <p><strong>Categories:</strong> Matrix Factorization, Social Matrix Factorization, Trust Metrics, Implicit Feedback, Explicit Feedback, Rating Prediction, Recommendation Systems, Social Networks, Model Comparison, Beyond Accuracy, User Behavior, Trust in Recommenders (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/45/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>