<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/explainability/">Explainability</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reproducibility/">Reproducibility</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/evaluation-methods/">Evaluation Methods</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reinforcement-learning/">Reinforcement Learning</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>CEERS: Counterfactual Evaluations of Explanations in Recommender Systems (2024)</h3>
    <p><strong>Authors:</strong> Mikhail Baklanov</p>
    <p>The growing emphasis on explainability in ethical AI, driven by regulations like GDPR, underscores the need for robust explanations of Recommender Systems (RS). Key to the development and research progress of such methods are reproducible, quantifiable evaluation metrics. Traditional human-involved evaluation methods are not reproducible, subjective, costly, and fail to capture the counterfactual nuances of AI explanations. Hence, there is a pressing need for objective and scalable metrics to accurately measure the correctness of explanation methods for recommender systems. Inspired by similar approaches in computer vision, this research aims to propose a counterfactual approach to evaluate explanation accuracy in RS. While counterfactual evaluation methods have been established in other domains, they are underexplored in RS. Our goal is to introduce quantifiable metrics that objectively assess the correctness of local explanations. This approach enhances evaluation reliability and scalability, integrating various recommenders, explanation algorithms, and datasets. Our goal is to provide a comprehensive mechanism combining model fidelity with explanation correctness, advancing transparency and trustworthiness in AI-driven recommender systems.</p>
    <p><strong>Categories:</strong> Explainability, Recommender Systems, Evaluation Metrics, Ethical AI, Counterfactual Analysis, Transparency, Trustworthy AI, Model Fidelity, Scalability (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1134/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Developing a Human-Centered Framework for Transparency in Fairness-Aware Recommender Systems (2022)</h3>
    <p><strong>Authors:</strong> Jessie J. Smith</p>
    <p>Though recommender systems fundamentally rely on human input and feedback, human-centered research in the RecSys discipline is lacking. When recommender systems aim to treat users more fairly, misinterpreting user objectives could lead to unintentional harm, whether or not fairness is part of the aim. When users seek to understand recommender systems better, a lack of transparency could act as an obstacle for their trust and adoption of the platform. Human-centered machine learning seeks to design systems that understand their users, while simultaneously designing systems that the users can understand. In this work, I propose to explore the intersection of transparency and user-system understanding through three phases of research that will result in a Human-Centered Framework for Transparency in Fairness-Aware Recommender Systems.</p>
    <p><strong>Categories:</strong> Recommender Systems, Fairness-Aware Recommendation, Transparency in Recommendations, Human-Centered Design, User-System Interaction, Trust in Recommendations, Ethical AI, Explainable AI (XAI), User Trust (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/815/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>