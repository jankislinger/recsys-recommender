<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/bias-mitigation/">Bias Mitigation</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/real-world-applications/">Real-world Applications</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reinforcement-learning/">Reinforcement Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reproducibility/">Reproducibility</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Siamese Neural Networks for Content-based Cold-Start Music Recommendation (2021)</h3>
    <p><strong>Authors:</strong> Michael Pulis, Josef Bajada</p>
    <p>Music recommendation systems typically use collaborative filtering to determine which songs to recommend to their users. This mechanism matches a user with listeners that have similar tastes, and uses their listening history to find songs that the user will probably like. The fundamental issue with this approach is that artists already need to have a significant user following to get a fair chance of being recommended. This is known as the music cold-start problem. In this work, we investigate the possibility of making music recommendations based on audio content so that new artists still get a good chance of being recommended, even if they do not have a sufficient number of listeners yet. We propose the use of Siamese Neural Networks (SNNs) to determine the similarity between two audio clips. Each clip is first pre-processed into a Mel-Spectrogram, which is then used as input to an SNN consisting of two identical Convolutional Neural Networks (CNNs). The output of each CNN is then compared together to determine whether two songs are similar or not. These were trained using audio from the Free Music Archive, with the genre used as a heuristic to determine the similarity between song pairs. A query-by-multiple-example (QBME) music recommendation system was developed that makes use of the proposed content-based similarity metric to find songs that match the userâ€™s tastes. This was packaged inside an online blind-test survey, which first prompts participants to select a set of preferred songs, and then recommends a number of songs which the subject is expected to listen to and rate on a Likert scale. The recommendations from the proposed algorithm were stochastically interleaved with songs selected randomly from the preferred genres of the user, as a baseline for comparison. The participants were not aware that the recommendations came from two different algorithms. Our findings show that 60.7% of the 150 participants gave higher ratings to the recommendations made by the proposed SNN-based algorithm. Findings also show that 55% of the recommended songs had less than 1,500 listens, demonstrating that the proposed content-based approach can provide a fairer exposure to all artists based on their music, independent of their fame and popularity.</p>
    <p><strong>Categories:</strong> Siamese Neural Networks, Neural Networks, Matrix Factorization, Cold Start, Item Cold Start, Music Recommendation, Recommendation Systems, Content-Based Filtering, Audio Features, Evaluation Metrics, A/B Test, User Survey, Diversity of Recommendations (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/706/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Investigating the Impact of Audio States in Music Streaming Sessions (2020)</h3>
    <p><strong>Authors:</strong> Rishabh Mehrotra, Aaron Ng</p>
    <p>Music streaming is inherently sequential in nature, with track sequence information playing a key role in user satisfaction with recommended music. In this work, we investigate the role audio characteristics of music content play in understanding music streaming sessions. Focusing on 18 audio attributes (e.g. dancability, acousticness, energy), we formulate audio transitioning in a session as a multiple changepoint detection problem, and extract latent states of different audio attributes within each session. Based on insights from large scale music streaming data from a popular music streaming platform, we investigate questions around the extent to which audio characteristics fluctuate within streaming sessions, the heterogeneity across different audio attributes and their impact on user satisfaction. Furthermore, we demonstrate the promise of such audio-based characterizing of sessions in better sequencing tracks in a session, and highlight the potential gains in user satisfaction on offer. We discuss implications on the design of track sequencing models, and identify important prediction tasks to further research on the topic.</p>
    <p><strong>Categories:</strong> Music Recommendation, Audio Features, Changepoint Detection, Time Series Analysis, User Satisfaction, Real-World Application, Track Sequencing, Beyond Accuracy, Diversity of Recommendations, Personalization (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/612/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Audio-Visual Encoding of Multimedia Content to Enhance Movie Recommendations (2018)</h3>
    <p><strong>Authors:</strong> Markus Schedl, Bogdan Ionescu, Paolo Cremonesi, Yashar Deldjoo, Mihai Gabriel Constantin, Hamid Eghbal-zadeh</p>
    <p>We propose a multi-modal content-based movie recommender system that replaces human-generated metadata by content descriptions automatically extracted from the visual and audio channels of a video. Content descriptors improve over traditional metadata in terms of both richness (it is possible to extract hundreds of meaningful features covering various modalities) and quality (content features are consistent across different systems and immune to human errors). Our recommender system integrates state-of-the-art aesthetic and deep visual features as well as block-level and i-vector audio features. For fusing the different modalities, we propose a rank aggregation strategy extending the Borda count approach. We evaluate the proposed multi-modal recommender system comprehensively against metadata-based baselines. To this end, we conduct two empirical studies: (i) a system-centric study to measure the offline quality of recommendations in terms of accuracy-related and beyond-accuracy performance measures (novelty, diversity, and coverage), and (ii) a user-centric online experiment, measuring different subjective metrics, including relevance, satisfaction, and diversity. In both studies, we use a dataset of more than 4,000 movie trailers, which makes our approach versatile. Our results shed light on the accuracy and beyond-accuracy performance of audio, visual, and textual features in content-based movie recommender systems.</p>
    <p><strong>Categories:</strong> Audio Features, Visual Features, Computer Vision, Speech Processing, Content-Based Recommendations, Multi-Modal Data, Movie Recommendations, Multi-Modal Recommender Systems, Rank Aggregation, Accuracy Metrics, Beyond Accuracy, User Survey (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/367/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>