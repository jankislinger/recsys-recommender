<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui primary button" style="margin: 5px;"
             href="/recsys-recommender/">Online Experiments</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reinforcement-learning/">Reinforcement Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/real-world-applications/">Real-world Applications</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/evaluation-methods/">Evaluation Methods</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Beyond Labels: Leveraging Deep Learning and LLMs for Content Metadata (2023)</h3>
    <p><strong>Authors:</strong> Jaya Kawale, Saurabh Agrawal, John Trenkle</p>
    <p>Content metadata plays a very important role in movie recommender systems as it provides valuable information about various aspects of a movie such as genre, cast, plot synopsis, box office summary, etc. Analyzing the metadata can help understand the user preferences and generate personalized recommendations catering to the niche tastes of the users. It can also help with content cold starting when the recommender system has little or no interaction data available to perform collaborative filtering. In this talk, we will focus on one particular type of metadata – genre labels. Genre labels associated with a movie or a TV series such as “horror” or “comedy” or “romance” help categorize a collection of movies into different themes and correspondingly setting up the audience expectation for a title. We present some of the challenges associated with using genre label information via traditional methods and propose a new way of examining the genre information that we call as the Genre Spectrum. The Genre Spectrum helps capture the various nuanced genres in a title and our offline and online experiments corroborate the effectiveness of the approach.</p>
    <p><strong>Categories:</strong> Deep Learning, Large Language Models (LLMs), Recommendation Systems, Content Metadata, Genre Analysis, Cold Start Problem, Personalized Recommendations, User Preferences, Offline Experiments, Online Experiments (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/993/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Rethinking Personalized Ranking at Pinterest: An End-to-End Approach (2022)</h3>
    <p><strong>Authors:</strong> Jiajing Xu</p>
    <p>In this work, we present our journey to revolutionize the personalized recommendation engine through end-to-end learning from raw user actions. We encode user’s long-term interest in PinnerFormer, a user embedding optimized for long-term future actions via a new dense all-action loss, and capture user’s short-term intention by directly learning from the real-time action sequences. We conducted both offline and online experiments to validate the performance of the new model architecture, and also address the challenge of serving such a complex model using mixed CPU/GPU setup in production. The proposed system has been deployed in production at Pinterest and has delivered significant online gains across organic and Ads applications.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Personalized Ranking, End-to-End Learning, Neural Networks, Transformer-Based Models, User Embeddings, Long-Term Interest, Short-Term Intention, Offline Experiments, Online Experiments, A/B Testing, Real-World Applications, Deployment in Production, Scalability, Performance Optimization (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/823/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Exploration in Recommender Systems (2021)</h3>
    <p><strong>Authors:</strong> Minmin Chen</p>
    <p>In the era of increasing choices, recommender systems are becoming indispensable in helping users navigate the million or billion pieces of content on recommendation platforms. As the focus of these systems shifts from attracting short-term user attention toward optimizing long term user experience on these platforms, reinforcement learning (and bandits) have emerged as appealing techniques to power these systems [5, 9, 26, 27]. The exploration-exploitation tradeoff, being the foundation of bandits and RL research, has been extensively studied [1, 2, 4, 6, 8, 10, 11, 18, 20, 21, 22, 23]. An agent is incentivized to exploit to maximize its return, i.e., by repeating actions taken in the past that produced high rewards. On the other hand, the agent needs to explore previously unseen actions in order to discover potentially better ones. Exploration has been shown to be extremely useful in solving tasks of long horizons or sparse reward in many RL applications [2, 14, 15, 16, 19]. While effective exploration is believed to positively influence the user experience on the platform, the exact value of exploration in recommender systems has not been well established.<br>In this talk, we examine the roles of exploration in recommender systems in three facets: 1) system exploration to reduce system uncertainty in regions with sparse feedback; 2) user exploration to introduce users to new interests/tastes; and 3) online exploration to take into account real-time user feedback. We showcase how each aspect of exploration contributes to the long term user experience through offline and live experiments on industrial recommendation platforms. We hope this talk can inspire more follow up work in understanding and improving exploration in recommender systems.</p>
    <p><strong>Categories:</strong> Reinforcement Learning, Multi-Armed Bandits, Exploration-Exploitation Tradeoff, User Exploration, System Exploration, Online Exploration, Long-Term User Experience, Industrial Applications, Real-Time Feedback, Offline Experiments, Online Experiments (<i>deepseek-r1:70b</i>)</p>
    <p><a href="/recsys-recommender/response/728/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Online Evaluation Methods for the Causal Effect of Recommendations (2021)</h3>
    <p><strong>Authors:</strong> Masahiro Sato</p>
    <p>Evaluating the causal effect of recommendations is an important objective because the causal effect on user interactions can directly leads to an increase in sales and user engagement. To select an optimal recommendation model, it is common to conduct A/B testing to compare model performance. However, A/B testing of causal effects requires a large number of users, making such experiments costly and risky. We therefore propose the first interleaving methods that can efficiently compare recommendation models in terms of causal effects. In contrast to conventional interleaving methods, we measure the outcomes of both items on an interleaved list and items not on the interleaved list, since the causal effect is the difference between outcomes with and without recommendations. To ensure that the evaluations are unbiased, we either select items with equal probability or weight the outcomes using inverse propensity scores. We then verify the unbiasedness and efficiency of online evaluation methods through simulated online experiments. The results indicate that our proposed methods are unbiased and that they have superior efficiency to A/B testing.</p>
    <p><strong>Categories:</strong> Causal Effect Evaluation, Recommendation Systems, Online Experiments, Interleaving Methods, A/B Testing, Causal Inference, Algorithm Comparison, User Engagement, Efficiency Optimization, Unbiased Evaluation (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/648/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>PURS: Personalized Unexpected Recommender System for Improving User Satisfaction (2020)</h3>
    <p><strong>Authors:</strong> Pan Li, Maofei Que, Alexander Tuzhilin, Zhichao Jiang, Yao Hu</p>
    <p>Classical recommender system methods typically face the filter bubble problem when users only receive recommendations of their familiar items, making them bored and dissatisfied. To address the filter bubble problem, unexpected recommendations have been proposed to recommend items significantly deviating from user’s prior expectations and thus surprising them by presenting ”fresh” and previously unexplored items to the users. In this paper, we describe a novel Personalized Unexpected Recommender System (PURS) model that incorporates unexpectedness into the recommendation process by providing multi-cluster modeling of user interests in the latent space and personalized unexpectedness via the self-attention mechanism and via selection of an appropriate unexpected activation function. Extensive offline experiments on three real-world datasets illustrate that the proposed PURS model significantly outperforms the state-of-the-art baseline approaches in terms of both accuracy and unexpectedness measures. In addition, we conduct an online A/B test at a major video platform Alibaba-Youku, where our model achieves over 3% increase in the average video view per user metric. The proposed model is in the process of being deployed by the company.</p>
    <p><strong>Categories:</strong> Recommender Systems, Surprise/Novelty, Personalization, User Satisfaction, Multi-Cluster Modeling, Latent Space Analysis, Self-Attention Mechanisms, Activation Functions, Real-World Applications, Industry Application, Model Performance, Online Experiments, Dataset Usage (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/549/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>A Joint Dynamic Ranking System with DNN and Vector-based Clustering Bandit (2020)</h3>
    <p><strong>Authors:</strong> Changping Peng, Jincheng Wang, Xiaoxiao Xu, Weipeng Yan, Yong Li, Yongjun Bao, Yu Liu</p>
    <p>The ad-ranking module is the core of the advertising recommender system. Existing ad-ranking modules are mainly based on the deep neural network click-through rate prediction model. Recently an innovative ad-ranking paradigm called DNN-MAB has been introduced to address DNN-only paradigms’ weakness in perceiving highly dynamic user intent over time. We introduce the DNN-MAB paradigm into our ad-ranking system to alleviate the Matthew effect that harms the user experience. Due to data sparsity, however, the actual performance of DNN-MAB is lower than expected. In this paper, we propose an innovative ad-ranking paradigm called DNN-VMAB to solve these problems. Based on vectorization and clustering, it utilizes latent collaborative information in user behavior data to find a set of ads with higher relativity and diversity. As an integration of the essences of classical collaborative filtering, deep click-through rate prediction model, and contextual multi-armed bandit, it can improve platform revenue and user experience. Both offline and online experiments show the advantage of our new algorithm over DNN-MAB and some other existing algorithms.</p>
    <p><strong>Categories:</strong> Advertising, Recommender Systems, Deep Neural Networks (DNN), Multi-Armed Bandits, Clustering, Collaborative Filtering, Ad-Ranking, Vectorization, Cold Start, Handling Sparse Data, Offline Experiments, Online Experiments, Monetization Strategies, User-Centric Design (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/603/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Addressing Delayed Feedback for Continuous Training with Neural Networks in CTR prediction (2019)</h3>
    <p><strong>Authors:</strong> Deepak Dilipkumar, Pranay Kumar Myana, Lucas Theis, Wenzhe Shi, Sofia Ira Ktena, Steven Yoo, Ferenc Huszár, Alykhan Tejani</p>
    <p>One of the challenges in display advertising is that the distribution of features and click through rate (CTR) can exhibit large shifts over time due to seasonality, changes to ad campaigns and other factors. The predominant strategy to keep up with these shifts is to train predictive models continuously, on fresh data, in order to prevent them from becoming stale. However, in many ad systems positive labels are only observed after a possibly long and random delay. These delayed labels pose a challenge to data freshness in continuous training: fresh data may not have complete label information at the time they are ingested by the training algorithm. Naive strategies which consider any data point a negative example until a positive label becomes available tend to underestimate CTR, resulting in inferior user experience and suboptimal performance for advertisers. The focus of this paper is to identify the best combination of loss functions and models that enable large-scale learning from a continuous stream of data in the presence of delayed labels. In this work, we compare 5 different loss functions, 3 of them applied to this problem for the first time. We benchmark their performance in offline settings on both public and proprietary datasets in conjunction with shallow and deep model architectures. We also discuss the engineering cost associated with implementing each loss function in a production environment. Finally, we carried out online experiments with the top performing methods, in order to validate their performance in a continuous training scheme. While training on 668 million in-house data points offline, our proposed methods outperform previous state-of-the-art by 3% relative cross entropy (RCE). During online experiments, we observed 55% gain in revenue per thousand requests (RPMq) against naive log loss. ,</p>
    <p><strong>Categories:</strong> Neural Networks, Loss Functions, Display Advertising, CTR Prediction, Advertising Systems, Delayed Feedback, Continuous Training, Offline Evaluation, Online Experiments, A/B Testing, Production Systems, Engineering Costs, Time-Aware Models, Stream Learning (<i>deepseek-r1:70b</i>)</p>
    <p><a href="/recsys-recommender/response/431/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>A Pareto-Efficient Algorithm for Multiple Objective Optimization in E-Commerce Recommendation (2019)</h3>
    <p><strong>Authors:</strong> Peng Jiang, Hongjie Chen, Yongfeng Zhang, Hanxiao Sun, Wenwu Ou, Xuanji Xiao, Xiao Lin, Changhua Pei, Fei Sun</p>
    <p>Recommendation with multiple objectives is an important but difficult problem, where the coherent difficulty lies in the possible conflicts between objectives. In this case, multi-objective optimization is expected to be Pareto efficient, where no single objective can be further improved without hurting the others. However existing approaches to Pareto efficient multi-objective recommendation still lack good theoretical guarantees. In this paper, we propose a general framework for generating Pareto efficient recommendations. Assuming that there are formal differentiable formulations for the objectives, we coordinate these objectives with a weighted aggregation. Then we propose a condition ensuring Pareto efficiency theoretically and a two-step Pareto efficient optimization algorithm. Meanwhile the algorithm can be easily adapted for Pareto Frontier generation and fair recommendation selection. We specifically apply the proposed framework on E-Commerce recommendation to optimize GMV and CTR simultaneously. Extensive online and offline experiments are conducted on the real-world E-Commerce recommender system and the results validate the Pareto efficiency of the framework. To the best of our knowledge, this work is among the first to provide a Pareto efficient framework for multi-objective recommendation with theoretical guarantees. Moreover, the framework can be applied to any other objectives with differentiable formulations and any model with gradients, which shows its strong scalability.</p>
    <p><strong>Categories:</strong> Multi-Objective Optimization, Pareto Efficiency, Recommendation Systems, E-commerce, Algorithm Design, Online Experiments, Scalability, Theoretical Guarantees, Fairness, Weighted Aggregation, Evaluation Metrics, Generalizability (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/427/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Recommending Product Sizes to Customers (2017)</h3>
    <p><strong>Authors:</strong> Vivek Varadarajan Sembium, Atul Saroop, Srujana Merugu, Rajeev Rastogi</p>
    <p>We propose a novel latent factor model for recommending product size fits {Small, Fit, Large} to customers. Latent factors for customers and products in our model correspond to their physical true size, and are learnt from past product purchase and returns data. The outcome for a customer, product pair is predicted based on the difference between customer and product true sizes, and efficient algorithms are proposed for computing customer and product true size values that minimize two loss function variants. In experiments with Amazon shoe datasets, we show that our latent factor models incorporating personas, and leveraging return codes show a 17-21% AUC improvement compared to baselines. In an online A/B test, recommendations produced by our algorithms show an improvement of 33 basis points in percentage of Fit transactions over control.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Latent Factor Models, E-commerce, Product Size Recommendations, Customer Behavior Analysis, AUC Improvement, Real-World Applications, Online Experiments, Personalization, Beyond Accuracy Metrics, Scalability, User Experience. (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/276/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Deep Learning Marketplace Recommenders in Online Experiments (2018)</h3>
    <p><strong>Authors:</strong> Simen Eide, Ning Zhou</p>
    <p>Marketplaces are platforms where users buy and sell various types of items. Recommendation systems are widely used in marketplaces to match users with items relevant to their interests and needs. This paper focuses on online experiments with deep neural network recommenders and presents the promising recommenders we found – hybrid item representation models combining features from traffic and content, sequence-based models, and multi-armed bandit models that optimize user engagement by re-ranking proposals from multiple submodels. Then it summarizes the online experiment results and discusses why some recommenders outperform others.</p>
    <p><strong>Categories:</strong> Deep Learning, Recommendation Systems, Marketplace, Hybrid Models, Sequence-Based Models, Multi-Armed Bandits, Online Experiments, User Engagement, Deep Neural Networks, Hybrid Recommenders, Re-ranking Proposals, Performance Analysis (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/372/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>