<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/bias-mitigation/">Bias Mitigation</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reinforcement-learning/">Reinforcement Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/real-world-applications/">Real-world Applications</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reproducibility/">Reproducibility</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Instructing and Prompting Large Language Models for Explainable Cross-domain Recommendations (2024)</h3>
    <p><strong>Authors:</strong> Alessandro Petruzzelli, Cataldo Musto, Pasquale Lops, Marco de Gemmis, Ivan Rinaldi, Giovanni Semeraro, Lucrezia Laraspata</p>
    <p>In this paper, we present a strategy to provide users with explainable cross-domain recommendations (CDR) that exploits large language models (LLMs). Generally speaking, cross-domain recommender systems typically suffer of data sparsity issues, since they require a large amount of data labeled in both base and target domains, which are not easy to collect. Accordingly, our approach relies on the intuition that the knowledge that is already encoded in LLMs can be used to bridge the domains and seamlessly provide users with personalized cross-domain suggestions. To this end, we designed a pipeline to: (a) instruct a LLM to handle a CDR task; (b) design a personalized prompt, based on the preferences of the user in a base domain, in both zero-shot and one-shot settings; (c) feed the LLM with the prompt, and process the answer in order to extract the recommendations in a target domain, together with a natural language explanation supporting the suggestion. As shown in the experimental evaluation, our approach beats several established state-of-the-art baselines for CDR in most of the experimental settings, thus showing the effectiveness of LLMs also in this novel and scarcely investigated scenario.</p>
    <p><strong>Categories:</strong> Large Language Models (LLMs), Cross-domain Recommendations, Explainable Recommendations, Recommendation Systems, Personalization, Zero-shot Learning, One-shot Learning, Data Sparsity, Natural Language Processing (NLP), Instruction Following (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1049/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Unleashing the Retrieval Potential of Large Language Models in Conversational Recommender Systems (2024)</h3>
    <p><strong>Authors:</strong> Ting Yang, Li Chen</p>
    <p>Conversational recommender systems (CRSs) aim to capture user preferences and provide personalized recommendations through interactive natural language interactions. The recent advent of large language models (LLMs) has revolutionized human engagement in natural conversations, driven by their extensive world knowledge and remarkable natural language understanding and generation capabilities. However, introducing LLMs into CRSs presents new technical challenges. Specifically, directly prompting LLMs for recommendation generation requires understanding a large and evolving item corpus, as well as grounding the generated recommendations in the real item space. Moreover, generating recommendations based on external recommendation engines or directly integrating their suggestions into responses may constrain the overall performance of LLMs, since these engines generally have inferior representation abilities compared to LLMs. To address these challenges, we propose an end-to-end large-scale CRS model, ReFICR, a novel LLM-enhanced conversational recommender that empowers a retrievable large language model to perform CRS subtasks by following retrieval and generation instructions through lightweight tuning. By decomposing the complex CRS task into multiple subtasks, we formulate these subtasks into two types of instruction formats: retrieval and generation. The hidden states of ReFICR are utilized as text embeddings to represent user preferences and items for retrieval. Simultaneously, ReFICR is trained to handle generative tasks. We optimize the contrastive objective to enhance text embeddings for retrieval and jointly fine-tune the large language model objective for generation. Our experimental results on public datasets demonstrate that ReFICR significantly outperforms baselines in terms of recommendation accuracy. Our code is publicly available at the link: https://anonymous.4open.science/r/ReFICR-0C3A.</p>
    <p><strong>Categories:</strong> Conversational Recommender Systems (CRSs), Large Language Models (LLMs), Recommendation Generation, Natural Language Processing (NLP), Retrieval-Based Systems, Instruction-Following Models, Contrastive Learning, End-to-End Models, Personalized Recommendations, Implicit Feedback, Hybrid Recommender Systems, Language Model Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1076/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Fairness Matters: A look at LLM-generated group recommendations (2024)</h3>
    <p><strong>Authors:</strong> Antonela Tommasel</p>
    <p>Recommender systems play a crucial role in how users consume information, with group recommendation receiving considerable attention. Ensuring fairness in group recommender systems entails providing recommendations that are useful and relevant to all group members rather than solely reflecting the majority’s preferences, while also addressing fairness concerns related to sensitive attributes (e.g., gender). Recently, the advancements on Large Language Models (LLMs) have enabled the development of new kinds of recommender systems. However, LLMs can perpetuate social biases present in training data, posing risks of unfair outcomes and harmful impacts. We investigated LLMs impact on group recommendation fairness, establishing and instantiating a framework that encompasses group definition, sensitive attribute combinations, and evaluation methodology. Our findings revealed the interactions patterns between sensitive attributes and LLMs and how they affected recommendation. This study advances the understanding of fairness considerations in group recommendation systems, laying the groundwork for future research.</p>
    <p><strong>Categories:</strong> Recommender Systems, Fairness, Group Recommendations, Large Language Models (LLMs), Sensitive Attributes, Bias Mitigation, Natural Language Processing (NLP), Evaluation Methodology, Social Biases, Societal Impact (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1089/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Embedding based retrieval for long tail search queries in ecommerce (2024)</h3>
    <p><strong>Authors:</strong> Arun Udayashankar, Yuyang Zhang, Akshay Kekuda</p>
    <p>In this abstract we present a series of optimizations we performed on the two-tower model architecture [14], and training and evaluation datasets to implement semantic product search at Best Buy. Search queries on bestbuy.com follow the pareto distribution whereby a minority of them account for most searches. This leaves us with a long tail of search queries that have low frequency of issuance. The queries in the long tail suffer from very spare interaction signals. Our current work focuses on building a model to serve the long tail queries. We present a series of optimizations we have done to this model to maximize conversion for the purpose of retrieval from the catalog. The first optimization we present is using a large language model to improve the sparsity of conversion signals. The second optimization is pretraining an off-the-shelf transformer-based model on the Best Buy catalog data. The third optimization we present is on the finetuning front. We use query-to-query pairs in addition to query-to-product pairs and combining the above strategies for finetuning the model. We also demonstrate how merging the weights of these finetuned models improves the evaluation metrics. Finally, we provide a recipe for curating an evaluation dataset for continuous monitoring of model performance with human-in-the-loop evaluation. We found that adding this recall mechanism to our current term match-based recall improved conversion by 3% in an online A/B test.</p>
    <p><strong>Categories:</strong> E-commerce, Long-Tail Queries, Natural Language Processing (NLP), Two-Tower Model, Transfer Learning, Finetuning, Evaluation Methods, Human Evaluation, Real-World Applications, Information Retrieval. (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1157/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Prompt Tuning for Item Cold-start Recommendation (2024)</h3>
    <p><strong>Authors:</strong> Jingchi Wang, Gaode Chen, Qi Zhang, Jingjian Lin, Yuezihan Jiang, Kaigui Bian, Wenhan Zhang, Peng Jiang, Yinjie Jiang</p>
    <p>The item cold-start problem is crucial for online recommender systems, as the success of the cold-start phase determines whether items can transition into popular ones. Prompt learning, a powerful technique used in natural language processing (NLP) to address zero- or few-shot problems, has been adapted for recommender systems to tackle similar challenges. However, existing methods typically rely on content-based properties or text descriptions for prompting, which we argue may be suboptimal for cold-start recommendations due to 1) semantic gaps with recommender tasks, 2) model bias caused by warm-up items contribute most of positive feedback to the model, which is the core of the cold-start problem that hinder the recommender quality on cold-start items. We propose to leverage high-value positive feedback, termed pinnacle feedback as prompt information, to simultaneously resolve the above two problems. We experimentally prove that comparing to content description proposed in existing works, the positive feedback is more suitable to serve as prompt information by bridging the semantic gaps. Besides, we propose item-wise personalized prompt networks to encode pinnaclce feedback to relieve the model bias by the positive feedback dominance problem. Extensive experiments on four real-world datasets demonstrate the superiority of our model over state-of-the-art methods. Moreover, PROMO has been successfully deployed on a popular short-video sharing platform, a billion-user scale commercial short-video application, achieving remarkable performance gains across various commercial metrics within cold-start scenarios.</p>
    <p><strong>Categories:</strong> Cold Start, Prompt Learning, Natural Language Processing (NLP), Recommender Systems, Semantic Gaps, Model Bias, High-Value Feedback, Personalized Prompts, Real-World Applications, A/B Testing, Evaluation Metrics, Feedback-Based Methods (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1055/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Bayesian Optimization with LLM-Based Acquisition Functions for Natural Language Preference Elicitation (2024)</h3>
    <p><strong>Authors:</strong> Armin Toroghi, David Austin, Anton Korikov, Scott Sanner</p>
    <p>Designing preference elicitation (PE) methodologies that can quickly ascertain a user’s top item preferences in a cold-start setting is a key challenge for building effective and personalized conversational recommendation (ConvRec) systems. While large language models (LLMs) constitute a novel technology that enables fully natural language (NL) PE dialogues, we hypothesize that monolithic LLM NL-PE approaches lack the multi-turn, decision-theoretic reasoning required to effectively balance the NL exploration and exploitation of user preferences towards an arbitrary item set. In contrast, traditional Bayesian optimization PE methods define theoretically optimal PE strategies, but fail to use NL item descriptions or generate NL queries, unrealistically assuming users can express preferences with direct item ratings and comparisons. To overcome the limitations of both approaches, we formulate NL-PE in a Bayesian Optimization (BO) framework that seeks to actively elicit natural language feedback to reduce uncertainty over item utilities to identify the best recommendation. Key challenges in generalizing BO to deal with natural language feedback include determining (a) how to leverage LLMs to model the likelihood of NL preference feedback as a function of item utilities and (b) how to design an acquisition function that works for language-based BO that can elicit in the infinite space of language. We demonstrate our framework in a novel NL-PE algorithm, PEBOL, which uses Natural Language Inference (NLI) between user preference utterances and NL item descriptions to maintain preference beliefs and BO strategies such as Thompson Sampling (TS) and Upper Confidence Bound (UCB) to guide LLM query generation. We numerically evaluate our methods in controlled experiments, finding that PEBOL achieves up to 131% improvement in MAP@10 after 10 turns of cold start NL-PE dialogue compared to monolithic GPT-3.5, despite relying on a much smaller 400M parameter NLI model for preference inference.</p>
    <p><strong>Categories:</strong> Bayesian Optimization, Large Language Models (LLMs), Natural Language Processing (NLP), Conversational Recommendation Systems, Preference Elicitation, Cold Start Problem, Algorithm Selection, Multi-Armed Bandits, Thompson Sampling, Upper Confidence Bound, Natural Language Inference (NLI), Evaluation Metrics, Machine Learning (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1020/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>LLM Based Generation of Item-Description for Recommendation System (2023)</h3>
    <p><strong>Authors:</strong> Brijraj Singh, Naoyuki Onoe, Arkadeep Acharya</p>
    <p>The description of an item plays a pivotal role in providing concise and informative summaries to captivate potential viewers and is essential for recommendation systems. Traditionally, such descriptions were obtained through manual web scraping techniques, which are time-consuming and susceptible to data inconsistencies. In recent years, Large Language Models (LLMs), such as GPT-3.5, and open source LLMs like Alpaca have emerged as powerful tools for natural language processing tasks. In this paper, we have explored how we can use LLMs to generate detailed descriptions of the items. To conduct the study, we have used the MovieLens 1M dataset comprising movie titles and the Goodreads Dataset consisting of names of books and subsequently, an open-sourced LLM, Alpaca, was prompted with few-shot prompting on this dataset to generate detailed movie descriptions considering multiple features like the names of the cast and directors for the ML dataset and the names of the author and publisher for the Goodreads dataset. The generated description was then compared with the scraped descriptions using a combination of Top Hits, MRR, and NDCG as evaluation metrics. The results demonstrated that LLM-based movie description generation exhibits significant promise, with results comparable to the ones obtained by web-scraped descriptions.</p>
    <p><strong>Categories:</strong> LLMs, Recommendation Systems, Item Description, MovieLens Dataset, Goodreads Dataset, Natural Language Processing (NLP), Content Generation, Web Scraping, Open Source Models, Evaluation Metrics, Beyond Accuracy, Real-World Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/971/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Alleviating the Long-Tail Problem in Conversational Recommender Systems (2023)</h3>
    <p><strong>Authors:</strong> Zhao Cao, Kun Zhou, Fan Pan, Zhipeng Zhao, Xiaolei Wang, Wayne Xin Zhao, Ji-Rong Wen</p>
    <p>Conversational recommender systems (CRS) aim to provide the recommendation service via natural language conversations. To develop an effective CRS, high-quality CRS datasets are very crucial. However, existing CRS datasets suffer from the long-tail issue, \ie a large proportion of items are rarely (or even never) mentioned in the conversations, which are called long-tail items. As a result, the CRSs trained on these datasets tend to recommend frequent items,  and the diversity of the recommended items would be largely reduced, making users easier to get bored. To address this issue, this paper presents <b>LOT-CRS</b>, a novel framework that focuses on simulating and utilizing a balanced CRS dataset (\ie covering all the items evenly) for improving <b>LO</b>ng-<b>T</b>ail recommendation performance of CRSs. In our approach, we design two pre-training tasks to enhance the understanding of simulated conversation for long-tail items, and adopt retrieval-augmented fine-tuning with label smoothness strategy to further improve the recommendation of long-tail items. Extensive experiments on two public CRS datasets have demonstrated the effectiveness and extensibility of our approach, especially on long-tail recommendation. All the experimental codes will be released after the review period.</p>
    <p><strong>Categories:</strong> Conversational Recommender Systems, Long-Tail Problem, Deep Learning, Natural Language Processing (NLP), Personalization, Recommendation Algorithms, Diversity of Recommendations, Beyond Accuracy Evaluation, Data Simulation, Coverage, Real-World Applications, Recommendation Improvement. (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/851/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Heterogeneous Knowledge Fusion: A Novel Approach for Personalized Recommendation via LLM (2023)</h3>
    <p><strong>Authors:</strong> Zhichao Feng, Wei Lin, Zixiang Ding, Xiang Li, Bin Yin, Yu Qin, Junjie Xie</p>
    <p>The analysis and mining of user heterogeneous behavior are of paramount importance in recommendation systems. However, the conventional approach of incorporating various types of heterogeneous behavior into recommendation models leads to feature sparsity and knowledge fragmentation issues. To address this challenge, we propose a novel approach for personalized recommendation via Large Language Model (LLM), by extracting and fusing heterogeneous knowledge from user heterogeneous behavior information. In addition, by combining heterogeneous knowledge and recommendation tasks, instruction tuning is performed on LLM for personalized recommendations. The experimental results demonstrate that our method can effectively integrate user heterogeneous behavior and significantly improve recommendation performance.</p>
    <p><strong>Categories:</strong> Heterogeneous Data, Large Language Models (LLMs), Personalized Recommendations, User Behavior Analysis, Knowledge Fusion, Recommendation Systems, Performance Improvement, Natural Language Processing (NLP), Heterogeneous Knowledge, Data Handling Challenges, Instruction Tuning, Advanced Techniques in Recommendation (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/997/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Recommendation as Language Processing (RLP): A Unified Pretrain, Personalized Prompt &amp; Predict Paradigm (P5) (2022)</h3>
    <p><strong>Authors:</strong> Zuohui Fu, Yingqiang Ge, Yongfeng Zhang, Shijie Geng, Shuchang Liu</p>
    <p>For a long time, different recommendation tasks require designing task-specific architectures and training objectives. As a result, it is hard to transfer the knowledge and representations from one task to another, thus restricting the generalization ability of existing recommendation approaches. To deal with such issues, considering that language can describe almost anything and language grounding is a powerful medium to represent various problems or tasks, we present a flexible and unified text-to-text paradigm called “Pretrain, Personalized Prompt, and Predict Paradigm” (P5) for recommendation, which unifies various recommendation tasks in a shared framework. In P5, all data such as user-item interactions, user descriptions, item metadata, and user reviews are converted to a common format — natural language sequences. The rich information from natural language assists P5 to capture deeper semantics for personalization and recommendation. Specifically, P5 learns different tasks with the same language modeling objective during pretraining. Thus, it serves as the foundation model for various downstream recommendation tasks, allows easy integration with other modalities, and enables instruction-based recommendation. P5 advances recommender systems from shallow model to deep model to big model, and will revolutionize the technical form of recommender systems towards universal recommendation engine. With adaptive personalized prompt for different users, P5 is able to make predictions in a zero-shot or few-shot manner and largely reduces the necessity for extensive fine-tuning. On several benchmarks, we conduct experiments to show the effectiveness of P5. To help advance future research on Recommendation as Language Processing (RLP), Personalized Foundation Models (PFM), and Universal Recommendation Engine (URE), we release the source code, dataset, prompts, and pretrained P5 model at https://github.com/jeykigung/P5.</p>
    <p><strong>Categories:</strong> Language Models, Unified Frameworks, Personalization, Natural Language Processing (NLP), Foundation Models, Transfer Learning, Zero-shot/Few-shot Learning, Real-world Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/770/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Argument-based generation and explanation of recommendations (2021)</h3>
    <p><strong>Authors:</strong> Andrés Segura-Tinoco</p>
    <p>In the recommender systems literature, it has been shown that, in addition to improving system effectiveness, explaining recommendations may increase user satisfaction, trust, persuasion and loyalty. In general, explanations focus on the filtering algorithms or the users and items involved in the generation of recommendations. However, on certain domains that are rich on user-generated textual content, it would be valuable to provide justifications of recommendations according to arguments that are explicit, underlying or related with the data used by the systems, e.g., the reasons for customers’ opinions in reviews of e-commerce sites, and the requests and claims in citizens’ proposals and debates of e-participation platforms. In this context, there is a need and challenging task to automatically extract and exploit the arguments given for and against evaluated items. We thus advocate to focus not only on user preferences and item features, but also on associated arguments. In other words, we propose to not only consider what is said about items, but also why it is said. Hence, arguments would not only be part of the recommendation explanations, but could also be used by the recommendation algorithms themselves. To this end, in this thesis, we propose to use argument mining techniques and tools that allow retrieving and relating argumentative information from textual content, and investigate recommendation methods that exploit that information before, during and after their filtering processes.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Explanation Mechanisms, Argument Mining, User Trust, Natural Language Processing (NLP), E-commerce, Citizen Engagement Platforms, Beyond Accuracy, User Satisfaction, Textual Data Analysis, Justification of Recommendations, Persuasion (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/713/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Learning to Match Job Candidates Using Multilingual Bi-Encoder BERT (2021)</h3>
    <p><strong>Authors:</strong> Dor Lavi</p>
    <p>Randstad is the global leader in the HR services industry. We support people and organizations in realizing their true potential by combining the power of today’s technology with our passion for people. In 2020, we helped more than two million candidates find a meaningful job with our 236,100 clients. Randstad is active in 38 markets around the world and has top-three positions in almost half of these. In 2020, Randstad had on average 34,680 corporate employees and generated revenue of € 20.7 billion. Each day, at Randstad, we employ industry-scale recommender systems to recommend thousands of candidates to our clients, and the other way around; vacancies to job seekers. Our “Talent Recommender” recommender system is based on a heterogeneous collection of input data: CVs, vacancy texts (job descriptions) and structured data (e.g., the location of a candidate or vacancy). The goal of the system is to recommend the best candidates (talents) to each open vacancy. CVs are user-generated PDF files. It goes without saying that parsing those files to plain text can be a challenge in itself and therefore out of scope for this talk. On the other hand, vacancies are usually structured formatted text. We should be aware that due to the difference in structure and preprocessing steps, that the input to the subsequent steps is inevitably noisy. Most NLP research in text similarity is based on the assumption that 2 pieces of information are the same but written differently [1]. Like two artists that paint the same landscape, but each with its own style. However, in our case the 2 documents complement one another like pieces in a puzzle, together they create the bigger picture, rather than 2 similar paintings. Some of our biggest challenges with the “Talent Recommender” stem from dealing with the diverse nature of our textual sources of data: vacancies and CVs. While both capture similar information, they are inherently different in many ways. First, the information in CVs and vacancies are similar, but there exists a vocabulary gap, where grammar and context differ. For example, where “I have 10 years of experience as an instructor” in a CV shares no word overlap with “We are looking for a talented tutor” in a vacancy, both cases express similar information regarding “experience in the field of education,” we need to overcome the synonyms gap “instructor” and “tutor.” In addition, the sentence structure is completely different, CVs are typically written in “storytelling mode” “I have. . . ,” while the vacancy is in “exploration mode” “we are looking. . . ” The second challenge is multilinguality. Since we are a multinational company that operates all across the globe, developing a model per language is not scalable in our case. We ultimately would like one maintainable model that supports as many languages as possible. Our last challenge is cross language similarity [ 4]. In some of the countries we operate, there is a high percentage of job seekers that are not native to that country. For example, many of the job descriptions in the Netherlands are in Dutch, however around 10% of the CVs are in English. Classic text models, like TF-IDF and Word2vec, capture information within one language, but hardly connect between languages. Simply put, even if trained on multiple languages each language will have its own cluster in space. So “logistics” in English and “logistiek” in Dutch are embedded in a completely different point in space, even though the meaning is the same. Furthermore, we know that the language of CV correlates with nationality and therefore can be a proxy discriminator. Due to the impact of these systems and the risks of unintended algorithmic bias and discrimination, HR is marked as a high risk domain in the recently published EC Artificial Intelligence Act [2]. To avoid discriminating against nationality we would like to recommend a candidate to the vacancy no matter which language the CV is written in. That is of course only if language is not a requirement for that vacancy. In this talk, we will show how we used our internal history of candidate placements to generate labeled CV-vacancy pairs dataset. Afterwards we fine-tune a multilingual BERT with bi encoder structure [3] over this dataset, by adding a cosine similarity log loss layer. We will explain how using the mentioned structure helps us overcome most of the challenges described above, and how it enables us to build a maintainable and scalable pipeline to match CVs and vacancies. In addition, we show how we gain a better semantic understanding, and learn to bridge the vocabulary gap. Finally, we highlight how multilingual transformers help us handle cross language barrier and might reduce discrimination.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Natural Language Processing (NLP), Machine Learning, Multilingual Models, Text Similarity, HR/Recruitment, Algorithmic Fairness, Bias Mitigation, Transformers/BERT, Information Retrieval, Cross-Language Learning, Real-World Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/733/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Towards a Taxonomy of User Feedback Intents for Conversational Recommendations (2019)</h3>
    <p><strong>Authors:</strong> Li Chen, Wanling Cai</p>
    <p>Understanding users’ feedback on recommendation in natural language is crucially important for assisting the system to refine its understanding of the user’s preferences and provide more accurate recommendations in the subsequent interactions. In this paper, we report the results of an exploratory study on a human-human dialogue dataset centered around movie recommendations. In particular, we manually labeled a set of over 200 dialogues at the utterance level, and then conducted descriptive analysis on them from both seekers’ and recommenders’ perspectives. The results reveal not only seekers’ feedback intents as well as the types of preferences they have expressed, but also the reactions of human recommenders that have finally led to successful recommendation. A taxonomy for feedback intents is established along with the results, which could be constructive for improving conversational recommender systems.</p>
    <p><strong>Categories:</strong> Feedback Handling, User Interaction, Natural Language Processing (NLP), Conversational Recommender Systems, Movie Recommendations, User Preferences, Taxonomy Development, Human-Computer Interaction (HCI), Dialogue Analysis, Recommendation Systems, Preference Elicitation, Evaluation Methods (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/520/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>ParsRec: A Meta-Learning Recommender System for Bibliographic Reference Parsing Tools (2018)</h3>
    <p><strong>Authors:</strong> Joeran Beel, Dominika Tkaczyk</p>
    <p>Bibliographic reference parsers extract metadata (e.g. author names, title, year) from bibliographic reference strings. No reference parser consistently gives the best results in every scenario. For instance, one tool may be best in extracting titles, and another tool in extracting author names. In this paper, we address the problem of reference parsing from a recommender-systems perspective. We propose ParsRec, a meta-learning approach that recommends the potentially best parser(s) for a given reference string. We evaluate ParsRec on 105k references from chemistry. We propose two approaches to meta-learning recommendations. The first approach learns the best parser for an entire reference string. The second approach learns the best parser for each field of a reference string. The second approach achieved a 2.6% increase in F1 (0.909 vs. 0.886, p < 0.001) over the best single parser (GROBID), reducing the false positive rate by 20.2% (0.075 vs. 0.094), and the false negative rate by 18.9% (0.107 vs. 0.132).</p>
    <p><strong>Categories:</strong> Recommender Systems, Meta-Learning, Bibliographic Parsing, Natural Language Processing (NLP), Evaluation Metrics, Chemistry Domain, Multi-Model Recommendations, False Positive Rate, False Negative Rate, Scalability, Data Mining, Bibliography Management, Research Tools. (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/423/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Semantic-based Tag Recommendation in Scientific Bookmarking Systems (2018)</h3>
    <p><strong>Authors:</strong> Hebatallah A. Mohamed Hassan</p>
    <p>Recently, tagging has become a common way for users to organize and share digital content, and tag recommendation (TR) has become a very important research topic. Most of the recommendation approaches which are based on text embedding have utilized bag-of-words technique. On the other hand, proposed deep learning methods for capturing semantic meanings in the text, have been proved to be effective in various natural language processing (NLP) applications. In this paper, we present a content-based TR method that adopts deep recurrent neural networks to encode titles and abstracts of scientific articles into semantic vectors for enhancing the recommendation task, specifically bidirectional gated recurrent units (bi-GRUs) with attention mechanism. The experimental evaluation is performed on a dataset from CiteULike. The overall findings show that the proposed model is effective in representing scientific articles for tag recommendation.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Deep Learning, Neural Networks, Attention Mechanism, Scientific Articles, Semantic Analysis, Tag Recommendation, Real-World Application, Experimental Evaluation, Natural Language Processing (NLP), Information Retrieval, Content-Based Filtering (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/393/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Recommendation of High Quality Representative Reviews in e-commerce (2017)</h3>
    <p><strong>Authors:</strong> Chetan Kalyan, Sudeshna Sarkar, Muthusamy Chelliah, Debanjan Paul, Prajit Prashant Sinai Nadkarni</p>
    <p>Users of ecommerce portals commonly use customer reviews for making purchase decisions. Many products contain tens or hundreds of reviews which makes it impossible for the customer to read all of them in order to get a good idea about the product. A review recommendation system that can recommend a subset of the reviews is thus useful for e-commerce websites. However customer reviews are of varied quality and different reviews cover different aspects or issues about the product. We follow previous work that maintain the statistical distribution of product aspects along with their associated sentiments of the entire review set for that particular product. However we address the challenge which arises due to the fact that similar aspects are mentioned in different reviews using different natural language expressions (e.g. camera, photo and picture refers to the same product aspect of camera). We use vector representations to identify mentions of similar aspects and group them together under single product aspect. Review helpfulness score may act as a proxy for quality of reviews, but this approach suffers from cold start problem as new reviews do not have any helpfulness score. We measure the quality of the review based on its content by doing supervised training using a convolutional neural network. Though  our neural network model is trained with reviews from Amazon dataset which have helpfulness score, our model can be used to predict the quality score of new reviews which do not have any helpfulness score. The recommended subset of reviews have high content score and the coverage of the product aspects, issues and sentiments are representative of the entire review set. The system is evaluated on datasets from Amazon and is found to be more useful than the competing methods.</p>
    <p><strong>Categories:</strong> Recommendation Systems, E-Commerce, Review Quality, Natural Language Processing (NLP), Product Aspects, Cold Start, Machine Learning, Sentiment Analysis, Neural Networks, Information Overload, Real-World Applications, Diversity of Recommendations, Evaluation Metrics (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/298/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>