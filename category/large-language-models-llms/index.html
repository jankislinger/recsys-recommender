<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui primary button" style="margin: 5px;"
             href="/recsys-recommender/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/popularity-bias/">Popularity Bias</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reinforcement-learning/">Reinforcement Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reproducibility/">Reproducibility</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/explainability/">Explainability</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Reproducibility of LLM-based Recommender Systems: the case study of P5 paradigm (2024)</h3>
    <p><strong>Authors:</strong> Marco Polignano, Cataldo Musto, Giovanni Semeraro, Pasquale Lops, Antonio Silletti</p>
    <p>Recommender systems field may greatly benefit of the availability of pretrained Large Language Models (LLMs), which can serve as the core mechanism to generate recommendations based on detailed user and item data, such as textual descriptions, user reviews, and metadata.  On one hand this new generation of LLM-based recommender systems paves the way to deal with traditional limitations, such as cold-start and data sparsity, but on the other hand this poses fundamental challenges for their accountability.  Reproducing experiments in the new context of LLM-based recommender systems is very challenging for several reasons. New approaches are published at an unprecedented pace, which makes difficult to have a clear picture of the main protocols and good practices in the experimental evaluation. Moreover, the lack of proper frameworks for LLM-based recommendation development and evaluation makes the process of benchmarking models complex and uncertain. In this work, we discuss the main issues encountered when trying to reproduce P5 (Pretrain, Personalized Prompt, and Prediction Paradigm), one of the first works unifying different recommendation tasks in a shared language modeling and natural language generation framework.  Starting from this study, we have developed OurFramework4LLM (anonymized name), a framework for training and evaluating LLMs, specifically for the recommendation task. It has been used to perform several experiments to assess the impact of different LLMs, personalization and novel set of more informative prompts on the overall performance of recommendations, in a fully reproducible environment.</p>
    <p><strong>Categories:</strong> Reproducibility, Large Language Models (LLMs), Recommender Systems, Framework Development, Benchmarking, Experimental Evaluation, P5 Paradigm, Natural Language Generation (NLG), Language Modeling, Cold-Start Problem, Data Sparsity, Personalization (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1130/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Leveraging LLM generated labels to reduce bad matches in job recommendations (2024)</h3>
    <p><strong>Authors:</strong> Dheeraj Toshniwal, Yingchi Pei, Yi Wei Pang, Nilanjan Sengupta</p>
    <p>Negative signals are increasingly employed to enhance recommendation quality. However, explicit negative feedback is often sparse and may disproportionately reflect the preferences of more vocal users. Commonly used implicit negative feedback, such as impressions without positive interactions, has the limitation of not accurately capturing users’ true negative preferences because users mainly pursue information they consider interesting. In this work, we present an approach that leverages fine-tuned Large Language Models (LLMs) to evaluate matches and generate negative signals at scale while maintaining cost efficiency. We demonstrate significant improvements in recommendation quality by deploying a traditional classifier trained using LLM-generated labels.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Job Recommendations, Negative Feedback Mechanisms, Large Language Models (LLMs), Implicit Feedback Analysis, Model Fine-Tuning, Scalability in ML Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1171/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Large Language Models as Evaluators for Recommendation Explanations (2024)</h3>
    <p><strong>Authors:</strong> Yishan Li, Bowen Sun, Weizhi Ma, Peijie Sun, Xiaoyu Zhang, Min Zhang, Jiayin Wang</p>
    <p>The explainability of recommender systems has attracted significant attention in academia and industry. Many efforts have been made for explainable recommendations, yet evaluating the quality of the explanations remains a challenging and unresolved issue. In recent years, leveraging LLMs as evaluators presents a promising avenue in Natural Language Processing tasks (e.g., sentiment classification, information extraction), as they perform strong capabilities in instruction following and common-sense reasoning. However, evaluating recommendation explanatory texts is different from these NLG tasks, as its criteria are related to human perceptions and are usually subjective. In this paper, we investigate whether LLMs can serve as evaluators of recommendation explanations. To answer the question, we utilize real user feedback on explanations given from previous work and additionally collect third-party annotations and LLM evaluations. We design and apply a 3-level meta-evaluation strategy to measure the correlation between evaluator labels and the ground truth provided by users. Our experiments reveal that LLMs, such as GPT4, can provide comparable evaluations with appropriate prompts and settings. We also provide further insights into combining human labels with the LLM evaluation process and utilizing ensembles of multiple heterogeneous LLM evaluators to enhance the accuracy and stability of evaluations. Our study verifies that utilizing LLMs as evaluators can be an accurate, reproducible and cost-effective solution for evaluating recommendation explanation texts. Our code is available at https://anonymous.4open.science/r/LLMasAnnotator-0043.</p>
    <p><strong>Categories:</strong> Explainability in Recommender Systems, Evaluation Metrics for Recommendations, Large Language Models (LLMs), Natural Language Processing (NLP) Tasks, Human-Centered AI, Recommendation Systems, Explainability Evaluation, User Feedback in Recommendations (<i>deepseek-r1:70b</i>)</p>
    <p><a href="/recsys-recommender/response/1119/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>LLMs for User Interest Exploration: A Hybrid Approach (2024)</h3>
    <p><strong>Authors:</strong> He Ma, Haokai Lu, Yueqi Wang, Yifan Liu, Ed H. Chi, Lexi Baugher, Ningren Han, Shuzhou Zhang, Yang Gu, Jianling Wang, Minmin Chen, Shuchao Bi</p>
    <p>Traditional recommendation systems are subject to a strong feedback loop by learning from and reinforcing past user-item interactions, which in turn limits the discovery of novel user interests. To address this, we introduce a hybrid hierarchical framework combining Large Language Models (LLMs) and classic recommendation models for user interest exploration. The framework controls the interfacing between the LLMs and the classic recommendation models through “interest clusters”, the granularity of which can be explicitly determined by algorithm designers. It recommends the next novel interests by first representing “interest clusters” using language, and employs a fine-tuned LLM to generate novel interest descriptions that are strictly within these predefined clusters. At the low level, it grounds these generated interests to an item-level policy by restricting classic recommendation models, in this case a transformer-based sequence recommender to return items that fall within the novel clusters generated at the high level. We showcase the efficacy of this approach on an industrial-scale commercial platform serving billions of users. Live experiments show a significant increase in both exploration of novel interests and overall user enjoyment of the platform.</p>
    <p><strong>Categories:</strong> Hybrid Models, Large Language Models (LLMs), Recommendation Systems, User Interest Exploration, Transformer-Based Recommenders, Content Generation, Interest Clustering, Real-World Applications, Live Experiments, User Behavior, Hierarchical Structures, Industrial Application, Scalability, Exploration vs Exploitation (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1092/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Towards Open-World Recommendation with Knowledge Augmentation from Large Language Models (2024)</h3>
    <p><strong>Authors:</strong> Weiwen Liu, Bo Chen, Yong Yu, Hong Zhu, Yunjia Xi, Weinan Zhang, Jianghao Lin, Xiaoling Cai, Jieming Zhu, Ruiming Tang</p>
    <p>Recommender system plays a vital role in various online services. However, its insulated nature of training and deploying separately within a specific closed domain limits its access to open-world knowledge. Recently, the emergence of large language models (LLMs) has shown promise in bridging this gap by encoding extensive world knowledge and demonstrating reasoning capabilities. Nevertheless, previous attempts to directly use LLMs as recommenders cannot meet the inference latency demand of industrial recommender systems. In this work, we propose an Open-World Knowledge Augmented Recommendation Framework with Large Language Models, dubbed KAR, to acquire two types of external knowledge from LLMs — the reasoning knowledge on user preferences and the factual knowledge on items. We introduce factorization prompting to elicit accurate reasoning on user preferences. The generated reasoning and factual knowledge are effectively transformed and condensed into augmented vectors by a hybrid-expert adaptor in order to be compatible with the recommendation task. The obtained vectors can then be directly used to enhance the performance of any recommendation model. We also ensure efficient inference by preprocessing and prestoring the knowledge from the LLM. Extensive experiments show that KAR significantly outperforms the state-of-the-art baselines and is compatible with a wide range of recommendation algorithms. We deploy KAR to Huawei’s news and music recommendation platforms and gain a 7% and 1.7% improvement in the online A/B test, respectively.</p>
    <p><strong>Categories:</strong> Large Language Models (LLMs), Knowledge Augmentation, Recommender Systems, Open-World Recommendation, Knowledge Graphs, User Preference Modeling, Factorization Prompting, Feature Extraction, Representation Learning, Hybrid Models, Efficiency Optimization, Scalability, State-of-the-Art Methods, Real-World Applications, A/B Testing, News, Music, Beyond Accuracy, Compatibility (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1071/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Bayesian Optimization with LLM-Based Acquisition Functions for Natural Language Preference Elicitation (2024)</h3>
    <p><strong>Authors:</strong> Armin Toroghi, David Austin, Anton Korikov, Scott Sanner</p>
    <p>Designing preference elicitation (PE) methodologies that can quickly ascertain a user’s top item preferences in a cold-start setting is a key challenge for building effective and personalized conversational recommendation (ConvRec) systems. While large language models (LLMs) constitute a novel technology that enables fully natural language (NL) PE dialogues, we hypothesize that monolithic LLM NL-PE approaches lack the multi-turn, decision-theoretic reasoning required to effectively balance the NL exploration and exploitation of user preferences towards an arbitrary item set. In contrast, traditional Bayesian optimization PE methods define theoretically optimal PE strategies, but fail to use NL item descriptions or generate NL queries, unrealistically assuming users can express preferences with direct item ratings and comparisons. To overcome the limitations of both approaches, we formulate NL-PE in a Bayesian Optimization (BO) framework that seeks to actively elicit natural language feedback to reduce uncertainty over item utilities to identify the best recommendation. Key challenges in generalizing BO to deal with natural language feedback include determining (a) how to leverage LLMs to model the likelihood of NL preference feedback as a function of item utilities and (b) how to design an acquisition function that works for language-based BO that can elicit in the infinite space of language. We demonstrate our framework in a novel NL-PE algorithm, PEBOL, which uses Natural Language Inference (NLI) between user preference utterances and NL item descriptions to maintain preference beliefs and BO strategies such as Thompson Sampling (TS) and Upper Confidence Bound (UCB) to guide LLM query generation. We numerically evaluate our methods in controlled experiments, finding that PEBOL achieves up to 131% improvement in MAP@10 after 10 turns of cold start NL-PE dialogue compared to monolithic GPT-3.5, despite relying on a much smaller 400M parameter NLI model for preference inference.</p>
    <p><strong>Categories:</strong> Bayesian Optimization, Large Language Models (LLMs), Natural Language Processing (NLP), Conversational Recommendation Systems, Preference Elicitation, Cold Start Problem, Algorithm Selection, Multi-Armed Bandits, Thompson Sampling, Upper Confidence Bound, Natural Language Inference (NLI), Evaluation Metrics, Machine Learning (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1020/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>CALRec: Contrastive Alignment of Generative LLMs For Sequential Recommendation (2024)</h3>
    <p><strong>Authors:</strong> Mohamed Hammad, Ivan Vulić, Xiang Zhai, Yaoyiran Li, Anna Korhonen, Keyi Yu, Moustafa Alzantot</p>
    <p>Traditional recommender systems such as matrix factorization methods rely on learning a shared dense embedding space to represent both items and user preferences. Sequence models such as RNN, GRUs, and, recently, Transformers have also excelled in the task of sequential recommendation. The sequential recommendation task requires understanding the sequential structure present in users’ historical interactions to predict the next item they may like. Building upon the success of Large Language Models (LLMs) in a variety of tasks, researchers have recently explored using LLMs that are pretrained on giant corpora of text for sequential recommendation. To use LLMs in sequential recommendations, both the history of user interactions and the model’s prediction of the next item are expressed in text form. We propose CALRec, a two-stage LLM finetuning framework that finetunes a pretrained LLM in a two-tower fashion using a mixture of two contrastive losses and a language modeling loss: the LLM is first finetuned on a data mixture from multiple domains followed by another round of target domain finetuning. Our model significantly outperforms many state-of-the-art baselines (+37% in Recall@1 and +24% in NDCG@10) and systematic ablation studies reveal that (i) both stages of finetuning are crucial, and, when combined, we achieve improved performance, and (ii) contrastive alignment is effective among the target domains explored in our experiments.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Sequential Recommendation, Large Language Models (LLMs), Contrastive Learning, Transformers, Fine-tuning, Performance Improvement, Text Representation (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1031/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Enhancing Cross-Domain Recommender Systems with LLMs: Evaluating Bias and Beyond-Accuracy Measures (2024)</h3>
    <p><strong>Authors:</strong> Thomas Elmar Kolb</p>
    <p>The research domain of recommender systems is rapidly evolving. Initially, optimization efforts focused primarily on accuracy. However, recent research has highlighted the importance of addressing bias and beyond-accuracy measures such as novelty, diversity, and serendipity. With the rise of multi-domain recommender systems, the need to re-examine bias and beyond-accuracy measures in cross-domain settings has become crucial. Traditional methods face challenges such as cold-start problems, which can potentially be mitigated by leveraging LLMs. This proposed work investigates how LLM-based recommendation methods can enhance cross-domain recommender systems, focusing on identifying, measuring, and mitigating bias while evaluating the impact of beyond-accuracy measures. We aim to provide new insights by comparing traditional and LLM-based systems within a real-world environment encompassing the domains of news, books, and various lifestyle areas. Our research seeks to address the outlined gaps and develop effective evaluation strategies for the unique challenges posed by LLMs in cross-domain recommender systems.</p>
    <p><strong>Categories:</strong> Cross-Domain Recommender Systems, Large Language Models (LLMs), Bias, Novelty, Diversity, Serendipity, Beyond Accuracy, Cold Start Problem, News Domain, Books Domain, Lifestyle Domain, Real-World Applications, Traditional Recommenders, Neural Networks, Multi-Domain Evaluation, Enhancing Recommender Systems (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1137/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Evaluation and simplification of text difficulty using LLMs in the context of recommending texts in French to facilitate language learning (2024)</h3>
    <p><strong>Authors:</strong> Michalis Vlachos, Yash Raj Shrestha, Henri Jamet, Maxime Manderlier</p>
    <p>We develop a recommendation system for foreign language learning. This recommends text or video content. It ranks digital content considering both the content’s difficulty and how the topic aligns to the learners’ interests. To achieve this, we automatically apply the following operations to any text: a. Classify its subject. b. Evaluate its linguistic difficulty. c. Potentially simplify its language level, while preserving its semantic content for adaptation to the reader’s language level. Once these three operations have produced a set of texts adapted to the reader’s interests and level, they are ranked by relevance using a recommendation system based on the reading and satisfaction of other users. In this paper, we focus on using Large Language Models (LLMs) to automatically perform these tasks on any set of texts. We present an approach for training and evaluation and compare both zero-shot and fine-tuned performance of state-of-the-art models. Our findings indicate a marked improvement in the prediction of French content difficulty (improvement range of 18-56%), a 27% enhancement in topic prediction accuracy with fine-tuned models compared to zero-shot models, and up to an 18% increase in NDCG in recommendation performance.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Language Learning, Text Simplification, Large Language Models (LLMs), Natural Language Processing, Education, French Language, Difficulty Evaluation, Automatic Content Adaptation, User Personalization, Model Evaluation, Recommendation Metrics, User Satisfaction (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1091/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Improving Data Efficiency for Recommenders and LLMs (2024)</h3>
    <p><strong>Authors:</strong> James Caverlee, Noveen Sachdeva, Jianmo Ni, Benjamin Coleman, Ed Chi, Lichan Hong, Wang-Cheng Kang, Derek Cheng</p>
    <p>In recent years, massive transformer-based architectures have driven breakthrough performance in practical applications like autoregressive text-generation (LLMs) and click-prediction (recommenders). A common recipe for success is to train large models on massive web-scale datasets, e.g., modern recommenders are trained on billions of user-item click events, and LLMs are trained on trillions of tokens extracted from the public internet. We are close to hitting the computational and economical limits of scaling up the size of these models, and we expect the next frontier of gains to come from improving the: (i) data quality of the training dataset, and (ii) data efficiency of the extremely expensive training procedure. Inspired by this shift, we present a set of “data-centric” techniques for recommendation and language models that summarizes a dataset into a terse data summary, which is both (i) high-quality, i.e., trains better quality models, and (ii) improves the data-efficiency of the overall training procedure. We propose techniques from two disparate data frameworks: (i) data selection (a.k.a., coreset construction) methods that sample portions of the dataset using grounded heuristics, and(ii) data distillation techniques that generate synthetic examples which are optimized to retain the signals needed for training high-quality models. Overall, this work sheds light on the challenges and opportunities offered by data optimization in web-scale systems, a particularly relevant focus as the recommendation community grapples with the grand challenge of leveraging LLMs.</p>
    <p><strong>Categories:</strong> Recommender Systems, Large Language Models (LLMs), Web-Scale Systems, Data Efficiency, Data Quality, Data Selection, Coreset Construction, Data Distillation, Synthetic Data, High-Quality Datasets, Cross-Domain Applications, Web-Scale Optimization, Recommender-LLM Integration (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1161/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Unleashing the Retrieval Potential of Large Language Models in Conversational Recommender Systems (2024)</h3>
    <p><strong>Authors:</strong> Ting Yang, Li Chen</p>
    <p>Conversational recommender systems (CRSs) aim to capture user preferences and provide personalized recommendations through interactive natural language interactions. The recent advent of large language models (LLMs) has revolutionized human engagement in natural conversations, driven by their extensive world knowledge and remarkable natural language understanding and generation capabilities. However, introducing LLMs into CRSs presents new technical challenges. Specifically, directly prompting LLMs for recommendation generation requires understanding a large and evolving item corpus, as well as grounding the generated recommendations in the real item space. Moreover, generating recommendations based on external recommendation engines or directly integrating their suggestions into responses may constrain the overall performance of LLMs, since these engines generally have inferior representation abilities compared to LLMs. To address these challenges, we propose an end-to-end large-scale CRS model, ReFICR, a novel LLM-enhanced conversational recommender that empowers a retrievable large language model to perform CRS subtasks by following retrieval and generation instructions through lightweight tuning. By decomposing the complex CRS task into multiple subtasks, we formulate these subtasks into two types of instruction formats: retrieval and generation. The hidden states of ReFICR are utilized as text embeddings to represent user preferences and items for retrieval. Simultaneously, ReFICR is trained to handle generative tasks. We optimize the contrastive objective to enhance text embeddings for retrieval and jointly fine-tune the large language model objective for generation. Our experimental results on public datasets demonstrate that ReFICR significantly outperforms baselines in terms of recommendation accuracy. Our code is publicly available at the link: https://anonymous.4open.science/r/ReFICR-0C3A.</p>
    <p><strong>Categories:</strong> Conversational Recommender Systems (CRSs), Large Language Models (LLMs), Recommendation Generation, Natural Language Processing (NLP), Retrieval-Based Systems, Instruction-Following Models, Contrastive Learning, End-to-End Models, Personalized Recommendations, Implicit Feedback, Hybrid Recommender Systems, Language Model Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1076/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>“More to Read” at the Los Angeles Times: Solving a Cold Start Problem with LLMs to Improve Story Discovery (2024)</h3>
    <p><strong>Authors:</strong> David Kaufman, Franklin Horn, Aurelia Alston, Won You</p>
    <p>News publishers, who are seeking to grow their digital audience, face a challenge in providing relevant content recommendations for unregistered users arriving directly to article pages. In these cold start scenarios, classic techniques, like asking a user to register and select topics of interest, fall short. We present a contextual targeting approach that leverages the user’s current article choice itself as an implicit signal of user interests. We designed and developed an interface with recommendations to help users discover more articles. Our online A/B testing demonstrated that our models increased click-through rates by 39.4% over a popularity baseline. One of them, a large language model (LLM), generates relevant recommendations that balance immersion and novelty. We discuss the implications of using LLMs for responsibly enhancing user experiences while upholding editorial standards. We identify key opportunities in detecting nuanced user preferences and identifying and interrupting filter bubbles on news publisher sites.</p>
    <p><strong>Categories:</strong> Cold Start, Large Language Models (LLMs), News, Recommendation Systems, Implicit Feedback, Contextual Targeting, A/B Test, Online Media, User Engagement, Editorial Standards, Filter Bubbles, Content Diversity, Personalization (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1150/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Distillation Matters: Empowering Sequential  Recommenders to Match the Performance of Large Language Models (2024)</h3>
    <p><strong>Authors:</strong> Jiawei Chen, Yi Wan, Heng Tang, Bohao Wang, Feng Liu, Pengbo Wang, Jun Wang, Yu Cui</p>
    <p>Owing to their powerful semantic reasoning capabilities, Large Language Models (LLMs) have been effectively utilized as recommenders, achieving impressive performance. However, the high inference latency of LLMs significantly restricts their practical deployment. To address this issue, this work investigates knowledge distillation from cumbersome LLM-based recommendation models to lightweight conventional sequential models. It encounters three challenges: 1) the teacher’s knowledge may not always be reliable; 2) the capacity gap between the teacher and student makes it difficult for the student to assimilate the teacher’s knowledge; 3) divergence in semantic space poses a challenge to distill the knowledge from embeddings. To tackle these challenges, this work proposes a novel distillation strategy, DLLM2Rec, specifically tailored for knowledge distillation from LLM-based recommendation models to conventional sequential models. DLLM2Rec comprises: 1) Importance-aware ranking distillation, which filters reliable and student-friendly knowledge by weighting instances according to teacher confidence and student-teacher consistency; 2)  Collaborative embedding distillation integrates knowledge from teacher embeddings with collaborative signals mined from the data. Extensive experiments demonstrate the effectiveness of the proposed DLLM2Rec, boosting three typical sequential models with an average improvement of 47.97%, even enabling them to surpass LLM-based recommenders in some cases.</p>
    <p><strong>Categories:</strong> Knowledge Distillation, Sequential Recommenders, Large Language Models (LLMs), Recommendation Systems, Performance Improvement, Efficiency Optimization, Cold Start, Algorithmic Innovation, Collaborative Filtering, Scalability and Efficiency (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1028/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>User knowledge prompt for sequential recommendation (2024)</h3>
    <p><strong>Authors:</strong> Yuuki Tachioka</p>
    <p>The large language model (LLM) based recommendation system is effective for sequential recommendation, because general knowledge of popular items is included in the LLM. To add domain knowledge of items, the conventional method uses a knowledge prompt obtained from the item knowledge graphs and has achieved SOTA performance. However, for personalized recommendation, it is necessary to consider user knowledge, which the conventional method does not fully consider because user knowledge is not included in the item knowledge graphs; thus, we propose a user knowledge prompt, which converts a user knowledge graph into a prompt using the relationship template. The existing prompt denoising framework is extended to prevent hallucination caused by undesirable interactions between knowledge graph prompts. We propose user knowledge prompts of user traits and user preferences and associate relevant items. Experiments on three types of dataset (movie, music, and book) show the significant and consistent improvement of our proposed user knowledge prompt.</p>
    <p><strong>Categories:</strong> Large Language Models (LLMs), Knowledge Graphs, Sequential Recommendations, Personalized Recommendation, Prompt Engineering, Movies, Music, Books, User Modeling, Empirical Evaluation, Prompt Denoising (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1198/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>GenUI(ne) CRS: UI Elements and Retrieval-Augmented Generation in Conversational Recommender Systems with LLMs (2024)</h3>
    <p><strong>Authors:</strong> Lien Michiels, Annelien Smets, Ulysse Maes</p>
    <p>Previous research has used Large Language Models (LLMs) to develop personalized Conversational Recommender Systems (CRS) with text-based user interfaces (UIs). However, the potential of LLMs to generate interactive graphical elements that enhance user experience remains largely unexplored. To address this gap, we introduce “GenUI(ne) CRS,” a novel framework designed to leverage LLMs for adaptive and interactive UIs. Our framework supports domain-specific graphical elements such as buttons and cards, in addition to text-based inputs. It also addresses the common LLM issue of outdated knowledge, known as the “knowledge cut-off,” by implementing Retrieval-Augmented Generation (RAG). To illustrate its potential, we developed a prototype movie CRS. This work demonstrates the feasibility of LLM-powered interactive UIs and paves the way for future CRS research, including user experience validation, transparent explanations, and addressing LLM biases.</p>
    <p><strong>Categories:</strong> Conversational Recommender Systems (CRS), Large Language Models (LLMs), UI/UX Design, Graphical User Interfaces (GUI), Retrieval-Augmented Generation (RAG), Movies, Human-Computer Interaction, User Experience, Transparency in Recommendations, Bias Mitigation (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1206/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Data Augmentation using Reverse Prompt for Cost-Efficient Cold-Start Recommendation (2024)</h3>
    <p><strong>Authors:</strong> Genki Kusano</p>
    <p>Recommendation systems that use auxiliary information such as product names and categories have been proposed to address the cold-start problem. However, these methods do not perform well when we only have insufficient warm-start training data. On the other hand, large language models (LLMs) can perform as effective cold-start recommendation systems even with limited warm-start data. However, they require numerous API calls for inferences, which leads to high operational costs in terms of time and money. This is a significant concern in industrial applications. In this paper, we introduce a new method, RevAug, which leverages LLMs as a data augmentation to enhance cost-efficient cold-start recommendation systems. To generate pseudo-samples, we have reversed the commonly used prompt for an LLM from “Would this user like this item?” to “What kind of items would this user like?”. Generated outputs by this reverse prompt are pseudo-auxiliary information utilized to enhance recommendation systems in the training phase. In numerical experiments with four real-world datasets, RevAug demonstrated superior performance in cold-start settings with limited warm-start data compared to existing methods. Moreover, RevAug significantly reduced API fees and processing time compared to an LLM-based recommendation method.</p>
    <p><strong>Categories:</strong> Cold Start, Data Augmentation, Large Language Models (LLMs), Recommendation Systems, Reverse Prompt, Cost Efficiency, Methodology, Performance in Cold-Start Settings, Real-World Applications. (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1081/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>