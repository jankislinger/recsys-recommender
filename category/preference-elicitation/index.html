<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/real-world-applications/">Real-world Applications</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/offline-evaluation/">Offline Evaluation</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reproducibility/">Reproducibility</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/explainability/">Explainability</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Bayesian Optimization with LLM-Based Acquisition Functions for Natural Language Preference Elicitation (2024)</h3>
    <p><strong>Authors:</strong> Armin Toroghi, David Austin, Anton Korikov, Scott Sanner</p>
    <p>Designing preference elicitation (PE) methodologies that can quickly ascertain a user’s top item preferences in a cold-start setting is a key challenge for building effective and personalized conversational recommendation (ConvRec) systems. While large language models (LLMs) constitute a novel technology that enables fully natural language (NL) PE dialogues, we hypothesize that monolithic LLM NL-PE approaches lack the multi-turn, decision-theoretic reasoning required to effectively balance the NL exploration and exploitation of user preferences towards an arbitrary item set. In contrast, traditional Bayesian optimization PE methods define theoretically optimal PE strategies, but fail to use NL item descriptions or generate NL queries, unrealistically assuming users can express preferences with direct item ratings and comparisons. To overcome the limitations of both approaches, we formulate NL-PE in a Bayesian Optimization (BO) framework that seeks to actively elicit natural language feedback to reduce uncertainty over item utilities to identify the best recommendation. Key challenges in generalizing BO to deal with natural language feedback include determining (a) how to leverage LLMs to model the likelihood of NL preference feedback as a function of item utilities and (b) how to design an acquisition function that works for language-based BO that can elicit in the infinite space of language. We demonstrate our framework in a novel NL-PE algorithm, PEBOL, which uses Natural Language Inference (NLI) between user preference utterances and NL item descriptions to maintain preference beliefs and BO strategies such as Thompson Sampling (TS) and Upper Confidence Bound (UCB) to guide LLM query generation. We numerically evaluate our methods in controlled experiments, finding that PEBOL achieves up to 131% improvement in MAP@10 after 10 turns of cold start NL-PE dialogue compared to monolithic GPT-3.5, despite relying on a much smaller 400M parameter NLI model for preference inference.</p>
    <p><strong>Categories:</strong> Bayesian Optimization, Large Language Models (LLMs), Natural Language Processing (NLP), Conversational Recommendation Systems, Preference Elicitation, Cold Start Problem, Algorithm Selection, Multi-Armed Bandits, Thompson Sampling, Upper Confidence Bound, Natural Language Inference (NLI), Evaluation Metrics, Machine Learning (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1020/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>EasyStudy: Framework for Easy Deployment of User Studies on Recommender Systems (2023)</h3>
    <p><strong>Authors:</strong> Ladislav Peska, Patrik Dokoupil</p>
    <p>Improvements in the recommender systems (RS) domain are not possible without a thorough way to evaluate and compare newly proposed approaches. User studies represent a viable alternative to online and offline evaluation schemes, but despite their numerous benefits, they are only rarely used. One of the main reasons behind this fact is that preparing a user study from scratch involves a lot of extra work on top of a simple algorithm proposal.  To simplify this task, we propose \textsc{EasyStudy}, a modular framework built on the credo “<i>Make simple things fast and hard things possible</i>”. It features ready-to-use datasets, preference elicitation methods, incrementally tuned baseline algorithms, study flow plugins, and evaluation metrics. As a result, a simple study comparing several RS can be deployed with just a few clicks, while more complex study designs can still benefit from a range of reusable components, such as preference elicitation. Overall, \textsc{EasyStudy} dramatically decreases the gap between the laboriousness of offline evaluation vs. user studies and, therefore, may contribute towards the more reliable and insightful user-centric evaluation of next-generation RS.</p>
    <p><strong>Categories:</strong> Recommender Systems, User-Centric Evaluation, Evaluation Methods, User Studies, Preference Elicitation, Framework Development, Baseline Algorithms, Beyond Accuracy Evaluation, Scalability, Modular Frameworks (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/962/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Soliciting User Preferences in Conversational Recommender Systems via Usage-related Questions (2021)</h3>
    <p><strong>Authors:</strong> Ivica Kostric, Filip Radlinski, Krisztian Balog</p>
    <p>A key distinguishing feature of conversational recommender systems over traditional recommender systems is their ability to elicit user preferences using natural language. Currently, the predominant approach to preference elicitation is to ask questions directly about items or item attributes. These strategies do not perform well in cases where the user does not have sufficient knowledge of the target domain to answer such questions. Conversely, in a shopping setting, talking about the planned use of items does not present any difficulties, even for those that are new to a domain. In this paper, we propose a novel approach to preference elicitation by asking implicit questions based on item usage. Our approach consists of two main steps. First, we identify the sentences from a large review corpus that contain information about item usage. Then, we generate implicit preference elicitation questions from those sentences using a neural text-to-text model. The main contributions of this work also include a multi-stage data annotation protocol using crowdsourcing for collecting high-quality labeled training data for the neural model. We show that out approach is effective in selecting review sentences and transforming them to elicitation questions, even with limited training data.</p>
    <p><strong>Categories:</strong> Conversational Recommender Systems, Natural Language Processing, Preference Elicitation, Implicit Feedback, Neural Models, Text Generation, Data Annotation, Crowdsourcing, Recommendation Systems, Review Mining, User Interaction, Usage-Based Recommendations (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/703/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Who Doesn’t Like Dinosaurs? Finding and Eliciting Richer Preferences for Recommendation (2020)</h3>
    <p><strong>Authors:</strong> Tobias Schnabel, Gonzalo Ramos, Saleema Amershi</p>
    <p>Real-world recommender systems often allow users to adjust the presented content through a variety of preference elicitation techniques such as “liking” or interest profiles. These elicitation techniques trade-off time and effort to users with the richness of the signal they provide to learning component driving the recommendations. In this paper, we explore this trade-off, seeking new ways for people to express their preferences with the goal of improving communication channels between users and the recommender system. Through a need-finding study, we observe the patterns in how people express their preferences during curation task, propose a taxonomy for organizing them, and point out research opportunities. We present a case study that illustrates how using this taxonomy to design an onboarding experience can lead to more accurate machine-learned recommendations while maintaining user satisfaction under low effort.</p>
    <p><strong>Categories:</strong> Preference Elicitation, User Interaction, Richer Preferences, Recommender Systems, Design of Interfaces, Usability, User-Centered Design, Case Study/Research Methods (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/559/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Towards Interactive Recommending in Model-based Collaborative Filtering Systems (2019)</h3>
    <p><strong>Authors:</strong> Benedikt Loepp, Jürgen Ziegler</p>
    <p>Numerous attempts have been made for increasing the interactivity in recommender systems, but the features actually available in today's systems are in most cases limited to rating or re-rating single items. We present a demonstrator that showcases how model-based collaborative filtering recommenders may be enhanced with advanced interaction and preference elicitation mechanisms in a holistic manner. Hereby, we underline that by employing methods we have proposed in the past it becomes possible to easily extend any matrix factorization recommender into a fully interactive, user-controlled system. By presenting and deploying our demonstrator, we aim at gathering further insights, both into how the different mechanisms may be intertwined even more closely, and how interaction behavior and resulting user experience are influenced when users can choose from these mechanisms at their own discretion.</p>
    <p><strong>Categories:</strong> Interactive Recommending, Model-based Collaborative Filtering, Matrix Factorization, Preference Elicitation, User-controlled Systems, Interaction Behavior, Real-world Applications, Recommendation System Optimization (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/503/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>IRF: Interactive Recommendation through Dialogue (2019)</h3>
    <p><strong>Authors:</strong> Oznur Alkan, Massimiliano Mattetti, Elizabeth M. Daly, Inge Vejsbjerg, Adi Botea</p>
    <p>Recent research focuses beyond recommendation accuracy, towards human factors that influence the acceptance of recommendations, such as user satisfaction, trust, transparency and sense of control. We present a generic interactive recommender framework that can add interaction functionalities to non-interactive recommender systems. We take advantage of dialogue systems to interact with the user and we design a middleware layer to provide the interaction functions, such as providing explanations for the recommendations, managing users' preferences learnt from dialogue, preference elicitation and refining recommendations based on learnt preferences.</p>
    <p><strong>Categories:</strong> Interactive Recommendations, Preference Elicitation, User Preference Learning, Explainable AI (XAI), Beyond Accuracy, Trust and Transparency, Human-Computer Interaction, Dialogue Systems Integration, Middleware Design, Framework Design (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/506/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Towards a Taxonomy of User Feedback Intents for Conversational Recommendations (2019)</h3>
    <p><strong>Authors:</strong> Li Chen, Wanling Cai</p>
    <p>Understanding users’ feedback on recommendation in natural language is crucially important for assisting the system to refine its understanding of the user’s preferences and provide more accurate recommendations in the subsequent interactions. In this paper, we report the results of an exploratory study on a human-human dialogue dataset centered around movie recommendations. In particular, we manually labeled a set of over 200 dialogues at the utterance level, and then conducted descriptive analysis on them from both seekers’ and recommenders’ perspectives. The results reveal not only seekers’ feedback intents as well as the types of preferences they have expressed, but also the reactions of human recommenders that have finally led to successful recommendation. A taxonomy for feedback intents is established along with the results, which could be constructive for improving conversational recommender systems.</p>
    <p><strong>Categories:</strong> Feedback Handling, User Interaction, Natural Language Processing (NLP), Conversational Recommender Systems, Movie Recommendations, User Preferences, Taxonomy Development, Human-Computer Interaction (HCI), Dialogue Analysis, Recommendation Systems, Preference Elicitation, Evaluation Methods (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/520/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Preference Elicitation as an Optimization Problem (2018)</h3>
    <p><strong>Authors:</strong> Filip Radlinski, Maarten de Rijke, Julia Kiseleva, Anna Sepliarskaia</p>
    <p>The new user cold-start problem arises when a recommender system does not yet have any information about a user. A common solution to this problem is to generate a user profile as part of the sign-up process, by asking the user to rate several items. We propose a new elicitation method to generate a static preference questionnaire (SPQ) that asks a new user to make pairwise comparisons between items by posing relative preference questions. Using a latent factor model, SPQ improves personalized recommendations by choosing a minimal and diverse set of static preference questions to ask any new user. We are the first to rigorously prove which optimization task should be solved in order to select the next preference question for static questionnaires. Our theoretical results are confirmed by extensive experimentation. We test the performance of SPQ on two real-world datasets, under two experimental conditions: simulated, when users behave according to LFM, and real, in which there is no user rating model. SPQ reduces the questionnaire length that is necessary to make accurate recommendations for new users by up to a factor of three compared to state-of-the-art preference elicitation methods. Moreover, solving the right optimization task, SPQ shows better performance than baselines with dynamically generated questions.</p>
    <p><strong>Categories:</strong> Cold Start, Recommendation Systems, User Profiling, Preference Elicitation, Optimization, Latent Factor Models, Real-World Applications, Experiments, Datasets, Evaluation Metrics, Performance Comparison, Efficiency, Pairwise Comparisons (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/357/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Acquisition of Music Pairwise Scores and Facial Expressions (2017)</h3>
    <p><strong>Authors:</strong> Matija Marolt, Nima Maleki, Matevž Pesek, Mehdi Elahi, Marko Tkalcic, Francesco Ricci</p>
    <p>We present a research tool for user preference elicitation that collects both explicit user feedback and unobtrusively acquired facial expressions. The concrete implementation is a web-based user interface where the user is presented with two music excerpts. After listening to both, the user provides a pairwise score (i.e. which of the two items is preferred) for each pair of music excerpts. The novelty of the demo is the integration of the unobtrusive acquisition of facial expressions through the webcam. During the listening of the music excerpts, the system extracts features related to the facial expressions of the user several times per second. The interaction runs as a web application, which allows for a large-scale remote acquisition of emotional data. Up to now, such acquisitions were usually done in controlled environments with few subjects, hence being of little use for the recommender systems community.</p>
    <p><strong>Categories:</strong> Music Recommendations, Web-Based Systems, Affective Computing, Facial Expression Analysis, Emotion Recognition, User Feedback, Recommender Systems, Data Collection Methods, Remote Data Acquisition, Preference Elicitation (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/302/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Improving the User Experience during Cold Start through Choice-Based Preference Elicitation (2015)</h3>
    <p><strong>Authors:</strong> Mark P. Graus, Martijn C. Willemsen</p>
    <p>We studied an alternative choice-based interface for preference elicitation during the cold start phase and compared it directly with a standard rating-based interface. In this alternative interface users started from a diverse set covering all movies and iteratively narrowed down through a matrix factorization latent feature space to smaller sets of items based on their choices. The results show that compared to a rating-based interface, the choice-based interface requires less effort and results in more satisfying recommendations, showing that it might be a promising candidate for alleviating the cold start problem of new users.</p>
    <p><strong>Categories:</strong> Cold Start, Preference Elicitation, Recommendation Systems, Matrix Factorization, User Experience, Choice-Based Interfaces, Effort Reduction, Satisfaction, User-Centered Design, Evaluation Methods, Latent Feature Space, Interface Design, Iterative Filtering (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/122/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Preference Elicitation for Narrowing the Recommended List for Groups (2014)</h3>
    <p><strong>Authors:</strong> Lihi Naamani-Dery, Meir Kalech, Bracha Shapira, Lior Rokach</p>
    <p>A group may appreciate recommendations on items that fit their joint preferences. When the members’ actual preferences are unknown, a recommendation can be made with the aid of collaborative filtering methods. We offer to narrow down the recommended list of items by eliciting the users’ actual preferences. Our final goal is to output top-k preferred items to the group out of the top-N recommendations provided by the recommender system (k < N), where one of the items is a necessary winner. We propose an iterative preference elicitation method, where users are required to provide item ratings per request. We suggest a heuristic that attempts to minimize the preference elicitation effort under two aggregation strategies. We evaluate our methods on real-world Netflix data as well as on simulated data which allows us to study different cases. We show that preference elicitation effort can be cut in up to 90% while preserving the most preferred items in the narrowed list.</p>
    <p><strong>Categories:</strong> Group Recommendations, Preference Elicitation, Collaborative Filtering, Iterative Methods, User Ratings, Real-World Applications, Simulation Studies, Heuristic Methods, Aggregation Strategies (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/50/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>