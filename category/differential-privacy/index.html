<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reinforcement-learning/">Reinforcement Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/cold-start/">Cold Start</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reproducibility/">Reproducibility</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/offline-evaluation/">Offline Evaluation</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/bias-mitigation/">Bias Mitigation</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>FedLoCA: Low-Rank Coordinated Adaptation with Knowledge Decoupling for Federated Recommendations (2024)</h3>
    <p><strong>Authors:</strong> Yong Liao, Boyu Fan, Pengyuan Zhou, Siqing Zhang, Yuchen Ding, Wei Sun</p>
    <p>Privacy protection in recommendation systems is gaining increasing attention, for which federated learning has emerged as a promising solution. Current federated recommendation systems grapple with high communication overhead due to sharing dense global embeddings, and also poorly reflect user preferences due to data heterogeneity. To overcome these challenges, we propose a two-stage Federated Low-rank Coordinated Adaptation (FedLoCA) framework to decouple global and client-specific knowledge into low-rank embeddings, which significantly reduces communication overhead while enhancing the system’s ability to capture individual user preferences amidst data heterogeneity. Further, to tackle gradient estimation inaccuracies stemming from data sparsity in federated recommendation systems, we introduce an adversarial gradient projected descent approach in low-rank spaces, which significantly boosts model performance while maintaining robustness. Remarkably, FedLoCA also alleviates performance loss even under the stringent constraints of differential privacy. Extensive experiments on various real-world datasets demonstrate that FedLoCA significantly outperforms existing methods in both recommendation accuracy and communication efficiency.</p>
    <p><strong>Categories:</strong> Federated Learning, Privacy Protection, Recommendation Systems, Communication Efficiency, Low-Rank Embeddings, Personalization, Gradient Estimation, Optimization, Differential Privacy, Data Heterogeneity, Cold Start, Evaluation Metrics (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1037/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Enhancing Privacy in Recommender Systems through Differential Privacy Techniques (2024)</h3>
    <p><strong>Authors:</strong> Angela Di Fazio</p>
    <p>Recommender systems have become essential tools for addressing information overload in the digital age. However, the collection and usage of user data for personalized recommendations raise significant privacy concerns. This research focuses on enhancing privacy in recommender systems through the application of differential privacy techniques, particularly in the domain of privacy-preserving data publishing. Our study aims to address three key research questions: (1) developing standardized metrics to characterize and compare recommendation datasets in the context of privacy-preserving data publishing, (2) designing differential privacy algorithms for private data publishing that preserve recommendation quality, and (3) examining the impact of differential privacy on beyond-accuracy objectives in recommender systems. We propose to develop domain-specific metrics for evaluating the similarity between recommendation datasets, analogous to those used in other domains such as trajectory data publication. Additionally, we will investigate methods to balance the trade-off between privacy guarantees and recommendation accuracy, considering the potential disparate impacts on different user subgroups. Finally, we aim to assess the broader implications of implementing differential privacy on beyond-accuracy objectives such as diversity, popularity bias, and fairness. By addressing these challenges, our research seeks to contribute to the advancement of privacy-preserving techniques in recommender systems, facilitating the responsible and secure use of recommendation data while maintaining the utility of personalized suggestions. The outcomes of this study have the potential to significantly benefit the field by enabling the reuse of existing algorithms with minimal adjustments while ensuring robust privacy guarantees.</p>
    <p><strong>Categories:</strong> Privacy Preservation, Differential Privacy, Recommender Systems, Metrics Evaluation, Beyond Accuracy Objectives, Domain-Specific Metrics, Privacy-Preserving Data Publishing, Trade-Off Analysis, User Subgroup Impacts, Diversity, Popularity Bias, Fairness, Responsible Data Use (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1139/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Privacy Preserving Conversion Modeling in Data Clean Room (2024)</h3>
    <p><strong>Authors:</strong> Behnam Rezaei, Xiangyi Chen, Ling Leng, Jiajing Xu, Jiankai Sun, Kungang Li</p>
    <p>In the realm of online advertising, accurately predicting the conversion rates (CVR) is crucial for enhancing advertising efficiency and user satisfaction. However, it faces the challenge that due to user privacy choices and advertiser requirements, the advertising platform cannot get the conversion data from some advertisers, making accurate CVR predictions difficult. Although current methods like split learning or vertical federated learning do not share label information directly, they still exchange sample-level gradients, which introduces a privacy risk as adversaries might infer label information through the shared gradients. To address these challenges, our proposed model training framework incorporates several innovative techniques. Firstly, we employ batch-level aggregated gradients instead of sample-level gradients to enhance privacy. Secondly, to minimize communication costs, we utilize adapter-based parameter-efficient fine-tuning methods such as Low-Rank Adaptation (LoRA) and gradient compression in conversion models. These methods allow for efficient collaboration between different parties while reducing the amount of data transferred. Lastly, we incorporate label differential privacy to protect model privacy. Given that this privacy protection alters the data distribution and can result in significant calibration error, we propose a de-biasing technique to ensure accurate model predictions even with perturbed label information. Our experimental results on industrial datasets demonstrate that our method achieves competitive performance while significantly reducing the communication overhead and complying with advertisers’ privacy requirements and user privacy choice. This framework establishes a new benchmark for privacy-preserving and high-performance CVR prediction in the digital advertising industry.</p>
    <p><strong>Categories:</strong> Privacy Preservation, Conversion Rate Prediction, Online Advertising, Machine Learning, Federated Learning, Differential Privacy, Optimization Methods, Data Sharing Challenges, Low-Rank Adaptation (LoRA), Gradient Compression, Advertising Technology, Real-World Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1181/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Private Matrix Factorization with Public Item Features (2023)</h3>
    <p><strong>Authors:</strong> Walid Krichene, Mihaela Curmei, Li Zhang</p>
    <p>We consider the problem of training private recommendation models with access to public item features. Training with Differential Privacy (DP) offers strong privacy guarantees, at the expense of loss in recommendation quality. We show that incorporating public item features during training can help mitigate this loss in quality. We propose a general approach based on collective matrix factorization, that works by simultaneously factorizing two matrices: the user feedback matrix (representing sensitive data) and an item feature matrix that encodes publicly available (non-sensitive) item information. The method is conceptually simple, easy to tune, and highly scalable. It can be applied to different types of public data, including: (1) categorical item features; (2) item-item similarities learned from public sources; and (3) publicly available user feedback. Evaluating our method on a standard DP recommendation benchmark, we find that using public item features significantly narrows the quality gap between the private models and their non-private counterpart. As privacy constraints become more stringent, the increased reliance on public side features leads to recommendations becoming more depersonalized, resulting in a smooth transition from collaborative filtering to item-based contextual recommendations.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Matrix Factorization, Differential Privacy, Item Features, Public Data, Privacy-Preserving, Scalability, Collaborative Filtering, Item-Based Recommendations, Evaluation Metrics, Recommendation Quality, Depersonalization (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/913/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Fairness-aware Federated Matrix Factorization (2022)</h3>
    <p><strong>Authors:</strong> Yingqiang Ge, Yongfeng Zhang, Shuchang Liu, Shuyuan Xu, Amelie Marian</p>
    <p>Achieving fairness over different user groups in recommender systems is an important problem. The majority of existing works achieve fairness through constrained optimization that combines the recommendation loss and the fairness constraint. To achieve fairness, the algorithm usually needs to know each user’s group affiliation feature such as gender or race. However, such involved user group feature is usually sensitive and requires protection. In this work, we seek a federated learning solution for the fair recommendation problem and identify the main challenge as an algorithmic conflict between the global fairness objective and the localized federated optimization process. On one hand, the fairness objective usually requires access to all users’ group information. On the other hand, the federated learning systems restrain the personal data in each user’s local space. As a resolution, we propose to communicate group statistics during federated optimization and use differential privacy techniques to avoid exposure of users’ group information when users require privacy protection. We illustrate the theoretical bounds of the noisy signal used in our method that aims to enforce privacy without overwhelming the aggregated statistics. Empirical results show that federated learning may naturally improve user group fairness and the proposed framework can effectively control this fairness with low communication overheads.</p>
    <p><strong>Categories:</strong> Matrix Factorization, Fairness, Federated Learning, Recommendation Systems, Algorithm Design, Differential Privacy, Evaluation Methods, Cold Start, Web Systems, Scalability, User Group Fairness (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/761/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Applying Differential Privacy to Matrix Factorization (2015)</h3>
    <p><strong>Authors:</strong> Arik Friedman, Arnaud Berlioz, Roksana Boreli, Shlomo Berkovsky, Mohamed Ali Kafaar</p>
    <p>Recommender systems are increasingly becoming an integral part of on-line services. As the recommendations rely on personal user information, there is an inherent loss of privacy resulting from the use of such systems. While several works studied privacy-enhanced neighborhood-based recommendations, little attention has been paid to privacy preserving latent factor models, like those represented by matrix factorization techniques. In this paper, we address the problem of privacy preserving matrix factorization by utilizing differential privacy, a rigorous and provable privacy preserving method. We propose and study several approaches for applying differential privacy to matrix factorization, and evaluate the privacy-accuracy trade-offs offered by each approach. We show that input perturbation yields the best recommendation accuracy, while guaranteeing a solid level of privacy protection.</p>
    <p><strong>Categories:</strong> Matrix Factorization, Differential Privacy, Recommender Systems, Privacy-Preserving Techniques, Input Perturbation, Recommendation Accuracy, Privacy-Accuracy Trade-offs. (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/86/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Fast Differentially Private Matrix Factorization (2015)</h3>
    <p><strong>Authors:</strong> Yu-Xiang Wang, Ziqi Liu, Alexander J. Smola</p>
    <p>Differentially private collaborative filtering is a challenging task, both in terms of accuracy and speed. We present a simple algorithm that is provably differentially private, while offering good performance, using a novel connection of differential privacy to Bayesian posterior sampling via Stochastic Gradient Langevin Dynamics. Due to its simplicity the algorithm lends itself to efficient implementation. By careful systems design and by exploiting the power law behavior of the data to maximize CPU cache bandwidth we are able to generate 1024 dimensional models at a rate of 8.5 million recommendations per second on a single PC.</p>
    <p><strong>Categories:</strong> Matrix Factorization, Differential Privacy, Collaborative Filtering, Scalability, Performance Optimization, Recommendation Systems, Probabilistic Methods, High-dimensional Models, Bayesian Inference, Stochastic Gradient Langevin Dynamics (SGLD), Real-world Applications, Web Systems (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/97/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>