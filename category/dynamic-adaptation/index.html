<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/user-behavior/">User Behavior</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/offline-evaluation/">Offline Evaluation</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/explainability/">Explainability</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reproducibility/">Reproducibility</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Augmenting Netflix Search with In-Session Adapted Recommendations (2022)</h3>
    <p><strong>Authors:</strong> Moumita Bhattacharya, Sudarshan Dnyaneshwar Lamkhede</p>
    <p>We motivate the need for recommendation systems that can cater to the members’ in-the-moment intent by leveraging their interactions from the current session. We provide an overview of an end-to-end in-session adaptive recommendations system in the context of Netflix Search. We discuss the challenges and potential solutions when developing such a system at production scale.</p>
    <p><strong>Categories:</strong> In-Session Recommendations, Production Systems, Personalized Recommendations, Media Recommendations, Scalability, Real-Time Adaptation, Recommendation Systems Algorithms, Dynamic Adaptation, Netflix Recommendations, Search Optimization (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/817/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Dynamic Global Sensitivity for Differentially Private Contextual Bandits (2022)</h3>
    <p><strong>Authors:</strong> Hongning Wang, David B. Zhao, Huazheng Wang</p>
    <p>Bandit algorithms have become a reference solution for interactive recommendation. However, as such algorithms directly interact with users for improved recommendations, serious privacy concerns have been raised regarding its practical use. In this work, we propose a differentially private linear contextual bandit algorithm, via a tree-based mechanism to add Laplace or Gaussian noise to model parameters. Our key insight is that as the model converges during online update, the global sensitivity of its parameters shrinks over time (thus named dynamic global sensitivity). Compared with existing solutions, our dynamic global sensitivity analysis allows us to inject less noise to obtain (ϵ, δ)-differential privacy with added regret caused by noise injection in . We provide a rigorous theoretical analysis over the amount of noise added via dynamic global sensitivity and the corresponding upper regret bound of our proposed algorithm. Experimental results on both synthetic and real-world datasets confirmed the algorithm’s advantage against existing solutions.</p>
    <p><strong>Categories:</strong> Differentially Private Contextual Bandits, Privacy, Recommendation Systems, Algorithm Mechanisms, Differential Privacy Techniques, Online Learning, Theoretical Analysis, Regret Analysis, Experimental Validation, Empirical Evaluation, Evaluation Metrics, Dynamic Adaptation, Context-Aware Recommendations (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/755/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Who do you think I am? Interactive User Modelling with Item Metadata (2022)</h3>
    <p><strong>Authors:</strong> Bart Goethals, Koen Ruymbeek, Joey De Pauw</p>
    <p>Recommender systems are used in many different applications and contexts, however their main goal can always be summarised as “connecting relevant content to interested users”. Explanations have been found to help recommender systems achieve this goal by giving users a look under the hood that helps them understand why they are recommended certain items. Furthermore, explanations can be considered to be the first step towards interacting with the system. Indeed, for a user to give feedback and guide the system towards better understanding her preferences, it helps if the user has a better idea of what the system has already learned.<br>To this end, we propose a linear collaborative filtering recommendation model that builds user profiles within the domain of item metadata. Our method is hence inherently transparent and explainable. Moreover, since recommendations are computed as a linear function of item metadata and the interpretable user profile, our method seamlessly supports interactive recommendation. In other words, users can directly tweak the weights of the learned profile for more fine-grained browsing and discovery of content based on their current interests. We demonstrate the interactive aspect of this model in an online application for discovering cultural events in Belgium.</p>
    <p><strong>Categories:</strong> Explainable Recommendations, Transparency, Collaborative Filtering, Item Metadata, Interactive Recommendation, User Profiling, User Feedback, Real World Application, Usability, Dynamic Adaptation, A/B Test, Core Recommendation. (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/802/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Multi-Armed Recommender System Bandit Ensembles (2019)</h3>
    <p><strong>Authors:</strong> Marcos Redondo, Rocío Cañamares, Pablo Castells</p>
    <p>It has long been found that well-configured recommender system ensembles can achieve better effectiveness than the combined systems separately. Sophisticated approaches have been developed to automatically optimize the ensembles’ configuration to maximize their performance gains. However most work in this area has targeted simplified scenarios where algorithms are tested and compared on a single non-interactive run. In this paper we consider a more realistic perspective bearing in mind the cyclic nature of the recommendation task, where a large part of the system’s input is collected from the reaction of users to the recommendations they are delivered. The cyclic process provides the opportunity for ensembles to observe and learn about the effectiveness of the combined algorithms, and improve the ensemble configuration progressively. In this paper we explore the adaptation of a multi-armed bandit approach to achieve this, by representing the combined systems as arms, and the ensemble as a bandit that at each step selects an arm to produce the next round of recommendations. We report experiments showing the effectiveness of this approach compared to ensembles that lack the iterative perspective. Along the way, we find illustrative pitfall examples that can result from common, single-shot offline evaluation setups. i>Presentation: Tuesday Poster Lunch</i</p>
    <p><strong>Categories:</strong> Multi-Armed Bandits, Recommender Systems, Ensemble Methods, Online Learning, Dynamic Adaptation, Feedback Loop, Evaluation Methods, User Interaction, Real-Time Recommendations (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/482/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Content Ordering Based On Commuting Patterns (2014)</h3>
    <p><strong>Authors:</strong> Omar Alonso, Travis Gingerich</p>
    <p>Recommender systems take into account a wide range of information about both an individual user and other user's preferences in order to provide relevant content. However, one source of information that appears to be under-utilized is contextual information about the users' trajectory: where they are currently located, and where they are traveling to. We demonstrate a system that recommends the reading order of Twitter content based on the user's planned travel.</p>
    <p><strong>Categories:</strong> Context-Aware Filtering, Social Media, Content Recommendation, Real-World Application, User Trajectory, Commute Patterns, Geolocation, Travel/Navigation, Dynamic Adaptation, Location-Based Personalization (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/61/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>