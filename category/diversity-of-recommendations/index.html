<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui primary button" style="margin: 5px;"
             href="/recsys-recommender/">Diversity of Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reproducibility/">Reproducibility</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reinforcement-learning/">Reinforcement Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/e-commerce/">E-commerce</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/cold-start/">Cold Start</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>How to Evaluate Serendipity in Recommender Systems: the Need for a Serendiptionnaire (2024)</h3>
    <p><strong>Authors:</strong> Brett Binst</p>
    <p>Recommender systems can assist in various user tasks and serve diverse values, including exploring the item space. Serendipity has recently received considerable attention, often seen as a way to broaden users’ tastes and counteract filter bubbles. However, the field of research on serendipity is fragmented regarding its evaluation methods, which impedes the progress of knowledge accumulation. This research plan proposes two studies to address these issues. First, a systematic literature review will be conducted to provide insights into how serendipity is currently studied in the field. This review will serve as a reference for novice researchers and help mitigate fragmentation by presenting a thorough overview of the field. This systematic literature review has already revealed a significant gap: the lack of a validated, widely accepted method for evaluating serendipity. Therefore, the second part of this research plan is to develop a validated questionnaire, the serendiptionnaire, to measure serendipity. This tool will provide a ground truth for evaluating serendipity, aiding in answering fundamental questions within the field and validating offline metrics.</p>
    <p><strong>Categories:</strong> Recommender Systems, Evaluation Methods, Serendipity, User Experience, Questionnaire Development, Systematic Literature Review, Diversity of Recommendations, Personalization, Evaluation Metrics, Real-World Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1143/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Recommending Healthy and Sustainable Meals exploiting Food Retrieval and Large Language Models (2024)</h3>
    <p><strong>Authors:</strong> Michele Ciro Di Carlo, Giovanni Semeraro, Giovanni Tempesta, Cataldo Musto, Alessandro Petruzzelli</p>
    <p>Many people are constantly seeking to make healthy food choices, but increasingly, we are also considering the impact our dietary habits have on the environment. This creates a complex challenge: how can we ensure that we are eating nutritious foods that nourish our bodies while also minimizing the environmental footprint of our meals?To address this issue, this paper proposes a novel framework called Healthy And Sustainable eating (HeASe). Given the rising global concerns about nutrition and environmental sustainability, individuals need effective tools to help them navigate these issues. HeASe leverages the latest advancements in artificial intelligence to empower users with knowledge and self-awareness.The framework works in two steps. First, it uses a food retrieval strategy that takes into account macro-nutrient information to identify alternative meals for a chosen recipe. This ensures that the substitutions maintain a similar nutritional profile. Next, HeASe employs large language models to re-rank these potential replacements while considering factors beyond just nutrition, such as the recipe’s environmental impact and other user-defined preferences. The experimental phase of this research demonstrates the capabilities of LLM in identifying the more sustainable and healthy recipe within a set of candidate options. This highlights the potential of these models to guide users towards food choices that are both nutritious and environmentally responsible.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Healthy Eating, Sustainability, Food Retrieval, Large Language Models, Beyond Accuracy, Diversity of Recommendations, Real-world Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1115/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Towards Sustainable Recommendations in Urban Tourism (2024)</h3>
    <p><strong>Authors:</strong> Pavel Merinov</p>
    <p>In the context of urban tourism promotion, I am exploring how recommender systems (RSs) can personalise information in order to shift tourists behaviour from typically popularity-biased towards more niche and urban-friendly. This problem has a great importance in sustainability online promotion campaigns. Urban destination managers strive to prevent overcrowding at popular points of interest (POIs), by attracting visitors to less popular POIs, while still providing personalised access to information. It is assumed, that this approach will maintain a healthy distribution of tourists in a city; both reducing tourist congestion, and, considering each POI as a local business, maintaining the long-term economic viability in a city. This problem has already received some attention in the literature, targeting major European touristic cities. However, many complex issues still need to be resolved for a comprehensive solution. In this extended abstract, I highlight open research problems, and identify key research questions (RQs) that are crucial for advancing sustainable tourism development leveraging RSs. Although the proposed methods are focused on urban tourism, their application extends to different areas of recommendations because the RQs and the proposed methods and techniques are general.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Sustainability, Urban Tourism, Congestion Management, Personalization, Economic Impact, Balancing Act, Generalizability, Real-World Applications, Research Questions, Diversity of Recommendations (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1147/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Multi-Objective Recommendation via Multivariate Policy Learning (2024)</h3>
    <p><strong>Authors:</strong> Ivan Potapov, Sourabh Vaid, Wenzhe Shi, Nakul Agarwal, Olivier Jeunen, Jatin Mandav, Aleksei Ustimenko</p>
    <p>Real-world recommender systems often need to balance multiple objectives when deciding which recommendations to present to users. These include behavioural signals (e.g. clicks, shares, dwell time), as well as broader objectives (e.g. diversity, fairness). Scalarisation methods are commonly used to handle this balancing task, where a weighted average of per-objective reward signals determines the final score used for ranking. Naturally, <i>how</i> these weights are computed exactly, is key to success for any online platform. We frame this as a decision-making task, where the scalarisation weights are <i>actions</i> taken to maximise an overall North Star reward (e.g. long-term user retention or growth). We extend existing policy learning methods to the continuous multivariate action domain, proposing to maximise a pessimistic lower bound on the North Star reward that the learnt policy will yield. Typical lower bounds based on normal approximations suffer from insufficient coverage, and we propose an efficient and effective policy-dependent correction for this. We provide guidance to design stochastic data collection policies, as well as highly sensitive reward signals. Empirical observations from simulations, offline and online experiments highlight the efficacy of our deployed approach.</p>
    <p><strong>Categories:</strong> Multi-Objective Optimization, Fairness in Recommendations, Diversity of Recommendations, Policy Learning, Reinforcement Learning in Recommender Systems, Implicit Feedback, Real-World Applications, A/B Testing, Scalarization Methods, Evaluation Methods, Scalability (<i>deepseek-r1:70b</i>)</p>
    <p><a href="/recsys-recommender/response/1051/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Bridging Viewpoints in News with Recommender Systems (2024)</h3>
    <p><strong>Authors:</strong> Jia Hua Jeng</p>
    <p>News Recommender systems (NRSs) aid in decision-making in news media. However, undesired effects can emerge. Among these are selective exposures that may contribute to polarization, potentially reinforcing existing attitudes through belief perseverance—discounting contrary evidence due to their opposing attitudinal strength. This can be unsafe for people, making it difficult to accept information objectively. A crucial issue in news recommender system research is how to mitigate these undesired effects by designing recommender interfaces and machine learning models that enable people to consider to be more open to different perspectives. Alongside accurate models, the user experience is an equally important measure. Indeed, the core statistics are based on users’ behaviors and experiences in this research project. Therefore, this research agenda aims to steer the choices of readers’ based on altering their attitudes. The core methods plan to concentrate on the interface design and ML model building involving manipulations of cues, users’ behaviors prediction, NRSs algorithm and changing the nudges. In sum, the project aims to provide insight in the extent to which news recommender systems can be effective in mitigating polarized opinions.</p>
    <p><strong>Categories:</strong> Machine Learning, News Recommender Systems, Bias Mitigation, Personalization, User Experience, Interface Design, Behavior Prediction, Nudge Theory, Selective Exposure, Diversity of Recommendations, Perspective Bridging, Accuracy in Recommendations, Attitude Alteration, Media, Public Opinion, Social Impact (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1135/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>beeFormer: Bridging the Gap Between Semantic and Interaction Similarity in Recommender Systems (2024)</h3>
    <p><strong>Authors:</strong> Vojtěch Vančura, Milan Straka, Pavel Kordík</p>
    <p>Recommender systems often use text-side information to improve their predictions, especially in cold-start or zero-shot recommendation scenarios, where traditional collaborative filtering approaches cannot be used. Many approaches to text-mining side information for recommender systems have been proposed over recent years, with sentence Transformers being the most prominent one. However, these models are trained to predict semantic similarity without utilizing interaction data with hidden patterns specific to recommender systems. In this paper, we propose beeFormer, a framework for training sentence Transformer models with interaction data. We demonstrate that our models trained with beeFormer can transfer knowledge between datasets while outperforming not only semantic similarity sentence Transformers but also traditional collaborative filtering methods. We also show that training on multiple datasets from different domains accumulates knowledge in a single model, unlocking the possibility of training universal, domain-agnostic sentence Transformer models to mine text representations for recommender systems. We release the source code, trained models, and additional details allowing replication of our experiments at https://github.com/recombee/beeformer.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Text Mining/Side Information, Sentence Transformers, Interaction Data, Cold Start, Transfer Learning, Universal Models, Diversity of Recommendations, Beyond Accuracy (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1188/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Leveraging Monte Carlo Tree Search for Group Recommendation (2024)</h3>
    <p><strong>Authors:</strong> J. Andres Diaz-Pace, Antonela Tommasel</p>
    <p>Group recommenders aim to provide recommendations that satisfy the collective preferences of multiple users, a challenging task due to the diverse individual tastes and conflicting interests to be balanced. This is often accomplished by using aggregation techniques that select items on which the group can agree. Traditional aggregators struggle with these complexities, as items are chosen independently, leading to sub-optimal recommendations lacking diversity, novelty, or fairness. In this paper, we propose an aggregation technique that leverages Monte Carlo Tree Search (MCTS) to enhance group recommendations. MCTS is used to explore and evaluate candidate recommendation sequences to optimize overall group satisfaction. We also investigate the integration of MCTS with LLMs aiming at better understanding interactions between user preferences and recommendation sequences to inform the search. Experimental evaluations, although preliminary, showed that our proposal outperforms existing aggregation techniques in terms of relevance and beyond-accuracy aspects of recommendations. The LLM integration achieved positive results for recommendations’ relevance. Overall, this work highlights the potential of heuristic search techniques to tackle the complexities of group recommendations.</p>
    <p><strong>Categories:</strong> Group Recommenders, Monte Carlo Tree Search, Heuristic Search, General Recommendation, User Satisfaction, Group Recommendations, Beyond Accuracy, Diversity of Recommendations, LLM Integration, Evaluation Metrics, Relevance, Novel Approaches (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1200/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>CAPRI-FAIR: Integration of Multi-sided Fairness in Contextual POI Recommendation Framework (2024)</h3>
    <p><strong>Authors:</strong> Yonchanok Khaokaew, Jeffrey Chan, Flora D. Salim, Francis Dela Cruz</p>
    <p>Point-of-interest (POI) recommendation, a form of context-aware recommendation, takes into account spatio-temporal constraints and contexts like distance, peak business hours, and previous user check-ins. Given the ability of these kinds of systems to influence not just the consumer’s travel experience, but also the POI’s business, it is important to consider fairness from multiple perspectives. Unfortunately, these systems tend to provide less accurate recommendations to inactive users, and less exposure to unpopular POIs. The goal of this paper is to develop a post-filter methodology that incorporates provider and consumer fairness factors into pre-existing recommendation models, to satisfy fairness metrics like item exposure, and performance metrics like precision and distance, making the system more sustainable to both consumers and providers. Experiments have shown that using a linear scoring model for provider fairness in re-scoring recommended items yields the best tradeoff between performance and long-tail exposure, in some cases without a significant decrease in precision. When attempting to address consumer fairness by recommending more popular POIs to inactive users, the result was an increase in precision for only some recommendation models and datasets. Finally, when considering the tradeoff between both parameters, the combinations that reached the Pareto front of consumer and provider fairness, unfortunately, achieved the lowest precision values. We find that the nature of this tradeoff depends heavily on the model and the dataset.</p>
    <p><strong>Categories:</strong> Fairness in Recommendations, Context-Aware Recommendations, Point of Interest (POI) Recommendations, Post-Filter Methodology, Provider Fairness, Consumer Fairness, Spatio-Temporal Recommendations, Long-Tail Recommendations, Diversity of Recommendations, Beyond Accuracy (<i>deepseek-r1:70b</i>)</p>
    <p><a href="/recsys-recommender/response/1078/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>ReLand: Integrating Large Language Models’ Insights into Industrial Recommenders via a Controllable Reasoning Pool (2024)</h3>
    <p><strong>Authors:</strong> Haoyu Chen, Changxin Tian, Jiawei Chen, Jun Zhou, Ziqi Liu, Li Yu, Chunjing Gan, Zhuo Zhang, Binbin Hu, Zhiqiang Zhang</p>
    <p>Recently, Large Language Models (LLMs) have shown significant potential in addressing the isolation issues faced by recommender systems. However, despite performance comparable to traditional recommenders, the current methods are cost-prohibitive for industrial applications. Consequently, existing LLM-based methods still need to catch up regarding effectiveness and efficiency. To tackle the above challenges, we present an LLM-enhanced recommendation framework named ReLand, which leverages Retrieval to effortlessly integrate Large language models’ insights into industrial recommenders. Specifically, ReLand employs LLMs to perform generative recommendations on sampled users (a.k.a., seed users), thereby constructing an LLM Reasoning Pool. Subsequently, we leverage retrieval to attach reliable recommendation rationales for the entire user base, ultimately effectively improving recommendation performance. Extensive offline and online experiments validate the effectiveness of ReLand. Since January 2024, ReLand has been deployed in the recommender system of Alipay, achieving statistically significant improvements of 3.19% in CTR and 1.08% in CVR.</p>
    <p><strong>Categories:</strong> Large Language Models, Recommender Systems, Industrial Applications, Retrieval-Based Methods, Generative Recommendations, Controllable Reasoning Pool, Cold Start, Interpretability of Recommendations, Diversity of Recommendations, Evaluation Metrics (CTR, CVR), Real-World Applications, A/B Testing (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1054/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Broadening the Scope: Evaluating the Potential of Recommender Systems beyond prioritizing Accuracy (2023)</h3>
    <p><strong>Authors:</strong> Vito Walter Anelli, Dario Di Palma, Vincenzo Paparella, Tommaso Di Noia</p>
    <p>Although beyond-accuracy metrics have gained attention in the last decade, the accuracy of recommendations is still considered the gold standard to evaluate Recommender Systems (RSs). This approach prioritizes the accuracy of recommendations, neglecting the quality of suggestions to enhance user needs, such as diversity and novelty, as well as trustworthiness regulations in RSs for user and provider fairness. As a result, single metrics determine the success of RSs, but this approach fails to consider other criteria simultaneously. A downside of this method is that the most accurate model configuration may not excel in addressing the remaining criteria. This study seeks to broaden RS evaluation by introducing a multi-objective evaluation that considers all model configurations simultaneously under several perspectives. To achieve this, several hyper-parameter configurations of an RS model are trained, and the Pareto-optimal ones are retrieved. The Quality Indicators (QI) of Pareto frontiers, which are gaining interest in Multi-Objective Optimization research, are adapted to RSs. QI enables evaluating the model’s performance by considering various configurations and giving the same importance to each metric. The experiments show that this multi-objective evaluation overturns the ranking of performance among RSs, paving the way to revisit the evaluation approaches of the RecSys research community. We release codes and datasets in the following GitHub repository: https://anonymous.4open.science/r/RecMOE-3ED3.</p>
    <p><strong>Categories:</strong> Beyond Accuracy, Multi-Objective Optimization, Evaluation Methods, Diversity of Recommendations, Fairness (User), Fairness (Provider), Trustworthiness, Quality Indicators, Pareto Frontiers, Recommender Systems, Broadening Scope, Real-World Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/952/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Deliberative Diversity for News Recommendations: Operationalization and Experimental User Study (2023)</h3>
    <p><strong>Authors:</strong> Rana Abdullah, Juliane A. Lischka, Laura Laugwitz, Lucien Heitz, Hendrik Meyer, Abraham Bernstein</p>
    <p>News recommender systems are an increasingly popular field of study that attracts a growing, interdisciplinary research community. As these systems play an important role in our daily lives, the mechanisms behind their curation processes are under close scrutiny. In the domain of personalized news, many platforms make design choices that are driven by economic incentives. In contrast to such systems that optimize for financial gains, there exists norm-driven diversity objectives, putting normative and democratic goals first. Their impact on users, however, in terms of triggering behavioral changes or affecting knowledgeability, is still under-researched. In this paper, we contribute to the field of news recommender system design by conducting a user study that looks at the impact of these normative approaches. We a.) operationalize the notion of deliberative democracy for news recommendations, show b.) the impact on political knowledgeability and c.) the influence on voting behavior. We found that exposure to small parties is associated with an increase in knowledge about their candidates and that intensive news consumption about a party can change the direction of attitudes towards their issues.</p>
    <p><strong>Categories:</strong> Recommendation Systems, News, Diversity of Recommendations, Ethics in AI, Deliberative Democracy, Experimental User Study, Political Knowledgeability, Voting Behavior, Norm-Driven Design, Beyond Accuracy, User Behavior, Exposure to Underrepresented Groups (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/916/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>gSASRec: Reducing Overconfidence in Sequential Recommendation Trained with Negative Sampling (2023)</h3>
    <p><strong>Authors:</strong> Craig Macdonald, Aleksandr V. Petrov</p>
    <p>Large catalogue size is one of the central challenges in training recommendation models: a large number of items makes it infeasible to compute scores for all items during training, forcing models to deploy negative sampling. However, negative sampling increases the proportion of positive interactions in the training data. Therefore models trained with negative sampling tend to overestimate the probabilities of positive interactions — a phenomenon we call overconfidence. While the absolute values of the predicted scores/probabilities are unimportant for ranking retrieved recommendations, overconfident models may fail to estimate nuanced differences in the top-ranked items, resulting in degraded performance. This paper shows that overconfidence explains why the popular SASRec model underperforms when compared to BERT4Rec (contrary to the BERT4Rec authors’ attribution to the bi-directional attention mechanism). We propose a novel Generalised Binary Cross-Entropy Loss function (gBCE) to mitigate overconfidence and theoretically prove that it can mitigate overconfidence. We further propose the gSASRec model, an improvement over SASRec that deploys an increased number of negatives and gBCE loss. We show through detailed experiments on three datasets that gSASRec does not exhibit the overconfidence problem. As a result, gSASRec can outperform BERT4Rec (e.g.\ +9.47\% NDCG on MovieLens-1M), while requiring less training time (e.g.\ -73\% training time on MovieLens-1M). Moreover, in contrast to BERT4Rec, gSASRec is suitable for large datasets that contain more than 1 million items.</p>
    <p><strong>Categories:</strong> Sequential Recommendation, Negative Sampling, Cross-Entropy Loss, Overconfidence, Recommendation Systems, Movies, Diversity of Recommendations, Beyond Accuracy, Scalability, Training Efficiency (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/864/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Incorporating Time in Sequential Recommendation Models (2023)</h3>
    <p><strong>Authors:</strong> James Caverlee, Mostafa Rahmani, Fei Wang</p>
    <p>Sequential models are designed to learn sequential patterns in data based on the chronological order of user interactions. However, they often ignore the timestamps of these interactions. Incorporating time is crucial because many sequential patterns are time-dependent, and the model cannot make time-aware recommendations without considering time. This article demonstrates that providing a rich representation of time can significantly improve the performance of sequential models. The existing literature treats time as a one-dimensional time-series obtained by quantizing time. In this study, we propose treating time as a multi-dimensional time-series and explore representation learning methods, including  a kernel based method and an embedding-based algorithm. Experiments on multiple datasets show that the inclusion of time significantly enhances the model’s performance, and multi-dimensional methods outperform the one-dimensional method by a substantial margin.</p>
    <p><strong>Categories:</strong> Sequential Models, Time Series, Kernel-based Methods, Embedding-based Algorithms, Sequential Recommendations, Temporal Dynamics, Recommendation Systems, Model Enhancement, Representation Learning, Performance Analysis, Methodological Innovations, Applied Research, User Interaction Patterns, Multi-dimensional Time Series, Data Analysis Techniques, Experimental Evaluation, Scalability, Cold Start, Diversity of Recommendations, Beyond Accuracy (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/907/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Collaborative filtering algorithms are prone to mainstream-taste bias (2023)</h3>
    <p><strong>Authors:</strong> Philipp Hager, Pantelis Analytis</p>
    <p>Collaborative filtering has been the main steam engine of the recommender systems community since the early 1990s. Collaborative filtering (and other) algorithms, however, have been predominantly evaluated by aggregating results across users or user groups. These performance averages hide large disparities: an algorithm may perform very well for some users (or groups) and very poorly for others. We show that performance variation is large and systematic. In experiments on three large scale datasets and using an array of collaborative filtering algorithms, we demonstrate the large performance disparities for different users across algorithms and datasets. We then show that performance variation is systematic and that two key features that characterize users, their mean taste similarity with other users and the dispersion in taste similarity, can explain performance variation better than previously identified features. We use these two features to visualize algorithm performance for different users, and point out that this mapping can be used to capture different categories of users that have been proposed before. Our results demonstrate an extensive mainstream-taste bias in all collaborative filtering algorithms, and they imply a fundamental fairness limitation that needs to be mitigated.</p>
    <p><strong>Categories:</strong> Collaborative Filtering, Fairness, Mainstream Bias, Algorithm Limitations, User Performance Variation, Taste Similarity, Evaluation Methods, Recommender Systems, Large Scale Datasets, Diversity of Recommendations, Visualization Techniques, User Centric Design (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/906/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>How Should We Measure Filter Bubbles? A Regression Model and Evidence for Online News (2023)</h3>
    <p><strong>Authors:</strong> Robin Verachtert, Jens Leysen, Annelien Smets, Jorre Vannieuwenhuyze, Lien Michiels, Bart Goethals</p>
    <p>News media play an important role in democratic societies.  Central to fulfilling this role is the premise that users should be exposed to diverse news.  However, news recommender systems are gaining popularity on news websites, which has sparked concerns over filter bubbles. Editors, policy-makers and scholars are worried that news recommender systems may expose users to less diverse content over time.  To the best of our knowledge, this hypothesis has not been tested in a longitudinal observational study of real users that interact with a real news website. Such observational studies require the use of research methods that are robust and can account for the many covariates that may influence the diversity of recommendations at any given time. In this work, we propose an analysis model to study whether the variety of articles recommended to a user decreases over time, in observational studies of real news websites with real users. Further, we present results from two case studies using aggregated and anonymized data that were collected by two western European news websites employing a collaborative filtering-based news recommender system to serve (personalized) recommendations to their users. Through these case studies we validate empirically that our modeling assumptions are sound and supported by the data, and that our model obtains more reliable and interpretable results than analysis methods used in prior empirical work on filter bubbles. Our case studies provide evidence of a small decrease in the topic variety of a user’s recommendations in the first weeks after they sign up, but no evidence of a decrease in political variety.</p>
    <p><strong>Categories:</strong> Collaborative Filtering, Filter Bubbles, News Recommender Systems, Online News, Diversity of Recommendations, Longitudinal Study, Regression Model, Real-World Applications, Empirical Evidence, Societal Implications, Case Study, Media, Beyond Accuracy, Research Methods, Model Interpretation, User Interaction Over Time (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/865/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Transparently Serving the Public: Enhancing Public Service Media Values through Exploration (2023)</h3>
    <p><strong>Authors:</strong> Andreas Grün, Xenija Neufeld</p>
    <p>In the last few years, we have reportedly underlined the importance of the Public Service Media Remit for ZDF as a Public Service Media provider. Offering fair, diverse, and useful recommendations to users is just as important for us as being transparent about our understanding of these values, the metrics that we are using to evaluate their extent, and the algorithms in our system that produce such recommendations. This year, we have made a major step towards transparency of our algorithms and metrics describing them for a broader audience, offering the possibility for the audience to learn details about our systems and to provide direct feedback to us. Having the possibility to measure and track PSM metrics, we have started to improve our algorithms towards PSM values. In this work, we describe these steps and the results of actively debasing and adding exploration into our recommendations to achieve more fairness.</p>
    <p><strong>Categories:</strong> Public Service Media (PSM), Recommendation Systems, Transparency in Algorithms, Fairness in Recommendations, Diversity of Recommendations, Algorithm Evaluation, User Feedback, Exploration Strategies (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1015/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>