<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/explainability/">Explainability</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reproducibility/">Reproducibility</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/real-world-applications/">Real-world Applications</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reinforcement-learning/">Reinforcement Learning</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Towards Open-World Recommendation with Knowledge Augmentation from Large Language Models (2024)</h3>
    <p><strong>Authors:</strong> Weiwen Liu, Bo Chen, Yong Yu, Hong Zhu, Yunjia Xi, Weinan Zhang, Jianghao Lin, Xiaoling Cai, Jieming Zhu, Ruiming Tang</p>
    <p>Recommender system plays a vital role in various online services. However, its insulated nature of training and deploying separately within a specific closed domain limits its access to open-world knowledge. Recently, the emergence of large language models (LLMs) has shown promise in bridging this gap by encoding extensive world knowledge and demonstrating reasoning capabilities. Nevertheless, previous attempts to directly use LLMs as recommenders cannot meet the inference latency demand of industrial recommender systems. In this work, we propose an Open-World Knowledge Augmented Recommendation Framework with Large Language Models, dubbed KAR, to acquire two types of external knowledge from LLMs — the reasoning knowledge on user preferences and the factual knowledge on items. We introduce factorization prompting to elicit accurate reasoning on user preferences. The generated reasoning and factual knowledge are effectively transformed and condensed into augmented vectors by a hybrid-expert adaptor in order to be compatible with the recommendation task. The obtained vectors can then be directly used to enhance the performance of any recommendation model. We also ensure efficient inference by preprocessing and prestoring the knowledge from the LLM. Extensive experiments show that KAR significantly outperforms the state-of-the-art baselines and is compatible with a wide range of recommendation algorithms. We deploy KAR to Huawei’s news and music recommendation platforms and gain a 7% and 1.7% improvement in the online A/B test, respectively.</p>
    <p><strong>Categories:</strong> Large Language Models (LLMs), Knowledge Augmentation, Recommender Systems, Open-World Recommendation, Knowledge Graphs, User Preference Modeling, Factorization Prompting, Feature Extraction, Representation Learning, Hybrid Models, Efficiency Optimization, Scalability, State-of-the-Art Methods, Real-World Applications, A/B Testing, News, Music, Beyond Accuracy, Compatibility (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1071/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>LLMs for User Interest Exploration: A Hybrid Approach (2024)</h3>
    <p><strong>Authors:</strong> He Ma, Haokai Lu, Yueqi Wang, Yifan Liu, Ed H. Chi, Lexi Baugher, Ningren Han, Shuzhou Zhang, Yang Gu, Jianling Wang, Minmin Chen, Shuchao Bi</p>
    <p>Traditional recommendation systems are subject to a strong feedback loop by learning from and reinforcing past user-item interactions, which in turn limits the discovery of novel user interests. To address this, we introduce a hybrid hierarchical framework combining Large Language Models (LLMs) and classic recommendation models for user interest exploration. The framework controls the interfacing between the LLMs and the classic recommendation models through “interest clusters”, the granularity of which can be explicitly determined by algorithm designers. It recommends the next novel interests by first representing “interest clusters” using language, and employs a fine-tuned LLM to generate novel interest descriptions that are strictly within these predefined clusters. At the low level, it grounds these generated interests to an item-level policy by restricting classic recommendation models, in this case a transformer-based sequence recommender to return items that fall within the novel clusters generated at the high level. We showcase the efficacy of this approach on an industrial-scale commercial platform serving billions of users. Live experiments show a significant increase in both exploration of novel interests and overall user enjoyment of the platform.</p>
    <p><strong>Categories:</strong> Hybrid Models, Large Language Models (LLMs), Recommendation Systems, User Interest Exploration, Transformer-Based Recommenders, Content Generation, Interest Clustering, Real-World Applications, Live Experiments, User Behavior, Hierarchical Structures, Industrial Application, Scalability, Exploration vs Exploitation (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1092/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Retrieval-augmented Recommender System: Enhancing Recommender Systems with Large Language Models (2023)</h3>
    <p><strong>Authors:</strong> Dario Di Palma</p>
    <p>Recommender Systems (RSs) play a pivotal role in delivering personalized recommendations across various domains, from e-commerce to content streaming platforms. Recent advancements in natural language processing have introduced Large Language Models (LLMs) that exhibit remarkable capabilities in understanding and generating human-like text. RS are renowned for their effectiveness and proficiency within clearly defined domains; nevertheless, they are limited in adaptability and incapable of providing recommendations for unexplored data. Conversely, LLMs exhibit contextual awareness and strong adaptability to unseen data. Combining these technologies creates a potent tool for delivering contextual and relevant recommendations, even in cold scenarios characterized by high data sparsity. The proposal aims to explore the possibilities of integrating LLMs into RS, introducing a novel approach called Retrieval-augmented Recommender Systems, which combines the strengths of retrieval-based and generation-based models to enhance the ability of RSs to provide relevant suggestions.</p>
    <p><strong>Categories:</strong> Recommender Systems, Large Language Models, Retrieval-Based Models, Generation-Based Models, Cold Start, Contextual Awareness, System Design, Adaptability, Hybrid Models, Innovative Approaches, Exploiting Language Models (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/984/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Hessian-aware Quantized Node Embeddings for Recommendation (2023)</h3>
    <p><strong>Authors:</strong> Hao Yang, Xia Hu, Kaixiong Zhou, Yan Zheng, Chin-Chia Michael Yeh, Huiyuan Chen, Kwei-Herng Lai</p>
    <p>Graph Neural Networks (GNNs) have achieved  state-of-the-art  performance in recommender systems. Nevertheless, the process of  searching and ranking  from a large item corpus    usually requires high latency, which limits the widespread deployment of GNNs in industry-scale applications. To address this issue, many  methods quantize user/item representations into the binary embedding space  to reduce space requirements and accelerate inference.  Also, they use the Straight-through Estimator (STE) to prevent zero gradients during back-propagation.  However, the STE often causes  gradient mismatch problem, leading to sub-optimal results. In this work, we present the Hessian-aware Quantized GNN (HQ-GNN) as an effective solution for discrete representations of users/items that enable fast retrieval. HQ-GNN is composed of two components: a GNN encoder for learning continuous node embeddings and a quantized module for compressing full-precision embeddings into low-bit ones. Consequently, HQ-GNN benefits from both lower memory requirements and faster inference speeds compared to vanilla GNNs.  To address the gradient mismatch problem in STE,  we  further consider the quantized errors and its second-order derivatives for better stability. The experimental results on several large-scale datasets show that HQ-GNN achieves a good balance between latency and performance.</p>
    <p><strong>Categories:</strong> Recommender Systems, Graph Neural Networks (GNN), Quantization, Low-bit Embeddings, Hessian-aware Optimization, Industry Applications, Gradient Mismatch, Latency Reduction, Recommendation Efficiency, Hybrid Models, Large-scale Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/901/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Combining Rating and Review Data by Initializing Latent Factor Models with Topic Models for Top-N Recommendation (2020)</h3>
    <p><strong>Authors:</strong> Barry Smyth, Aonghus Lawlor, Francisco J. Peña, Diarmuid O’Reilly-Morgan, Elias Z. Tragos, Erika Duriakova, Neil Hurley</p>
    <p>Nowadays we commonly have multiple sources of data associated with items. Users may provide numerical ratings, or implicit interactions, but may also provide textual reviews. Although many algorithms have been proposed to jointly learn a model over both interactions and textual data, there is room to improve the many factorization models that are proven to work well on interactions data, but are not designed to exploit textual information. Our focus in this work is to propose a simple, yet easily applicable and effective, method to incorporate review data into such factorization models. In particular, we propose to build the user and item embeddings within the topic space of a topic model learned from the review data. This has several advantages: we observe that initializing the user and item embeddings in topic space leads to faster convergence of the factorization algorithm to a model that out-performs models initialized randomly, or with other state-of-the-art initialization strategies. Moreover, constraining user and item factors to topic space allows for the learning of an interpretable model that users can visualise.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Explicit Feedback, Implicit Feedback, Latent Factor Models, Topic Models, User/Item Embeddings, Textual Data, Initialization Strategies, Model Convergence, Model Interpretability, Hybrid Models, Top-N Recommendations (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/575/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>RecSeats: A Hybrid Convolutional Neural Network Choice Model for Seat Recommendations at Reserved Seating Venues (2020)</h3>
    <p><strong>Authors:</strong> Théo Moins, Simon J. Blanchard, Daniel Aloise</p>
    <p>Predicting locational choices (i.e., where one chooses to sit) is a challenging task because preferences are highly heterogeneous and depend not only on the location of the seats in the environment but also on the location of others. In the present research, we propose RecSeats - a framework to predict locational choices. The framework augments individual-level discrete choice models with a convolutional neural network (CNN) which can capture higher order interactions between features of available seats. The framework is flexible and can accommodate complexity in real-world locational choice data such as variability in the number of tickets purchased and the number and locations from past purchases. Applied to both locational choice experiment data and to ticketing data from a large North-American concert hall, we show that augmenting individual-level discrete choice models with a CNN consistently provides strong predictive accuracy.</p>
    <p><strong>Categories:</strong> Hybrid Models, Convolutional Neural Networks (CNN), Recommendation Systems, Seat Recommendations, Locational Choice, Venue Management, Discrete Choice Models, Predictive Accuracy, Real-World Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/551/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>FISSA: Fusing Item Similarity Models with Self-Attention Networks for Sequential Recommendation (2020)</h3>
    <p><strong>Authors:</strong> Jing Lin, Zhong Ming, Weike Pan</p>
    <p>Sequential recommendation has been a hot research topic because of its practicability and high accuracy by capturing the sequential information. As deep learning (DL) based methods being widely adopted to model the local and dynamic preferences beneath users’ behavior sequences, the modeling of users’ global and static preferences tends to be underestimated that usually, only some simple and crude users’ latent representations are introduced. Moreover, most existing methods hold an assumption that users’ intention can be fully captured by considering the historical behaviors, while neglect the possible uncertainty of users’ intention in reality, which may be influenced by the appearance of the candidate items to be recommended. In this paper, we thus focus on these two issues, i.e., the imperfect modeling of users’ global preferences in most DL-based sequential recommendation methods and the uncertainty of users’ intention brought by the candidate items, and propose a novel solution named fusing item similarity models with self-attention networks (FISSA) for sequential recommendation. Specifically, we treat the state-of-the-art self-attentive sequential recommendation (SASRec) model as the local representation learning module to capture the dynamic preferences beneath users’ behavior sequences in our FISSA, and further propose a global representation learning module to improve the modeling of users’ global preferences and a gating module that balances the local and global representations by taking the information of the candidate items into account. The global representation learning module can be seen as a location-based attention layer, which is effective to fit in well with the parallelization training process of the self-attention framework. The gating module calculates the weight by modeling the relationship among the candidate item, the recently interacted item and the global preference of each user using an MLP layer. Extensive empirical studies on five commonly used datasets show that our FISSA significantly outperforms eight state-of-the-art baselines in terms of two commonly used metrics.</p>
    <p><strong>Categories:</strong> Sequential Recommendation, Deep Learning, Self-Attention Networks, User Preference Modeling, Hybrid Models, Uncertainty in User Intent, Global Representation Learning, Local Representation Learning, Item Similarity Models, Gating Module, Recommender Systems Evaluation (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/537/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>MEANTIME: Mixture of Attention Mechanisms with Multi-temporal Embeddings for Sequential Recommendation (2020)</h3>
    <p><strong>Authors:</strong> Sung Min Cho, Eunhyeok Park, Sungjoo Yoo</p>
    <p>Recently, self-attention based models have achieved state-of-the-art performance in sequential recommendation task. Following the custom from language processing, most of these models rely on a simple positional embedding to exploit the sequential nature of the user’s history. However, there are some limitations regarding the current approaches. First, sequential recommendation is different from language processing in that timestamp information is available. Previous models have not made good use of it to extract additional contextual information. Second, using a simple embedding scheme can lead to information bottleneck since the same embedding has to represent all possible contextual biases. Third, since previous models use the same positional embedding in each attention head, they can wastefully learn overlapping patterns. To address these limitations, we propose MEANTIME (MixturE of AtteNTIon mechanisms with Multi-temporal Embeddings) which employs multiple types of temporal embeddings designed to capture various patterns from the user’s behavior sequence, and an attention structure that fully leverages such diversity. Experiments on real-world data show that our proposed method outperforms current state-of-the-art sequential recommendation methods, and we provide an extensive ablation study to analyze how the model gains from the diverse positional information.</p>
    <p><strong>Categories:</strong> Sequential Recommendation, Attention Mechanisms, Temporal Embeddings, User Behavior Analysis, Model Architecture, Cold Start Problem, Evaluation Metrics, Real-World Applications, Diversity of Recommendations, Novel Methods, Hybrid Models (<i>deepseek-r1:70b</i>)</p>
    <p><a href="/recsys-recommender/response/582/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>On the Heterogeneous Information Needs in the Job Domain: A Unified Platform for Student Career (2020)</h3>
    <p><strong>Authors:</strong> Markus Reiter-Haas</p>
    <p>Finding the right job is a difficult task for anyone as it usually depends on many factors like salary, job description, or geographical location. Students with almost no prior experience, especially, have a hard time on the job market, which is very competitive in nature. Additionally, students often suffer a lack of orientation, as they do not know what kind of job is suitable for their education. At Talto1, we realized this and have built a platform to help Austrian university students with finding their career paths as well as providing them with content that is relevant to their career possibilities. This is mainly achieved by guiding the students toward different types of entities that are related to their career, i.e., job postings, company profiles, and career-related articles.<br>In this talk, we share our experiences with solving the recommendation problem for university students. One trait of the student-focused job domain is that behaviour of the students differs depending on their study progression. At the beginning of their studies, they need study-specific career information and part-time jobs to earn additional money. Whereas, when they are nearing graduation, they require information about their potential future employers and entry-level full-time jobs. Moreover, we can observe seasonal patterns in user activity in addition to the need of handling both logged-in and anonymous session users at the same time.<br>To cope with the requirements of the job domain, we built hybrid models based on a microservice architecture that utilizes popular algorithms from the literature such as Collaborative Filtering, Content-based Filtering as well as various neural embedding approaches (e.g., Doc2Vec, Autoencoders, etc.). We further adapted our architecture to calculate relevant recommendations in real-time (i.e., after a recommendation is requested) as individual user sessions in Talto are usually short-lived and context-dependent. Here we found that the online performance of the utilized approach also depends on the location context [1]. Hence, the current location of a user on the mobile or web application impacts the expected recommendations.<br>One optimization criterion on the Talto career platform is to provide relevant cross-entity recommendations as well as explain why those were shown. Recently, we started to tackle this by learning embeddings of entities that lie in the same embedding space [2]. Specifically, we pre-train word embeddings and link different entities by shared concepts, which we use for training the network embeddings. This embeds both the concepts and the entities into a common vector space, where the common vector space is a result of considering the textual content, as well as the network information (i.e., links to concepts). This way, different entity types (e.g., job postings, company profiles, and articles) are directly comparable and are suited for a real-time recommendation setting. Interestingly enough, with such an approach we also end up with individual words sharing the same embedding space. This, in turn, can be leveraged to enhance the textual search functionality of a platform, which is most commonly based just on a TF-IDF model.<br>Furthermore, we found that such embeddings allow us to tackle the problem of explainability in an algorithm-agnostic way. Since the Talto platform utilizes various recommendation algorithms as well as continuously conducts AB tests, an algorithm-agnostic explainability model would be best suited to provide the students with meaningful explanations. As such, we will also go into the details on how we can adapt our explanation model to not rely on the utilized recommendation algorithm.</p>
    <p><strong>Categories:</strong> Collaborative Filtering, Content-Based Filtering, Doc2Vec, Autoencoders, Hybrid Models, Job Domain, Students, Platform Design, Cross-Entity Recommendations, Explainability, Real-Time Recommendations, User Session Handling, Seasonal Patterns, Location Context, A/B Tests, System Architecture, Textual Search (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/629/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>CB2CF: A Neural Multiview Content-to-Collaborative Filtering Model for Completely Cold Item Recommendations (2019)</h3>
    <p><strong>Authors:</strong> Ori Katz, Noam Koenigstein, Eylon Yogev, Oren Barkan</p>
    <p>In Recommender Systems research, algorithms are often characterized as either Collaborative Filtering (CF) or Content Based (CB). CF algorithms are trained using a dataset of user preferences while CB algorithms are typically based on item profiles. These approaches harness different data sources and therefore the resulting recommended items are generally very different. This paper presents the CB2CF, a deep neural multiview model that serves as a bridge from items content into their CF representations. CB2CF is a ‘real-world’ algorithm designed for Microsoft Store services that handle around a billion users worldwide. CB2CF is demonstrated on movies and apps recommendations, where it is shown to outperform an alternative CB model on completely cold items.</p>
    <p><strong>Categories:</strong> Content-Based Filtering, Collaborative Filtering, Cold Start, Neural Networks, Multiview Approaches, Recommender Systems, Real-World Applications, Scalability, Movies Recommendations, Apps Recommendations, Hybrid Models (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/439/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>From Preference into Decision Making: Modeling User Interactions in Recommender Systems (2019)</h3>
    <p><strong>Authors:</strong> Gediminas Adomavicius, Qian Zhao, Martijn C. Willemsen, F. Maxwell Harper, Joseph A. Konstan</p>
    <p>User-system interaction in recommender systems involves three aspects: temporal browsing (viewing recommendation lists and/or searching/filtering), action (performing actions on recommended items, e.g., clicking, consuming) and inaction (neglecting or skipping recommended items). Modern recommenders build machine learning models from recordings of such user interaction with the system, and in doing so they commonly make certain assumptions (e.g., pairwise preference orders, independent or competitive probabilistic choices, etc.). In this paper, we set out to study the effects of these assumptions along three dimensions in eight different single models and three associated hybrid models on a user browsing data set collected from a real-world recommender system application. We further design a novel model based on recurrent neural networks and multi-task learning, inspired by Decision Field Theory, a model of human decision making. We report on precision, recall, and MAP, finding that this new model outperforms the others.</p>
    <p><strong>Categories:</strong> User Interaction Modeling, Decision Making, Recommender Systems, Evaluation Metrics (Precision, Recall), Recurrent Neural Networks, Multi-Task Learning, Hybrid Models, Real-World Applications, A/B Testing, System Design, Machine Learning Approaches, Cold Start (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/475/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>FineNet: A Joint Convolutional and Recurrent Neural Network Model to Forecast and Recommend Anomalous Financial Items (2019)</h3>
    <p><strong>Authors:</strong> Yu-Che Tsai, You-Jia Chen, Chih-Yao Chen, Cheng-Te Li, Pei-Chi Wang, Shao-Lun Ma, Yu-Chieh Chang</p>
    <p>Financial technology (FinTech) draws much attention in these years, with the advances of machine learning and deep learning. In this work, given historical time series of stock prices of companies, we aim at forecasting upcoming anomalous financial items, i.e., abrupt soaring or diving stocks, in financial time series, and recommending the corresponding stocks to support financial operations. We propose a novel joint convolutional and recurrent neural network model, Financial Event Neural Network (FineNet), to forecast and recommend anomalous stocks. Experiments conducted on the time series of stock prices of 300 well-known companies exhibit the promising performance of FineNet in terms of precision and recall. We build FineNet as a Web platform for live demonstration.</p>
    <p><strong>Categories:</strong> Convolutional Neural Network, Recurrent Neural Network, FinTech, Financial Time Series, Anomaly Detection, Financial Anomaly Detection, Forecasting, Precision, Recall, Web Application, Hybrid Models, Financial Items (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/509/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Deep Learning Marketplace Recommenders in Online Experiments (2018)</h3>
    <p><strong>Authors:</strong> Simen Eide, Ning Zhou</p>
    <p>Marketplaces are platforms where users buy and sell various types of items. Recommendation systems are widely used in marketplaces to match users with items relevant to their interests and needs. This paper focuses on online experiments with deep neural network recommenders and presents the promising recommenders we found – hybrid item representation models combining features from traffic and content, sequence-based models, and multi-armed bandit models that optimize user engagement by re-ranking proposals from multiple submodels. Then it summarizes the online experiment results and discusses why some recommenders outperform others.</p>
    <p><strong>Categories:</strong> Deep Learning, Recommendation Systems, Marketplace, Hybrid Models, Sequence-Based Models, Multi-Armed Bandits, Online Experiments, User Engagement, Deep Neural Networks, Hybrid Recommenders, Re-ranking Proposals, Performance Analysis (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/372/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>entity2rec: Learning User-Item Relatedness from Knowledge Graphs for Top-N Item Recommendation (2017)</h3>
    <p><strong>Authors:</strong> Raphaël Troncy, Enrico Palumbo, Giuseppe Rizzo</p>
    <p>Knowledge Graphs have proven to be extremely valuable to recommender systems, as they enable hybrid graph-based recommendation models encompassing both collaborative and content information. Leveraging this wealth of heterogeneous information for top-N item recommendation is a challenging task, as it requires the ability of effectively encoding a diversity of semantic relations and connectivity patterns. In this work, we propose a novel approach to learning user-item relatedness from knowledge graphs for top-N item recommendations. We start from a knowledge graph modeling user-item and item-item relations and we learn property-specific vector representations of users and items applying neural language models on the network. These representations are used to create property-specific user-item relatedness features, which are in turn fed into learning to rank algorithms to learn a global relatedness model that optimizes top-N item recommendations. We evaluate the proposed approach in terms of ranking quality on the MovieLens 1M dataset, outperforming two state-of-the-art recommender systems, and we assess the importance of property-specific relatedness scores on the overall ranking quality.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Hybrid Models, Top-N Recommendation, Deep Learning, Learning to Rank, Knowledge Graphs, Movies, Ranking Quality, Beyond Accuracy, User-Item Embeddings, Hybrid Approaches (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/287/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Local Item-Item Models For Top-N Recommendation (2016)</h3>
    <p><strong>Authors:</strong> George Karypis, Evangelia Christakopoulou</p>
    <p>Item-based approaches based on SLIM (Sparse LInear Methods) have demonstrated very good performance for top-N recommendation; however they only estimate a single model for all the users. This work is based on the intuition that not all users behave in the same way — instead there exist subsets of like-minded users. By using different item-item models for these user subsets, we can capture differences in their preferences and this can lead to improved performance for top-N recommendations. In this work, we extend SLIM by combining global and local SLIM models. We present a method that computes the prediction scores as a user-specific combination of the predictions derived by a global and local item-item models. We present an approach in which the global model, the local models, their user-specific combination, and the assignment of users to the local models are jointly optimized to improve the top-N recommendation performance. Our experiments show that the proposed method improves upon the standard SLIM model and outperforms competing top-N recommendation approaches.</p>
    <p><strong>Categories:</strong> Item-Item Collaborative Filtering, Sparse Linear Models (SLIM), Recommendation Systems, Top-N Recommendations, Personalized Recommendations, Local vs Global Models, User Segmentation/Clustering, Hybrid Models, Optimization Techniques, Recommendation Performance, Empirical Validation (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/187/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Convolutional Matrix Factorization for Document Context-Aware Recommendation (2016)</h3>
    <p><strong>Authors:</strong> Hwanjo Yu, Sungyong Lee, Jinoh Oh, Chanyoung Park, Donghyun Kim</p>
    <p>Sparseness of user-to-item rating data is one of the major factors that deteriorate the quality of recommender system. To handle the sparsity problem, several recommendation techniques have been proposed that additionally consider auxiliary information to improve rating prediction accuracy. In particular, when rating data is sparse, document modeling-based approaches have improved the accuracy by additionally utilizing textual data such as reviews, abstracts, or synopses. However, due to the inherent limitation of the bag-of-words model, they have difficulties in effectively utilizing contextual information of the documents, which leads to shallow understanding of the documents. This paper proposes a novel context-aware recommendation model, convolutional matrix factorization (ConvMF) that integrates convolutional neural network (CNN) into probabilistic matrix factorization (PMF). Consequently, ConvMF captures contextual information of documents and further enhances the rating prediction accuracy. Our extensive evaluations on three real-world datasets show that ConvMF significantly outperforms the state-of-the-art recommendation models even when the rating data is extremely sparse. We also demonstrate that ConvMF successfully captures subtle contextual difference of a word in a document. Our implementation and datasets are available at http://dm.postech.ac.kr/ConvMF.</p>
    <p><strong>Categories:</strong> Matrix Factorization, Convolutional Neural Networks, Recommendation Systems, Text Mining, Natural Language Processing, Sparsity, Context-Aware Recommendations, Real-World Applications, Hybrid Models (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/168/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>