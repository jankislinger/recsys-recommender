<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reproducibility/">Reproducibility</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reinforcement-learning/">Reinforcement Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/cold-start/">Cold Start</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/beyond-accuracy/">Beyond Accuracy</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Understanding Fairness in Recommender Systems: A Healthcare Perspective (2024)</h3>
    <p><strong>Authors:</strong> Veronica Kecki, Alan Said</p>
    <p>Fairness in AI-driven decision-making systems has become a critical concern, especially when these systems directly affect human lives. This paper explores the public’s comprehension of fairness in healthcare recommendations. We conducted a survey where participants selected from four fairness metrics – Demographic Parity, Equal Accuracy, Equalized Odds, and Positive Predictive Value – across different healthcare scenarios to assess their understanding of these concepts. Our findings reveal that fairness is a complex and often misunderstood concept, with a generally low level of public understanding regarding fairness metrics in recommender systems. This study highlights the need for enhanced information and education on algorithmic fairness to support informed decision-making in using these systems. Furthermore, the results suggest that a one-size-fits-all approach to fairness may be insufficient, pointing to the importance of context-sensitive designs in developing equitable AI systems.</p>
    <p><strong>Categories:</strong> Fairness, Recommender Systems, Healthcare, Ethics in AI, Public Understanding, Algorithmic Fairness, Education, Context-aware Systems, Healthcare Applications, User Survey (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1201/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Deliberative Diversity for News Recommendations: Operationalization and Experimental User Study (2023)</h3>
    <p><strong>Authors:</strong> Rana Abdullah, Juliane A. Lischka, Laura Laugwitz, Lucien Heitz, Hendrik Meyer, Abraham Bernstein</p>
    <p>News recommender systems are an increasingly popular field of study that attracts a growing, interdisciplinary research community. As these systems play an important role in our daily lives, the mechanisms behind their curation processes are under close scrutiny. In the domain of personalized news, many platforms make design choices that are driven by economic incentives. In contrast to such systems that optimize for financial gains, there exists norm-driven diversity objectives, putting normative and democratic goals first. Their impact on users, however, in terms of triggering behavioral changes or affecting knowledgeability, is still under-researched. In this paper, we contribute to the field of news recommender system design by conducting a user study that looks at the impact of these normative approaches. We a.) operationalize the notion of deliberative democracy for news recommendations, show b.) the impact on political knowledgeability and c.) the influence on voting behavior. We found that exposure to small parties is associated with an increase in knowledge about their candidates and that intensive news consumption about a party can change the direction of attitudes towards their issues.</p>
    <p><strong>Categories:</strong> Recommendation Systems, News, Diversity of Recommendations, Ethics in AI, Deliberative Democracy, Experimental User Study, Political Knowledgeability, Voting Behavior, Norm-Driven Design, Beyond Accuracy, User Behavior, Exposure to Underrepresented Groups (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/916/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Find My Next Job Labor Market Recommendations Using Administrative Big Data (2019)</h3>
    <p><strong>Authors:</strong> Snorre S. Frid-Nielsen</p>
    <p>Labor markets are undergoing change due to factors such as automatization and globalization, motivating the development of occupational recommender systems for jobseekers and caseworkers. This study generates occupational recommendations by utilizing a novel data set consisting of administrative records covering the entire Danish workforce. Based on actual labor market behavior in the period 2012-2015, how well can different models predict each users’ next occupation in 2016? Through offline experiments, the study finds that gradient-boosted decision tree models provide the best recommendations for future occupations in terms of mean reciprocal ranking and recall. Further, gradient-boosted decision tree models offer distinct advantages in the labor market domain due to their interpretability and ability to harness additional background information on workers. However, the study raises concerns regarding trade-offs between model accuracy and ethical issues, including privacy and the social reinforcement of gender divides. i>Presentation: Tuesday Poster Lunch</i</p>
    <p><strong>Categories:</strong> Labor Markets, Big Data, Recommender Systems, Administrative Records, Machine Learning, Gradient Boosting, Model Comparison, Evaluation Metrics, Ethics in AI, Privacy, Gender Bias, Workforce Development (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/478/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>