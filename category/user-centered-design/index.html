<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui primary button" style="margin: 5px;"
             href="/recsys-recommender/">User-Centered Design</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/real-world-applications/">Real-world Applications</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/evaluation-methods/">Evaluation Methods</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reinforcement-learning/">Reinforcement Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/explainability/">Explainability</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Evaluating the Pros and Cons of Recommender Systems Explanations (2024)</h3>
    <p><strong>Authors:</strong> Kathrin Wardatzky</p>
    <p>Despite the growing interest in explainable AI in the RecSys community, the evaluation of explanations is still an open research topic. Typically, explanations are evaluated using offline metrics, with a case study, or through a user study. In my research, I will have a closer look at the evaluation of the effects of explanations on users. I investigate two possible factors that can impact the effects reported in recent publications, namely the explanation design and content as well as the users themselves. I further address the problem of determining promising explanations for an application scenario from a seemingly endless pool of options. Lastly, I propose a user study to close some of the research gaps established in the surveys and investigate how recommender systems explanations impact the understanding of users with different backgrounds.</p>
    <p><strong>Categories:</strong> Explainable AI, Recommender Systems (RecSys), Evaluation Methods, User Study, Explanation Design, User-Centered Design, Offline Metrics, Case Study (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1140/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Looks Can Be Deceiving: Linking User-Item Interactions and User’s Propensity Towards Multi-Objective Recommendations (2023)</h3>
    <p><strong>Authors:</strong> Ludovico Boratto, Patrik Dokoupil, Ladislav Peska</p>
    <p>Multi-objective recommender systems (MORS) provide suggestions to users according to multiple (and possibly conflicting) goals. When a system optimizes its results at the individual-user level, it tailors them on a user’s propensity towards the different objectives. Hence, the capability to understand users’ fine-grained needs towards each goal is crucial. In this paper, we present the results of a user study in which we monitored the way users interacted with recommended items, as well as their self-proclaimed propensities towards relevance, novelty and diversity objectives. The study was divided into several sessions, where users evaluated recommendation lists originating from a relevance-only single-objective baseline as well as MORS. We show that despite MORS-based recommendations attracted less selections, its presence in the early sessions is crucial for users’ satisfaction in the later stages. Surprisingly, the self-proclaimed willingness of users to interact with novel and diverse items is not always reflected in the recommendations they accept. Post-study questionnaires provide insights on how to deal with this matter, suggesting that MORS-based results should be accompanied by elements that allow users to understand the recommendations, so as to facilitate their acceptance.</p>
    <p><strong>Categories:</strong> Multi-Objective Recommendations, User-item Interactions, User Propensity, Evaluation, User Satisfaction, User Preferences, Questionnaire-Based Evaluation, Recommendation Objectives, Multi-Objective Optimization, User-Centered Design, Beyond Accuracy (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/921/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>User-Centric Conversational Recommendation: Adapting the Need of User with Large Language Models (2023)</h3>
    <p><strong>Authors:</strong> Gangyi Zhang</p>
    <p>Conversational recommender systems (CRS) promise to provide a more natural user experience for exploring and discovering items of interest through ongoing conversation. However, effectively modeling user preferences during conversations and generating personalized recommendations in real time remain challenging problems. Users often express their needs in a vague and evolving manner, and CRS must adapt to capture the dynamics and uncertainty in user preferences to have productive interactions. This research develops user-centric methods for building conversational recommendation system that can understand complex and changing user needs. We propose a graph-based conversational recommendation framework that represents multi-turn conversations as reasoning over a user-item-attribute graph. Enhanced conversational path reasoning incorporates graph neural networks to improve representation learning in this framework. To address uncertainty and dynamics in user preferences, we present the vague preference multi-round conversational recommendation scenario and an adaptive vague preference policy learning solution that employs reinforcement learning to determine recommendation and preference elicitation strategies tailored to the user. Looking to the future, large language models offer promising opportunities to enhance various aspects of CRS, including user modeling, policy learning, response generation.  Overall, this research takes a user-centered perspective in designing conversational agents that can adapt to the inherent ambiguity involved in natural language dialogues with people.</p>
    <p><strong>Categories:</strong> Conversational Recommender Systems, Large Language Models, Graph Neural Networks, Reinforcement Learning, User Dynamics, Conversational Agents, Personalization, Real-Time Recommendations, Multi-Round Dialogue, AI/ML in Recommendations, User-Centered Design (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/983/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>HUMMUS: A Linked, Healthiness-Aware, User-centered and Argument-Enabling Recipe Data Set for Recommendation (2023)</h3>
    <p><strong>Authors:</strong> Sylvie Calabretto, Armin Gerl, Felix Bölz, Harald Kosch, Lionel Brunie, Diana Nurbakova</p>
    <p>The overweight and obesity rate is increasing for decades worldwide. Healthy nutrition is, besides education and physical activity, one of the various keys to tackle this issue. In an effort to increase the availability of digital, healthy recommendations, the scientific area of food recommendation extends its focus from the accuracy of the recommendations to beyond-accuracy goals like transparency and healthiness. To address this issue a data basis is required, which in the ideal case encompasses user-item interactions like ratings and reviews, food-related information like recipe details, nutritional data, and in the best case additional data which describes the food items and their relations semantically. Though several recipe recommendation data sets exist, to the best of our knowledge, a holistic large-scale healthiness-aware and connected data sets have not been made available yet. The lack of such data could partially explain the poor popularity of the topic of healthy food recommendation when compared to the domain of movie recommendation. In this paper, we show that taking into account only user-item interactions is not sufficient for a recommendation. To close this gap, we propose a connected data set called HUMMUS (Health-aware User-centered recoMMedation and argUment enabling data Set) collected from Food.com containing multiple features including rich nutrient information, text reviews, and ratings, enriched by the authors with extra features such as Nutri-scores and connections to semantic data like the FoodKG and the FoodOn ontology. We hope that these data will contribute to the healthy food recommendation domain.</p>
    <p><strong>Categories:</strong> Health and Nutrition, Recommendation Systems, Data Sets, User-Centered Design, Food and Recipes, Semantic Data, Linked Data, Evaluation Metrics, Real-world Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/937/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Designing and evaluating explainable AI for non-AI experts: challenges and opportunities (2022)</h3>
    <p><strong>Authors:</strong> Katrien Verbert, Vero Vanden Abeele, Maxwell Szymanski</p>
    <p>Artificial intelligence (AI) has seen a steady increase in use in the health and medical field, where it is used by lay users and health experts alike. However, these AI systems often lack transparency regarding the inputs and decision making process (often called black boxes), which in turn can be detrimental to the user’s satisfaction and trust towards these systems. Explainable AI (XAI) aims to overcome this problem by opening up certain aspects of the black box, and has proven to be a successful means of increasing trust, transparency and even system effectiveness. However, for certain groups (i.e. lay users in health), explanation methods and evaluation metrics still remain underexplored. In this paper, we will outline our research regarding designing and evaluating explanations for health recommendations for lay users and domain experts, as well as list a few takeaways we were already able to find in our initial studies.</p>
    <p><strong>Categories:</strong> Explainable AI, Transparency, Trust in AI, Healthcare, Medicine, User-Centered Design, Evaluation Metrics, Health Recommendations, Explanation Methods, User Trust, Challenges and Opportunities, User Satisfaction (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/811/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Exploring the Impact of Temporal Bias in Point-of-Interest Recommendation (2022)</h3>
    <p><strong>Authors:</strong> Ali Tourani, Hossein A. Rahmani, Yashar Deldjoo, Mohammadmehdi Naghiaei</p>
    <p>Recommending appropriate travel destinations to consumers based on contextual information such as their check-in time and location is a primary objective of Point-of-Interest (POI) recommender systems. However, the issue of contextual bias (i.e., how much consumers prefer one situation over another) has received little attention from the research community. This paper examines the effect of temporal bias, defined as the difference between users’ check-in hours, leisure vs. work hours, on the consumer-side fairness of context-aware recommendation algorithms. We believe that eliminating this type of temporal (and geographical) bias might contribute to a drop in traffic-related air pollution, noting that rush-hour traffic may be more congested. To surface effective POI recommendation, we evaluated the sensitivity of state-of-the-art context-aware models to the temporal bias contained in users’ check-in activities on two POI datasets, namely Gowalla and Yelp. The findings show that the examined context-aware recommendation models prefer one group of users over another based on the time of check-in and that this preference persists even when users have the same amount of interactions.</p>
    <p><strong>Categories:</strong> Context-Aware Recommendation, Temporal Bias, Fairness in Recommendations, Environmental Impact, Location-Based Services, POI Recommendation, Temporal Dynamics, User Behavior, Scalability, User-Centered Design, Real-World Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/789/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Top-K Contextual Bandits with Equity of Exposure (2021)</h3>
    <p><strong>Authors:</strong> Olivier Jeunen, Bart Goethals</p>
    <p>The contextual bandit paradigm provides a general framework for decision-making under uncertainty. It is theoretically well-defined and well-studied, and many personalisation use-cases can be cast as a bandit learning problem. Because this allows for the direct optimisation of utility metrics that rely on online interventions (such as click-through-rate (CTR)), this framework has become an attractive choice to practitioners. Historically, the literature on this topic has focused on a one-sided, user-focused notion of utility, overall disregarding the perspective of content providers in online marketplaces (for example, musical artists on streaming services). If not properly taken into account – recommendation systems in such environments are known to lead to unfair distributions of attention and exposure, which can directly affect the income of the providers. Recent work has shed a light on this, and there is now a growing consensus that some notion of “equity of exposure” might be preferable to implement in many recommendation use-cases.<br>We study how the top-K contextual bandit problem relates to issues of disparate exposure, and how this disparity can be minimised. The predominant approach in practice is to greedily rank the top-K items according to their estimated utility, as this is optimal according to the well-known Probability Ranking Principle. Instead, we introduce a configurable tolerance parameter that defines an acceptable decrease in utility for a maximal increase in fairness of exposure. We propose a personalised exposure-aware arm selection algorithm that handles this relevance-fairness trade-off on a user-level, as recent work suggests that users’ openness to randomisation may vary greatly over the global populace. Our model-agnostic algorithm deals with arm selection instead of utility modelling, and can therefore be implemented on top of any existing bandit system with minimal changes. We conclude with a case study on carousel personalisation in music recommendation: empirical observations highlight the effectiveness of our proposed method and show that exposure disparity can be significantly reduced with a negligible impact on user utility.</p>
    <p><strong>Categories:</strong> Contextual Bandits, Equity of Exposure, Personalization, Fairness in Recommendations, Top-K Selection, Music Recommendation, Algorithm Design, User-Centered Design, Relevance-Fairness Trade-off, Evaluation Methods, Exposure Disparity, Machine Learning, Bandit Algorithms, Case Study. (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/670/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>An Interpretable Recommendation Model for Gerontological Care (2021)</h3>
    <p><strong>Authors:</strong> Paula Castro, Andre Paulino de Lima, Maria Pimentel, Brunela Orlandi, Laurentino Augusto Dantas, Marcelo Garcia Manzato</p>
    <p>Recommender systems have been successfully applied to diverse areas, but their use in the healthcare domain is still rare. One challenge of applying recommender systems to this domain is related to legal concerns about the consequences of provided recommendations. In this work, we advance an expert-in-the-loop, explanation-first approach to tackle this challenge in a specific healthcare niche: gerontological care. A key aspect of the proposed approach is that both recommendations and explanations reflect the structured questionnaire employed by the practitioner to identify patient needs. Another key aspect is that a clinical dataset of patient assessments and respective assigned interventions is used to estimate effects of alternative interventions during the recommendation process. To evaluate the feasibility of this modelling approach, an explanation style was designed with help of practitioners, and a recommendation model was devised and evaluated against a clinical dataset, which was collected by a partner research group working on gerontological primary care. When compared to other traditional recommendation models, the attained precision was competitive across several evaluation conditions. The results suggest that the proposed approach is feasible and may point new ways of adapting recommender systems to play an assistive role in health care.</p>
    <p><strong>Categories:</strong> Interpretable Models, Healthcare, Gerontology, Regulatory Concerns, Expert Collaboration, Patient Needs, Clinical Data, User-Centered Design, Model Evaluation, Feasibility Studies, Method Comparison, Explainable AI (XAI) (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/680/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Connecting Students with Research Advisors Through User-Controlled Recommendation (2021)</h3>
    <p><strong>Authors:</strong> Peter Brusilovsky, Alireza Javadian Sabet, Behnam Rahdari</p>
    <p>We present Grapevine, a user-controlled recommender that enables undergraduate and graduate students to find a suitable research advisor. This system combines the ideas from the areas of exploratory search, user modeling, and recommender systems by employing state-of-the-art knowledge extraction, grape-based recommendation, and an intelligent user interface. In this paper, we demonstrate the system’s key components and how they work as a whole.</p>
    <p><strong>Categories:</strong> Recommendation Systems, User Control/Personalization, Exploratory Search, User Modeling, Knowledge Extraction, Intelligent User Interfaces, Education, HCI, User-Centered Design (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/705/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Ensuring Fairness in Group Recommendations by Rank-Sensitive Balancing of Relevance (2020)</h3>
    <p><strong>Authors:</strong> Derek Bridge, Mesut Kaya, Nava Tintarev</p>
    <p>For group recommendations, one objective is to recommend an ordered set of items, a top-N, to a group such that each individual recommendation is relevant for everyone. A common way to do this is to select items on which the group can agree, using so-called ‘aggregation strategies’. One weakness of these aggregation strategies is that they select items independently of each other. They therefore cannot guarantee properties such as fairness, that apply to the set of recommendations as a whole.<br>In this paper, we give a definition of fairness that ‘balances’ the relevance of the recommended items across the group members in a rank-sensitive way. Informally, an ordered set of recommended items is considered fair to a group if the relevance of the items in the top-N is balanced across the group members for each prefix of the top-N. In other words, the first item in the top-N should, as far as possible, balance the interests of all group members; the first two items taken together must do the same; also the first three; and so on up to N. In this paper, we formalize this notion of rank-sensitive balance and provide a greedy algorithm (GFAR) for finding a top-N set of group recommendations that satisfies our definition.<br>We compare the performance of GFAR to five approaches from the literature on two datasets, one from each of the movie and music domains. We evaluate performance for 42 different configurations (two datasets, seven different group sizes, three different group types) and for ten evaluation metrics. We find that GFAR performs significantly better than all other algorithms around 43% of the time; in only 10% of cases are there algorithms that are significantly better than GFAR. Furthermore, GFAR performs particularly well in the most difficult cases, where groups are large and interests within the group diverge. We attribute GFAR’s success both to its rank-sensitivity and its way of balancing relevance. Current methods do not define fairness in a rank-sensitive way (although some achieve a degree of rank-sensitivity through the use of greedy algorithms) and none define balance in the way that we do.</p>
    <p><strong>Categories:</strong> Group Recommendations, Fairness in Recommendation, Algorithm Design, Evaluation Metrics, User-Centered Design, Relevance Balancing, Rank-Sensitive Fairness, Aggregation Strategies, Algorithm Performance Analysis, Movie Domain, Music Domain, Diverse Interests Handling (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/534/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>PicTouRe – A Picture-Based Tourism Recommender (2020)</h3>
    <p><strong>Authors:</strong> Hannes Werthner, Mete Sertkan, Julia Neidhardt</p>
    <p>We present PicTouRe – a picture-based tourism recommender. PicTouRe aims to mitigate people’s difficulties in explicitly expressing their touristic preferences, which is even more challenging in the initial phase of travel decision making. Addressing this issue, with PicTouRe we follow the idiom “a picture is worth a thousand words” and use pictures as a tool to implicitly elicit peoples’ touristic preferences. We describe the core concept of PicTouRe - the Generic Profiler, which in essence determines an explainable vector representation, i.e., touristic profile, given any picture collection as input. We showcase a user’s journey through PicTouRe and describe the steps behind. Finally, we present results of a first user study supporting our approach. PicTouRe is available under https://pictoprof.ec.tuwien.ac.at and a demo video under https://youtu.be/xZnXLPcenEs.</p>
    <p><strong>Categories:</strong> Tourism, Recommender Systems, Visual Recommendations, Picture-Based, Implicit Feedback, User-Centered Design, Explainable AI, Profiling, Evaluation Methods, Real-World Application (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/595/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Don’t Judge a Book by its Cover: Exploring Book Traits Children Favor (2020)</h3>
    <p><strong>Authors:</strong> Ashlee Milton, Levesson Batista, Siqi Gao, Yiu-Kai Ng, Garrett Allen, Maria Soledad Pera</p>
    <p>We present the preliminary exploration we conducted to identify traits that can influence children’s preferences in books. Findings offer insights for the design of recommender algorithms that would look beyond patterns inferred from traditional user-system interactions (e.g., ratings) for recommendation purposes, since when it comes to children such data is rarely, if at all, available.</p>
    <p><strong>Categories:</strong> Books, Children, Recommender Systems, User Preferences, Child Behavior, Algorithm Design, Implicit Feedback, Education, Preference Inference, User-Centered Design (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/605/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Who Doesn’t Like Dinosaurs? Finding and Eliciting Richer Preferences for Recommendation (2020)</h3>
    <p><strong>Authors:</strong> Tobias Schnabel, Gonzalo Ramos, Saleema Amershi</p>
    <p>Real-world recommender systems often allow users to adjust the presented content through a variety of preference elicitation techniques such as “liking” or interest profiles. These elicitation techniques trade-off time and effort to users with the richness of the signal they provide to learning component driving the recommendations. In this paper, we explore this trade-off, seeking new ways for people to express their preferences with the goal of improving communication channels between users and the recommender system. Through a need-finding study, we observe the patterns in how people express their preferences during curation task, propose a taxonomy for organizing them, and point out research opportunities. We present a case study that illustrates how using this taxonomy to design an onboarding experience can lead to more accurate machine-learned recommendations while maintaining user satisfaction under low effort.</p>
    <p><strong>Categories:</strong> Preference Elicitation, User Interaction, Richer Preferences, Recommender Systems, Design of Interfaces, Usability, User-Centered Design, Case Study/Research Methods (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/559/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Explaining and Exploring Job Recommendations: a User-driven Approach for Interacting with Knowledge-based Job Recommender Systems (2019)</h3>
    <p><strong>Authors:</strong> Nyi Nyi Htun, Gerd Goetschalckx, Robin De Croon, Katrien Verbert, Francisco Gutiérrez, Sven Charleer</p>
    <p>The dynamics of the labor market and the tasks with which jobs are being composed are continuously evolving. Job mobility is not evident, and providing effective recommendations in this context has also been found to be particularly challenging. In this paper, we present Labor Market Explorer, an interactive dashboard that enables job seekers to explore the labor market in a personalized way based on their skills and competences. Through a user-centered design process involving job seekers and job mediators, we developed this dashboard to enable job seekers to explore job recommendations and their required competencies, as well as how these competencies map to their profile. Evaluation results indicate the dashboard empowers job seekers to explore, understand, and find relevant vacancies, mostly independent of their background and age.</p>
    <p><strong>Categories:</strong> Job Recommendations, User-Centered Design, Interactive Visualization, Knowledge-Based Systems, Labor Market Dynamics, Competence Mapping, Evaluation Methods, Personalized Recommendations, User Interaction, Empowerment of Users (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/441/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Combining Text Summarization and Aspect-based Sentiment Analysis of Users’ Reviews to Justify Recommendations (2019)</h3>
    <p><strong>Authors:</strong> Pasquale Lops, Giovanni Semeraro, Marco de Gemmis, Cataldo Musto, Gaetano Rossiello</p>
    <p>In this paper we present a methodology to justify recommendations that relies on the information extracted from users’ reviews discussing the available items. The intuition behind the approach is to conceive the justification as a summary of the most relevant and distinguishing aspects ofthe item, automatically obtained by analyzing the available reviews. To this end, we designed a pipeline of natural language processing techniques based on aspect extraction, sentiment analysis and text summarization to gather the reviews, process the relevant excerpts,and generate a unique synthesis presenting the main characteristics of the item. Such a summary is finally presented to the target user as justification of the recommendation she received. In the experimental evaluation we carried out a user study in the movie domain (N=141) and the results showed that our approach is able to make the recommendation process more transparent, engaging and trustful for the users. Moreover, the proposed method also beat another review-based explanation technique, thus confirming the validity of our intuition. i>Presentation: Monday Poster Lunch</i</p>
    <p><strong>Categories:</strong> Recommendation Systems, Natural Language Processing, Text Summarization, Aspect-Based Sentiment Analysis, Movie Domain, User Study, Explainability, Trust, Experimental Results, Evaluation Methodology, Pipeline Design, Transparency in AI, User Feedback, Sentiment Analysis, Aspect Extraction, User-Centered Design (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/469/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Designing for the Better by Taking Users into Account: A Qualitative Evaluation of User Control Mechanisms in (News) Recommender Systems (2019)</h3>
    <p><strong>Authors:</strong> Jaron Harambam, Mykola Makhortykh, Dimitrios Bountouridis, Joris van Hoboken</p>
    <p>Recommender systems (RS) are on the rise in many domains. While they offer great promises, they also raise concerns: lack of transparency, reduction of diversity, little to no user control. In this paper, we align with the normative turn in computer science which scrutinizes the ethical and societal implications of RS. We focus and elaborate on the concept of user control because that mitigates multiple problems at once. Taking the news industry as our domain, we conducted four focus groups, or moderated think-aloud sessions, with Dutch news readers (N=21) to systematically study how people evaluate different control mechanisms (at the input, process, and output phase) in a News Recommender Prototype (NRP). While these mechanisms are sometimes met with distrust about the actual control they offer, we found that an intelligible user profile (including reading history and flexible preferences settings), coupled with possibilities to influence the recommendation algorithms is highly valued, especially when these control mechanisms can be operated in relation to achieving personal goals. By bringing (future) users’ perspectives to the fore, this paper contributes to a  richer understanding of why and how to design for user control in recommender systems.</p>
    <p><strong>Categories:</strong> Recommender Systems, News Domain, User Control Mechanisms, Qualitative Evaluation, Ethical Considerations, Societal Implications, User Study, Input Control Mechanisms, Process Control Mechanisms, Output Control Mechanisms, Transparency, Personalization, News Recommender Systems, User-Centered Design, Usability (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/438/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>