<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui primary button" style="margin: 5px;"
             href="/recsys-recommender/">Word Embeddings</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/bias-mitigation/">Bias Mitigation</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/offline-evaluation/">Offline Evaluation</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reproducibility/">Reproducibility</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Word2vec applied to Recommendation: Hyperparameters Matter (2018)</h3>
    <p><strong>Authors:</strong> Jimena Royo-Letelier, Hugo Caselles-Dupré, Florian Lesaint</p>
    <p>Skip-gram with negative sampling, a popular variant of Word2vec originally designed and tuned to create word embeddings for Natural Language Processing, has been used to create item embeddings with successful applications in recommendation. While these fields do not share the same type of data, neither evaluate on the same tasks, recommendation applications tend to use the same already tuned hyperparameters values, even if optimal hyperparameters values are often known to be data and task dependent. We thus investigate the marginal importance of each hyperparameter in a recommendation setting through large hyperparameter grid searches on various datasets. Results reveal that optimizing neglected hyperparameters, namely negative sampling distribution, number of epochs, subsampling parameter and window-size, significantly improves performance on a recommendation task, and can increase it by an order of magnitude. Importantly, we find that optimal hyperparameters configurations for Natural Language Processing tasks and Recommendation tasks are noticeably different.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Word Embeddings, Collaborative Filtering, Algorithm Performance, Hyperparameter Optimization, Item Embeddings, Cross-Domain Applications, Beyond Accuracy, Explicit Feedback, Implicit Feedback, Domain Adaptation (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/407/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Using Citation-Context to Reduce Topic Drifting on Pure Citation-Based Recommendation (2018)</h3>
    <p><strong>Authors:</strong> Anita Khadka, Petr Knoth</p>
    <p>Recent works in the area of academic recommender systems have demonstrated the effectiveness of co-citation and citation closeness in related-document recommendations. However, documents recommended from such systems may drift away from the main concept of the query document. In this work, we investigate whether incorporating the textual information in close proximity to a citation as well as the citation position could reduce such drifting and further increase the performance of the recommender system. To investigate this, we run experiments with several recommendation methods on a newly created and now publicly available dataset containing 53 million unique citation based records. We then conduct a user-based evaluation with domain-knowledgeable participants. Our results show that a new method based on the combination of Citation Proximity Analysis (CPA), topic modelling and word embeddings achieve more than 20% improvement in Normalised Discounted Cumulative Gain (nDCG) compared to CPA.</p>
    <p><strong>Categories:</strong> Academic Recommender Systems, Citation-Based Methods, Academic Research, Citation Proximity Analysis (CPA), Topic Modeling, Word Embeddings, Domain Expert Evaluation, User Evaluation, Evaluation Metrics, Topic Drifting, Scalability, Recommendation Methods, Beyond Citation-Based, Academic Domain (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/406/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>A Semantic-Aware Profile Updating Model for Text Recommendation (2017)</h3>
    <p><strong>Authors:</strong> Hossein Rahmatizadeh Zagheli, Hamed Zamani, Azadeh Shakery</p>
    <p>Content-based recommender systems (CBRSs) rely on user-item similarities that are calculated between user profiles and item representations. Appropriate representations for each user profile based on the user’s past preferences can result in a great impact on user’s satisfaction in CBRSs. In this paper, we focus on text recommendation and propose a novel profile updating model based on previously recommended items as well as semantic similarity of terms calculated using distributed representation of words. We evaluate our models using two standard text recommendation datasets: TREC-9 Filtering Track and CLEF 2008-09 INFILE Track collections. Our experiments investigate the importance of both past recommended items and semantic similarities in recommendation performance. The proposed profile updating method significantly outperforms the baselines, which indicates the importance of incorporating semantic similarities in the profile updating task.</p>
    <p><strong>Categories:</strong> Content-Based Filtering, Profile Updating, Text Recommendation, Natural Language Processing (NLP), Word Embeddings, User Interaction, Semantic Similarity, User Satisfaction, Profile Management, Method Evaluation. (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/291/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Cross Domain Recommendation Using Vector Space Transfer Learning (2016)</h3>
    <p><strong>Authors:</strong> Masahiro Kazama, Istvan Varga</p>
    <p>The cold start problem, frequent with recommender systems, addresses the issue in cases where we don’t know enough about our users (e.g., the user hasn’t rated anything yet, or there are no user activities) in that specific domain. In our paper we present a simple and robust transfer learning approach where we model users’ behavior in a source domain, transferring that knowledge to a new, target domain. First, we vectorize the items by using word2vec for each dataset independently. Second, we calculate the transformation matrix that connects the source dataset to the target dataset by using their common users.</p>
    <p><strong>Categories:</strong> Cold Start, Transfer Learning, Vector Space Models, Cross Domain Recommendations, Recommender Systems, Matrix Factorization, User Behavior Modeling, Word Embeddings (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/231/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Representing Items as Word-Embedding Vectors and Generating Recommendations by Measuring their Linear Independence (2016)</h3>
    <p><strong>Authors:</strong> Ludovico Boratto, Roberto Saia, Gianni Fenu, Salvatore Carta</p>
    <p>In order to generate effective results, it is essential for a recommender system to model the information about the user interests in a profile. Even though word embeddings (i.e., vector representations of textual descriptions) have proven to be effective in many contexts, a content-based recommendation approach that employs them is still less effective than collaborative strategies (e.g., SVD). In order to overcome this issue, we introduce a novel criterion to evaluate the word-embedding representation of the items a user rated. The proposed approach defines a vector space in which the similarity between an unevaluated item and those in a user profile is measured in terms of linear independence. Experiments show its effectiveness to perform a better ranking of the items, w.r.t. collaborative filtering, both when compared to a latent-factor-based approach (SVD) and to a classic neighborhood user-based system.</p>
    <p><strong>Categories:</strong> Word Embeddings, Collaborative Filtering, Content-Based Recommendations, Vector Space Models, Linear Independence, Recommendation Quality, Evaluation Criteria, Comparison Studies (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/241/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Dish Discovery via Word Embeddings on Restaurant Reviews (2016)</h3>
    <p><strong>Authors:</strong> Yi-Fan Chu, Yi Ho, Ming-Feng Tsai, Chuan-Ju Wang, Chih-Yu Chao</p>
    <p>This paper proposes a novel framework for automatic dish discovery via word embeddings on restaurant reviews. We collect a dataset of user reviews from Yelp and parse the reviews to extract dish words. Then, we utilize the processed reviews as training texts to learn the embedding vectors of words via the skip-gram model. In the paper, a nearest- neighbor like score function is proposed to rank the dishes based on their learned representations. We brief some analyses on the preliminary experiments and present a web-based visualization at http://clip.csie.org/yelp/.</p>
    <p><strong>Categories:</strong> Natural Language Processing (NLP), Word Embeddings, Recommendation Systems, Food/Cuisine Domain, Yelp Dataset, User Reviews, Skip-Gram Model, Dish Discovery, Text Mining, Web-Based Visualization, Preliminary Experiments (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/222/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Word Embedding techniques for Content-based Recommender Systems: an empirical evaluation (2015)</h3>
    <p><strong>Authors:</strong> Pasquale Lops, Marco De Gemmis, Cataldo Musto, Giovanni Semeraro</p>
    <p>This work presents an empirical comparison among three widespread techniques as Latent Semantic Indexing, Random Indexing and the more recent Word2Vec. Specifically, we employed these techniques to learn a low-dimensional vector space and we exploited it to represent both items and user profiles in a recommendation scenario. The performance of the techniques has been evaluated against two state-of-the-art datasets, and experimental results provided good insights which pave the way to several future directions.</p>
    <p><strong>Categories:</strong> Content-Based Recommendation, Word Embeddings, Latent Semantic Indexing, Random Indexing, Word2Vec, Information Retrieval, Empirical Evaluation, Vector Space Models, Evaluation Metrics, Research Insights (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/165/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>