<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui primary button" style="margin: 5px;"
             href="/recsys-recommender/">System Design</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/explainability/">Explainability</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/offline-evaluation/">Offline Evaluation</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/scalability/">Scalability</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/cold-start/">Cold Start</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reproducibility/">Reproducibility</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Toward 100TB Recommendation Models with Embedding Offloading (2024)</h3>
    <p><strong>Authors:</strong> Sarunya Pumma, Levy Zhao, Joshua Deng, Dennis Van Der Staay, Jian He, Intaik Park, Ehsan Ardestani, Damian Reeves, Yu Guo, Paul Zhang, Henry Tsang</p>
    <p>Training recommendation models become memory-bound with large embedding tables, and fast GPU memory is scarce. In this paper, we explore embedding caches and prefetch pipelines to effectively leverage large but slow host memory for embedding tables. We introduce Locality-Aware Sharding and iterative planning that automatically size caches optimally and produce effective sharding plans. Embedding Offloading, a system that combines all of these components and techniques, is implemented on top of Meta’s open-source libraries, FBGEMM GPU and TorchRec, and it is used to improve scalability and efficiency of industry-scale production models. Embedding Offloading achieved 37x model scale to 100TB model size with only 26% training speed regression.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Embedding, Scalability, Memory Optimization, System Design, Cache Management, Sharding, Production Systems, Industry Applications, System Performance, GPU Memory, Resource Management (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1178/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Large Language Model Augmented Narrative Driven Recommendations (2023)</h3>
    <p><strong>Authors:</strong> Hamed Zamani, Sheshera Mysore, Andrew Mccallum</p>
    <p>Narrative-driven recommendation (NDR) presents an information access problem where users solicit recommendations with verbose descriptions of their preferences and context, for example, travelers soliciting recommendations for points of interest while describing their likes/dislikes and travel circumstances. These requests are increasingly important with the rise of natural language-based conversational interfaces for search and recommendation systems. However, NDR lacks abundant training data for models, and current platforms commonly do not support these requests. Fortunately, classical user-item interaction datasets contain rich textual data, e.g., reviews, which often describe user preferences and context — this may be used to bootstrap training for NDR models. In this work, we explore using large language models (LLMs) for data augmentation to train NDR models. We use LLMs for authoring synthetic narrative queries from user-item interactions with few-shot prompting and train retrieval models for NDR on synthetic queries and user-item interaction data. Our experiments demonstrate that this is an effective strategy for training small-parameter retrieval models that outperform other retrieval and LLM baselines for narrative-driven recommendation.</p>
    <p><strong>Categories:</strong> Narrative-Driven Recommendations, Large Language Models (LLMs), Data Augmentation, Recommendation Systems, Natural Language Processing, User-Item Interaction, System Design, Textual Data, Retrieval Models, Sparse Data Handling, Synthetic Queries. (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/908/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Reward innovation for long-term member satisfaction (2023)</h3>
    <p><strong>Authors:</strong> Jiangwei Pan, Henry Wang, Gary Tang, Justin Basilico</p>
    <p>Many large-scale recommender systems train on engagements because of their data abundance, immediacy of feedback, and correlation to user preferences. At Netflix and many digital products, engagement is an imperfect proxy to the overall goal of long-term user satisfaction. One way we address this misalignment is via reward innovation. In this paper, we provide a high-level description of the problem and motivate our approach. Finally, we present some practical insights into this track of work including challenges, lessons learned, and systems we’ve built to support the effort.</p>
    <p><strong>Categories:</strong> Recommendation Systems, User Engagement, Long-Term Satisfaction, Reward Mechanisms, User Retention, System Design, Practical Insights, Metric Alignment, Engagement Metrics Limitations, Beyond Accuracy, System Implementation (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1010/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Retrieval-augmented Recommender System: Enhancing Recommender Systems with Large Language Models (2023)</h3>
    <p><strong>Authors:</strong> Dario Di Palma</p>
    <p>Recommender Systems (RSs) play a pivotal role in delivering personalized recommendations across various domains, from e-commerce to content streaming platforms. Recent advancements in natural language processing have introduced Large Language Models (LLMs) that exhibit remarkable capabilities in understanding and generating human-like text. RS are renowned for their effectiveness and proficiency within clearly defined domains; nevertheless, they are limited in adaptability and incapable of providing recommendations for unexplored data. Conversely, LLMs exhibit contextual awareness and strong adaptability to unseen data. Combining these technologies creates a potent tool for delivering contextual and relevant recommendations, even in cold scenarios characterized by high data sparsity. The proposal aims to explore the possibilities of integrating LLMs into RS, introducing a novel approach called Retrieval-augmented Recommender Systems, which combines the strengths of retrieval-based and generation-based models to enhance the ability of RSs to provide relevant suggestions.</p>
    <p><strong>Categories:</strong> Recommender Systems, Large Language Models, Retrieval-Based Models, Generation-Based Models, Cold Start, Contextual Awareness, System Design, Adaptability, Hybrid Models, Innovative Approaches, Exploiting Language Models (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/984/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Stability of Explainable Recommendation (2023)</h3>
    <p><strong>Authors:</strong> Sairamvinay Vijayaraghavan, Prasant Mohapatra</p>
    <p>Explainable Recommendation has been gaining attention over the last few years in industry and academia. Explanations provided along with recommendations for each user in a recommender system framework have many uses: particularly reasoning why a suggestion is provided and how well an item aligns with a user’s personalized preferences. Hence, explanations can play a huge role in influencing users to purchase products. However, the reliability of the explanations under varying scenarios has not been strictly verified in an empirical perspective. Unreliable explanations can bear strong consequences such as attackers leveraging explanations for manipulating and tempting users to purchase target items: that the attackers would want to promote. In this paper, we study the vulnerability of existent feature-oriented explainable recommenders, particularly analyzing their performance under different levels of external noises added into model parameters. We conducted experiments by analyzing three important state-of-the-art explainable recommenders when trained on two widely used e-commerce based recommendation datasets of different scales. We observe that all the explainable models are vulnerable to increased noise levels. Experimental results verify our hypothesis that the ability to explain recommendations does decrease along with increasing noise levels and particularly adversarial noise does contribute to a much stronger decrease. Our study presents an empirical verification on the topic of robust explanations in recommender systems which can be extended to different types of explainable recommenders in RS.</p>
    <p><strong>Categories:</strong> Explainability, Security, Adversarial Attacks, Robustness, Recommender Systems, Empirical Evaluation, E-commerce, Model Stability, Trustworthiness, Algorithmic Approaches, System Design, Noise Impact, Methodology (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/934/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Evolution of Walmart.com Sponsored Products – An ML System Overview (2022)</h3>
    <p><strong>Authors:</strong> Stephen Guo, Musen Wen</p>
    <p></p>
    <p><strong>Categories:</strong> Retail, E-commerce, Digital Advertising, Machine Learning, Recommender Systems, System Design, Scalability, Real-World Applications, User Behavior Analysis, Performance Metrics, Marketing Strategies (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/836/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>TinyKG: Memory-Efficient Training Framework for Knowledge Graph Neural Recommender Systems (2022)</h3>
    <p><strong>Authors:</strong> Hao Yang, Xia Hu, Chin-Chia Michael Yeh, Huiyuan Chen, Xiaoting Li, Kaixiong Zhou, Yan Zheng</p>
    <p>There has been an explosion of interest in designing various Knowledge Graph Neural Networks (KGNNs), which achieve state-of-the-art performance and provide great explainability for recommendation. The promising performance is mainly resulting from their capability of capturing high-order proximity messages over the knowledge graphs. However, training KGNNs at scale is challenging due to the high memory usage. In the forward pass, the automatic differentiation engines (e.g., TensorFlow/PyTorch) generally need to cache all intermediate activation maps in order to compute gradients in the backward pass, which leads to a large GPU memory footprint. Existing work solves this problem by utilizing multi-GPU distributed frameworks. Nonetheless, this poses a practical challenge when seeking to deploy KGNNs in memory-constrained environments, especially for industry-scale graphs.<br>Here we present TinyKG, a memory-efficient GPU-based training framework for KGNNs for the tasks of recommendation. Specifically, TinyKG uses exact activations in the forward pass while storing a quantized version of activations in the GPU buffers. During the backward pass, these low-precision activations are dequantized back to full-precision tensors, in order to compute gradients. To reduce the quantization errors, TinyKG applies a simple yet effective quantization algorithm to compress the activations, which ensures unbiasedness with low variance. As such, the training memory footprint of KGNNs is largely reduced with negligible accuracy loss. To evaluate the performance of our TinyKG, we conduct comprehensive experiments on real-world datasets. We found that our TinyKG with INT2 quantization aggressively reduces the memory footprint of activation maps with 7 ×, only with 2% loss in accuracy, allowing us to deploy KGNNs on memory-constrained devices.</p>
    <p><strong>Categories:</strong> Memory Optimization, Knowledge Graph Neural Networks, Recommendation Systems, Real-World Applications, Quantization Methods, GPU-Based Training, Memory Efficiency, Industry-Scale Problems, Resource Constraints, Evaluation Methodology, System Design, Activation Compression. (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/784/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Zillow: Volume Governing for Email and Push Messages (2022)</h3>
    <p><strong>Authors:</strong> Ruomeng Xu, Shruti Kamath, Balasubramanian Thiagarajan, Eric Paul Nichols</p>
    <p>This talk describes the system used at Zillow to govern the quantity of email and push messages sent to users. Emphasis is given to practical issues and lessons learned in running the system in production.</p>
    <p><strong>Categories:</strong> Communication Channels, Email Management, Push Notifications, Volume Control, User Engagement, System Design, Production Systems, Best Practices, Monitoring, Real-World Applications, Zillow (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/841/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>V-Elliot: Design, Evaluate and Tune Visual Recommender Systems (2021)</h3>
    <p><strong>Authors:</strong> Claudio Pomo, Felice Antonio Merra, Alejandro Bellogin, Vito Walter Anelli, Daniele Malitesta, Antonio Ferrara, Francesco M Donini, Tommaso Di Noia</p>
    <p>The paper introduces Visual-Elliot (V-Elliot), a reproducibility framework for Visual Recommendation systems (VRSs) based on Elliot. framework provides the widest set of VRSs compared to other recommendation frameworks in the literature (i.e., 6 state-of-the-art models which have been commonly employed as baselines in recent works). The framework pipeline spans from the dataset preprocessing and item visual features loading to easily train and test complex combinations of visual models and evaluation settings. V-Elliot provides an extended set of features to ease the design, testing, and integration of novel VRSs into V-Elliot. The framework exploits of dataset filtering/splitting functions, 40 evaluation metrics, five hyper-parameter optimization methods, more than 50 recommendation algorithms, and two statistical hypothesis tests. The files of this demonstration are available at: github.com/sisinflab/elliot.</p>
    <p><strong>Categories:</strong> Visual Recommender Systems, Recommender System Frameworks, Reproducibility, Baseline Models, Evaluation Metrics, Hyperparameter Optimization, Dataset Preprocessing, Statistical Tests, Open Source Tools, System Design, Framework Evaluation, Tools and Systems (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/710/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>A Low-Code Tool Supporting the Development of Recommender Systems (2021)</h3>
    <p><strong>Authors:</strong> Claudio Di Sipio, Davide Di Ruscio, Juri Di Rocco, Phuong Thanh Nguyen</p>
    <p>The design of recommender systems (RSs) to support software development encompasses the fulfillment of different steps, including data preprocessing, choice of the most appropriate algorithms, item delivery. Though RSs can alleviate the curse of information overload, existing approaches resemble black-box systems, in which the end-user is not expected to fine-tune or personalize the overall process.<br>In this work, we propose LEV4REC, a low-code environment to assist developers in designing, configuring, and delivering recommender systems. The first step supported by the proposed tool includes defining an initial model that allows for the configuration of the crucial components of the wanted RS. Then, a subsequent phase is performed to finalize the RS design, e.g., to specify configuration parameters. LEV4REC is eventually capable of generating source code for the desired RS. To evaluate the capabilities of the approach, we used LEV4REC to specify two existing RSs built on top of two different recommendation algorithms, i.e., collaborative filtering and supervised machine learning.</p>
    <p><strong>Categories:</strong> Recommender Systems, Algorithm Selection, Collaborative Filtering, Supervised Machine Learning, Low-Code Development, Software Development Tools, Code Generation, System Design (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/696/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>An Analysis Of Entire Space Multi-Task Models For Post-Click Conversion Prediction (2021)</h3>
    <p><strong>Authors:</strong> Rafael Barreto, Conor O’Brien, James Neufield, Kin Sum Liu, Jonathan J Hunt</p>
    <p>Industrial recommender systems are frequently tasked with approximating probabilities for multiple, often closely related, user actions. For example, predicting if a user will click on an advertisement and if they will then purchase the advertised product. The conceptual similarity between these tasks has promoted the use of multi-task learning: a class of algorithms that aim to bring positive inductive transfer from related tasks. Here, we empirically evaluate multi-task learning approaches with neural networks for an online advertising task. Specifically, we consider approximating the probability of post-click conversion events (installs) (CVR) for mobile app advertising on a large-scale advertising platform, using the related click events (CTR) as an auxiliary task. We use an ablation approach to systematically study recent approaches that incorporate both multitask learning and “entire space modeling” which train the CVR on all logged examples rather than learning a conditional likelihood of conversion given clicked. Based on these results we show that several different approaches result in similar levels of positive transfer from the data-abundant CTR task to the CVR task and offer some insight into how the multi-task design choices address the two primary problems affecting the CVR task: data sparsity and data bias. Our findings add to the growing body of evidence suggesting that standard multi-task learning is a sensible approach to modelling related events in real-world large-scale applications and suggest the specific multitask approach can be guided by ease of implementation in an existing system.</p>
    <p><strong>Categories:</strong> Recommender Systems, Online Advertising, Multi-Task Learning, Neural Networks, Entire Space Modeling, Evaluation Methodology, Data Sparsity, Data Bias, Mobile App Advertising, System Design (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/679/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Unbiased Ad Click Prediction for Position-aware Advertising Systems (2020)</h3>
    <p><strong>Authors:</strong> Chih-Jen Lin, Jui-Yang Hsia, Bowen Yuan, Yaxu Liu, Zhenhua Dong</p>
    <p>Click-through rate (CTR) prediction is a core problem of building advertising systems. In many real-world applications, because an ad placed in various positions has different click probabilities, the position information should be considered in both training and prediction. For such position-aware systems, existing approaches learn CTR models from clicks/not-clicks on historically displayed events by leveraging the position information in different ways. In this work, we explain that these approaches may give a heavily biased model. We first point out that in position-aware systems, two different types of selection biases coexist in displayed events. Secondly, we explain that some approaches attempting to eliminate the position effect from clicks/not-clicks may possess an additional bias. Finally, to obtain an unbiased CTR model for position-aware systems, we propose a novel counterfactual learning framework. Experiments confirm both our analysis on selection biases and the effectiveness of our proposed counterfactual learning framework.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Click-Through Rate Prediction, Selection Bias, Position-Aware Advertising, Counterfactual Learning, Machine Learning, System Design, Online Advertising, Implicit Feedback, Real World Applications, Evaluation Metrics (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/558/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Auto-Surprise: An Automated Recommender-System (AutoRecSys) Library with Tree of Parzens Estimator (TPE) Optimization (2020)</h3>
    <p><strong>Authors:</strong> Rohan Anand, Joeran Beel</p>
    <p>We introduce Auto-Surprise1, an automated recommender system library. Auto-Surprise is an extension of the Surprise recommender system library and eases the algorithm selection and configuration process. Compared to an out-of-the-box Surprise library, without hyper parameter optimization, AutoSurprise performs better, when evaluated with MovieLens, Book Crossing and Jester datasets. It may also result in the selection of an algorithm with significantly lower runtime. Compared to Surprise’s grid search, Auto-Surprise performs equally well or slightly better in terms of RMSE, and is notably faster in finding the optimum hyperparameters.</p>
    <p><strong>Categories:</strong> Automated Algorithm Selection, Hyperparameter Tuning, System Design, RMSE, Computational Efficiency, Performance Comparison, TPE Optimization, Movies, Books, Recommendation Quality, Scalability (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/597/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>From Preference into Decision Making: Modeling User Interactions in Recommender Systems (2019)</h3>
    <p><strong>Authors:</strong> Gediminas Adomavicius, Qian Zhao, Martijn C. Willemsen, F. Maxwell Harper, Joseph A. Konstan</p>
    <p>User-system interaction in recommender systems involves three aspects: temporal browsing (viewing recommendation lists and/or searching/filtering), action (performing actions on recommended items, e.g., clicking, consuming) and inaction (neglecting or skipping recommended items). Modern recommenders build machine learning models from recordings of such user interaction with the system, and in doing so they commonly make certain assumptions (e.g., pairwise preference orders, independent or competitive probabilistic choices, etc.). In this paper, we set out to study the effects of these assumptions along three dimensions in eight different single models and three associated hybrid models on a user browsing data set collected from a real-world recommender system application. We further design a novel model based on recurrent neural networks and multi-task learning, inspired by Decision Field Theory, a model of human decision making. We report on precision, recall, and MAP, finding that this new model outperforms the others.</p>
    <p><strong>Categories:</strong> User Interaction Modeling, Decision Making, Recommender Systems, Evaluation Metrics (Precision, Recall), Recurrent Neural Networks, Multi-Task Learning, Hybrid Models, Real-World Applications, A/B Testing, System Design, Machine Learning Approaches, Cold Start (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/475/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Recommending What Video to Watch Next: A Multitask Ranking System (2019)</h3>
    <p><strong>Authors:</strong> Lichan Hong, Ed Chi, Maheswaran Sathiamoorthy, Li Wei, Aditee Kumthekar, Aniruddh Nath, Xinyang Yi, Zhe Zhao, Shawn Andrews, Jilin Chen</p>
    <p>In this paper, we introduce a large scale multi-objective ranking system for recommending what video to watch next on an industrial video sharing platform. The system faces many real-world challenges, including the presence of multiple competing ranking objectives, as well as implicit selection biases in user feedback. To tackle these challenges, we explored a variety of soft-parameter sharing techniques such as Multi-gate Mixture-of-Experts so as to efficiently optimize for multiple ranking objectives. Additionally, we mitigated the selection biases by adopting a Wide & Deep framework. We demonstrated that our proposed techniques can lead to substantial improvements on recommendation quality on one of the world’s largest video sharing platforms.</p>
    <p><strong>Categories:</strong> Video Recommendations, Multi-Objective Optimization, Implicit Feedback, Algorithm Design, Model Architecture, Real-World Applications, Recommendation Quality, Multi-Task Learning, Bias Mitigation, System Design, Platform-Specific (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/458/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>With a little help from my friends: use of recommendations at school (2019)</h3>
    <p><strong>Authors:</strong> Theo Huibers, Emiliana Murgia, Maria Soledad Pera, Monica Landoni</p>
    <p>In this exploratory paper, we study the usage of recommendations by and for children (ages 9 to 11) in an educational setting. From our preliminary analysis, it becomes apparent that recommender systems (RS) could provide extra support to and help children successfully complete inquiry tasks. Nonetheless, children have difficulty in recognizing the role of RS, in terms of aiding information discovery for classroom assignments. Findings from our study set a foundation that can inform future design and development of RS for children that support classroom-related work.</p>
    <p><strong>Categories:</strong> Education, Child Development, Recommender Systems, Educational Technology, User Experience, Human-Computer Interaction, School Applications, Information Discovery, System Design (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/526/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>