<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui primary button" style="margin: 5px;"
             href="/recsys-recommender/">Video Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reinforcement-learning/">Reinforcement Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/evaluation-methods/">Evaluation Methods</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/real-world-applications/">Real-world Applications</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Bridging the Gap: Unpacking the Hidden Challenges in Knowledge Distillation for Online Ranking Systems (2024)</h3>
    <p><strong>Authors:</strong> Shuo Yang, Yang Liu, Nikhil Khani, Li Wei, Pendo Abbo, Aniruddh Nath, Shawn Andrews</p>
    <p>Knowledge Distillation (KD) is a powerful approach for compressing large models into smaller, more efficient models, particularly beneficial for latency-sensitive applications like recommender systems. However, current KD research predominantly focuses on Computer Vision (CV) and NLP tasks, overlooking unique data characteristics and challenges inherent to recommender systems.  This paper addresses these overlooked challenges, specifically: (1) mitigating data distribution shifts between teacher and student models, (2) efficiently identifying optimal teacher configurations within time and budgetary constraints, and (3) enabling computationally efficient and rapid sharing of teacher labels to support multiple students. We present a robust KD system developed and rigorously evaluated on multiple large-scale personalized video recommendation systems within Google. Our live experiment results demonstrate significant improvements in student model performance while ensuring consistent and reliable generation of high-quality teacher labels from continuous data streams.</p>
    <p><strong>Categories:</strong> Knowledge Distillation, Recommender Systems, Online Ranking, Data Distribution Shifts, Teacher-Student Models, Model Compression, Optimization Techniques, Efficient Label Sharing, Multi-Teacher Settings, Video Recommendations, Large-Scale Systems, Performance Improvement, Real-World Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1158/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>MODEM: Decoupling User Behavior for Shared-Account Video Recommendations on Large Screen Devices (2024)</h3>
    <p><strong>Authors:</strong> Jiang Li, Lantao Hu, Zhen Zhang, Xiang Feng, Yongqi Liu, Muyang Li</p>
    <p>In scenarios involving sequence recommendations on large screen devices, such as tablets or TVs, the equipment is often shared among multiple users. This sharing leads to a mixture of behaviors from different users, posing significant challenges to recommendation systems, especially when clear supervisory signals for distinguishing among users are absent. Current solutions tend to either operate in an unsupervised manner or rely on constructed supervisory signals that are not entirely reliable. Moreover, the peculiarities of short video recommendations in this context have not been thoroughly explored in existing research. In response to these challenges, this paper introduces Multi-User Contrastive Decoupling Model (MODEM), a novel short video recommendation model specifically designed for large screen devices. MODEM leverages an attention mechanism, grounded in session segmentation, to disentangle the intertwined user behavior histories. It also discriminates between the impacts of long and short viewing behaviors on short video recommendations by cross-analyzing sequences of both. Furthermore, we have developed a contrastive learning method to oversee the decoupling of user behaviors effectively. Our evaluations demonstrate noticeable improvements through both offline assessments within public datasets and online A/B testing within Kuaishou’s short video recommendation environment on large screen devices. Specifically, our online A/B tests resulted in a 0.55% increase in watch time. These results underscore MODEM’s efficacy in enhancing recommendation quality in shared account contexts.</p>
    <p><strong>Categories:</strong> Video Recommendations, Large Screen Devices, Shared Accounts, User Behavior Analysis, Attention Mechanism, Contrastive Learning, Session Segmentation, A/B Testing, Real-World Application, Beyond Accuracy, Cold Start (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1098/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>A Model-Agnostic Framework for Recommendation via Interest-aware Item Embeddings (2023)</h3>
    <p><strong>Authors:</strong> Yu Xiong, Amit Kumar Jaiswal</p>
    <p>Item representation holds significant importance in recommendation systems, which encompasses domains such as news, retail, and videos. Retrieval and ranking models utilise item representation to capture the user-item relationship based on user behaviours. While existing representation learning methods primarily focus on optimising item-based mechanisms, such as attention and sequential modelling. However, these methods lack a modelling mechanism to directly reflect user interests within the learned item representations. Consequently, these methods may be less effective in capturing user interests indirectly. To address this challenge, we propose a novel Interest-aware Capsule network (IaCN) recommendation model, a model-agnostic framework that directly learns interest-oriented item representations. IaCN serves as an auxiliary task, enabling the joint learning of both item-based and interest-based representations. This framework adopts existing recommendation models without requiring substantial redesign. We evaluate the proposed approach on benchmark datasets, exploring various scenarios involving different deep neural networks, behaviour sequence lengths, and joint learning ratios of interest-oriented item representations. Experimental results demonstrate significant performance enhancements across diverse recommendation models, validating the effectiveness of our approach.</p>
    <p><strong>Categories:</strong> Model-Agnostic Methods, Neural Networks, News Recommendations, Retail Recommendations, Video Recommendations, Item Embeddings, User Interest Modeling, Recommendation Frameworks, Deep Learning Models, Behavior Modeling (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/949/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Uncovering User Interest from Biased and Noised Watch Time in Video Recommendation (2023)</h3>
    <p><strong>Authors:</strong> Jun Xu, Guohao Cai, Zhenhua Dong, Haiyuan Zhao, Lei Zhang, Ji-Rong Wen</p>
    <p>In micro-video recommendation scenarios, watch time is commonly adopted as an indicator of users’ interest. However, watch time is not only determined by the matching of users’ interests but is affected by other factors. These factors mainly lie in two folds: on the one hand, users tend to spend more time on those charming videos with the growth of the duration (i.e., video length), named as duration bias; on the other hand, it costs people a period of time to judge whether they like the video, named as noisy watching. Consequently, the existence of duration bias and noisy watching make watch time an inadequate label for training a reliable recommendation model. Moreover, current methods focus only on the duration bias and ignore the duration noise, so they do not really uncover the user interest from watch time. In this study, we first analyze the generation mechanism of users’ watch time in a unified causal viewpoint. Unlike current methods, which only notice the duration bias in watch time, we considered the watch time as a mixture of the user’s actual interest, the duration biased watch time, and the noisy watch time. To mitigate both the duration bias and noisy watching, we propose Debiased and Denoised watch time Correction (D$^2$Co), which can be divided into two steps: First, we employ a duration-wise Gaussian Mixture Model plus frequency-weighted moving average for estimating the bias and noise terms; Then we utilize a sensitivity-controlled correction function to separate the user interest from the watch time, which is robust to the estimation error of bias and noise terms. The experiments on two public video recommendation datasets indicate the effectiveness of the proposed method.</p>
    <p><strong>Categories:</strong> Video Recommendations, Duration Bias, Noisy Watching, Algorithm Development, Data Cleaning/Preprocessing, User Interest Modeling, Training Challenges, Data Analysis, Signal Processing, Recommendation Accuracy (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/886/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Investigating Multimodal Features for Video Recommendations at Globoplay (2020)</h3>
    <p><strong>Authors:</strong> Felipe Ferreira</p>
    <p>Globoplay is Globo Group’s digital video streaming platform and offers a very diverse video content catalogue ranging from international to brazilian productions such as movies, series, soap operas, and TV programs produced by Globo Group. One of the challenges with such large and diverse content collection is its distribution to the user base in order to help our subscribers with finding relevant content that meets their expectations and to increase their engagement with the product. In this work, we show the result of a content-based recommendation approach based on multi-modal features such as visual characteristics and audio patterns found in the video content. Using techniques applied to short videos, we model it as a similarity problem based on the content of the video, where, given a video, we establish the top-n videos most similar to it in the collection. For the evaluation, we conducted a study through interviews with a group of users to understand their perception of recommendations based on audiovisual characteristics. For the future, we plan to: explore and define the best approach to combine text, audio and video features for video recommendations; explore audiovisual features with other recommendation approaches such as session based and collaborative filtering; perform AB testing in production; and evaluate the proposal impact in business metrics.</p>
    <p><strong>Categories:</strong> Multimodal Features, Content-Based Filtering, Video Recommendations, Recommendation Systems, Feature Engineering, Similarity-Based Recommendations, User Feedback, Beyond Accuracy, Real-World Applications, Media and Entertainment, Evaluation Methods (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/625/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Recommending What Video to Watch Next: A Multitask Ranking System (2019)</h3>
    <p><strong>Authors:</strong> Lichan Hong, Ed Chi, Maheswaran Sathiamoorthy, Li Wei, Aditee Kumthekar, Aniruddh Nath, Xinyang Yi, Zhe Zhao, Shawn Andrews, Jilin Chen</p>
    <p>In this paper, we introduce a large scale multi-objective ranking system for recommending what video to watch next on an industrial video sharing platform. The system faces many real-world challenges, including the presence of multiple competing ranking objectives, as well as implicit selection biases in user feedback. To tackle these challenges, we explored a variety of soft-parameter sharing techniques such as Multi-gate Mixture-of-Experts so as to efficiently optimize for multiple ranking objectives. Additionally, we mitigated the selection biases by adopting a Wide & Deep framework. We demonstrated that our proposed techniques can lead to substantial improvements on recommendation quality on one of the world’s largest video sharing platforms.</p>
    <p><strong>Categories:</strong> Video Recommendations, Multi-Objective Optimization, Implicit Feedback, Algorithm Design, Model Architecture, Real-World Applications, Recommendation Quality, Multi-Task Learning, Bias Mitigation, System Design, Platform-Specific (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/458/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Sampling-Bias-Corrected Neural Modeling for Large Corpus Item Recommendations (2019)</h3>
    <p><strong>Authors:</strong> Xinyang Yi, Lukasz Heldt, Lichan Hong, Aditee Kumthekar, Li Wei, Derek Zhiyuan Cheng, Zhe Zhao, Ji Yang, Ed Chi</p>
    <p>Many recommendation systems retrieve and score items from a very large corpus. A common recipe to handle data sparsity and power-law item distribution is to learn item representations from its content features. Apart from many content-aware systems based on matrix factorization, we consider a modeling framework using two-tower neural net, with one of the towers (item tower) encoding a wide variety of item content features. A general recipe of training such two-tower models is to optimize loss functions calculated from in-batch negatives, which are items sampled from a random mini-batch. However, in-batch loss is subject to sampling biases, potentially hurting model performance, particularly in the case of highly skewed distribution. In this paper, we present a novel algorithm for estimating item frequency from streaming data. Through theoretical analysis and simulation, we show that the proposed algorithm can work without requiring fixed item vocabulary, and is capable of producing unbiased estimation and being adaptive to item distribution change. We then apply the sampling-bias-corrected modeling approach to build a large scale neural retrieval system for YouTube recommendations. The system is deployed to retrieve personalized suggestions from a corpus with tens of millions of videos. We demonstrate the effectiveness of sampling-bias correction through offline experiments on two real-world datasets. We also conduct live A/B testings to show that the neural retrieval system leads to improved recommendation quality for YouTube.</p>
    <p><strong>Categories:</strong> Neural Networks, Two-Tower Architecture, Matrix Factorization, Recommendation Systems, Video Recommendations, Item Representation Learning, Cold Start, Scalability, Offline Experiments, A/B Testing, Streaming Data Processing, Sampling Bias Correction (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/454/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Latent Factor Representations for Cold-Start Video Recommendation (2016)</h3>
    <p><strong>Authors:</strong> Sujoy Roy, Sharat Chandra Guntuku</p>
    <p>Recommending items that have rarely/never been viewed by users is a bottleneck for collaborative filtering (CF) based recommendation algorithms. To alleviate this problem, item content representation (mostly in textual form) has been used as auxiliary information for learning latent factor representations. In this work we present a novel method for learning latent factor representation for videos based on modelling the emotional connection between user and item. First of all we present a comparative analysis of state-of-the art emotion modelling approaches that brings out a surprising finding regarding the efficacy of latent factor representations in modelling emotion in video content. Based on this finding we present a method visual-CLiMF for learning latent factor representations for cold start videos based on implicit feedback. Visual-CLiMF is based on the popular collaborative less-is-more approach but demonstrates how emotional aspects of items could be used as auxiliary information to improve MRR performance. Experiments on a new data set and the Amazon products data set demonstrate the effectiveness of visual-CLiMF which outperforms existing CF methods with or without content information.</p>
    <p><strong>Categories:</strong> Cold Start, Latent Factor Representations, Collaborative Filtering, Video Recommendations, Emotion Modeling, Recommendation Systems, Implicit Feedback, Evaluation Methods, Auxiliary Information, Collaborative Less-Is-More (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/182/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Deep Neural Networks for YouTube Recommendations (2016)</h3>
    <p><strong>Authors:</strong> Emre Sargin, Jay Adams, Paul Covington</p>
    <p>YouTube represents one of the largest scale and most sophisticated industrial recommendation systems in existence. In this paper, we describe the system at a high level and focus on the dramatic performance improvements brought by deep learning. The paper is split according to the classic two-stage information retrieval dichotomy: first, we detail a deep candidate generation model and then describe a separate deep ranking model. We also provide practical lessons and insights derived from designing, iterating and maintaining a massive recommendation system with enormous user-facing impact.</p>
    <p><strong>Categories:</strong> Deep Learning, Candidate Generation, Ranking Models, Recommendation Systems, Video Recommendations, Large-Scale Systems, Industrial Applications, User Impact, Performance Improvements (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/170/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>