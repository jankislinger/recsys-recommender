<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reproducibility/">Reproducibility</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reinforcement-learning/">Reinforcement Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/cold-start/">Cold Start</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/evaluation-methods/">Evaluation Methods</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Towards Psychologically Grounded Dynamic Preference Models (2022)</h3>
    <p><strong>Authors:</strong> Benjamin Recht, Mihaela Curmei, Dylan Hadfield-Menell, Andreas Haupt</p>
    <p>Designing recommendation systems that serve content aligned with time varying preferences requires proper accounting of the feedback effects of recommendations on human behavior and psychological condition. We argue that modeling the influence of recommendations on people’s preferences must be grounded in psychologically plausible models. We contribute a methodology for developing grounded dynamic preference models. We demonstrate this method with models that capture three classic effects from the psychology literature: Mere-Exposure, Operant Conditioning, and Hedonic Adaptation. We conduct simulation-based studies to show that the psychological models manifest distinct behaviors that can inform system design. Our study has two direct implications for dynamic user modeling in recommendation systems. First, the methodology we outline is broadly applicable for psychologically grounding dynamic preference models. It allows us to critique recent contributions based on their limited discussion of psychological foundation and their implausible predictions. Second, we discuss implications of dynamic preference models for recommendation systems evaluation and design. In an example, we show that engagement and diversity metrics may be unable to capture desirable recommendation system performance.</p>
    <p><strong>Categories:</strong> Psychological Models, Recommendation Systems, Dynamic User Modeling, Feedback Effects, Human Behavior, Mere-Exposure Effect, Operant Conditioning, Hedonic Adaptation, Simulation Studies, System Design Implications, Evaluation Metrics, Engagement Metrics, Diversity Metrics, Methodology Development (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/783/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Identifying New Podcasts with High General Appeal Using a Pure Exploration Infinitely-Armed Bandit Strategy (2022)</h3>
    <p><strong>Authors:</strong> Hugues Bouchard, Javed Aslam, Kevin Jamieson, Maryam Aziz, Alice Y. Wang, Jesse Anderton</p>
    <p>Podcasting is an increasingly popular medium for entertainment and discourse around the world, with tens of thousands of new podcasts released on a monthly basis. We consider the problem of identifying from these newly-released podcasts those with the largest potential audiences so they can be considered for personalized recommendation to users. We first study and then discard a supervised approach due to the inadequacy of either content or consumption features for this task, and instead propose a novel non-contextual bandit algorithm in the fixed-budget infinitely-armed pure-exploration setting. We demonstrate that our algorithm is well-suited to the best-arm identification task for a broad class of arm reservoir distributions, out-competing a large number of state-of-the-art algorithms. We then apply the algorithm to identifying podcasts with broad appeal in a simulated study, and show that it efficiently sorts podcasts into groups by increasing appeal while avoiding the popularity bias inherent in supervised approaches.</p>
    <p><strong>Categories:</strong> Multi-Armed Bandits, Pure Exploration, Podcasts, Entertainment, Recommendation Systems, Cold Start, Resource Allocation, Best Arm Identification, Simulation Studies, Algorithm Comparison, Mitigating Bias, Beyond Accuracy Evaluation (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/766/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Preference Elicitation for Narrowing the Recommended List for Groups (2014)</h3>
    <p><strong>Authors:</strong> Lihi Naamani-Dery, Meir Kalech, Bracha Shapira, Lior Rokach</p>
    <p>A group may appreciate recommendations on items that fit their joint preferences. When the members’ actual preferences are unknown, a recommendation can be made with the aid of collaborative filtering methods. We offer to narrow down the recommended list of items by eliciting the users’ actual preferences. Our final goal is to output top-k preferred items to the group out of the top-N recommendations provided by the recommender system (k < N), where one of the items is a necessary winner. We propose an iterative preference elicitation method, where users are required to provide item ratings per request. We suggest a heuristic that attempts to minimize the preference elicitation effort under two aggregation strategies. We evaluate our methods on real-world Netflix data as well as on simulated data which allows us to study different cases. We show that preference elicitation effort can be cut in up to 90% while preserving the most preferred items in the narrowed list.</p>
    <p><strong>Categories:</strong> Group Recommendations, Preference Elicitation, Collaborative Filtering, Iterative Methods, User Ratings, Real-World Applications, Simulation Studies, Heuristic Methods, Aggregation Strategies (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/50/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>