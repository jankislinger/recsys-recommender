<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/explainability/">Explainability</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reproducibility/">Reproducibility</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/offline-evaluation/">Offline Evaluation</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/e-commerce/">E-commerce</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Enhancing Cross-Domain Recommender Systems with LLMs: Evaluating Bias and Beyond-Accuracy Measures (2024)</h3>
    <p><strong>Authors:</strong> Thomas Elmar Kolb</p>
    <p>The research domain of recommender systems is rapidly evolving. Initially, optimization efforts focused primarily on accuracy. However, recent research has highlighted the importance of addressing bias and beyond-accuracy measures such as novelty, diversity, and serendipity. With the rise of multi-domain recommender systems, the need to re-examine bias and beyond-accuracy measures in cross-domain settings has become crucial. Traditional methods face challenges such as cold-start problems, which can potentially be mitigated by leveraging LLMs. This proposed work investigates how LLM-based recommendation methods can enhance cross-domain recommender systems, focusing on identifying, measuring, and mitigating bias while evaluating the impact of beyond-accuracy measures. We aim to provide new insights by comparing traditional and LLM-based systems within a real-world environment encompassing the domains of news, books, and various lifestyle areas. Our research seeks to address the outlined gaps and develop effective evaluation strategies for the unique challenges posed by LLMs in cross-domain recommender systems.</p>
    <p><strong>Categories:</strong> Cross-Domain Recommender Systems, Large Language Models (LLMs), Bias, Novelty, Diversity, Serendipity, Beyond Accuracy, Cold Start Problem, News Domain, Books Domain, Lifestyle Domain, Real-World Applications, Traditional Recommenders, Neural Networks, Multi-Domain Evaluation, Enhancing Recommender Systems (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1137/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Enhancing Privacy in Recommender Systems through Differential Privacy Techniques (2024)</h3>
    <p><strong>Authors:</strong> Angela Di Fazio</p>
    <p>Recommender systems have become essential tools for addressing information overload in the digital age. However, the collection and usage of user data for personalized recommendations raise significant privacy concerns. This research focuses on enhancing privacy in recommender systems through the application of differential privacy techniques, particularly in the domain of privacy-preserving data publishing. Our study aims to address three key research questions: (1) developing standardized metrics to characterize and compare recommendation datasets in the context of privacy-preserving data publishing, (2) designing differential privacy algorithms for private data publishing that preserve recommendation quality, and (3) examining the impact of differential privacy on beyond-accuracy objectives in recommender systems. We propose to develop domain-specific metrics for evaluating the similarity between recommendation datasets, analogous to those used in other domains such as trajectory data publication. Additionally, we will investigate methods to balance the trade-off between privacy guarantees and recommendation accuracy, considering the potential disparate impacts on different user subgroups. Finally, we aim to assess the broader implications of implementing differential privacy on beyond-accuracy objectives such as diversity, popularity bias, and fairness. By addressing these challenges, our research seeks to contribute to the advancement of privacy-preserving techniques in recommender systems, facilitating the responsible and secure use of recommendation data while maintaining the utility of personalized suggestions. The outcomes of this study have the potential to significantly benefit the field by enabling the reuse of existing algorithms with minimal adjustments while ensuring robust privacy guarantees.</p>
    <p><strong>Categories:</strong> Privacy Preservation, Differential Privacy, Recommender Systems, Metrics Evaluation, Beyond Accuracy Objectives, Domain-Specific Metrics, Privacy-Preserving Data Publishing, Trade-Off Analysis, User Subgroup Impacts, Diversity, Popularity Bias, Fairness, Responsible Data Use (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1139/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Integrating the ACT-R Framework with Collaborative Filtering for Explainable Sequential Music Recommendation (2023)</h3>
    <p><strong>Authors:</strong> Christian Wallmann, Markus Schedl, Elisabeth Lex, Dominik Kowald, Marta Moscati, Markus Reiter-Haas</p>
    <p>Music listening sessions often consist of sequences including repeating tracks. Modeling such relistening behavior with models of human memory has been proven effective in predicting the next track of a session. However, these models intrinsically lack the capability of recommending novel tracks that the target user has not listened to in the past. Collaborative filtering strategies, on the contrary, provide novel recommendations by leveraging past collective behaviors but are often limited in their ability to provide explanations. To narrow this gap, we propose four hybrid algorithms that integrate collaborative filtering with the cognitive architecture ACT-R. We compare their performance in terms of accuracy, novelty, diversity, and popularity bias, to baselines of different types, including pure ACT-R, kNN-based, and neural-networks-based approaches. We show that the proposed algorithms are able to achieve the best performances in terms of novelty and diversity, and simultaneously achieve a higher accuracy of recommendation with respect to pure ACT-R models. Furthermore, we illustrate how the proposed models can provide explainable recommendations.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Music, ACT-R Framework, Collaborative Filtering, Explainability, Accuracy, Novelty, Diversity, Popularity Bias, kNN-Based Algorithms, Neural Networks, Sequential Recommendations, Real-World Applications, Hybrid Methods, Cold Start (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/919/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Measuring Commonality in Recommendation of Cultural Content: Recommender Systems to Enhance Cultural Citizenship (2022)</h3>
    <p><strong>Authors:</strong> Georgina E. M. Born, Gustavo Ferreira, Fernando Diaz, Andres Ferraro</p>
    <p>Recommender systems have become the dominant means of curating cultural content, significantly influencing the nature of individual cultural experience. While the majority of academic and industrial research on recommender systems optimizes for personalized user experience, this paradigm does not capture the ways that recommender systems impact cultural experience in the aggregate, across populations of users. Although existing novelty, diversity, and fairness studies probe how recommender systems relate to the broader social role of cultural content, they do not adequately center culture as a core concept and challenge. In this work, we introduce commonality as a new measure of recommender systems that reflects the degree to which recommendations familiarize a given user population with specified categories of cultural content. Our proposed commonality metric responds to a set of arguments developed through an interdisciplinary dialogue between researchers in computer science and the social sciences and humanities. With reference to principles underpinning non-profit, public service media (PSM) systems in democratic societies, we identify universality of address and content diversity in the service of strengthening cultural citizenship as particularly relevant goals for recommender systems delivering cultural content. Taking diversity in movie recommendation as a case study in enhancing pluralistic cultural experience, we empirically compare the performance of recommendation algorithms using commonality and existing utility, diversity, novelty, and fairness metrics. Our results demonstrate that commonality captures a property of system behavior complementary to existing metrics and suggest the need for alternative, non-personalized interventions in recommender systems oriented to strengthening cultural citizenship across populations of users. In this way, commonality contributes to a growing body of scholarship developing ‘public good’ rationales for digital media and machine learning systems.</p>
    <p><strong>Categories:</strong> Recommender Systems, Cultural Recommendations, Commonality, Societal Implications, Public Service Media, Movies, Evaluation Metrics, Diversity, Fairness, Beyond Accuracy (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/790/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Towards Unified Metrics for Accuracy and Diversity for Recommender Systems (2021)</h3>
    <p><strong>Authors:</strong> Filip Radlinski, Javier Parapar</p>
    <p>Recommender systems evaluation has evolved rapidly in recent years. However, for offline evaluation, accuracy is the de facto standard for assessing the superiority of one method over another, with most research comparisons focused on tasks ranging from rating prediction to ranking metrics for top-n recommendation. Simultaneously, recommendation diversity and novelty have become recognized as critical to users’ perceived utility, with several new metrics recently proposed for evaluating these aspects of recommendation lists. Consequently, the accuracy-diversity dilemma frequently shows up as a choice to make when creating new recommendation algorithms.<br>We propose a novel adaptation of a unified metric, derived from one commonly used for search system evaluation, to Recommender Systems. The proposed metric combines topical diversity and accuracy, and we show it to satisfy a set of desired properties that we formulate axiomatically. These axioms are defined as fundamental constraints that a good unified metric should always satisfy. Moreover, beyond the axiomatic analysis, we present an experimental evaluation of the metric with collaborative filtering data. Our analysis shows that the metric respects the desired theoretical constraints and behaves as expected when performing offline evaluation.</p>
    <p><strong>Categories:</strong> Evaluation Metrics, Accuracy, Diversity, Recommender Systems, Collaborative Filtering, Combined Metrics, Recommendation Lists, User Perceived Utility, Offline Evaluation, Accuracy-Diversity Dilemma, Application (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/667/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>User Bias in Beyond-Accuracy Measurement of Recommendation Algorithms (2021)</h3>
    <p><strong>Authors:</strong> Ningxia Wang, Li Chen</p>
    <p>There are various biases in recommender systems. Recognizing biases, as well as unfairness caused by problematic biases, is the first step of system optimization. Related studies on algorithmic biases are mainly from the perspective of either items or users. For the latter (we call it “algorithmic user bias”), existing works have considered algorithms’ accuracy performances measured by accuracy metrics like RMSE. However, algorithmic user biases in beyond-accuracy measurements have rarely been studied, even though beyond-accuracy oriented recommendation algorithms have been increasingly investigated, with the purpose of breaking through the personalization limits of traditional accuracy-oriented algorithms (such as the typical “filter bubble” phenomenon). To fill in the research gap, in this work, we employ a large-scale survey dataset collected from a commercial platform, in which more than 11,000 users’ ratings on the recommendation’s 5 performance objectives (i.e., relevance, diversity, novelty, unexpectedness, and serendipity) and 8 kinds of user characteristics (i.e., gender, age, big-5 personality traits, and curiosity) are available. We study user biases of four algorithms (i.e., HOT, Rel-CF, Nov-CF, and Ser-CF) in terms of those five measurements between user groups of the eight user characteristics. We further look into users’ behavior patterns like the preference of using more positive ratings, in order to interpret the observed biases. Finally, based on the observed algorithmic user bias and users’ behavior patterns, we analyze the possible factors leading to the biases and recognize problematic biases that may lead to unfairness.</p>
    <p><strong>Categories:</strong> Algorithmic Bias, User Bias, Beyond Accuracy, Recommendation Algorithms, Algorithm Evaluation, User Characteristics, Fairness, Survey Methods, Diversity, Personalization (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/669/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Sparse Feature Factorization for Recommender Systems with Knowledge Graphs (2021)</h3>
    <p><strong>Authors:</strong> Antonio Ferrara, Alberto Carlo Maria Mancino, Vito Walter Anelli, Tommaso Di Noia</p>
    <p>Deep Learning and factorization-based collaborative filtering recommendation models have undoubtedly dominated the scene of recommender systems in recent years. However, despite their outstanding performance, these methods require a training time proportional to the size of the embeddings and it further increases when also side information is considered for the computation of the recommendation list. In fact, in these cases we have that with a large number of high-quality features, the resulting models are more complex and difficult to train. This paper addresses this problem by presenting KGFlex: a sparse factorization approach that grants an even greater degree of expressiveness. To achieve this result, KGFlex analyzes the historical data to understand the dimensions the user decisions depend on (e.g., movie direction, musical genre, nationality of book writer). KGFlex represents each item feature as an embedding and it models user-item interactions as a factorized entropy-driven combination of the item attributes relevant to the user. KGFlex facilitates the training process by letting users update only those relevant features on which they base their decisions. In other words, the user-item prediction is mediated by the user’s personal view that considers only relevant features. An extensive experimental evaluation shows the approach’s effectiveness, considering the recommendation results’ accuracy, diversity, and induced bias. The public implementation of KGFlex is available at https://split.to/kgflex.</p>
    <p><strong>Categories:</strong> Sparse Feature Factorization, Recommender Systems, Knowledge Graphs, Machine Learning, Movies, Music, Embeddings, Relevant Features, Model Complexity, Accuracy, Diversity, Bias (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/661/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Values of Exploration in Recommender Systems (2021)</h3>
    <p><strong>Authors:</strong> Mohit Sharma, Ya Le, Yuyan Wang, Minmin Chen, Ed Chi, Can Xu, Lee Richardson</p>
    <p>Reinforcement Learning (RL) has been sought after to bring next-generation recommender systems to further improve user experience on recommendation platforms. While the exploration-exploitation tradeoff is the foundation of RL research, the value of exploration in (RL-based) recommender systems is less well understood. Exploration, commonly seen as a tool to reduce model uncertainty in regions of sparse user interaction/feedback, is believed to cost user experience in the short term, while the indirect benefit of better model quality arrives at a later time. We focus on another aspect of exploration, which we refer to as user exploration to help discover new user interests, and argue it can improve user experience even in the more imminent term.<br>We examine the role of user exploration in changing different facets of recommendation quality that more directly impact user experience. To do so, we introduce a series of methods inspired by exploration research in RL to increase user exploration in an RL-based recommender system, and study their effect on the end recommendation quality, more specifically, on accuracy, diversity, novelty and serendipity. We propose a set of metrics to measure (RL based) recommender systems in these four aspects and evaluate the impact of exploration-induced methods against these metrics. In addition to the offline measurements, we conduct live experiments on an industrial recommendation platform serving billions of users to showcase the benefit of user exploration. Moreover, we use conversion of casual users to core users as an indicator of the holistic long-term user experience and study the values of user exploration in helping platforms convert users. Through offline analyses and live experiments, we study the correlation between these four facets of recommendation quality and long term user experience, and connect serendipity to improved long term user experience.</p>
    <p><strong>Categories:</strong> Reinforcement Learning, Exploration-Exploitation Tradeoff, Recommender Systems, User Experience, Serendipity, Novelty, Diversity, Evaluation Metrics, Real World Applications, Long Term User Experience (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/673/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Using Conceptual Incongruity as a Basis for Making Recommendations (2020)</h3>
    <p><strong>Authors:</strong> Nisheeth Srivastava, Tushar Shandhilya</p>
    <p>We evaluate the possibility of using within-item measures of meta-data similarity to improve recommendation rankings along psychologically salient dimensions of incongruity and creativity. Our approach contrasts with recently developed methods at introducing diversity into recommendations which rely on across-item measurements of dissimilarity, while sharing several formal and algorithmic elements. We show that semantic distance based operationalizations of psychological constructs show substantial correlation with empirical data. We further show that incongruity predicts variability in satisfaction as measured by movie ratings in a large corpus. Empirical results from a two month-long user study demonstrate that incongruity-based recommendations attract considerably more interaction from users, and users expressed significantly greater satisfaction given these recommendations. Based on these observations, we propose that using incongruity to diversify recommendations may be useful in expanding recommendation repertoires along interesting psychological dimensions, complementing relevance-based search.</p>
    <p><strong>Categories:</strong> Incongruity, Creativity, Psychology, Recommendation Systems, Diversity, Methodology, Evaluation Metrics, Real-World Applications, User Interaction, Recommendation Techniques (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/585/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Do Channels Matter?: Illuminating Interpersonal Influence on Music Recommendations (2020)</h3>
    <p><strong>Authors:</strong> Minju Park, So Yeon Park, Kyogu Lee, Hyun Jeong Kim</p>
    <p>Researchers and service providers have focused on leveraging social information acquired from interactions between users to improve the accuracy of system recommendations. However, few have explained the characteristics of music recommendations through interpersonal relationships. To investigate how interpersonal relationships affect users’ evaluation of music recommendation, we conducted a survey-based study that compared two types of recommendation channels—interpersonal (i.e., from friends) and non-interpersonal (i.e., from systems). We found that relevance was evaluated higher in music recommended from non-interpersonal channels on average, while diversity, novelty, and serendipity were higher in interpersonal channels. Non-interpersonal channels surpassed interpersonal channels in terms of convenience, frequency, and adoption rate. These results illustrate that interpersonal and non-interpersonal channels have different strengths and that digital streaming platforms, which have mainly provided system recommendations thus far, need to better support interpersonal channels for richer user experience.</p>
    <p><strong>Categories:</strong> Recommendation Channels, Social Recommendations, Interpersonal Relationships, User Experience, Evaluation of Recommendations, Diversity, Serendipity, Relevance, Digital Platforms, User-Centric Design. (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/607/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Explanation Chains: Recommendations by Explanation (2017)</h3>
    <p><strong>Authors:</strong> Derek Bridge, Arpit Rana</p>
    <p>Given a set of candidate items, Recommendation by Explanation constructs a justification for recommending each item, in the form of what we call an Explanation Chain, and then recommends those candidates that have the best explanations. By unifying recommendation and explanation, this approach enables us to find relevant recommendations with explanations that have a high degree of both fidelity and interpretability. Experimental results on a movie recommendation dataset show that our approach also provides sets of recommendations that have a high degree of serendipity, low popularity-bias and high diversity.</p>
    <p><strong>Categories:</strong> Explanation-Based Recommendations, Movies, Fidelity, Interpretability, Serendipity, Popularity Bias, Diversity, Explanation Chains, Beyond Accuracy, Recommendation by Explanation (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/300/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>A Robust Model for Paper-Reviewer Assignment (2014)</h3>
    <p><strong>Authors:</strong> Xiang Liu, Nasir Memon, Torsten Suel</p>
    <p>Automatic expert assignment is a common problem encountered in both industry and academia. For example, for conference program chairs and journal editors, in order to collect “good” judgments for a paper, it is necessary for them to assign the paper to the most appropriate reviewers. Choosing appropriate reviewers of course includes a number of considerations such as expertise and authority, but also diversity and avoiding conflicts. In this paper, we explore the expert retrieval problem and implement an automatic paper-reviewer recommendation system that considers aspects of expertise, authority, and diversity. In particular, a graph is first constructed on the possible reviewers and the query paper, incorporating expertise and authority information. Then a Random Walk with Restart (RWR) model is employed on the graph with a sparsity constraint, incorporating diversity information. Extensive experiments on two reviewer recommendation benchmark datasets show that the proposed method obtains performance gains over the state-of-the-art reviewer recommendation systems in terms of expertise, authority, diversity, and, most importantly, relevance as judged by human experts.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Reviewer Recommendation, Graph-Based Methods, Machine Learning, Random Walk with Restart (RWR), Expertise, Authority, Diversity, Relevance, Academic Context, Assignment Problem, Fairness (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/4/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>