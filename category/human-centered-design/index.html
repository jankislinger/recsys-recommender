<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/explainability/">Explainability</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/real-world-applications/">Real-world Applications</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reinforcement-learning/">Reinforcement Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/evaluation-methods/">Evaluation Methods</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/cold-start/">Cold Start</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>AI-based Human-Centered Recommender Systems: Empirical Experiments and Research Infrastructure (2024)</h3>
    <p><strong>Authors:</strong> Ruixuan Sun</p>
    <p>This is a dissertation plan built around human-centered empirical experiments evaluating recommender systems (RecSys). We see this as an important research theme since many AI-based RecSys algorithmic studies lack real human assessment. Therefore, we do not know how they work in the wild that only human experiments can tell us. We split this extended abstract into two parts — 1) A series of individual studies focusing on open questions about different human values or recommendation algorithms. Our completed works include user control over content diversity, user appreciation on DL-RecSys algorithms, and human-LLMRec interaction study. We also propose three future works to understand news recommendation depolarization, personalized news podcast, and interactive user representation; 2) An experimentation infrastructure named POPROX. As a personalized news recommendation platform, it aims to support the longitudinal study needs from the general AI and RecSys research community.</p>
    <p><strong>Categories:</strong> AI-based Recommender Systems, Human-Centered Design, Empirical Experiments, Deep Learning Algorithms, Large Language Models, News Recommendations, Content Diversity, Personalization, Longitudinal Studies, Media, Research Infrastructure, User Interaction (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1129/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Towards Companion Recommenders Assisting Users’ Long-Term Journeys (2023)</h3>
    <p><strong>Authors:</strong> Minmin Chen, Konstantina Christakopoulou</p>
    <p>Nowadays, with the abundance of the internet content, users expect the recommendation platforms to not only help them with one-off decisions and short-term tasks, but to also support their persistent and overarching interest journeys, including their real-life goals that last days, months or even years. In order for recommender systems to truly assist users through their real-life journeys, they need to first be able to understand and reason about interests, needs, and goals users want to pursue; and then plan taking those into account. However, the task presents several challenges. In this talk, we will present the key steps and elements needed to tackle the problem — particularly (1) user research for interest journeys; (2) personalized and interpretable user profiles; (3) adapting large language models, and other foundational models, for better user understanding; (4) better planning at a macro-level through reinforcement learning and reason-and-act conversational agents; (5) novel journey-powered front end user experiences, allowing for more user control. We hope that the talk will help inspire other researchers, and will pave the way towards companion recommenders that can truly assist the users throughout their interest journeys.</p>
    <p><strong>Categories:</strong> Companion Recommenders, Long-term Goals, User Journeys, Personalized Recommendations, Large Language Models, Foundational Models, Reinforcement Learning, Conversational Agents, Reasoning Mechanisms, Interest Journey Modeling, User Control, Human-Centered Design, Sustained Engagement (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1019/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Developing a Human-Centered Framework for Transparency in Fairness-Aware Recommender Systems (2022)</h3>
    <p><strong>Authors:</strong> Jessie J. Smith</p>
    <p>Though recommender systems fundamentally rely on human input and feedback, human-centered research in the RecSys discipline is lacking. When recommender systems aim to treat users more fairly, misinterpreting user objectives could lead to unintentional harm, whether or not fairness is part of the aim. When users seek to understand recommender systems better, a lack of transparency could act as an obstacle for their trust and adoption of the platform. Human-centered machine learning seeks to design systems that understand their users, while simultaneously designing systems that the users can understand. In this work, I propose to explore the intersection of transparency and user-system understanding through three phases of research that will result in a Human-Centered Framework for Transparency in Fairness-Aware Recommender Systems.</p>
    <p><strong>Categories:</strong> Recommender Systems, Fairness-Aware Recommendation, Transparency in Recommendations, Human-Centered Design, User-System Interaction, Trust in Recommendations, Ethical AI, Explainable AI (XAI), User Trust (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/815/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>A Human Perspective on Algorithmic Similarity (2020)</h3>
    <p><strong>Authors:</strong> Zachary Schendel</p>
    <p>In the Netflix user interface (UI), when a row or UI element is named “Because you Watched...”, “More Like This”, or “Because you added to your list”, the overarching goal is to recommend a movie or TV show that a member might like based on the fact that they took a meaningful action on a source item. We have employed similar recommendations in many UI elements: on the homepage as a row of recommendations, after you click into a title, or as a piece of information about why a member should watch a title. <br>From an algorithmic perspective, there are many ways to define a “successful” similar recommendation. We sought to broaden the definition of success. To this end, the Consumer Insights team recently completed a suite of research projects to explore the intricacies of member perceptions of similar recommendations. The Netflix Consumer Insights team employs qualitative (e.g., in-depth interviews) and quantitative (e.g., surveys) research methods, interfacing directly with Netflix members to uncover pain points that can inspire new product innovation. The research concluded that, while the typical member believes movies are broadly similar when they share a common genre or theme, similarity is more complex, nuanced, and personal than we might have imagined. The vernacular we use in the UI implies that there should be at least some kind of relationship between the source item and the recommendations that follow. Many of our similar recommendations felt “out of place”, mostly because the relationship between the source item and the recommendation was unclear or absent. When similar recommendations tell a completely misleading, incorrect, or confusing story, member trust can be broken.<br>We will structure the presentation around three new insights that our research found to have an influence on the perception of similarity in the context of Netflix as well as the research methods used to uncover those insights. First, the reason a member loves a given movie will vary. For example, do you want to watch other baseball movies like Field of Dreams, or would you prefer other romances like Field of Dreams? Second, members are more or less flexible about how similar a recommendation actually needs to be depending on the properties of and their interactions with the canvas containing the recommendation. For example, a Because You Watched row on the homepage implies vaguer similarity while a More Like This gallery behind a click into the source item implies stricter similarity. Finally, even when we held the UI element constant, we found that similar recommendations are only valuable in some contexts. After finishing a movie, a member might prefer a similar recommendation one day and a change of pace the next. Research methods discussed will include single-arrangement Inverse Multi-Dimensional Scaling [1], survey experimentation, and ways to apply qualitative research to improve algorithmic recommendations.</p>
    <p><strong>Categories:</strong> Recommendation Systems, User Interface (UI) Design, Algorithmic Similarity, User Experience (UX), Qualitative Research Methods, Quantitative Research Methods, Human-Centered Design, Content Recommendations, Consumer Insights, Streaming Services, Evaluation Methods, Personalization in Recommendations (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/619/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Users in the Loop: A Psychologically-Informed Approach to Similar Item Retrieval (2019)</h3>
    <p><strong>Authors:</strong> Amy A. Winecoff, Matthew Graham, Florin Brasoveanu, Pearce Washabaugh, Bryce Casavant</p>
    <p>Recommender systems (RS) often leverage information about the similarity between items’ features to make recommendations. Yet, many commonly used similarity functions make mathematical assumptions such as symmetry (i.e., Sim(a,b) = Sim(b,a)) that are inconsistent with how humans make similarity judgments. Moreover, most algorithm validations either do not directly measure users’ behavior or fail to comply with methodological standards for psychological research. RS that are developed and evaluated without regard to users’ psychology may fail to meet users’ needs. To provide recommendations that do meet the needs of users, we must: 1) develop similarity functions that account for known properties of human cognition, and 2) rigorously evaluate the performance of these functions using methodologically sound user testing. Here, we develop a framework for evaluating users’ judgments of similarity that is informed by best practices in psychological research methods. Employing users’ fashion item similarity judgments collected using our framework, we demonstrate that a psychologically-informed similarity function (i.e., Tversky contrast model) outperforms a psychologically-naive similarity function (i.e., Jaccard similarity) in predicting users’ similarity judgments.</p>
    <p><strong>Categories:</strong> Recommender Systems, Psychological Models, Similarity Functions, User Behavior Analysis, Evaluation Methods, Framework Development, Human-Centered Design, Recommendation Accuracy (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/466/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Algorithms Aside: Recommendation As The Lens Of Life (2016)</h3>
    <p><strong>Authors:</strong> Marko Tkalcic, Paolo Cremonesi, Anna Zacchi, Ayse Göker, Daniel Kohlsdorf, Davide Malagoli, Jean-Yves Le Moine, Martha Larson, Francesco Ricci, Domonkos Tikk, Andreas Lommatzsch, Thuy Ngoc Nguyen, Tamas Motajcsek, Jasminko Novak, Kristaps Dobrajs, Franca Garzotto, Omar Alonso, Andrew Demetriou, Frank Hopfgartner, Mario Scriminaci</p>
    <p>In this position paper, we take the experimental approach of putting algorithms aside, and reflect on what recommenders would be for people if they were not tied to technology. By looking at some of the shortcomings that current recommenders have fallen into and discussing their limitations from a human point of view, we ask the question: if freed from all limitations, what should, and what could, RecSys be? We then turn to the idea that life itself is the best recommender system, and that people themselves are the query. By looking at how life brings people in contact with options that suit their needs or match their preferences, we hope to shed further light on what current RecSys could be doing better. Finally, we look at the forms that RecSys could take in the future. By formulating our vision beyond the reach of usual considerations and current limitations, including business models, algorithms, data sets, and evaluation methodologies, we attempt to arrive at fresh conclusions that may inspire the next steps taken by the community of researchers working on RecSys.</p>
    <p><strong>Categories:</strong> Future Directions, Human-Centered Design, Ethical Considerations, Philosophy of Recommendations, Personalization Beyond Algorithms, Visionary Concepts, Societal Impact, Business Models in Recommendations, Reflections on Recommender Systems (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/217/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Recommender Systems for Self-Actualization (2016)</h3>
    <p><strong>Authors:</strong> Saadhika Sivakumar, Daricia Wilkinson, Bart P. Knijnenburg</p>
    <p>Every day, we are confronted with an abundance of decisions that require us to choose from a seemingly endless number of choice options. Recommender systems are supposed to help us deal with this formidable task, but some scholars claim that these systems instead put us inside a “Filter Bubble” that severely limits our perspectives. This paper presents a new direction for recommender systems research with the main goal of supporting users in developing, exploring, and understanding their unique personal preferences.</p>
    <p><strong>Categories:</strong> Recommender Systems, Personalization, Filter Bubbles, Diversity of Recommendations, Human-Centered Design, Personal Preference Development, User Modeling, Beyond Accuracy, User-Centric Design, Human-Computer Interaction, Theoretical Research (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/230/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>