<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui primary button" style="margin: 5px;"
             href="/recsys-recommender/">Multi-Task Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/bias-mitigation/">Bias Mitigation</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reinforcement-learning/">Reinforcement Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/real-world-applications/">Real-world Applications</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Co-optimize Content Generation and Consumption in a Large Scale Video Recommendation System (2024)</h3>
    <p><strong>Authors:</strong> Yuening Li, Mingyan Gao, Qingyun Liu, Sourabh Bansod, Shuchao Bi, Liang Liu, Yaping Zhang, Zhen Zhang</p>
    <p>Multi-task prediction models and value models are the de-facto standard ranking components in modern large-scale content recommendation systems. However, they are typically optimized to model users’ passive consumption behaviors, and rank content in a way to grow only consumption-centric values. In this talk, we discuss the key insight that it is possible to model sparse participatory content-generation actions as well and grow ecosystem value through a new ranking system. We made the following key technical contributions in this system: (1) introducing ranking for content generation based on a categorization of user participation actions of different sparsity, including proxy intent action or access point clicks. (2) improving sparse task prediction quality and stability by causal task relationship modeling, conditional loss modeling and ResNet based shared bottom network. (3) personalizing the value model to minimize conflicts between different values, through e.g. ranking inspiring content higher for users who actively generate content. (4) conducting systematic evaluation of proposed approach in a large short-form video UGC (User-Generated Content) platform.</p>
    <p><strong>Categories:</strong> Multi-Task Learning, Video Recommendation, User-Generated Content, Content Generation, Large-Scale Systems, Evaluation Metrics, Causal Modeling, Network Architecture, User Participation, Scalability, Content Creation, User-Centric Design (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1156/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Bridging Search and Recommendation in Generative Retrieval: Does One Task Help the Other? (2024)</h3>
    <p><strong>Authors:</strong> Marco De Nadai, Ali Vardasbi, Enrico Palumbo, Hugues Bouchard, Gustavo Penha</p>
    <p>Generative retrieval for search and recommendation is a promising paradigm for retrieving items, offering an alternative to traditional methods that depend on external indexes and nearest-neighbor searches. Instead, generative models directly associate inputs with item IDs. Given the impressive capabilities of Large Language Models (LLMs), these generative systems play a crucial role in centralizing a variety of Information Retrieval (IR) tasks in a single model that performs tasks such as query understanding, retrieval, recommendation, explanation, re-ranking, and response generation. Despite the growing interest in such a unified generative approach for IR systems, the advantages of using a single, multi-task model over multiple specialized models are not well established in the literature. This paper investigates whether and when such a unified approach can outperform task-specific models in the IR tasks of search and recommendation, broadly co-existing in multiple industrial online platforms, such as Spotify, YouTube, and Netflix. Previous work shows that (1) the latent representations of items, learned by generative recommenders, are biased towards popularity, and (2) content-based and collaborative-filtering-based information can improve an item’s representations. Motivated by this, our study is guided by two hypotheses: [H1] the joint training regularizes the estimation of each item’s popularity, and [H2] the joint training regularizes the item’s latent representations, where search captures content-based aspects of an item and recommendation captures collaborative-filtering aspects. Our extensive experiments with both simulated and real-world data support both [H1] and [H2] as key contributors to the effectiveness improvements observed in the unified search and recommendation generative models over the single-task approaches.</p>
    <p><strong>Categories:</strong> Generative Models, Large Language Models (LLMs), Information Retrieval (IR), Search Systems, Recommendation Systems, Multi-Task Learning, Real-World Applications, Evaluation Metrics, Latent Representations, Popularity Bias, Collaborative Filtering, Content-Based Filtering, Explanation Generation, Industrial Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1030/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Utilizing Non-click Samples via Semi-supervised Learning for Conversion Rate Prediction (2024)</h3>
    <p><strong>Authors:</strong> Junhao Wang, Dongbo Huang, Shanyang Jiang, Lan Zhang, Cheng Ding, Lan Xu, Jiahui Huang</p>
    <p>Conversion rate (CVR) prediction is essential in recommendation systems, facilitating precise matching between recommended items and users’ preferences. However, the sample selection bias (SSB) and data sparsity (DS) issues pose challenges to accurate prediction. Existing works have proposed the click-through and conversion rate (CTCVR) prediction task which models samples from exposure to “click and conversion” in entire space and incorporates multi-task learning. This approach has shown efficacy in mitigating these challenges. Nevertheless, it intensifies the false negative sample (FNS) problem. To be more specific, the CTCVR task implicitly treats all the CVR labels of non-click samples as negative, overlooking the possibility that some samples might convert if clicked. This oversight can negatively impact CVR model performance, as empirical analysis has confirmed. To this end, we advocate for discarding the CTCVR task and proposing a Non-click samples Improved Semi-supErvised (NISE) method for conversion rate prediction, where the non-click samples are treated as unlabeled. Our approach aims to predict their probabilities of conversion if clicked, utilizing these predictions as pseudo-labels for further model training. This strategy can help alleviate the FNS problem, and direct modeling of the CVR task across the entire space also mitigates the SSB and DS challenges. Additionally, we conduct multi-task learning by introducing an auxiliary click-through rate prediction task, thereby enhancing embedding layer representations. Our approach is applicable to various multi-task architectures. Comprehensive experiments are conducted on both public and production datasets, demonstrating the superiority of our proposed method in mitigating the FNS challenge and improving the CVR estimation.</p>
    <p><strong>Categories:</strong> Semi-Supervised Learning, Conversion Rate Prediction, Recommendation Systems, Click-Through Rate (CTR), Sample Selection Bias, Data Sparsity, Multi-Task Learning, Non-Click Samples, False Negative Samples, Model Improvement, User Behavior Prediction, Enhanced Models (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1073/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>M3REC: A Meta-based Multi-scenario Multi-task Recommendation Framework (2023)</h3>
    <p><strong>Authors:</strong> Zerong Lan, Yingyi Zhang, Xianneng Li</p>
    <p>Users in recommender systems exhibit multi-behavior in multiple business scenarios on real-world e-commerce platforms. A crucial challenge in such systems is to make recommendations for each business scenario at the same time. On top of this, multiple predictions (e.g., Click Through Rate and Conversion Rate) need to be made simultaneously in order to improve the platform revenue. Research focus on making recommendations for several business scenarios is in the field of Multi-Scenario Recommendation (MSR), and Multi-Task Recommendation (MTR) mainly attempts to solve the possible problems in collaboratively executing different recommendation tasks. However, existing researchers have paid attention to either MSR or MTR, ignoring the integration of MSR and MTR that faces the issue of conflict between scenarios and tasks. To address the above issue, we propose a Meta-based Multi-scenario Multi-task RECommendation framework (M3REC) to serve multiple tasks in multiple business scenarios by a unified model. However, integrating MSR and MTR in a proper manner is non-trivial due to: 1) Unified representation problem: Users’ and items’ representation behave Non-i.i.d in different scenarios and tasks which takes inconsistency into recommendations. 2) Synchronous optimization problem: Tasks distribution varies in different scenarios, and a unified optimization method is needed to optimize multi-tasks in multi-scenarios. Thus, to unified represent users and items, we design a Meta-Item-Embedding Generator (MIEG) and a User-Preference Transformer (UPT). The MIEG module can generate initialized item embedding using item features through meta-learning technology, and the UPT module can transfer user preferences in other scenarios. Besides, the M3REC framework uses a specifically designed backbone network together with a task-specific aggregate gate to promote all tasks to achieve the purpose of optimizing multiple tasks in multiple business scenarios within one model. Experiments on two public datasets have shown that M3REC outperforms those compared MSR and MTR state-of-the-art methods.</p>
    <p><strong>Categories:</strong> Meta-Learning, E-commerce, Multi-Scenario Recommendation, Multi-Task Learning, Cold Start, User Representation, Beyond Accuracy, Real-world Application, Model Architecture, Multi-Task Optimization (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/911/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Multi-task Item-attribute Graph Pre-training for Strict Cold-start Item Recommendation (2023)</h3>
    <p><strong>Authors:</strong> Hao Peng, Zhiwei Liu, Chenyu You, Philip Yu, Liangwei Yang, Chen Wang, Yuwei Cao</p>
    <p>Recommendation systems suffer in the strict cold-start (SCS) scenario, where the user-item interactions are entirely unavailable. The well-established, dominating identity (ID)-based approaches completely fail to work. Cold-start recommenders, on the other hand, leverage item contents (brand, title, descriptions, etc.) to map the new items to the existing ones. However, the existing SCS recommenders explore item contents in coarse-grained manners that introduce noise or information loss. Moreover, informative data sources other than item contents, such as users’ purchase sequences and review texts, are largely ignored. In this work, we explore the role of the fine-grained item attributes in bridging the gaps between the existing and the SCS items and pre-train a knowledgeable item-attribute graph for SCS item recommendation. Our proposed framework, ColdGPT, models item-attribute correlations into an item-attribute graph by extracting fine-grained attributes from item contents. ColdGPT then transfers knowledge into the item-attribute graph from various available data sources, i.e., item contents, historical purchase sequences, and review texts of the existing items, via multi-task learning. To facilitate the positive transfer, ColdGPT designs specific submodules according to the natural forms of the data sources and proposes to coordinate the multiple pre-training tasks via unified alignment-and-uniformity losses. Our pre-trained item-attribute graph acts as an implicit, extendable item embedding matrix, which enables the SCS item embeddings to be easily acquired by inserting these items into the item-attribute graph and propagating their attributes’ embeddings. We carefully process three public datasets, i.e., Yelp, Amazon-home, and Amazon-sports, to guarantee the SCS setting for evaluation. Extensive experiments show that ColdGPT consistently outperforms the existing SCS recommenders by large margins and even surpasses models that are pre-trained on 75 – 224 times more, cross-domain data on two out of four datasets. Our code and pre-processed datasets for SCS evaluations are publicly available to help future SCS studies.</p>
    <p><strong>Categories:</strong> Cold Start, Multi-Modal Learning, Fine-Grained Item Attributes, Graph Neural Networks, Recommendation Systems, Self-Supervised Learning, Multi-Task Learning, Real-World Applications, Pre-trained Models (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/872/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>BVAE: Behavior-aware Variational Autoencoder for Multi-Behavior Multi-Task Recommendation (2023)</h3>
    <p><strong>Authors:</strong> Yang Liu, Qianzhen Rao, Weike Pan, Zhong Ming</p>
    <p>A practical recommender system should be able to handle heterogeneous behavioral feedback as inputs and has multi-task outputs ability. Although the heterogeneous one-class collaborative filtering (HOCCF) and multi-task learning (MTL) methods has been well studied, there is still a lack of targeted manner in their combined fields, i.e., Multi-behavior Multi-task Recommendation (MMR). To fill the gap, we propose a novel recommendation framework called Behavior-aware Variational AutoEncoder (BVAE), which meliorates the parameter sharing and loss minimization method with the VAE structure to address the MMR problem. Specifically, our BVAE includes address behavior-aware semi-encoders and decoders, and a target feature fusion network with a global feature filtering network, while using standard deviation to weigh loss. These modules generate the behavior-aware recommended item list via constructing better semantic feature vectors for users, i.e., from dual perspectives of behavioral preference and global interaction. In addition, we optimize our BVAE in terms of adaptability and robustness, i.e., it is concise and flexible to consume any amount of behaviors with different distributions. Extensive empirical studies on two real and widely used datasets confirm the validity of our design and show that our BVAE can outperform the state-of-the-art related baseline methods under multiple evaluation metrics.</p>
    <p><strong>Categories:</strong> Variational Autoencoder, Collaborative Filtering, Multi-Task Learning, Recommendation Systems, Multi-Behavior Recommendations, User Behavior Modeling, Empirical Evaluation, Beyond Accuracy, State-of-the-Art Comparisons, Adaptability, Robustness, Scalability, Model Efficiency, Heterogeneous Feedback (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/852/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Understanding and Modeling Passive-Negative Feedback for Short-video Sequential Recommendation (2023)</h3>
    <p><strong>Authors:</strong> Chen Gao, Yong Li, Depeng Jin, Yunzhu Pan, Kun Gai, Yang Song</p>
    <p>Sequential recommendation is one of the most important tasks in recommender systems, which aims to recommend the next interacted item with historical behaviors as input. Traditional sequential recommendation always mainly considers the collected positive feedback such as click, purchase, etc. However, in short-video platforms such as TikTok, video viewing behavior may not always represent positive feedback. Specifically, the videos are played automatically, and users passively receive the recommended videos. In this new scenario, users passively express negative feedback by skipping over videos they do not like, which provides valuable information about their preferences. Different from the negative feedback studied in traditional recommender systems, this passive-negative feedback can reflect users’ interests and serve as an important supervision signal in extracting users’ preferences. Therefore, it is essential to carefully design and utilize it in this novel recommendation scenario. In this work, we first conduct analyses based on a large-scale real-world short-video behavior dataset and illustrate the significance of leveraging passive feedback. We then propose a novel method that deploys the sub-interest encoder, which incorporates positive feedback and passive-negative feedback as supervision signals to learn the user’s current active sub-interest. Moreover, we introduce an adaptive fusion layer to integrate various sub-interests effectively. To enhance the robustness of our model, we then introduce a multi-task learning module to simultaneously optimize two kinds of feedback – passive-negative feedback and traditional randomly-sampled negative feedback. The experiments on two large-scale datasets verify that the proposed method can significantly outperform state-of-the-art approaches. The codes and collected datasets are anonymously released at https:// anonymous.4open.science/ r/ SINE-2047/ to benefit the community.</p>
    <p><strong>Categories:</strong> Passive-Negative Feedback, Short-Video Recommendation, Sequential Recommendation, User Preferences Modeling, Recommendation Systems, Passive Feedback, Negative Feedback Handling, Behavior Analysis, Content Consumption Patterns, Modeling User Interests, Multi-Task Learning, Large-Scale Datasets (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/888/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Loss Harmonizing for Multi-Scenario CTR Prediction (2023)</h3>
    <p><strong>Authors:</strong> Congcong Liu, Zhangang Lin, Changping Peng, Jingping Shao, Fei Teng, Xue Jiang, Pei Wang, Liang Shi</p>
    <p>Large-scale industrial systems often include multiple scenarios to satisfy diverse user needs. The common approach of using one model per scenario does not scale well and not suitable for minor scenarios with limited samples. An solution is to train a model on all scenarios, which can introduce domination and bias from the main scenario. MMoE-like structures have been proposed for multi-scenario prediction, but they do not explicitly address the issue of gradient unbalancing. This work proposes an adaptive loss harmonizing (ALH) algorithm for multi-scenario CTR prediction. It balances training by dynamically adjusting the learning speed, resulting in improved prediction performance. Experiments conducted on real production dataset and a rigorous A/B test prove the superiority of our method.</p>
    <p><strong>Categories:</strong> Click-Through Rate (CTR) Prediction, Multi-Scenario Prediction, Machine Learning Optimization, Large-Scale Systems, Recommendation Systems, Real-World Applications, Model Efficiency, Multi-Task Learning, Adaptive Algorithms (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1003/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Nonlinear Bandits Exploration for Recommendations (2023)</h3>
    <p><strong>Authors:</strong> Minmin Chen, Yi Su</p>
    <p>The paradigm of framing recommendations as (sequential) decision-making processes has gained significant interest. To achieve long-term user satisfaction, these interactive systems need to strikes a balance between exploitation (recommending high-reward items) and exploration (exploring uncertain regions for potentially better items). Classical bandit algorithms like Upper-Confidence-Bound and Thompson Sampling, and their contextual extensions with linear payoffs have exhibited strong theoretical guarantees and empirical success in managing the exploration-exploitation trade-off. Building efficient exploration-based systems for deep neural network powered real-world, large-scale industrial recommender systems remains under studied. In addition, these systems are often multi-stage, multi-objective and response time sensitive.  In this talk, we share our experience in addressing these challenges in building exploration based industrial recommender systems. Specifically, we adopt the Neural Linear Bandit algorithm, which effectively combines the representation power of deep neural networks, with the simplicity of linear bandits to incorporate exploration in DNN based recommender systems. We introduce  exploration capability to both the nomination and ranking stage of the industrial recommender system.  In the context of the ranking stage, we delve into the extension of this algorithm to accommodate the multi-task setup, enabling exploration in systems with multiple objectives. Moving on to the nomination stage, we will address the development of efficient bandit algorithms tailored to factorized bi-linear models. These algorithms play a crucial role in facilitating maximum inner product search, which is commonly employed in large-scale retrieval systems. We validate our algorithms and present findings from real-world live experiments.</p>
    <p><strong>Categories:</strong> Multi-Armed Bandits, Recommendation Systems, Deep Learning, Exploration, Exploitation, Neural Linear Bandit, Industrial Recommender Systems, Nomination Stage, Ranking Stage, Multi-Task Learning, Large Scale Systems, Real World Applications, Efficiency, Beyond Accuracy, Evaluation Metrics, Performance Evaluation, Algorithm Performance (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1012/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Disentangling Motives behind Item Consumption and Social Connection for Mutually-enhanced Joint Prediction (2023)</h3>
    <p><strong>Authors:</strong> Yew Soon Ong, Jie Zhang, Zhu Sun, Youchen Sun, Xiao Sha</p>
    <p>Item consumption and social connection, as common user behaviors in many web applications, have been extensively studied. However, most current works separately perform either item or social link prediction tasks, possibly with the help of the other as an auxiliary signal. Moreover, they merely consider the behaviors in a holistic manner yet neglect the multi-faceted motives behind them (e.g., watching movies to kill time or with friends; connecting with others due to friendships or colleagues). To fill the gap, we propose to disentangle the multi-faceted motives in each network, defined respectively by the two types of behaviors, for mutually- enhanced joint prediction (DMJP). Specifically, we first learn the disentangled user representations driven by motives of multi-facets in both networks. Thereafter, the mutual influence of the two networks is subtly discriminated at the facet-to-facet level. The fine-grained mutual influence, proven to be asymmetric, is then exploited to help refine user representations in both networks, with the goal of achieving a mutually-enhanced joint item and social link prediction. Empirical studies on three public datasets showcase the superiority of DMJP against state-of-the-arts (SOTAs) on both tasks.</p>
    <p><strong>Categories:</strong> User Behavior, Social Networks, Item Recommendation, Joint Modeling, Disentangled Representation Learning, Multi-Task Learning, Matrix Factorization, Recommendation Quality, Empirical Analysis, Network Dynamics (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/861/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Task Aware Feature Extraction Framework for Sequential Dependence Multi-Task Learning (2023)</h3>
    <p><strong>Authors:</strong> Hongwei Cheng, Wenfang Lin, Xuewen Tao, Mingming Ha, Qiongxu Ma, Xiaobo Guo</p>
    <p>In online recommendation, financial service, etc., the most common application of multi-task learning (MTL) is the multi-step conversion estimations. A core property of the multi-step conversion is the sequential dependence among tasks. Most existing works focus far more on the specific post-view click-through rate (CTR) and post-click conversion rate (CVR) estimations, which neglect the generalization of sequential dependence multi-task learning (SDMTL). Besides, the performance of the SDMTL framework is also deteriorated by the interference derived from implicitly conflict information passing between adjacent tasks. In this paper, a systematic learning paradigm of the SDMTL problem is established for the first time, which can transform the SDMTL problem into a general MTL problem and be applicable to more general multi-step conversion scenarios with longer conversion path or stronger task dependence. Also, the distribution dependence between adjacent task spaces is illustrated from a theoretical point of view. On the other hand, an SDMTL architecture, named Task Aware Feature Extraction (TAFE), is developed to enable dynamic task representation learning from a sample-wise view. TAFE selectively reconstructs the implicit shared information corresponding to each sample case and performs explicit task-specific extraction under dependence constraints. Extensive experiments on offline public and real-world industrial datasets, and online A/B implementations demonstrate the effectiveness and applicability of proposed theoretical and implementation frameworks.</p>
    <p><strong>Categories:</strong> Multi-Task Learning, Sequential Dependence, Click-Through Rate Prediction, Conversion Rate Estimation, Online Recommendation, Financial Services, Feature Extraction, Multi-Step Conversion, Task Representation, A/B Testing, Real-World Applications, Theoretical Analysis, Generalization, Dynamic Task Representation, Frameworks and Architectures. (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/887/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>STAN: Stage-Adaptive Network for Multi-Task Recommendation by Learning User Lifecycle-Based Representation (2023)</h3>
    <p><strong>Authors:</strong> Wenhao Zheng, Suhang Wang, Xuanji Xiao, Wanda Li</p>
    <p>Recommendation systems play a vital role in many online platforms, with their primary objective being to satisfy and retain users. As directly optimizing user retention is challenging, multiple evaluation metrics are often employed. Existing methods generally formulate the optimization of these evaluation metrics as a multi-task learning problem, but often overlook the fact that user preferences for different tasks are personalized and change over time. Identifying and tracking the evolution of user preferences can lead to better user retention. To address this issue, we introduce the concept of “user lifecycle,” consisting of multiple stages characterized by users’ varying preferences for different tasks. We propose a novel <b>St</b>age-<b>A</b>daptive <b>N</b>etwork (<b>STAN</b>) framework for modeling user lifecycle stages. STAN first identifies latent user lifecycle stages based on learned user preferences, and then employs the stage representation to enhance multi-task learning performance. Our experimental results using both public and industrial datasets demonstrate that the proposed model significantly improves multi-task prediction performance compared to state-of-the-art methods, highlighting the importance of considering user lifecycle stages in recommendation systems. Furthermore, online A/B testing reveals that our model outperforms the existing model, achieving a significant improvement of 3.05\% in staytime per user and 0.88\% in CVR. These results indicate that our approach effectively improves the overall efficiency of the multi-task recommendation system.</p>
    <p><strong>Categories:</strong> Multi-Task Learning, User Lifecycle, Recommendation Systems, Personalization, Online Experiments (A/B Test), User Retention, Model Adaptation, Staytime, Click-Through Rate (CTR), User Preference Evolution, Scalability, Industrial Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/882/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>MCM: A Multi-task Pre-trained Customer Model for Personalization (2023)</h3>
    <p><strong>Authors:</strong> Tianxin Wang, Peng Wan, Rui Luo, Jingyuan Deng</p>
    <p>Personalization plays a critical role in helping customers discover the products and contents they prefer for e-commerce stores.Personalized recommendations differ in contents, target customers, and UI. However, they require a common core capability – the ability to deeply understand customers’ preferences and shopping intents. In this paper, we introduce the MLCM (Multi-task Large pre-trained Customer Model), a large pre-trained BERT-based multi-task customer model with 10 million trainable parameters for e-commerce stores. This model aims to empower all personalization projects by providing commonly used preference scores for recommendations, customer embeddings for transfer learning, and a pre-trained model for fine-tuning. In this work, we improve the SOTA BERT4Rec framework to handle heterogeneous customer signals and multi-task training as well as innovate new data augmentation method that is suitable for recommendation task. Experimental results show that MLCM outperforms the original BERT4Rec by 17% on preference prediction tasks. Additionally, we demonstrate that the model can be easily fine-tuned to assist a specific recommendation task. For instance, after fine-tuning MLCM for an incentive based recommendation project, performance improves by 60% on the conversion prediction task and 25% on the click-through prediction task compared to the production baseline model.</p>
    <p><strong>Categories:</strong> Personalization, Recommendation Systems, Multi-Task Learning, Deep Learning, E-Commerce, Customer Modeling, Natural Language Processing, Transfer Learning, Data Augmentation, Model Fine-Tuning, Performance Improvement, Incentive-Based Recommendations, Conversion Prediction, Click-Through Rate, Real-World Applications. (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1004/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>M2TRec: Metadata-aware Multi-task Transformer for Large-scale and Cold-start free Session-based Recommendations (2022)</h3>
    <p><strong>Authors:</strong> Sejoon Oh, Amir Afsharinejad, Xiquan Cui, Walid Shalaby, Srijan Kumar</p>
    <p>Session-based recommender systems (SBRSs) have shown superior performance over conventional methods. However, they show limited scalability on large-scale industrial datasets since most models learn one embedding per item. This leads to a large memory requirement (of storing one vector per item) and poor performance on sparse sessions with cold-start or unpopular items. Using one public and one large industrial dataset, we experimentally show that state-of-the-art SBRSs have low performance on sparse sessions with sparse items. We propose M2TRec, a Metadata-aware Multi-task Transformer model for session-based recommendations. Our proposed method learns a transformation function from item metadata to embeddings, and is thus, item-ID free (i.e., does not need to learn one embedding per item). It integrates item metadata to learn shared representations of diverse item attributes. During inference, new or unpopular items will be assigned identical representations for the attributes they share with items previously observed during training, and thus will have similar representations with those items, enabling recommendations of even cold-start and sparse items. Additionally, M2TRec is trained in a multi-task setting to predict the next item in the session along with its primary category and subcategories. Our multi-task strategy makes the model converge faster and significantly improves the overall performance. Experimental results show significant performance gains using our proposed approach on sparse items on the two datasets.</p>
    <p><strong>Categories:</strong> Session-Based Recommendations, Cold Start, Metadata-Aware Models, Multi-Task Learning, Scalability, Transformer-Based Models, Large-Scale Recommendations, Implicit Feedback, Industrial Applications, Embedding-Free Methods (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/788/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>An Analysis Of Entire Space Multi-Task Models For Post-Click Conversion Prediction (2021)</h3>
    <p><strong>Authors:</strong> Rafael Barreto, Conor O’Brien, James Neufield, Kin Sum Liu, Jonathan J Hunt</p>
    <p>Industrial recommender systems are frequently tasked with approximating probabilities for multiple, often closely related, user actions. For example, predicting if a user will click on an advertisement and if they will then purchase the advertised product. The conceptual similarity between these tasks has promoted the use of multi-task learning: a class of algorithms that aim to bring positive inductive transfer from related tasks. Here, we empirically evaluate multi-task learning approaches with neural networks for an online advertising task. Specifically, we consider approximating the probability of post-click conversion events (installs) (CVR) for mobile app advertising on a large-scale advertising platform, using the related click events (CTR) as an auxiliary task. We use an ablation approach to systematically study recent approaches that incorporate both multitask learning and “entire space modeling” which train the CVR on all logged examples rather than learning a conditional likelihood of conversion given clicked. Based on these results we show that several different approaches result in similar levels of positive transfer from the data-abundant CTR task to the CVR task and offer some insight into how the multi-task design choices address the two primary problems affecting the CVR task: data sparsity and data bias. Our findings add to the growing body of evidence suggesting that standard multi-task learning is a sensible approach to modelling related events in real-world large-scale applications and suggest the specific multitask approach can be guided by ease of implementation in an existing system.</p>
    <p><strong>Categories:</strong> Recommender Systems, Online Advertising, Multi-Task Learning, Neural Networks, Entire Space Modeling, Evaluation Methodology, Data Sparsity, Data Bias, Mobile App Advertising, System Design (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/679/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Developing Recommendation System to provide a Personalized Learning experience at Chegg (2020)</h3>
    <p><strong>Authors:</strong> Deb Sanghamitra</p>
    <p>Online learning has become the primary source of education in 2020 with the impact of COVID-19 forcing millions of students to stay at home. In order to personalize the learning experience we have built a recommendation system that takes advantage of the  (1) Rich content developed at Chegg (2) An excellent knowledge graph that organizes content in a hierarchical fashion (3) Interaction of students across multiple products to enhance user signal in individual products.<br>Chegg is a centralized learning platform. Students visit Chegg to get help with homework using Chegg Study, learn from flashcards for their tests, practice examinations, learn relevant concepts, work with a tutor online to get one on one learning experience. This represents a large amount of content available to students. In order to organize the content we have developed a Knowledge Graph with nodes representing a hierarchical scheme of concepts  taught at different educational institutions and the content at Chegg. In order to create edges between concept nodes and content we build text classifiers to tag content with concept nodes.<br>Often students will interact with one or two products such as Chegg Study or Text Book rentals and browse other products such as flashcards, exam practice, etc. In order to suggest relevant content to them, we deduce the concepts they have been studying in products where they are more active and suggest content in products where they are less active.<br>In this presentation I will talk about the general framework for developing personalized recommendations at Chegg and do a deep dive into (1) Text classifiers required for content tagging and (2) Building cross product recommendations. In text classification,  I will go into details about working with noisy training data and model improvements using multi-task learning [1]. For cross product recommendations I will talk about combining user signals from multiple products [2] to deduce general pattern of student interest and use that information to retrieve relevant content — for example flashcards or practice exams for users.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Personalized Learning, Education Domain, Knowledge Graphs, Text Classification, Cross-Product Recommendations, User Signal Analysis, Multi-Task Learning, Handling Noisy Data, Real-World Applications, Content Organization (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/622/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>