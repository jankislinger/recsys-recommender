<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui primary button" style="margin: 5px;"
             href="/recsys-recommender/">Robustness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/explainability/">Explainability</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/beyond-accuracy/">Beyond Accuracy</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reinforcement-learning/">Reinforcement Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/evaluation-methods/">Evaluation Methods</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>A Novel Evaluation Perspective on GNNs-based Recommender Systems through the Topology of the User-Item Graph (2024)</h3>
    <p><strong>Authors:</strong> Alberto Carlo Maria Mancino, Vito Walter Anelli, Claudio Pomo, Tommaso Di Noia, Eugenio Di Sciascio, Daniele Malitesta</p>
    <p>Recently, graph neural networks (GNNs)-based recommender systems have encountered great success in recommendation. As the number of GNNs approaches rises, some works have started questioning the theoretical and empirical reasons behind their superior performance. Nevertheless, this investigation still disregards that GNNs treat the recommendation data as a topological graph structure. Building on this assumption, in this work, we provide a novel evaluation perspective on GNNs-based recommendation, which investigates the impact of the graph topology on the recommendation performance. To this end, we select some (topological) properties of the recommendation data and three GNNs-based recommender systems (i.e., LightGCN, DGCF, and SVD-GCN). Then, starting from three popular recommendation datasets (i.e., Yelp2018, Gowalla, and Amazon-Book) we sample them to obtain 1,800 size-reduced datasets that still resemble the original ones but can encompass a wider range of topological structures. We use this procedure to build a large pool of samples for which data characteristics and recommendation performance of the selected GNNs models are measured. Through an explanatory framework, we find strong correspondences between graph topology and GNNs performance, offering a novel evaluation perspective on these models.</p>
    <p><strong>Categories:</strong> Graph Neural Networks, GNN-based Recommender Systems, Recommendation Systems, Real-World Applications, Evaluation Framework, Graph Topology Analysis, Data Characteristics, Recommendation Performance, Scalability, Robustness, Model Interpretability, Beyond Accuracy, Evaluation Metrics, Novel Evaluation Perspective (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1116/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Improving the Shortest Plank: Vulnerability-Aware Adversarial Training for Robust Recommender System (2024)</h3>
    <p><strong>Authors:</strong> Fei Sun, Qi Cao, Yunfan Wu, Huawei Shen, Xueqi Cheng, Kaike Zhang</p>
    <p>Recommender systems play a pivotal role in mitigating information overload in diverse fields. Nonetheless, the inherent openness of these systems introduces vulnerabilities, allowing attackers to insert fake users to skew the exposure of certain items, known as poisoning attacks. Adversarial training emerges as a notable defense mechanism against such poisoning attacks within recommender systems. Traditional adversarial training methods apply perturbations with the same scale across all users to their embeddings to maintain system robustness against the worst-case attacks. Yet, in reality, attacks often affect only a subset of users who are actually vulnerable to the specific attacks. These indiscriminate perturbations make it difficult to balance effective protection for vulnerable users and avoidance of recommendation quality degradation for those who are not. To address this issue, our research delves into understanding user vulnerability. Considering that poisoning attacks pollutes the training data, we observe that the extent of a recommender system’s fit to users’ training data, particularly when high, correlates with an increased likelihood of users incorporating attack information, thus indicating their vulnerability. Leveraging these insights, we introduce the Vulnerability-aware Adversarial Training (VAT) method, designed to counteract poisoning attacks in recommender systems. VAT employs a novel vulnerability-aware function to estimate users’ vulnerability based on the degree to which they are fitted by the system. Guided by this evaluation, VAT applies user-specific perturbations to embeddings. thereby not only reducing the success rate of attacks but also preserving—and potentially enhancing—the quality of recommendations. Comprehensive experiments confirm VAT’s superior defensive capabilities against various attacks and recommendation models.</p>
    <p><strong>Categories:</strong> Adversarial Training, Poisoning Attacks, Robustness, Security, User Vulnerability Analysis, Defense Mechanisms, Recommender Systems, Machine Learning, Adversarial Machine Learning, Security in Recommender Systems (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1045/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>BVAE: Behavior-aware Variational Autoencoder for Multi-Behavior Multi-Task Recommendation (2023)</h3>
    <p><strong>Authors:</strong> Yang Liu, Qianzhen Rao, Weike Pan, Zhong Ming</p>
    <p>A practical recommender system should be able to handle heterogeneous behavioral feedback as inputs and has multi-task outputs ability. Although the heterogeneous one-class collaborative filtering (HOCCF) and multi-task learning (MTL) methods has been well studied, there is still a lack of targeted manner in their combined fields, i.e., Multi-behavior Multi-task Recommendation (MMR). To fill the gap, we propose a novel recommendation framework called Behavior-aware Variational AutoEncoder (BVAE), which meliorates the parameter sharing and loss minimization method with the VAE structure to address the MMR problem. Specifically, our BVAE includes address behavior-aware semi-encoders and decoders, and a target feature fusion network with a global feature filtering network, while using standard deviation to weigh loss. These modules generate the behavior-aware recommended item list via constructing better semantic feature vectors for users, i.e., from dual perspectives of behavioral preference and global interaction. In addition, we optimize our BVAE in terms of adaptability and robustness, i.e., it is concise and flexible to consume any amount of behaviors with different distributions. Extensive empirical studies on two real and widely used datasets confirm the validity of our design and show that our BVAE can outperform the state-of-the-art related baseline methods under multiple evaluation metrics.</p>
    <p><strong>Categories:</strong> Variational Autoencoder, Collaborative Filtering, Multi-Task Learning, Recommendation Systems, Multi-Behavior Recommendations, User Behavior Modeling, Empirical Evaluation, Beyond Accuracy, State-of-the-Art Comparisons, Adaptability, Robustness, Scalability, Model Efficiency, Heterogeneous Feedback (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/852/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Stability of Explainable Recommendation (2023)</h3>
    <p><strong>Authors:</strong> Sairamvinay Vijayaraghavan, Prasant Mohapatra</p>
    <p>Explainable Recommendation has been gaining attention over the last few years in industry and academia. Explanations provided along with recommendations for each user in a recommender system framework have many uses: particularly reasoning why a suggestion is provided and how well an item aligns with a user’s personalized preferences. Hence, explanations can play a huge role in influencing users to purchase products. However, the reliability of the explanations under varying scenarios has not been strictly verified in an empirical perspective. Unreliable explanations can bear strong consequences such as attackers leveraging explanations for manipulating and tempting users to purchase target items: that the attackers would want to promote. In this paper, we study the vulnerability of existent feature-oriented explainable recommenders, particularly analyzing their performance under different levels of external noises added into model parameters. We conducted experiments by analyzing three important state-of-the-art explainable recommenders when trained on two widely used e-commerce based recommendation datasets of different scales. We observe that all the explainable models are vulnerable to increased noise levels. Experimental results verify our hypothesis that the ability to explain recommendations does decrease along with increasing noise levels and particularly adversarial noise does contribute to a much stronger decrease. Our study presents an empirical verification on the topic of robust explanations in recommender systems which can be extended to different types of explainable recommenders in RS.</p>
    <p><strong>Categories:</strong> Explainability, Security, Adversarial Attacks, Robustness, Recommender Systems, Empirical Evaluation, E-commerce, Model Stability, Trustworthiness, Algorithmic Approaches, System Design, Noise Impact, Methodology (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/934/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Adversarial Collaborative Filtering for Free (2023)</h3>
    <p><strong>Authors:</strong> Chin-Chia Michael Yeh, Vivian Lai, Yan Zheng, Hao Yang, Mahashweta Das, Yujie Fan, Xiaoting Li, Huiyuan Chen</p>
    <p>Collaborative Filtering (CF) has been successfully applied to help users discover the items of interest. Nevertheless, existing CF methods suffer from noisy data issue, which negatively impacts the quality of personalized recommendation. To tackle this problem, many  prior studies leverage the adversarial learning principle to regularize the representations of users and items, which  has shown great ability in improving both generalizability and robustness. Generally, those methods  learn adversarial perturbations and model parameters using min-max optimization framework. However, there still have two major limitations: 1) Existing methods lack theoretical guarantees of why adding perturbations improve the model generalizability and robustness since noisy data is naturally different from adversarial attacks; 2)  Solving min-max optimization is time-consuming.  In addition to updating the model parameters, each iteration requires additional computations to update the perturbations, making them not scalable for industry-scale datasets. In this paper, we present Sharpness-aware Matrix Factorization (SharpMF), a simple yet effective method that conducts adversarial training without extra computational cost over the base optimizer. To achieve this goal, we first revisit the existing adversarial collaborative filtering and discuss its connection with recent Sharpness-aware Minimization. This analysis shows that adversarial training actually seeks model parameters that lie in neighborhoods having uniformly low loss values, resulting in better generalizability. To reduce the computational overhead, SharpMF introduces a novel trajectory loss to measure sharpness between current weights and past weights. Experimental results on real-world datasets demonstrate that our SharpMF achieves superior performance with almost zero additional computational cost comparing to adversarial training.</p>
    <p><strong>Categories:</strong> Adversarial Training, Collaborative Filtering, Matrix Factorization, Recommendation Systems, Noise Handling, Generalizability, Robustness, Computational Efficiency, Optimization Techniques, Real-World Applications, User-Centric Design, Scalability, Robustness in Machine Learning (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/848/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Evaluating Off-Policy Evaluation: Sensitivity and Robustness (2021)</h3>
    <p><strong>Authors:</strong> Kazuki Mogi, Yuta Saito, Kei Tateno, Yusuke Narita, Haruka Kiyohara, Takuma Udagawa</p>
    <p>Off-policy Evaluation (OPE), or offline evaluation in general, evaluates the performance of hypothetical policies leveraging only offline log data. It is particularly useful in applications where the online interaction involves high stakes and expensive setting such as precision medicine and recommender systems. Since many OPE estimators have been proposed and some of them have hyperparameters to be tuned, there is an emerging challenge for practitioners to select and tune OPE estimators for their specific application. Unfortunately, identifying a reliable estimator from results reported in research papers is often difficult because the current experimental procedure evaluates and compares the estimators’ performance on a narrow set of hyperparameters and evaluation policies. Therefore, it is difficult to know which estimator is safe and reliable to use. In this work, we develop Interpretable Evaluation for Offline Evaluation (IEOE), an experimental procedure to evaluate OPE estimators’ robustness to changes in hyperparameters and/or evaluation policies in an interpretable manner. Then, using the IEOE procedure, we perform extensive evaluation of a wide variety of existing estimators on Open Bandit Dataset, a large-scale public real-world dataset for OPE. We demonstrate that our procedure can evaluate the estimators’ robustness to the hyperparamter choice, helping us avoid using unsafe estimators. Finally, we apply IEOE to real-world e-commerce platform data and demonstrate how to use our protocol in practice.</p>
    <p><strong>Categories:</strong> Off-Policy Evaluation, Reinforcement Learning, Recommender Systems, Precision Medicine, Algorithm Selection, Hyperparameter Tuning, Experimental Design, Real-World Applications, Sensitivity Analysis, Robustness, Evaluation Metrics, Practical Implementation (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/639/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Debiasing Item-to-Item Recommendations With Small Annotated Datasets (2020)</h3>
    <p><strong>Authors:</strong> Tobias Schnabel, Paul N. Bennett</p>
    <p>Item-to-item recommendation (e.g., “People who like this also like...”) is a ubiquitous and important type of recommendation in real-world systems. Observational data from historical interaction logs abound in these settings. However, since virtually all observational data exhibit biases, such as time-in-inventory or interface biases, it is crucial that recommender algorithms account for these biases. In this paper, we develop a principled approach for item-to-item recommendation based on causal inference and present a practical and highly effective method for estimating the causal parameters from a small annotated dataset. Empirically, we find that our approach substantially improves upon existing methods while requiring only small amounts of annotated data.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Bias Mitigation, Fairness, Item-to-Item Recommendations, Causal Inference, Beyond Accuracy, Empirical Evaluation, Practical Applications, Ethics, Robustness, Small Datasets, Evaluation Methods (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/530/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Compositional Network Embedding for Link Prediction (2019)</h3>
    <p><strong>Authors:</strong> Peng Jiang, Wenwu Ou, Tianshu Lyu, Fei Sun, Yan Zhang</p>
    <p>Network embedding has proved extremely useful in a variety of network analysis tasks such as node classification, link prediction, and network visualization. Almost all the existing network embedding methods learn to map the node IDs to their corresponding node embeddings. This design principle, however, hinders the existing methods from being applied in real cases. Node ID is not generalizable and, thus, the existing methods have to pay great effort in cold-start problem. The heterogeneous network usually requires extra work to encode node types, as node type is not able to be identified by node ID. Node ID carries rare information, resulting in the criticism that the existing methods are not robust to noise. To address this issue, we introduce Compositional Network Embedding, a general inductive network representation learning framework that generates node embeddings by combining node features based on the ‘principle of compositionally’. Instead of directly optimizing an embedding lookup based on arbitrary node IDs, we learn a composition function that infers node embeddings by combining the corresponding node attribute embeddings through a graph-based loss. For evaluation, we conduct the experiments on link prediction under four different settings. The results verified the effectiveness and generalization ability of compositional network embeddings, especially on unseen nodes. i>Presentation: Monday Poster Lunch</i</p>
    <p><strong>Categories:</strong> Network Embedding, Link Prediction, Machine Learning Techniques, Cold Start Problem, Feature-Based Methods, Scalability, Experimental Evaluation, Network Analysis, Compositionality Principle, Generalization Ability, Robustness (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/468/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Adversarial Tensor Factorization for Context-aware Recommendation (2019)</h3>
    <p><strong>Authors:</strong> Huiyuan Chen, Jing Li</p>
    <p>Contextual factors such as time, location, or tag, can affect user preferences for a particular item. Context-aware recommendations are thus critical to improve both quality and explainability of recommender systems, compared to traditional recommendations solely based on user-item interactions. Tensor factorization machines have achieved state-of-the-art performance  due to their generic integration of users, items, and contextual factors in one unify way. However,  few work has focused on the robustness of a context-aware recommender system. Improving the robustness of a tensor-based model is challenging due to the sparsity of the observed tensor and the multi-linear nature of tensor factorization. In this paper, we propose ATF, a model that combines tensor factorization and adversarial learning for context-aware recommendations. Doing so allows us to reap the benefits of tensor factorization, while enhancing the robustness of a recommender model, and thus improves its performance. Empirical studies on two real-world datasets show that the proposed method outperforms standard tensor-based  methods. i>Presentation: Monday Poster Lunch</i</p>
    <p><strong>Categories:</strong> Context-aware Recommendations, Tensor Factorization, Adversarial Learning, Recommender Systems, Robustness, Performance Improvement, Multi-Linear Models, Real World Applications, Recommendation Quality (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/464/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Categorical-Attributes-Based Item Classification for Recommender Systems (2018)</h3>
    <p><strong>Authors:</strong> Jilin Chen, Minmin Chen, Alex Beutel, Ed Chi, Francois Belletti, Sagar Jain, Qian Zhao</p>
    <p>Many techniques to utilize side information of users and/or items as inputs to recommenders to improve recommendation, especially on cold-start items/users, have been developed over the years. In this work, we test the approach of utilizing item side information, specifically categorical attributes, in the output of recommendation models either through multi-task learning or hierarchical classification. We first demonstrate the efficacy of these approaches for both matrix factorization and neural networks with a medium-size real-word data set. We then show that they improve a neural-network based production model in an industrial-scale recommender system. We demonstrate the robustness of the hierarchical classification approach by introducing noise in building the hierarchy. Lastly, we investigate the generalizability of hierarchical classification on a simulated dataset by building two user models in which we can fully control the generative process of user-item interactions.</p>
    <p><strong>Categories:</strong> Matrix Factorization, Neural Networks, Multi-Task Learning, Hierarchical Classification, Recommender Systems, Cold Start Problem, Industrial-Scale Evaluation, Robustness, Generalizability, Item Side Information, Simulated Data (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/331/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>On the Robustness and Discriminative Power of IR Metrics for Top-N Recommendation (2018)</h3>
    <p><strong>Authors:</strong> Alejandro Bellogin, Daniel Valcarce, Pablo Castells, Javier Parapar</p>
    <p>The evaluation of Recommender Systems is still an open issue in the field. Despite its limitations, offline evaluation usually constitutes the first step in assessing recommendation methods due to its reduced costs and high reproducibility. Selecting the appropriate metric is a central issue in offline evaluation. Among the properties of recommendation systems, ranking accuracy attracts the most attention nowadays. In this paper, we aim to shed light on the advantages of different ranking metrics which were previously used in Information Retrieval and are now typically used for assessing top-N recommender systems. We propose methodologies for comparing the robustness and the discriminative power of different metrics. On the one hand, we study the influence of cut-offs and we find that deeper cut-offs offer greater robustness and discriminative power. On the other hand, we find that precision offers high robustness and Normalised Discounted Cumulative Gain provides the best discriminative power.</p>
    <p><strong>Categories:</strong> Recommender Systems, Evaluation Metrics, Ranking Accuracy, Robustness, Discriminative Power, Top-N Recommendations, Information Retrieval, Evaluation Cutoffs, Methodologies (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/351/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Attacking Item-Based Recommender Systems with Power Items (2014)</h3>
    <p><strong>Authors:</strong> David Wilson, Carlos Seminario</p>
    <p>Recommender Systems (RS) are vulnerable to attack by malicious users who intend to bias the recommendations for their own benefit. Research in this area has developed attack models, detection methods, and mitigation schemes to understand and protect against such attacks. For Collaborative Filtering RSs, model-based approaches such as item-based and matrix-factorization were found to be more robust to many types of attack. Advice in designing for system robustness has thus been to employ model-based approaches. Our recent work with the Power User Attack (PUA), however, determined that attackers disguised as influential users can successfully attack (from the attacker’s viewpoint) SVD-based recommenders, as well as user-based. Though item-based systems remained robust to the PUA. In this paper we investigate a new, complementary attack model, the Power Item Attack (PIA), that uses influential items to successfully attack RSs. We show that the PIA is able to impact not only user-based and SVD-based recommenders but also the heretofore highly robust item-based approach, using a novel multi-target attack vector.</p>
    <p><strong>Categories:</strong> Recommender Systems, Security, Attacks, Item-Based Recommenders, User-Based Recommenders, Matrix Factorization, Robustness, Vulnerability, System Exploits, Multi-Target Attack Vector, Power Items, Innovation (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/2/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>