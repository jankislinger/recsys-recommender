<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui primary button" style="margin: 5px;"
             href="/recsys-recommender/">Explanation Generation</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/bias-mitigation/">Bias Mitigation</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reproducibility/">Reproducibility</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/offline-evaluation/">Offline Evaluation</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Bridging Search and Recommendation in Generative Retrieval: Does One Task Help the Other? (2024)</h3>
    <p><strong>Authors:</strong> Marco De Nadai, Ali Vardasbi, Enrico Palumbo, Hugues Bouchard, Gustavo Penha</p>
    <p>Generative retrieval for search and recommendation is a promising paradigm for retrieving items, offering an alternative to traditional methods that depend on external indexes and nearest-neighbor searches. Instead, generative models directly associate inputs with item IDs. Given the impressive capabilities of Large Language Models (LLMs), these generative systems play a crucial role in centralizing a variety of Information Retrieval (IR) tasks in a single model that performs tasks such as query understanding, retrieval, recommendation, explanation, re-ranking, and response generation. Despite the growing interest in such a unified generative approach for IR systems, the advantages of using a single, multi-task model over multiple specialized models are not well established in the literature. This paper investigates whether and when such a unified approach can outperform task-specific models in the IR tasks of search and recommendation, broadly co-existing in multiple industrial online platforms, such as Spotify, YouTube, and Netflix. Previous work shows that (1) the latent representations of items, learned by generative recommenders, are biased towards popularity, and (2) content-based and collaborative-filtering-based information can improve an item’s representations. Motivated by this, our study is guided by two hypotheses: [H1] the joint training regularizes the estimation of each item’s popularity, and [H2] the joint training regularizes the item’s latent representations, where search captures content-based aspects of an item and recommendation captures collaborative-filtering aspects. Our extensive experiments with both simulated and real-world data support both [H1] and [H2] as key contributors to the effectiveness improvements observed in the unified search and recommendation generative models over the single-task approaches.</p>
    <p><strong>Categories:</strong> Generative Models, Large Language Models (LLMs), Information Retrieval (IR), Search Systems, Recommendation Systems, Multi-Task Learning, Real-World Applications, Evaluation Metrics, Latent Representations, Popularity Bias, Collaborative Filtering, Content-Based Filtering, Explanation Generation, Industrial Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1030/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>VMI-PSL: Visual Model Inspector for Probabilistic Soft Logic (2020)</h3>
    <p><strong>Authors:</strong> Aaron Rodden, Tarun Salh, Lise Getoor, Eriq Augustine</p>
    <p>Hybrid recommender systems achieve state-of-the-art performance by integrating several different information sources along with multiple recommendation approaches. Probabilistic Soft Logic (PSL) has been shown to be an accessible and effective means of creating extensible hybrid recommenders [11]. PSL allows users to easily create intuitive models that incorporate background information and capture complex interactions. However these complex interactions can sometimes make PSL models difficult to inspect, debug, and understand. In this paper, we present a generic visual model inspector for PSL, and show how our inspector can be used on a hybrid recommender system to: debug errors in the model, analyze the performance of individual components of the model, and explain recommendations made by the model.</p>
    <p><strong>Categories:</strong> Probabilistic Soft Logic (PSL), Hybrid Recommenders, Visualization Tools, Model Debugging, Explainability, Interpretability of Models, Component Analysis, Background Knowledge Integration, Explanation Generation, Recommendation Systems, Tools &amp; Frameworks (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/593/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Why I like it: Multi-task Learning for Recommendation and Explanation (2018)</h3>
    <p><strong>Authors:</strong> Ruihai Dong, Yichao Lu, Barry Smyth</p>
    <p>We describe a novel, multi-task recommendation model, which jointly learns to perform rating prediction and recommendation explanation by combining matrix factorization, for rating prediction, and adversarial sequence to sequence learning for explanation generation. The result is evaluated using real-world datasets to demonstrate improved rating prediction performance, compared to state-of-the-art alternatives, while producing effective, personalized explanations.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Multi-Task Learning, Matrix Factorization, Adversarial Learning, Sequence-to-Sequence Models, Rating Prediction, Explanation Generation, Personalized Recommendations, Deep Learning, Real-World Applications, Hybrid Methods, Evaluation Metrics (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/363/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>ExpLOD: A Framework for Explaining Recommendations based on the Linked Open Data Cloud (2016)</h3>
    <p><strong>Authors:</strong> Fedelucio Narducci, Pasquale Lops, Marco De Gemmis, Giovanni Semeraro, Cataldo Musto</p>
    <p>In this paper we present ExpLOD, a framework which exploits the information available in the Linked Open Data (LOD) cloud to generate a natural language explanation of the suggestions produced by a recommendation algorithm. The methodology is based on building a graph in which the items liked by a user are connected to the items recommended through the properties available in the LOD cloud. Next, given this graph, we implemented some techniques to rank those properties and we used the most relevant ones to feed a module for generating explanations in natural language. In the experimental evaluation we performed a user study with 308 subjects aiming to investigate to what extent our explanation framework can lead to more transparent, trustful and engaging recommendations. The preliminary results provided us with encouraging findings, since our algorithm performed better than both a non-personalized explanation baseline and a popularity-based one.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Explanation Generation, Linked Open Data (LOD), Natural Language Processing (NLP), User Study, Trust in Recommendations, Explainable AI (XAI), Transparency in Recommendations, Graph-Based Methods, Evaluation Techniques, Framework Design (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/204/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Exploiting Reviews to Guide Users’ Selections (2015)</h3>
    <p><strong>Authors:</strong> Maria Soledad Pera, Nevena Dragovic</p>
    <p>We introduce HRS, a recommender that exploits user reviews and identifies the features that are most likely appealing to users. HRS incorporates this knowledge into the recommendation process to generate a list of top-k recommendations, each of which is paired with an explanation that (i) showcases why a particular item was recommended and (ii) helps users decide which items, among the ones  recommended,  are  best  tailored  towards  their  individual interests. Empirical studies conducted using the Amazon dataset demonstrate the correctness of the proposed methodology.</p>
    <p><strong>Categories:</strong> Recommender Systems, User Feedback/Reviews, Explanation Generation, Amazon Dataset, Feature Extraction, Empirical Evaluation, User-Centered Design, Recommendation Accuracy, Beyond Accuracy, Natural Language Processing (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/149/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>