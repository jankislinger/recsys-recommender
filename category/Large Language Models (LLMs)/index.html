<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui primary button" style="margin: 5px;"
             href="/recsys-recommender/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/Transfer%20Learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/Explainability/">Explainability</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/Sequential%20Recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/AB%20Testing/">AB Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/Reproducibility/">Reproducibility</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/Fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/AB%20Test/">AB Test</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/Reinforcement%20Learning/">Reinforcement Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/Data%20Sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/Cold%20Start/">Cold Start</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/Evaluation%20Metrics/">Evaluation Metrics</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Towards Open-World Recommendation with Knowledge Augmentation from Large Language Models (2024)</h3>
    <p><strong>Authors:</strong> Weiwen Liu, Bo Chen, Yong Yu, Hong Zhu, Yunjia Xi, Weinan Zhang, Jianghao Lin, Xiaoling Cai, Jieming Zhu, Ruiming Tang</p>
    <p>Recommender system plays a vital role in various online services. However, its insulated nature of training and deploying separately within a specific closed domain limits its access to open-world knowledge. Recently, the emergence of large language models (LLMs) has shown promise in bridging this gap by encoding extensive world knowledge and demonstrating reasoning capabilities. Nevertheless, previous attempts to directly use LLMs as recommenders cannot meet the inference latency demand of industrial recommender systems. In this work, we propose an Open-World Knowledge Augmented Recommendation Framework with Large Language Models, dubbed KAR, to acquire two types of external knowledge from LLMs — the reasoning knowledge on user preferences and the factual knowledge on items. We introduce factorization prompting to elicit accurate reasoning on user preferences. The generated reasoning and factual knowledge are effectively transformed and condensed into augmented vectors by a hybrid-expert adaptor in order to be compatible with the recommendation task. The obtained vectors can then be directly used to enhance the performance of any recommendation model. We also ensure efficient inference by preprocessing and prestoring the knowledge from the LLM. Extensive experiments show that KAR significantly outperforms the state-of-the-art baselines and is compatible with a wide range of recommendation algorithms. We deploy KAR to Huawei’s news and music recommendation platforms and gain a 7% and 1.7% improvement in the online A/B test, respectively.</p>
    <p><strong>Categories:</strong> Large Language Models (LLMs), Knowledge Augmentation, Recommender Systems, Open-World Recommendation, Knowledge Graphs, User Preference Modeling, Factorization Prompting, Feature Extraction, Representation Learning, Hybrid Models, Efficiency Optimization, Scalability, State-of-the-Art Methods, Real-World Applications, A/B Testing, News, Music, Beyond Accuracy, Compatibility (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1071/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Unleashing the Retrieval Potential of Large Language Models in Conversational Recommender Systems (2024)</h3>
    <p><strong>Authors:</strong> Ting Yang, Li Chen</p>
    <p>Conversational recommender systems (CRSs) aim to capture user preferences and provide personalized recommendations through interactive natural language interactions. The recent advent of large language models (LLMs) has revolutionized human engagement in natural conversations, driven by their extensive world knowledge and remarkable natural language understanding and generation capabilities. However, introducing LLMs into CRSs presents new technical challenges. Specifically, directly prompting LLMs for recommendation generation requires understanding a large and evolving item corpus, as well as grounding the generated recommendations in the real item space. Moreover, generating recommendations based on external recommendation engines or directly integrating their suggestions into responses may constrain the overall performance of LLMs, since these engines generally have inferior representation abilities compared to LLMs. To address these challenges, we propose an end-to-end large-scale CRS model, ReFICR, a novel LLM-enhanced conversational recommender that empowers a retrievable large language model to perform CRS subtasks by following retrieval and generation instructions through lightweight tuning. By decomposing the complex CRS task into multiple subtasks, we formulate these subtasks into two types of instruction formats: retrieval and generation. The hidden states of ReFICR are utilized as text embeddings to represent user preferences and items for retrieval. Simultaneously, ReFICR is trained to handle generative tasks. We optimize the contrastive objective to enhance text embeddings for retrieval and jointly fine-tune the large language model objective for generation. Our experimental results on public datasets demonstrate that ReFICR significantly outperforms baselines in terms of recommendation accuracy. Our code is publicly available at the link: https://anonymous.4open.science/r/ReFICR-0C3A.</p>
    <p><strong>Categories:</strong> Conversational Recommender Systems (CRSs), Large Language Models (LLMs), Recommendation Generation, Natural Language Processing (NLP), Retrieval-Based Systems, Instruction-Following Models, Contrastive Learning, End-to-End Models, Personalized Recommendations, Implicit Feedback, Hybrid Recommender Systems, Language Model Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1076/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Large Language Models as Evaluators for Recommendation Explanations (2024)</h3>
    <p><strong>Authors:</strong> Yishan Li, Bowen Sun, Weizhi Ma, Peijie Sun, Xiaoyu Zhang, Min Zhang, Jiayin Wang</p>
    <p>The explainability of recommender systems has attracted significant attention in academia and industry. Many efforts have been made for explainable recommendations, yet evaluating the quality of the explanations remains a challenging and unresolved issue. In recent years, leveraging LLMs as evaluators presents a promising avenue in Natural Language Processing tasks (e.g., sentiment classification, information extraction), as they perform strong capabilities in instruction following and common-sense reasoning. However, evaluating recommendation explanatory texts is different from these NLG tasks, as its criteria are related to human perceptions and are usually subjective. In this paper, we investigate whether LLMs can serve as evaluators of recommendation explanations. To answer the question, we utilize real user feedback on explanations given from previous work and additionally collect third-party annotations and LLM evaluations. We design and apply a 3-level meta-evaluation strategy to measure the correlation between evaluator labels and the ground truth provided by users. Our experiments reveal that LLMs, such as GPT4, can provide comparable evaluations with appropriate prompts and settings. We also provide further insights into combining human labels with the LLM evaluation process and utilizing ensembles of multiple heterogeneous LLM evaluators to enhance the accuracy and stability of evaluations. Our study verifies that utilizing LLMs as evaluators can be an accurate, reproducible and cost-effective solution for evaluating recommendation explanation texts. Our code is available at https://anonymous.4open.science/r/LLMasAnnotator-0043.</p>
    <p><strong>Categories:</strong> Explainability in Recommender Systems, Evaluation Metrics for Recommendations, Large Language Models (LLMs), Natural Language Processing (NLP) Tasks, Human-Centered AI, Recommendation Systems, Explainability Evaluation, User Feedback in Recommendations (<i>deepseek-r1:70b</i>)</p>
    <p><a href="/recsys-recommender/response/1119/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>GenUI(ne) CRS: UI Elements and Retrieval-Augmented Generation in Conversational Recommender Systems with LLMs (2024)</h3>
    <p><strong>Authors:</strong> Lien Michiels, Annelien Smets, Ulysse Maes</p>
    <p>Previous research has used Large Language Models (LLMs) to develop personalized Conversational Recommender Systems (CRS) with text-based user interfaces (UIs). However, the potential of LLMs to generate interactive graphical elements that enhance user experience remains largely unexplored. To address this gap, we introduce “GenUI(ne) CRS,” a novel framework designed to leverage LLMs for adaptive and interactive UIs. Our framework supports domain-specific graphical elements such as buttons and cards, in addition to text-based inputs. It also addresses the common LLM issue of outdated knowledge, known as the “knowledge cut-off,” by implementing Retrieval-Augmented Generation (RAG). To illustrate its potential, we developed a prototype movie CRS. This work demonstrates the feasibility of LLM-powered interactive UIs and paves the way for future CRS research, including user experience validation, transparent explanations, and addressing LLM biases.</p>
    <p><strong>Categories:</strong> Conversational Recommender Systems (CRS), Large Language Models (LLMs), UI/UX Design, Graphical User Interfaces (GUI), Retrieval-Augmented Generation (RAG), Movies, Human-Computer Interaction, User Experience, Transparency in Recommendations, Bias Mitigation (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1206/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Evaluation and simplification of text difficulty using LLMs in the context of recommending texts in French to facilitate language learning (2024)</h3>
    <p><strong>Authors:</strong> Michalis Vlachos, Yash Raj Shrestha, Henri Jamet, Maxime Manderlier</p>
    <p>We develop a recommendation system for foreign language learning. This recommends text or video content. It ranks digital content considering both the content’s difficulty and how the topic aligns to the learners’ interests. To achieve this, we automatically apply the following operations to any text: a. Classify its subject. b. Evaluate its linguistic difficulty. c. Potentially simplify its language level, while preserving its semantic content for adaptation to the reader’s language level. Once these three operations have produced a set of texts adapted to the reader’s interests and level, they are ranked by relevance using a recommendation system based on the reading and satisfaction of other users. In this paper, we focus on using Large Language Models (LLMs) to automatically perform these tasks on any set of texts. We present an approach for training and evaluation and compare both zero-shot and fine-tuned performance of state-of-the-art models. Our findings indicate a marked improvement in the prediction of French content difficulty (improvement range of 18-56%), a 27% enhancement in topic prediction accuracy with fine-tuned models compared to zero-shot models, and up to an 18% increase in NDCG in recommendation performance.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Language Learning, Text Simplification, Large Language Models (LLMs), Natural Language Processing, Education, French Language, Difficulty Evaluation, Automatic Content Adaptation, User Personalization, Model Evaluation, Recommendation Metrics, User Satisfaction (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1091/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Improving Data Efficiency for Recommenders and LLMs (2024)</h3>
    <p><strong>Authors:</strong> James Caverlee, Noveen Sachdeva, Jianmo Ni, Benjamin Coleman, Ed Chi, Lichan Hong, Wang-Cheng Kang, Derek Cheng</p>
    <p>In recent years, massive transformer-based architectures have driven breakthrough performance in practical applications like autoregressive text-generation (LLMs) and click-prediction (recommenders). A common recipe for success is to train large models on massive web-scale datasets, e.g., modern recommenders are trained on billions of user-item click events, and LLMs are trained on trillions of tokens extracted from the public internet. We are close to hitting the computational and economical limits of scaling up the size of these models, and we expect the next frontier of gains to come from improving the: (i) data quality of the training dataset, and (ii) data efficiency of the extremely expensive training procedure. Inspired by this shift, we present a set of “data-centric” techniques for recommendation and language models that summarizes a dataset into a terse data summary, which is both (i) high-quality, i.e., trains better quality models, and (ii) improves the data-efficiency of the overall training procedure. We propose techniques from two disparate data frameworks: (i) data selection (a.k.a., coreset construction) methods that sample portions of the dataset using grounded heuristics, and(ii) data distillation techniques that generate synthetic examples which are optimized to retain the signals needed for training high-quality models. Overall, this work sheds light on the challenges and opportunities offered by data optimization in web-scale systems, a particularly relevant focus as the recommendation community grapples with the grand challenge of leveraging LLMs.</p>
    <p><strong>Categories:</strong> Recommender Systems, Large Language Models (LLMs), Web-Scale Systems, Data Efficiency, Data Quality, Data Selection, Coreset Construction, Data Distillation, Synthetic Data, High-Quality Datasets, Cross-Domain Applications, Web-Scale Optimization, Recommender-LLM Integration (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1161/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Bridging Search and Recommendation in Generative Retrieval: Does One Task Help the Other? (2024)</h3>
    <p><strong>Authors:</strong> Marco De Nadai, Ali Vardasbi, Enrico Palumbo, Hugues Bouchard, Gustavo Penha</p>
    <p>Generative retrieval for search and recommendation is a promising paradigm for retrieving items, offering an alternative to traditional methods that depend on external indexes and nearest-neighbor searches. Instead, generative models directly associate inputs with item IDs. Given the impressive capabilities of Large Language Models (LLMs), these generative systems play a crucial role in centralizing a variety of Information Retrieval (IR) tasks in a single model that performs tasks such as query understanding, retrieval, recommendation, explanation, re-ranking, and response generation. Despite the growing interest in such a unified generative approach for IR systems, the advantages of using a single, multi-task model over multiple specialized models are not well established in the literature. This paper investigates whether and when such a unified approach can outperform task-specific models in the IR tasks of search and recommendation, broadly co-existing in multiple industrial online platforms, such as Spotify, YouTube, and Netflix. Previous work shows that (1) the latent representations of items, learned by generative recommenders, are biased towards popularity, and (2) content-based and collaborative-filtering-based information can improve an item’s representations. Motivated by this, our study is guided by two hypotheses: [H1] the joint training regularizes the estimation of each item’s popularity, and [H2] the joint training regularizes the item’s latent representations, where search captures content-based aspects of an item and recommendation captures collaborative-filtering aspects. Our extensive experiments with both simulated and real-world data support both [H1] and [H2] as key contributors to the effectiveness improvements observed in the unified search and recommendation generative models over the single-task approaches.</p>
    <p><strong>Categories:</strong> Generative Models, Large Language Models (LLMs), Information Retrieval (IR), Search Systems, Recommendation Systems, Multi-Task Learning, Real-World Applications, Evaluation Metrics, Latent Representations, Popularity Bias, Collaborative Filtering, Content-Based Filtering, Explanation Generation, Industrial Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1030/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Reproducibility of LLM-based Recommender Systems: the case study of P5 paradigm (2024)</h3>
    <p><strong>Authors:</strong> Marco Polignano, Cataldo Musto, Giovanni Semeraro, Pasquale Lops, Antonio Silletti</p>
    <p>Recommender systems field may greatly benefit of the availability of pretrained Large Language Models (LLMs), which can serve as the core mechanism to generate recommendations based on detailed user and item data, such as textual descriptions, user reviews, and metadata.  On one hand this new generation of LLM-based recommender systems paves the way to deal with traditional limitations, such as cold-start and data sparsity, but on the other hand this poses fundamental challenges for their accountability.  Reproducing experiments in the new context of LLM-based recommender systems is very challenging for several reasons. New approaches are published at an unprecedented pace, which makes difficult to have a clear picture of the main protocols and good practices in the experimental evaluation. Moreover, the lack of proper frameworks for LLM-based recommendation development and evaluation makes the process of benchmarking models complex and uncertain. In this work, we discuss the main issues encountered when trying to reproduce P5 (Pretrain, Personalized Prompt, and Prediction Paradigm), one of the first works unifying different recommendation tasks in a shared language modeling and natural language generation framework.  Starting from this study, we have developed OurFramework4LLM (anonymized name), a framework for training and evaluating LLMs, specifically for the recommendation task. It has been used to perform several experiments to assess the impact of different LLMs, personalization and novel set of more informative prompts on the overall performance of recommendations, in a fully reproducible environment.</p>
    <p><strong>Categories:</strong> Reproducibility, Large Language Models (LLMs), Recommender Systems, Framework Development, Benchmarking, Experimental Evaluation, P5 Paradigm, Natural Language Generation (NLG), Language Modeling, Cold-Start Problem, Data Sparsity, Personalization (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1130/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>“More to Read” at the Los Angeles Times: Solving a Cold Start Problem with LLMs to Improve Story Discovery (2024)</h3>
    <p><strong>Authors:</strong> David Kaufman, Franklin Horn, Aurelia Alston, Won You</p>
    <p>News publishers, who are seeking to grow their digital audience, face a challenge in providing relevant content recommendations for unregistered users arriving directly to article pages. In these cold start scenarios, classic techniques, like asking a user to register and select topics of interest, fall short. We present a contextual targeting approach that leverages the user’s current article choice itself as an implicit signal of user interests. We designed and developed an interface with recommendations to help users discover more articles. Our online A/B testing demonstrated that our models increased click-through rates by 39.4% over a popularity baseline. One of them, a large language model (LLM), generates relevant recommendations that balance immersion and novelty. We discuss the implications of using LLMs for responsibly enhancing user experiences while upholding editorial standards. We identify key opportunities in detecting nuanced user preferences and identifying and interrupting filter bubbles on news publisher sites.</p>
    <p><strong>Categories:</strong> Cold Start, Large Language Models (LLMs), News, Recommendation Systems, Implicit Feedback, Contextual Targeting, A/B Test, Online Media, User Engagement, Editorial Standards, Filter Bubbles, Content Diversity, Personalization (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1150/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Instructing and Prompting Large Language Models for Explainable Cross-domain Recommendations (2024)</h3>
    <p><strong>Authors:</strong> Alessandro Petruzzelli, Cataldo Musto, Pasquale Lops, Marco de Gemmis, Ivan Rinaldi, Giovanni Semeraro, Lucrezia Laraspata</p>
    <p>In this paper, we present a strategy to provide users with explainable cross-domain recommendations (CDR) that exploits large language models (LLMs). Generally speaking, cross-domain recommender systems typically suffer of data sparsity issues, since they require a large amount of data labeled in both base and target domains, which are not easy to collect. Accordingly, our approach relies on the intuition that the knowledge that is already encoded in LLMs can be used to bridge the domains and seamlessly provide users with personalized cross-domain suggestions. To this end, we designed a pipeline to: (a) instruct a LLM to handle a CDR task; (b) design a personalized prompt, based on the preferences of the user in a base domain, in both zero-shot and one-shot settings; (c) feed the LLM with the prompt, and process the answer in order to extract the recommendations in a target domain, together with a natural language explanation supporting the suggestion. As shown in the experimental evaluation, our approach beats several established state-of-the-art baselines for CDR in most of the experimental settings, thus showing the effectiveness of LLMs also in this novel and scarcely investigated scenario.</p>
    <p><strong>Categories:</strong> Large Language Models (LLMs), Cross-domain Recommendations, Explainable Recommendations, Recommendation Systems, Personalization, Zero-shot Learning, One-shot Learning, Data Sparsity, Natural Language Processing (NLP), Instruction Following (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1049/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Playlist Search Reinvented: LLMs Behind the Curtain (2024)</h3>
    <p><strong>Authors:</strong> Tarun Sharma, Siddharth Sharma, Geetha Aluri, Joaquin Delgado</p>
    <p>Improving search functionality poses challenges such as data scarcity for model training, metadata enrichment for comprehensive document indexing, and the labor-intensive manual annotation for evaluation. Traditionally, iterative methods relying on human annotators and customer feedback have been used. However, recent advancements in Large Language Models (LLMs) offer new solutions. This paper focuses on applying LLMs to playlist search in Amazon Music. Leveraging LLMs’ contextual understanding and generative capabilities automates metadata enrichment, reducing manual efforts and expediting training. LLMs also address data scarcity by generating synthetic training data and serve as scalable judges for evaluation, enhancing search performance assessment. We demonstrate how these innovations enhance playlist search, overcoming traditional limitations to improve search result accuracy and relevance.</p>
    <p><strong>Categories:</strong> Large Language Models (LLMs), Music, Entertainment, Search Functionality, Evaluation Methods, Data Generation/Synthesis, Real-World Applications, Automation, Scalability, Metadata Enrichment (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1169/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>LARR: Large Language Model Aided Real-time Scene Recommendation with Semantic Understanding (2024)</h3>
    <p><strong>Authors:</strong> Zhizhong Wan, Fei Jiang, Wei Lin, Bin Yin, Junjie Xie, Xiang Li</p>
    <p>Click-Through Rate (CTR) prediction is crucial for Recommendation System(RS), aiming to provide personalized recommendation services for users in many aspects such as food delivery, e-commerce and so on. However, traditional RS relies on collaborative signals, which lacks semantic understanding to real-time scenes. We also noticed that a major challenge in utilizing Large Language Models (LLMs) for practical recommendation purposes is their efficiency in dealing with long text input. To break through the problems above, we propose Large Language Model Aided Real-time Scene Recommendation(LARR), adopt LLMs for semantic understanding, utilizing real-time scene information in RS without requiring LLM to process the entire real-time scene text directly, thereby enhancing the efficiency of LLM-based CTR modeling. Specifically, recommendation domain-specific knowledge is injected into LLM and then RS employs an aggregation encoder to build real-time scene information from separate LLM’s outputs. Firstly, a LLM is continue-pretrained on corpus built from recommendation data with the aid of special tokens. Subsequently, the LLM is fine-tuned via contrastive learning on three kinds of sample construction strategies. Through this step, LLM is transformed into a text embedding model. Finally, LLM’s separate outputs for different scene features are aggregated by an encoder, aligning to collaborative signals in RS, enhancing the performance of recommendation model.</p>
    <p><strong>Categories:</strong> Recommendation Systems (RS), Large Language Models (LLMs), Real-Time Processing, Semantic Understanding, Click-Through Rate (CTR) Prediction, Efficiency in LLMs, Aggregation Methods, Pre-training and Fine-tuning, Contrastive Learning, Text Embedding Models (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1043/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Leveraging LLM generated labels to reduce bad matches in job recommendations (2024)</h3>
    <p><strong>Authors:</strong> Dheeraj Toshniwal, Yingchi Pei, Yi Wei Pang, Nilanjan Sengupta</p>
    <p>Negative signals are increasingly employed to enhance recommendation quality. However, explicit negative feedback is often sparse and may disproportionately reflect the preferences of more vocal users. Commonly used implicit negative feedback, such as impressions without positive interactions, has the limitation of not accurately capturing users’ true negative preferences because users mainly pursue information they consider interesting. In this work, we present an approach that leverages fine-tuned Large Language Models (LLMs) to evaluate matches and generate negative signals at scale while maintaining cost efficiency. We demonstrate significant improvements in recommendation quality by deploying a traditional classifier trained using LLM-generated labels.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Job Recommendations, Negative Feedback Mechanisms, Large Language Models (LLMs), Implicit Feedback Analysis, Model Fine-Tuning, Scalability in ML Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1171/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Fairness Matters: A look at LLM-generated group recommendations (2024)</h3>
    <p><strong>Authors:</strong> Antonela Tommasel</p>
    <p>Recommender systems play a crucial role in how users consume information, with group recommendation receiving considerable attention. Ensuring fairness in group recommender systems entails providing recommendations that are useful and relevant to all group members rather than solely reflecting the majority’s preferences, while also addressing fairness concerns related to sensitive attributes (e.g., gender). Recently, the advancements on Large Language Models (LLMs) have enabled the development of new kinds of recommender systems. However, LLMs can perpetuate social biases present in training data, posing risks of unfair outcomes and harmful impacts. We investigated LLMs impact on group recommendation fairness, establishing and instantiating a framework that encompasses group definition, sensitive attribute combinations, and evaluation methodology. Our findings revealed the interactions patterns between sensitive attributes and LLMs and how they affected recommendation. This study advances the understanding of fairness considerations in group recommendation systems, laying the groundwork for future research.</p>
    <p><strong>Categories:</strong> Recommender Systems, Fairness, Group Recommendations, Large Language Models (LLMs), Sensitive Attributes, Bias Mitigation, Natural Language Processing (NLP), Evaluation Methodology, Social Biases, Societal Impact (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1089/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Distillation Matters: Empowering Sequential  Recommenders to Match the Performance of Large Language Models (2024)</h3>
    <p><strong>Authors:</strong> Jiawei Chen, Yi Wan, Heng Tang, Bohao Wang, Feng Liu, Pengbo Wang, Jun Wang, Yu Cui</p>
    <p>Owing to their powerful semantic reasoning capabilities, Large Language Models (LLMs) have been effectively utilized as recommenders, achieving impressive performance. However, the high inference latency of LLMs significantly restricts their practical deployment. To address this issue, this work investigates knowledge distillation from cumbersome LLM-based recommendation models to lightweight conventional sequential models. It encounters three challenges: 1) the teacher’s knowledge may not always be reliable; 2) the capacity gap between the teacher and student makes it difficult for the student to assimilate the teacher’s knowledge; 3) divergence in semantic space poses a challenge to distill the knowledge from embeddings. To tackle these challenges, this work proposes a novel distillation strategy, DLLM2Rec, specifically tailored for knowledge distillation from LLM-based recommendation models to conventional sequential models. DLLM2Rec comprises: 1) Importance-aware ranking distillation, which filters reliable and student-friendly knowledge by weighting instances according to teacher confidence and student-teacher consistency; 2)  Collaborative embedding distillation integrates knowledge from teacher embeddings with collaborative signals mined from the data. Extensive experiments demonstrate the effectiveness of the proposed DLLM2Rec, boosting three typical sequential models with an average improvement of 47.97%, even enabling them to surpass LLM-based recommenders in some cases.</p>
    <p><strong>Categories:</strong> Knowledge Distillation, Sequential Recommenders, Large Language Models (LLMs), Recommendation Systems, Performance Improvement, Efficiency Optimization, Cold Start, Algorithmic Innovation, Collaborative Filtering, Scalability and Efficiency (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1028/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>User knowledge prompt for sequential recommendation (2024)</h3>
    <p><strong>Authors:</strong> Yuuki Tachioka</p>
    <p>The large language model (LLM) based recommendation system is effective for sequential recommendation, because general knowledge of popular items is included in the LLM. To add domain knowledge of items, the conventional method uses a knowledge prompt obtained from the item knowledge graphs and has achieved SOTA performance. However, for personalized recommendation, it is necessary to consider user knowledge, which the conventional method does not fully consider because user knowledge is not included in the item knowledge graphs; thus, we propose a user knowledge prompt, which converts a user knowledge graph into a prompt using the relationship template. The existing prompt denoising framework is extended to prevent hallucination caused by undesirable interactions between knowledge graph prompts. We propose user knowledge prompts of user traits and user preferences and associate relevant items. Experiments on three types of dataset (movie, music, and book) show the significant and consistent improvement of our proposed user knowledge prompt.</p>
    <p><strong>Categories:</strong> Large Language Models (LLMs), Knowledge Graphs, Sequential Recommendations, Personalized Recommendation, Prompt Engineering, Movies, Music, Books, User Modeling, Empirical Evaluation, Prompt Denoising (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1198/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>