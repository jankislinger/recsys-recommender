<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/scalability/">Scalability</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/performance-evaluation/">Performance Evaluation</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/e-commerce/">E-commerce</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/evaluation-methods/">Evaluation Methods</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Enhancing Performance and Scalability of Large-Scale Recommendation Systems with Jagged Flash Attention (2024)</h3>
    <p><strong>Authors:</strong> Hong Li, Mingwei Tang, Meng Liu, Junjie Yang, Dai Li, Xing Liu, Tunhou Zhang, Arnold Overwijk, Haoci Zhang, Rengan Xu, Sijia Chen, Sri Reddy, Devashish Shankar, Jiaqi Zhai, Bill Zhu, Boyang Li, Zehua Zhang, Yifan Xu, Yuxi Hu</p>
    <p>The integration of hardware accelerators has significantly advanced the capabilities of modern recommendation systems, enabling the exploration of complex ranking paradigms previously deemed impractical. However, the GPU-based computational costs present substantial challenges. In this paper, we demonstrate our development of an efficiency-driven approach to explore these paradigms, moving beyond traditional reliance on native PyTorch modules. We address the specific challenges posed by ranking models’ dependence on categorical features, which vary in length and complicate GPU utilization. We introduce Jagged Feature Interaction Kernels, a novel method designed to extract fine-grained insights from long categorical features through efficient handling of dynamically sized tensors. We further enhance the performance of attention mechanisms by integrating Jagged tensors with Flash Attention. As the feature length grows, the Jagged Flash Attention is able to scale memory linearly rather than quadratically. Our experimental results demonstrate that Jagged Flash Attention achieves speedups of 2.4× to 5.6× over dense attention and reduces memory usage by up to 21.8×. This allows to scale the recommendation systems with longer features and more complex model architecture.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Scalability, GPU Usage, Categorical Features, Efficient Algorithms, Flash Attention, Memory Efficiency, Hardware Acceleration, Performance Optimization, Large-Scale Systems, Attention Mechanisms, Novel Methods, Efficiency-Driven Approaches, Complex Model Architectures. (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1163/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Navigating the Feedback Loop in Recommender Systems: Insights and Strategies from Industry Practice (2023)</h3>
    <p><strong>Authors:</strong> Ding Tong, Justin Basilico, James McInerney, Ting-Po Lee, Qifeng Qiao</p>
    <p>Understanding and measuring the impact of feedback loops in industrial recommender systems is challenging, leading to the underestimation of the deterioration. In this study, we define open and closed feedback loops and investigate the unique reasons behind the emergence of feedback loops in the industry, drawing from real-world examples that have received limited attention in prior research. We highlight the measurement challenges associated with capturing the full impact of feedback loops using traditional online A/B tests. To address this, we propose the use of offline evaluation frameworks as surrogates for long-term feedback loop bias, supported by a practical simulation system using real data. Our findings provide valuable insights for optimizing the performance of recommender systems operating under feedback loop conditions.</p>
    <p><strong>Categories:</strong> Feedback Loops, Recommender Systems, Industry Practice, A/B Test, Evaluation Methods, Real-World Applications, Open Feedback Loop, Closed Feedback Loop, Practical Recommendations, Performance Optimization, Industrial Systems, Simulation, Recommendation Strategies (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1005/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>InTune: Reinforcement Learning-based Data Pipeline Optimization for Deep Recommendation Models (2023)</h3>
    <p><strong>Authors:</strong> Pablo Delgado, Kabir Nagrecha, Lingyi Liu, Prasanna Padmanabhan</p>
    <p>Deep learning-based recommendation models (DLRMs) have become an essential component of many modern recommender systems. Several companies are now building large compute clusters reserved only for DLRM training, driving new interest in cost- & time- saving optimizations. The systems challenges faced in this setting are unique; while typical deep learning (DL) training jobs are dominated by model execution times, the most important factor in DLRM training performance is often online data ingestion. In this paper, we explore the unique characteristics of this data ingestion problem and provide insights into the specific bottlenecks and challenges of the DLRM training pipeline at scale. We study real-world DLRM data processing pipelines taken from our compute cluster to both observe the performance impacts of online ingestion and to identify shortfalls in existing data pipeline optimizers. We find that current tooling either yields sub-optimal performance, frequent crashes, or else requires impractical cluster re-organization to adopt. Our studies lead us to design and build a new solution for data pipeline optimization, InTune. InTune employs a reinforcement learning (RL) agent to learn how to distribute CPU resources across a DLRM data pipeline to more effectively parallelize data-loading and improve throughput. Our experiments show that InTune can build an optimized data pipeline configuration within only a few minutes, and can easily be integrated into existing training workflows. By exploiting the responsiveness and adaptability of RL, InTune achieves significantly higher online data ingestion rates than existing optimizers, thus reducing idle times in model execution and increasing efficiency. We apply InTune to our real-world cluster, and find that it increases data ingestion throughput by as much as 2.29X versus current state-of-the-art data pipeline optimizers while also improving both CPU & GPU utilization.</p>
    <p><strong>Categories:</strong> Reinforcement Learning, Deep Learning Recommender Models, Data Pipeline Optimization, Resource Allocation, Performance Optimization, Real-World Applications, Large-Scale Systems, Compute Clusters, Resource Utilization, Deep Learning, Scalability (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/873/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Rethinking Personalized Ranking at Pinterest: An End-to-End Approach (2022)</h3>
    <p><strong>Authors:</strong> Jiajing Xu</p>
    <p>In this work, we present our journey to revolutionize the personalized recommendation engine through end-to-end learning from raw user actions. We encode user’s long-term interest in PinnerFormer, a user embedding optimized for long-term future actions via a new dense all-action loss, and capture user’s short-term intention by directly learning from the real-time action sequences. We conducted both offline and online experiments to validate the performance of the new model architecture, and also address the challenge of serving such a complex model using mixed CPU/GPU setup in production. The proposed system has been deployed in production at Pinterest and has delivered significant online gains across organic and Ads applications.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Personalized Ranking, End-to-End Learning, Neural Networks, Transformer-Based Models, User Embeddings, Long-Term Interest, Short-Term Intention, Offline Experiments, Online Experiments, A/B Testing, Real-World Applications, Deployment in Production, Scalability, Performance Optimization (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/823/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Fit to Run: Personalised Recommendations for Marathon Training (2020)</h3>
    <p><strong>Authors:</strong> Aonghus Lawlor, Barry Smyth, Jakim Berndsen</p>
    <p>Training for the marathon is a complex problem. In order to run an optimal time, runners must find the right workload for their current abilities and identify the correct balance between the hard work and rest throughout their training programmes. We propose a recommender system that will help guide runners through the weeks leading up to the marathon. Using a large sample of marathon training data (8730 runners), we generate user profiles that capture both a runner’s current fitness and training levels, and leverage this information to generate tailored recommendations for future weeks of training. We investigate patterns of successful runners to determine how best to schedule recommendations and training to allow for improvement in fitness levels alongside adequate rest.</p>
    <p><strong>Categories:</strong> Personalised Recommendations, Sports, Healthcare, Fitness, Training Programs, User Profiling, Performance Optimization, Data-Driven Approaches, Evaluation Metrics, Workload Management (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/573/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Recommendation with the Right Slice: Speeding Up Collaborative Filtering with Factorization Machines (2015)</h3>
    <p><strong>Authors:</strong> Babak Loni, Alan Hanjalic, Alexandros Karatzoglou, Martha Larson</p>
    <p>We propose an alternative way to efficiently exploit rating data for collaborative filtering with Factorization Machines (FMs). Our approach partitions user-item matrix into ‘slices’ which are mutually exclusive with respect to items. The training phase makes direct use of the slice of interest ( slice), while incorporating information from other slices indirectly. FMs represent user-item interactions as feature vectors, and they offer the advantage of easy incorporation of complementary information. We exploit this advantage to integrate information from other slices. We demonstrate, using experiments on two benchmark datasets, that improved performance can be achieved, while the time complexity of training can be reduced significantly.</p>
    <p><strong>Categories:</strong> Collaborative Filtering, Factorization Machines, Recommendations, Scalability, Efficiency Improvements, Rating-based Collaborative Filtering, Data Integration, Algorithm Evaluation, Time Complexity Analysis, Performance Optimization (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/154/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Fast Differentially Private Matrix Factorization (2015)</h3>
    <p><strong>Authors:</strong> Yu-Xiang Wang, Ziqi Liu, Alexander J. Smola</p>
    <p>Differentially private collaborative filtering is a challenging task, both in terms of accuracy and speed. We present a simple algorithm that is provably differentially private, while offering good performance, using a novel connection of differential privacy to Bayesian posterior sampling via Stochastic Gradient Langevin Dynamics. Due to its simplicity the algorithm lends itself to efficient implementation. By careful systems design and by exploiting the power law behavior of the data to maximize CPU cache bandwidth we are able to generate 1024 dimensional models at a rate of 8.5 million recommendations per second on a single PC.</p>
    <p><strong>Categories:</strong> Matrix Factorization, Differential Privacy, Collaborative Filtering, Scalability, Performance Optimization, Recommendation Systems, Probabilistic Methods, High-dimensional Models, Bayesian Inference, Stochastic Gradient Langevin Dynamics (SGLD), Real-world Applications, Web Systems (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/97/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>