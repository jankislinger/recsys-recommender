<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reinforcement-learning/">Reinforcement Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reproducibility/">Reproducibility</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/e-commerce/">E-commerce</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/evaluation-methods/">Evaluation Methods</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Towards Empathetic Conversational Recommender Systems (2024)</h3>
    <p><strong>Authors:</strong> Mingfei Liang, Yougang Lyu, Zhaochun Ren, Zhanhui Kang, Pengjie Ren, Xin Xin, Xiaoyu Zhang, Bo Zhang, Maarten de Rijke, Ruobing Xie</p>
    <p>Conversational recommender systems (CRSs) are able to elicit user preferences through multi-turn dialogues. They typically incorporate external knowledge and pre-trained language models to capture the dialogue context. Most CRS approaches, trained on benchmark datasets, assume that the standard items and responses in these benchmarks are optimal. However, they overlook that users may express negative emotions with the standard items and may not feel emotionally engaged by the standard responses. This issue leads to a tendency to replicate the logic of recommenders in the dataset instead of aligning with user needs. To remedy this misalignment, we introduce empathy within a CRS. With empathy we refer to a system’s ability to capture and express emotions. We propose an empathetic conversational recommender (ECR) framework. ECR contains two main modules: emotion-aware item recommendation and emotion-aligned response generation. Specifically, we employ user emotions to refine user preference modeling for accurate recommendations. To generate human-like emotional responses, ECR applies retrieval-augmented prompts to fine-tune a pre-trained language model aligning with emotions and mitigating hallucination. To address the challenge of insufficient supervision labels, we enlarge our empathetic data using emotion labels annotated by large language models and emotional reviews collected from external resources. We propose novel evaluation metrics to capture user satisfaction in real-world CRS scenarios. Our experiments on the ReDial dataset validate the efficacy of our framework in enhancing recommendation accuracy and improving user satisfaction.</p>
    <p><strong>Categories:</strong> Conversational Recommender Systems, Empathy, Emotion-Aware Recommendation, Natural Language Processing, Multi-Turn Dialogues, User Experience, Emotional Responses Generation, Human-Centered AI, Sentiment Analysis, User Preference Modeling (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1070/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Evaluation and simplification of text difficulty using LLMs in the context of recommending texts in French to facilitate language learning (2024)</h3>
    <p><strong>Authors:</strong> Michalis Vlachos, Yash Raj Shrestha, Henri Jamet, Maxime Manderlier</p>
    <p>We develop a recommendation system for foreign language learning. This recommends text or video content. It ranks digital content considering both the content’s difficulty and how the topic aligns to the learners’ interests. To achieve this, we automatically apply the following operations to any text: a. Classify its subject. b. Evaluate its linguistic difficulty. c. Potentially simplify its language level, while preserving its semantic content for adaptation to the reader’s language level. Once these three operations have produced a set of texts adapted to the reader’s interests and level, they are ranked by relevance using a recommendation system based on the reading and satisfaction of other users. In this paper, we focus on using Large Language Models (LLMs) to automatically perform these tasks on any set of texts. We present an approach for training and evaluation and compare both zero-shot and fine-tuned performance of state-of-the-art models. Our findings indicate a marked improvement in the prediction of French content difficulty (improvement range of 18-56%), a 27% enhancement in topic prediction accuracy with fine-tuned models compared to zero-shot models, and up to an 18% increase in NDCG in recommendation performance.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Language Learning, Text Simplification, Large Language Models (LLMs), Natural Language Processing, Education, French Language, Difficulty Evaluation, Automatic Content Adaptation, User Personalization, Model Evaluation, Recommendation Metrics, User Satisfaction (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1091/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>LyricLure: Mining Catchy Hooks in Song Lyrics to Enhance Music Discovery and Recommendation (2024)</h3>
    <p><strong>Authors:</strong> Tarun Sharma, Siddharth Sharma, Joaquin Delgado, Ajinkya Walimbe, Akshay Shukla</p>
    <p>Amazon Music encounters a significant challenge as users increasingly rely on catchy lines from lyrics to search for both new releases and other popular songs. Integrating lyrics into existing lexical search index or using lyrics vector index pose difficulties due to lyrics text length. While lexical scoring mechanisms like BM25 are inadequate and necessitates complex query planning and index schema for long text, text embedding similarity based techniques often retrieve noisy near-similar meaning lyrics, resulting in low precision. This paper introduces a proactive approach to extract catchy phrases from song lyrics, overcoming the limitations of conventional graph-based phrase extractors and deep learning models, which are primarily designed for extractive summarization or task-specific key phrase extraction from domain-specific corpora. Additionally, we employ a multi-step mechanism to mine search query logs for potential unresolved user queries containing catchy phrases from lyrics. This involves creation of word and character k-gram index for lyric chunks, careful query and lyrics domain-centric normalization (and expansion) and a re-ranking layer incorporating lexical and well as semantic similarity. Together these strategies helped us create a high retrieval source specifically for serving lyrics intent queries with high recall.</p>
    <p><strong>Categories:</strong> Music, Recommendation Systems, Text Mining, Natural Language Processing, Phrase Extraction, Query Log Analysis, Indexing Techniques, Text Preprocessing, Re-ranking Mechanisms, Search Algorithms (BM25, Similarity), Retrieval Optimization, Lyrics Analysis, Lexical Search, Multi-Step Processing (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1170/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Large Language Model Augmented Narrative Driven Recommendations (2023)</h3>
    <p><strong>Authors:</strong> Hamed Zamani, Sheshera Mysore, Andrew Mccallum</p>
    <p>Narrative-driven recommendation (NDR) presents an information access problem where users solicit recommendations with verbose descriptions of their preferences and context, for example, travelers soliciting recommendations for points of interest while describing their likes/dislikes and travel circumstances. These requests are increasingly important with the rise of natural language-based conversational interfaces for search and recommendation systems. However, NDR lacks abundant training data for models, and current platforms commonly do not support these requests. Fortunately, classical user-item interaction datasets contain rich textual data, e.g., reviews, which often describe user preferences and context — this may be used to bootstrap training for NDR models. In this work, we explore using large language models (LLMs) for data augmentation to train NDR models. We use LLMs for authoring synthetic narrative queries from user-item interactions with few-shot prompting and train retrieval models for NDR on synthetic queries and user-item interaction data. Our experiments demonstrate that this is an effective strategy for training small-parameter retrieval models that outperform other retrieval and LLM baselines for narrative-driven recommendation.</p>
    <p><strong>Categories:</strong> Narrative-Driven Recommendations, Large Language Models (LLMs), Data Augmentation, Recommendation Systems, Natural Language Processing, User-Item Interaction, System Design, Textual Data, Retrieval Models, Sparse Data Handling, Synthetic Queries. (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/908/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>MCM: A Multi-task Pre-trained Customer Model for Personalization (2023)</h3>
    <p><strong>Authors:</strong> Tianxin Wang, Peng Wan, Rui Luo, Jingyuan Deng</p>
    <p>Personalization plays a critical role in helping customers discover the products and contents they prefer for e-commerce stores.Personalized recommendations differ in contents, target customers, and UI. However, they require a common core capability – the ability to deeply understand customers’ preferences and shopping intents. In this paper, we introduce the MLCM (Multi-task Large pre-trained Customer Model), a large pre-trained BERT-based multi-task customer model with 10 million trainable parameters for e-commerce stores. This model aims to empower all personalization projects by providing commonly used preference scores for recommendations, customer embeddings for transfer learning, and a pre-trained model for fine-tuning. In this work, we improve the SOTA BERT4Rec framework to handle heterogeneous customer signals and multi-task training as well as innovate new data augmentation method that is suitable for recommendation task. Experimental results show that MLCM outperforms the original BERT4Rec by 17% on preference prediction tasks. Additionally, we demonstrate that the model can be easily fine-tuned to assist a specific recommendation task. For instance, after fine-tuning MLCM for an incentive based recommendation project, performance improves by 60% on the conversion prediction task and 25% on the click-through prediction task compared to the production baseline model.</p>
    <p><strong>Categories:</strong> Personalization, Recommendation Systems, Multi-Task Learning, Deep Learning, E-Commerce, Customer Modeling, Natural Language Processing, Transfer Learning, Data Augmentation, Model Fine-Tuning, Performance Improvement, Incentive-Based Recommendations, Conversion Prediction, Click-Through Rate, Real-World Applications. (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1004/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Leveraging Large Language Models for Sequential Recommendation (2023)</h3>
    <p><strong>Authors:</strong> Panos Louridas, Dietmar Jannach, Marios Fragkoulis, Wouter Zorgdrager, Jesse Harte, Asterios Katsifodimos</p>
    <p>Sequential recommendation problems have received increasing attention in research during the past few years, leading to the inception of a large variety of algorithmic approaches. In this work, we explore how large language models (LLMs), which are nowadays introducing disruptive effects in many AI-based applications, can be used to build or improve sequential recommendation approaches. Specifically, we devise and evaluate three approaches to leverage the power of LLMs in different ways. Our results from experiments on two datasets show that initializing the state-of-the-art sequential recommendation model BERT4Rec with embeddings obtained from an LLM improves NDCG by 15-20% compared to the vanilla BERT4Rec model. Furthermore, we find that a simple approach that leverages LLM embeddings for producing recommendations, can provide competitive performance by highlighting semantically related items. We publicly share the code and data of our experiments to ensure reproducibility.</p>
    <p><strong>Categories:</strong> Large Language Models, Sequential Recommendation, Algorithmic Approaches, Recommendation Systems, Evaluation Methods, Natural Language Processing, Performance Improvement, Embeddings, Reproducibility, Datasets, Research Methods (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/956/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Soliciting User Preferences in Conversational Recommender Systems via Usage-related Questions (2021)</h3>
    <p><strong>Authors:</strong> Ivica Kostric, Filip Radlinski, Krisztian Balog</p>
    <p>A key distinguishing feature of conversational recommender systems over traditional recommender systems is their ability to elicit user preferences using natural language. Currently, the predominant approach to preference elicitation is to ask questions directly about items or item attributes. These strategies do not perform well in cases where the user does not have sufficient knowledge of the target domain to answer such questions. Conversely, in a shopping setting, talking about the planned use of items does not present any difficulties, even for those that are new to a domain. In this paper, we propose a novel approach to preference elicitation by asking implicit questions based on item usage. Our approach consists of two main steps. First, we identify the sentences from a large review corpus that contain information about item usage. Then, we generate implicit preference elicitation questions from those sentences using a neural text-to-text model. The main contributions of this work also include a multi-stage data annotation protocol using crowdsourcing for collecting high-quality labeled training data for the neural model. We show that out approach is effective in selecting review sentences and transforming them to elicitation questions, even with limited training data.</p>
    <p><strong>Categories:</strong> Conversational Recommender Systems, Natural Language Processing, Preference Elicitation, Implicit Feedback, Neural Models, Text Generation, Data Annotation, Crowdsourcing, Recommendation Systems, Review Mining, User Interaction, Usage-Based Recommendations (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/703/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Information Interactions in Outcome Prediction: Quantification and Interpretation using Stochastic Block Models (2021)</h3>
    <p><strong>Authors:</strong> Gaël Poux-Médard, Sabine Loudcher, Julien Velcin</p>
    <p>In most real-world applications, it is seldom the case that a result appears independently from an environment. In social networks, users’ behavior results from the people they interact with, news in their feed, or trending topics. In natural language, the meaning of phrases emerges from the combination of words. In general medicine, a diagnosis is established on the basis of the interaction of symptoms. Here, we propose the Interacting Mixed Membership Stochastic Block Model (IMMSBM), which investigates the role of interactions between entities (hashtags, words, memes, etc.) and quantifies their importance within the aforementioned corpora. We find that in inference tasks, taking them into account leads to average relative changes with respect to non-interacting models of up to 150% in the probability of an outcome and greatly improves the predictions performances. Furthermore, their role greatly improves the predictive power of the model. Our findings suggest that neglecting interactions when modeling real-world phenomena might lead to incorrect conclusions being drawn.</p>
    <p><strong>Categories:</strong> Network Analysis, Graph Theory, Outcome Prediction, Interaction Effects, Probabilistic Models, Social Networks, Natural Language Processing, General Medicine, Model Improvement, Real-World Applications, Stochastic Block Models, Machine Learning, Algorithm Families, Mixed Membership Models, Model Development, Evaluation Metrics (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/644/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Combining Text Summarization and Aspect-based Sentiment Analysis of Users’ Reviews to Justify Recommendations (2019)</h3>
    <p><strong>Authors:</strong> Pasquale Lops, Giovanni Semeraro, Marco de Gemmis, Cataldo Musto, Gaetano Rossiello</p>
    <p>In this paper we present a methodology to justify recommendations that relies on the information extracted from users’ reviews discussing the available items. The intuition behind the approach is to conceive the justification as a summary of the most relevant and distinguishing aspects ofthe item, automatically obtained by analyzing the available reviews. To this end, we designed a pipeline of natural language processing techniques based on aspect extraction, sentiment analysis and text summarization to gather the reviews, process the relevant excerpts,and generate a unique synthesis presenting the main characteristics of the item. Such a summary is finally presented to the target user as justification of the recommendation she received. In the experimental evaluation we carried out a user study in the movie domain (N=141) and the results showed that our approach is able to make the recommendation process more transparent, engaging and trustful for the users. Moreover, the proposed method also beat another review-based explanation technique, thus confirming the validity of our intuition. i>Presentation: Monday Poster Lunch</i</p>
    <p><strong>Categories:</strong> Recommendation Systems, Natural Language Processing, Text Summarization, Aspect-Based Sentiment Analysis, Movie Domain, User Study, Explainability, Trust, Experimental Results, Evaluation Methodology, Pipeline Design, Transparency in AI, User Feedback, Sentiment Analysis, Aspect Extraction, User-Centered Design (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/469/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>BERT, ELMo, USE and InferSent Sentence Encoders: The Panacea for Research-Paper Recommendation? (2019)</h3>
    <p><strong>Authors:</strong> Alessandro Micarelli, Giuseppe Sansonetti, Joeran Beel, Fabio Gasparetti, Hebatallah A. Mohamed Hassan</p>
    <p>Content-based approaches to research paper recommendation are important when user feedback is sparse or not available. The task of content-based matching is challenging, mainly due to the problem of determining the semantic similarity of texts. Nowadays, there exist many sentence embedding models that learn deep semantic representations by being trained on huge corpora, aiming to provide transfer learning to a wide variety of natural language processing tasks. In this work, we present a comparative evaluation among five well-known pre-trained sentence encoders deployed in the pipeline of title-based research paper recommendation. The experimented encoders are USE, BERT, InferSent, ELMo, and SciBERT. For our study, we propose a methodology for evaluating such models in reranking BM25-based recommendations. The experimental results show that the sole consideration of semantic information from these encoders does not lead to improved recommendation performance over the traditional BM25 technique, while their integration enables the retrieval of a set of relevant papers that may not be retrieved by the BM25 ranking function.</p>
    <p><strong>Categories:</strong> BERT, ELMo, USE, InferSent, Research Papers, Content-Based Recommendations, Natural Language Processing, Evaluation, Model Comparison, Recommendation Evaluation, BM25 Integration, Semantic Similarity (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/510/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Deep Language-based Critiquing for Recommender Systems (2019)</h3>
    <p><strong>Authors:</strong> Ga Wu, Scott Sanner, Harold Soh, Kai Luo</p>
    <p>Critiquing is a method for conversational recommendation that adapts recommendations in response to user preference feedback regarding item attributes.  Historical critiquing methods were largely based on constraint- and utility-based methods for modifying recommendations w.r.t. these critiqued attributes.  In this paper, we revisit the critiquing approach from the lens of deep learning based recommendation methods and language-based interaction.  Concretely, we propose an end-to-end deep learning framework with two variants that extend the Neural Collaborative Filtering architecture with explanation and critiquing components.  These architectures not only predict personalized keyphrases for a user and item but also embed language-based feedback in the latent space that in turn modulates subsequent critiqued recommendations. We evaluate the proposed framework on two recommendation datasets containing user reviews.  Empirical results show that our modified NCF approach not only provides a strong baseline recommender and high-quality personalized item keyphrase suggestions, but that it also properly suppresses items predicted to have a critiqued keyphrase. In summary, this paper provides a first step to unify deep recommendation and language-based feedback in what we hope to be a rich space for future research in deep critiquing for conversational recommendation.</p>
    <p><strong>Categories:</strong> Neural Collaborative Filtering, Deep Learning, Recommendation Systems, Critiquing, User Feedback, Natural Language Processing, Beyond Accuracy, Diversity of Recommendations (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/435/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Neural Gaussian Mixture Model for Review-based Rating Prediction (2018)</h3>
    <p><strong>Authors:</strong> Haofei Zhou, Jian Yu, Dong Deng, Liping Jing, Sun Shaolong</p>
    <p>Reviews has been proven to be an important information in recommendation. Different from the overall user-item rating matrix, it can provide textual information that exhibits why a user likes an item or not. Recently, more and more researchers have paid attention on review-based rating prediction. There are two challenging issues: how to extract representative features to characterize users / items from reviews and how to leverage them for recommendation system. In this paper, we propose a Neural Gaussian Mixture Model for review-based rating prediction task (NGMM). Among it, the textual review information is used to construct two parallel neural networks for users and items respectively, so that the users’ preferences and items’ properties can be sufficiently extracted and written as two latent vectors. A shared layer is introduced on the top to couple these two networks together and model user-item rating based on the features learned from reviews. Specifically, each rating is modeled via a Gaussian mixture model, where each Gaussian component has zero variance, the mean described by the corresponding component in user’s latent vector and the weight indicated by the corresponding component in item’s latent vector. Extensive experiments are conducted on five real-world Amazon review datasets. The experimental results have demonstrated that our proposed NGMM model achieves the state-of-the-art performance in review-based rating prediction task.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Review-based Recommendations, Rating Prediction, Deep Learning, Neural Networks, Natural Language Processing, Feature Extraction, Collaborative Filtering, Gaussian Mixture Model, Probabilistic Models, Real-World Applications, Evaluation and Benchmarking (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/353/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Can Readability Enhance Recommendations on Community Question Answering Sites? (2017)</h3>
    <p><strong>Authors:</strong> Ion Madrazo, Oghenemaro Anuyah, David McNeill, Maria Soledad Pera</p>
    <p>We present an initial examination on the impact text complexity has when incorporated into the recommendation process in community question answering sites. We use Read2Vec, a readability assessment tool designed to measure the readability level of short documents, to inform a traditional content-based recommendation strategy. The results highlight the benefits of incorporating readability information in this process.</p>
    <p><strong>Categories:</strong> Recommendation Algorithms, Content-Based Recommendations, Readability, Community Question Answering (CQA), Text Complexity, Evaluation Methods, Content Analysis, Human-Computer Interaction, Natural Language Processing, User Experience (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/316/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Recommender Systems in the Internet of Talking Things (IoTT) (2017)</h3>
    <p><strong>Authors:</strong> Marco De Gemmis, Fedelucio Narducci, Pasquale Lops, Giovanni Semeraro</p>
    <p>In the Internet of Things, smart devices are connected to collect and to exchange data. In our vision, in the Internet of Talking Things, objects such as intelligent fridges will be able to communicate with humans to set up preferences and profiling options which allow a personalized usage of the object. In this paper, we present a recommender system implemented as a Telegram Bot, that can fit with the previous scenario. The system is a movie recommender which exploits the information available in the Linked Open Data (LOD) cloud for generating the recommendations and leading the conversation with the user. It can be easily seen as an intelligent component of a connected TV.</p>
    <p><strong>Categories:</strong> Recommender Systems, Internet of Things (IoT), Human-Computer Interaction, Natural Language Processing, Movie Recommendations, Linked Open Data, Semantic Web, Knowledge Graphs, Chatbot Integration, Conversational Agents, Personalization, Real-World Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/314/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Topical Semantic Recommendations for Auteur Films (2016)</h3>
    <p><strong>Authors:</strong> Till Plumbaum, Andreas Lommatzsch, Christian Rakow</p>
    <p>With the ubiquity of fast internet connections and the growing availability of Video-On-Demand (VOD) services powerful recommender systems are needed. Traditionally, movie recommender systems apply user-based collaborative filtering providing high quality recommendations if users maintain user profiles describing preferences and movie ratings. The shortcomings of Collaborative Filtering are that comprehensive user profiles are required and users tend to get recommendations very similar to the user profile (filter bubble). In addition, CF-based recommenders neither consider current trends nor the context. In order to overcome these weaknesses, we develop a system identifying interesting events in the stream of current news and deploying this information for computing recommendations. Our system gathers topics of interest from Twitter and RSS-Feeds, extracts relevant Named Entities, and uses semantic relations for recommending movies closely related to these topics. We explain the used algorithms and show that our system provides highly relevant recommendations.</p>
    <p><strong>Categories:</strong> Movie Recommendations, Auteur Films, Collaborative Filtering, Context-Aware Recommendations, Named Entity Recognition, Semantic Analysis, Real-Time Data, Trend Detection, Video-on-Demand, Personalized Recommendations, Topic Modeling, Beyond Accuracy, Diversity of Recommendations, Natural Language Processing, Recommendation Systems, Event-Based Recommendations (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/238/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Convolutional Matrix Factorization for Document Context-Aware Recommendation (2016)</h3>
    <p><strong>Authors:</strong> Hwanjo Yu, Sungyong Lee, Jinoh Oh, Chanyoung Park, Donghyun Kim</p>
    <p>Sparseness of user-to-item rating data is one of the major factors that deteriorate the quality of recommender system. To handle the sparsity problem, several recommendation techniques have been proposed that additionally consider auxiliary information to improve rating prediction accuracy. In particular, when rating data is sparse, document modeling-based approaches have improved the accuracy by additionally utilizing textual data such as reviews, abstracts, or synopses. However, due to the inherent limitation of the bag-of-words model, they have difficulties in effectively utilizing contextual information of the documents, which leads to shallow understanding of the documents. This paper proposes a novel context-aware recommendation model, convolutional matrix factorization (ConvMF) that integrates convolutional neural network (CNN) into probabilistic matrix factorization (PMF). Consequently, ConvMF captures contextual information of documents and further enhances the rating prediction accuracy. Our extensive evaluations on three real-world datasets show that ConvMF significantly outperforms the state-of-the-art recommendation models even when the rating data is extremely sparse. We also demonstrate that ConvMF successfully captures subtle contextual difference of a word in a document. Our implementation and datasets are available at http://dm.postech.ac.kr/ConvMF.</p>
    <p><strong>Categories:</strong> Matrix Factorization, Convolutional Neural Networks, Recommendation Systems, Text Mining, Natural Language Processing, Sparsity, Context-Aware Recommendations, Real-World Applications, Hybrid Models (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/168/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>