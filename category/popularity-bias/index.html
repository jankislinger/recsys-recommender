<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui primary button" style="margin: 5px;"
             href="/recsys-recommender/">Popularity Bias</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/bias-mitigation/">Bias Mitigation</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/explainability/">Explainability</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/offline-evaluation/">Offline Evaluation</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Exploratory Analysis of Recommending Urban Parks for Health-Promoting Activities (2024)</h3>
    <p><strong>Authors:</strong> Daniele Quercia, Sanja Šćepanović, Ke Zhou, Linus W. Dietz</p>
    <p>Parks are essential spaces for promoting urban health, and recommender systems could assist individuals in discovering parks for leisure and health-promoting activities. This is particularly important in large cities like London, which has over 1,500 named parks, making it challenging to understand what each park offers. Due to the lack of datasets and the diverse health-promoting activities parks can support (e.g., physical, social, nature-appreciation), it is unclear which recommendation algorithms are best suited for this task. To explore the dynamics of recommending parks for specific activities, we created two datasets: one from a survey of over 250 London residents, and another by inferring visits from over 1 million geotagged Flickr images taken in London parks. Analyzing the geographic patterns of these visits revealed that recommending nearby parks is ineffective, suggesting that this recommendation task is distinct from Point of Interest recommendation. We then tested various recommendation models, identifying a significant popularity bias in the results. Additionally, we found that personalized models have advantages in recommending parks beyond the most popular ones. The data and findings from this study provide a foundation for future research on park recommendations.</p>
    <p><strong>Categories:</strong> Urban Parks, Recommender Systems, Health-Promoting Activities, User Surveys, Popularity Bias, Geographic Patterns, Personalization Techniques, Dataset Creation, Public Health Impact, A/B Test, Recommendation Systems Research (<i>deepseek-r1:70b</i>)</p>
    <p><a href="/recsys-recommender/response/1192/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Putting Popularity Bias Mitigation to the Test: A User-Centric Evaluation in Music Recommenders (2024)</h3>
    <p><strong>Authors:</strong> Robin Ungruh, Karlijn Dinnissen, Maria Soledad Pera, Hanna Hauptmann, Anja Volk</p>
    <p>Popularity bias is a prominent phenomenon in recommender systems (RS), especially in the music domain. Although popularity bias mitigation techniques are known to enhance the fairness of RS while maintaining their high performance, there is a lack of understanding regarding users’ actual perception of the suggested music. To address this gap, we conducted a user study (n=40) exploring user satisfaction and perception of personalized music recommendations generated by algorithms that explicitly mitigate popularity bias. Specifically, we investigate item-centered and user-centered bias mitigation techniques, aiming to ensure fairness for artists or users, respectively. Results show that neither mitigation technique harms the users’ satisfaction with the recommendation lists despite promoting underrepresented items. However, the item-centered mitigation technique impacts user perception; by promoting less popular items, it reduces users’ familiarity with the items. Lower familiarity evokes discovery—the feeling that the recommendations enrich the user’s taste. We demonstrate that this  can ultimately lead to higher satisfaction, highlighting the potential of less-popular recommendations to improve the user experience.</p>
    <p><strong>Categories:</strong> Recommendation Algorithms, Music Recommendations, Popularity Bias, User-Centric Evaluation, Bias Mitigation, Recommender Systems Evaluation, Personalization, User Perception, Fairness in Recommendations, Discovery (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1056/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Enhancing Privacy in Recommender Systems through Differential Privacy Techniques (2024)</h3>
    <p><strong>Authors:</strong> Angela Di Fazio</p>
    <p>Recommender systems have become essential tools for addressing information overload in the digital age. However, the collection and usage of user data for personalized recommendations raise significant privacy concerns. This research focuses on enhancing privacy in recommender systems through the application of differential privacy techniques, particularly in the domain of privacy-preserving data publishing. Our study aims to address three key research questions: (1) developing standardized metrics to characterize and compare recommendation datasets in the context of privacy-preserving data publishing, (2) designing differential privacy algorithms for private data publishing that preserve recommendation quality, and (3) examining the impact of differential privacy on beyond-accuracy objectives in recommender systems. We propose to develop domain-specific metrics for evaluating the similarity between recommendation datasets, analogous to those used in other domains such as trajectory data publication. Additionally, we will investigate methods to balance the trade-off between privacy guarantees and recommendation accuracy, considering the potential disparate impacts on different user subgroups. Finally, we aim to assess the broader implications of implementing differential privacy on beyond-accuracy objectives such as diversity, popularity bias, and fairness. By addressing these challenges, our research seeks to contribute to the advancement of privacy-preserving techniques in recommender systems, facilitating the responsible and secure use of recommendation data while maintaining the utility of personalized suggestions. The outcomes of this study have the potential to significantly benefit the field by enabling the reuse of existing algorithms with minimal adjustments while ensuring robust privacy guarantees.</p>
    <p><strong>Categories:</strong> Privacy Preservation, Differential Privacy, Recommender Systems, Metrics Evaluation, Beyond Accuracy Objectives, Domain-Specific Metrics, Privacy-Preserving Data Publishing, Trade-Off Analysis, User Subgroup Impacts, Diversity, Popularity Bias, Fairness, Responsible Data Use (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1139/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Enhancing Recommendation Quality of the SASRec Model by Mitigating Popularity Bias (2024)</h3>
    <p><strong>Authors:</strong> Xenija Neufeld, Sebastian Loth, Andreas Grün, Venkata Harshit Koneru</p>
    <p>ZDF is a Public Service Media (PSM) broadcaster in Germany that uses recommender systems on its streaming service platform ZDFmediathek. One of the main use cases within the ZDFmediathek is Next Video, which is currently based on a Self-Attention based Sequential Recommendation model (SASRec). For this use case, we modified the loss function, the sampling method of negative items, and introduced the top-k negative sampling strategy and compared this to the vanilla SASRec model. We show that this not only reduces popularity bias, but also increases clicks and the viewing volume compared to that of the vanilla version.</p>
    <p><strong>Categories:</strong> SASRec, Popularity Bias, Recommendation Quality, Streaming Services, Public Service Media, Clicks/Engagement Metrics, Loss Function Modification, Negative Sampling Strategies, Real World Applications, A/B Testing, User Experience Optimization, Cold Start Problem (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1164/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Bridging Search and Recommendation in Generative Retrieval: Does One Task Help the Other? (2024)</h3>
    <p><strong>Authors:</strong> Marco De Nadai, Ali Vardasbi, Enrico Palumbo, Hugues Bouchard, Gustavo Penha</p>
    <p>Generative retrieval for search and recommendation is a promising paradigm for retrieving items, offering an alternative to traditional methods that depend on external indexes and nearest-neighbor searches. Instead, generative models directly associate inputs with item IDs. Given the impressive capabilities of Large Language Models (LLMs), these generative systems play a crucial role in centralizing a variety of Information Retrieval (IR) tasks in a single model that performs tasks such as query understanding, retrieval, recommendation, explanation, re-ranking, and response generation. Despite the growing interest in such a unified generative approach for IR systems, the advantages of using a single, multi-task model over multiple specialized models are not well established in the literature. This paper investigates whether and when such a unified approach can outperform task-specific models in the IR tasks of search and recommendation, broadly co-existing in multiple industrial online platforms, such as Spotify, YouTube, and Netflix. Previous work shows that (1) the latent representations of items, learned by generative recommenders, are biased towards popularity, and (2) content-based and collaborative-filtering-based information can improve an item’s representations. Motivated by this, our study is guided by two hypotheses: [H1] the joint training regularizes the estimation of each item’s popularity, and [H2] the joint training regularizes the item’s latent representations, where search captures content-based aspects of an item and recommendation captures collaborative-filtering aspects. Our extensive experiments with both simulated and real-world data support both [H1] and [H2] as key contributors to the effectiveness improvements observed in the unified search and recommendation generative models over the single-task approaches.</p>
    <p><strong>Categories:</strong> Generative Models, Large Language Models (LLMs), Information Retrieval (IR), Search Systems, Recommendation Systems, Multi-Task Learning, Real-World Applications, Evaluation Metrics, Latent Representations, Popularity Bias, Collaborative Filtering, Content-Based Filtering, Explanation Generation, Industrial Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1030/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>On the Consistency, Discriminative Power and Robustness of Sampled Metrics in Offline Top-N Recommender System Evaluation (2023)</h3>
    <p><strong>Authors:</strong> Dorota Glowacka, Yang Liu, Alan Medlar</p>
    <p>Negative item sampling in offline top-n recommendation evaluation has become increasingly wide-spread, but remains controversial. While several studies have warned against using sampled evaluation metrics on the basis of being a poor approximation of the full ranking (i.e.~using all negative items), others have highlighted their improved discriminative power and potential to make evaluation more robust. Unfortunately, empirical studies on negative item sampling are based on relatively few methods (between 3-12) and, therefore, lack the statistical power to assess the impact of negative item sampling in practice. In this article, we present preliminary findings from a comprehensive benchmarking study of negative item sampling based on 52 recommendation algorithms and 3 benchmark data sets. We show how the number of sampled negative items and different sampling strategies affect the consistency and discriminative power of sampled evaluation metrics. Furthermore, we investigate the impact of sparsity bias and popularity bias on the robustness of these metrics. In brief, we show that the optimal parameterizations for negative item sampling are dependent on data set characteristics and the goals of the investigator, suggesting a need for greater transparency in related experimental design decisions.</p>
    <p><strong>Categories:</strong> Evaluation Metrics, Offline Evaluation, Negative Item Sampling, Recommendation Algorithms, Consistency in Metrics, Discriminative Power, Robustness of Metrics, Sparsity Bias, Popularity Bias (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/961/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Evaluating The Effects of Calibrated Popularity Bias Mitigation: A Field Study (2023)</h3>
    <p><strong>Authors:</strong> Astrid Tessem, Anastasiia Klimashevskaia, Dietmar Jannach, Lars Skjærven, Christoph Trattner, Mehdi Elahi</p>
    <p>Despite their proven various benefits, Recommender Systems can cause or amplify certain undesired effects. In this paper, we focus on Popularity Bias, i.e., the tendency of a recommender system to utilize the effect of recommending popular items to the user. Prior research has studied the negative impact of this type of bias on individuals and society as a whole and proposed various approaches to mitigate this in various domains. However, almost all works adopted offline methodologies to evaluate the effectiveness of the proposed approaches. Unfortunately, such offline simulations can potentially be rather simplified and unable to capture the full picture. To contribute to this line of research and given a particular lack of knowledge about how debiasing approaches work not only offline, but online as well, we present in this paper the results of user study on a national broadcaster movie streaming platform in [country]1, i.e., [platform], following the A/B testing methodology. We deployed an effective mitigation approach for popularity bias, called Calibrated Popularity (CP), and monitored its performance in comparison to the platform’s existing collaborative filtering recommendation approach as a baseline over a period of almost four months. The results obtained from a large user base interacting in real-time with the recommendations indicate that the evaluated debiasing approach can be effective in addressing popularity bias while still maintaining the level of user interest and engagement</p>
    <p><strong>Categories:</strong> Recommender Systems, Popularity Bias, Field Study, A/B Testing, Collaborative Filtering, Real-Time Interaction, User Interest/Engagement, Streaming Platforms, Bias Mitigation, Evaluation Methodology, Real-World Applications, User Behavior Analysis (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/953/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Integrating the ACT-R Framework with Collaborative Filtering for Explainable Sequential Music Recommendation (2023)</h3>
    <p><strong>Authors:</strong> Christian Wallmann, Markus Schedl, Elisabeth Lex, Dominik Kowald, Marta Moscati, Markus Reiter-Haas</p>
    <p>Music listening sessions often consist of sequences including repeating tracks. Modeling such relistening behavior with models of human memory has been proven effective in predicting the next track of a session. However, these models intrinsically lack the capability of recommending novel tracks that the target user has not listened to in the past. Collaborative filtering strategies, on the contrary, provide novel recommendations by leveraging past collective behaviors but are often limited in their ability to provide explanations. To narrow this gap, we propose four hybrid algorithms that integrate collaborative filtering with the cognitive architecture ACT-R. We compare their performance in terms of accuracy, novelty, diversity, and popularity bias, to baselines of different types, including pure ACT-R, kNN-based, and neural-networks-based approaches. We show that the proposed algorithms are able to achieve the best performances in terms of novelty and diversity, and simultaneously achieve a higher accuracy of recommendation with respect to pure ACT-R models. Furthermore, we illustrate how the proposed models can provide explainable recommendations.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Music, ACT-R Framework, Collaborative Filtering, Explainability, Accuracy, Novelty, Diversity, Popularity Bias, kNN-Based Algorithms, Neural Networks, Sequential Recommendations, Real-World Applications, Hybrid Methods, Cold Start (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/919/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Overcoming Recommendation Limitations with Neuro-Symbolic Integration (2023)</h3>
    <p><strong>Authors:</strong> Tommaso Carraro</p>
    <p>Despite being studied for over twenty years, Recommender Systems (RSs) still suffer from important issues that limit their applicability in real-world scenarios. Data sparsity, cold start, and explainability are some of the most impacting problems. Intuitively, these historical limitations can be mitigated by injecting prior knowledge into recommendation models. Neuro-Symbolic (NeSy) approaches are suitable candidates for achieving this goal. Specifically, they aim to integrate learning (e.g., neural networks) with symbolic reasoning (e.g., logical reasoning). Generally, the integration lets a neural model interact with a logical knowledge base, enabling reasoning capabilities. In particular, NeSy approaches have been shown to deal well with poor training data, and their symbolic component could enhance model transparency. This gives insights that NeSy systems could potentially mitigate the aforementioned RSs limitations. However, the application of such systems to RSs is still in its early stages, and most of the proposed architectures do not really exploit the advantages of a NeSy approach. To this end, we conducted preliminary experiments with a Logic Tensor Network (LTN), a novel NeSy framework. We used the LTN to train a vanilla Matrix Factorization model using a First-Order Logic knowledge base as an objective. In particular, we encoded facts to enable the regularization of the latent factors using content information, obtaining promising results. In this paper, we review existing NeSy recommenders, argue about their limitations, show our preliminary results with the LTN, and propose interesting future works in this novel research area. In particular, we show how the LTN can be intuitively used to regularize models, perform cross-domain recommendation, ensemble learning, and explainable recommendation, reduce popularity bias, and easily define the loss function of a model.</p>
    <p><strong>Categories:</strong> Neuro-Symbolic Integration, Recommender Systems, Data Sparsity, Cold Start Problem, Explainability, Neural Networks, Symbolic Reasoning, Logic Tensor Networks (LTN), Matrix Factorization, Content-Based Recommendations, Model Transparency, Regularization, Cross-Domain Recommendation, Ensemble Learning, Popularity Bias (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/986/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Station and Track Attribute-Aware Music Personalization (2023)</h3>
    <p><strong>Authors:</strong> M. Jeffrey Mei, Oliver Bembom, Andreas Ehmann</p>
    <p>We present a transformer for music personalization that recommends tracks given a station seed (artist) and improves the accuracy vs. a baseline matrix factorization method by 10%. Adding more embeddings to capture track and station attributes further improves the accuracy of our recommendations, and also improves recommendation diversity, i.e. mitigates popularity bias. We analyze the learned embeddings and find they learn both explicit attributes provided at training and implicit attributes that may inform listener preferences. We also find that unlike matrix factorization, our model can identify and transfer relevant listener preferences across different genres and artists.</p>
    <p><strong>Categories:</strong> Transformer-Based Models, Music Recommendations, Matrix Factorization, Attribute-Based Recommendations, Recommendation Diversity, Popularity Bias, Listener Preferences, Cross-Domain Recommendations, Evaluation Methods (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1006/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Localify.org: Locally-focus Music Artist and Event Recommendation (2023)</h3>
    <p><strong>Authors:</strong> Cassandra Raineault, Kieran Bentley, Griffin Homan, Paul Gagliano, April Trainor, Elizabeth Richards, Douglas Turnbull, Victoria Conrad</p>
    <p>Cities with strong local music scenes enjoy many social and economic benefits.  To this end, we are interested in developing a locally-focused artist and event recommendation system called Localify.org that supports and promotes local music scenes. Local artists tend to be relatively obscure and reside in the long tail of the artist’s popularity distribution. In this demo paper, we describe both the overall system architecture as well as our core recommender system that uses artist-artist similarity information as opposed to user-artist preference information. We also discuss the role of popularity bias and how we attempt to ameliorate it in the context of local music recommendation.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Music, Local Recommendations, Community Engagement, Content-Based Filtering, Long Tail, Obscure Artists, Popularity Bias, Fairness, System Architecture, Technical Demonstration, Diversity of Recommendations (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/970/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>What We Evaluate When We Evaluate Recommender Systems: Understanding Recommender Systems’ Performance using Item Response Theory (2023)</h3>
    <p><strong>Authors:</strong> Yang Liu, Alan Medlar, Dorota Glowacka</p>
    <p>Current practices in offline evaluation use rank-based metrics to measure the quality of recommendation lists. This approach has practical benefits as it centers assessment on the output of the recommender system and, therefore, measures performance from the perspective of end-users. However, this methodology neglects how recommender systems more broadly model user preferences, which is not captured by only considering the top-n recommendations. In this article, we use item response theory (IRT), a family of latent variable models used in psychometric assessment, to gain a comprehensive understanding of offline evaluation. We used IRT to jointly estimate the latent abilities of 51 recommendation algorithms and the characteristics of 3 commonly used benchmark data sets. For all data sets, the latent abilities estimated by IRT suggest that higher scores from traditional rank-based metrics do not reflect improvements in modeling user preferences. Furthermore, we show the top-n recommendations with the most discriminatory power are biased towards lower difficulty items, leaving much room for improvement. Lastly, we highlight the role of popularity in evaluation by investigating how user engagement and item popularity influence recommendation difficulty.</p>
    <p><strong>Categories:</strong> Evaluation Metrics, Item Response Theory, Recommendation Algorithms, Multi-Algorithm Analysis, User Modeling, Latent Variable Models, Offline Evaluation, Beyond Accuracy, Benchmark Datasets, Popularity Bias, Difficulty Modeling, User Engagement (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/889/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Countering Popularity Bias by Regularizing Score Differences (2022)</h3>
    <p><strong>Authors:</strong> Sung Min Cho, Wondo Rhee, Bongwon Suh</p>
    <p>Recommendation system often suffers from popularity bias. Often the training data inherently exhibits long-tail distribution in item popularity (data bias). Moreover, the recommendation systems could give unfairly higher recommendation scores to popular items even among items a user equally liked, resulting in over-recommendation of popular items (model bias). In this study we propose a novel method to reduce the model bias while maintaining accuracy by directly regularizing the recommendation scores to be equal across items a user preferred. Akin to contrastive learning, we extend the widely used pairwise loss (BPR loss) which maximizes the score differences between preferred and unpreferred items, with a regularization term that minimizes the score differences within preferred and unpreferred items, respectively, thereby achieving both high debias and high accuracy performance with no additional training. To test the effectiveness of the proposed method, we design an experiment using a synthetic dataset which induces model bias with baseline training; we showed applying the proposed method resulted in drastic reduction of model bias while maintaining accuracy. Comprehensive comparison with earlier debias methods showed the proposed method had advantages in terms of computational validity and efficiency. Further empirical experiments utilizing four benchmark datasets and four recommendation models indicated the proposed method showed general improvements over performances of earlier debias methods. We hope that our method could help users enjoy diverse recommendations promoting serendipitous findings. Code available at https://github.com/stillpsy/popbias.</p>
    <p><strong>Categories:</strong> Popularity Bias, Recommendation Systems, Regularization, Pairwise Loss, Loss Functions, Evaluation Metrics, Fairness, Diversity of Recommendations, Model Accuracy, Bias Mitigation, Benchmark Datasets (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/753/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>The Idiosyncratic Effects of Adversarial Training on Bias in Personalized Recommendation Learning (2021)</h3>
    <p><strong>Authors:</strong> Felice Antonio Merra, Tommaso Di Noia, Vito Walter Anelli</p>
    <p>Recently, recommendation systems have been proven to be susceptible to malicious perturbations of the model weights. To overcome this vulnerability, Adversarial Regularization emerged as one of the most effective solutions. Interestingly, the technique not only robustifies the model, but also significantly increases its accuracy. To date, unfortunately, the effect of Adversarial Regularization beyond-accuracy evaluation dimensions is unknown. This paper sheds light on these aspects and investigates how Adversarial Regularization impacts the amplification of popularity bias, and the deterioration of novelty and coverage of the recommendation list. The results highlight that, with imbalanced data distribution, Adversarial Regularization amplifies the popularity bias. Moreover, the empirical validation on five datasets confirms that it degrades the diversity and novelty of the generated recommendation. Code and data are available at https://github.com/sisinflab/The-Idiosyncratic-Effects-of-Adversarial-Training.</p>
    <p><strong>Categories:</strong> Adversarial Training, Adversarial Regularization, Recommendation Systems, Personalized Recommendations, Bias in AI, Algorithmic Bias, Popularity Bias, Diversity of Recommendations, Novelty of Recommendations, Coverage of Recommendations, Beyond Accuracy, Imbalanced Data Distribution, Adversarial Attacks, Quality of Recommendations (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/698/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Biases in Recommendation System (2021)</h3>
    <p><strong>Authors:</strong> Saumya Bhadani</p>
    <p>Recommendation systems shape what people consume and experience online, which makes it critical to assess their effect on society and whether they are affected by any potential source of bias. My research focuses on a specific source of bias — popularity — that is especially relevant in two online contexts: news consumption, and cultural markets. Social media newsfeeds, which are designed to optimize the engagement of users, may inadvertently promote inaccurate and partisan news domains, since these are often popular among like-minded and polarized audiences. More generally, in any type of cultural market, popularity bias may lead to the suppression of niche quality products, which may not attract enough attention. In the context of online newsfeeds, I am investigating whether the political diversity of the audience of a news website can be used as signal of journalistic quality. In an analysis of a comprehensive dataset of news source reliability ratings and web browsing histories, I have shown that the diversity of the audience of a news website is a valuable signal to counter popularity bias and to promote journalistic quality. To further validate these results experimentally, I propose to have direct interactions with social media users through surveys. Here, I provide the details of a field study that I am planning to undertake using an experimental social media platform. More generally, in the context of any online cultural market, political audience diversity may not be applicable but the idea of diversity as a signal for higher quality might still be useful. For example, movies which are liked by an “age diverse” population or books which are read by racially diverse audience may have better quality than other items. However, in this research I have explored audience diversity in the context of social media newsfeeds only. For any online cultural market, I propose a method to quantify the popularity bias through an empirical analysis, using data from several existing markets. Accurately estimating the impact of popularity bias can help us advance our understanding of machine biases and also lead to the development of more robust recommendation systems.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Bias in Algorithms, Popularity Bias, News Consumption, Cultural Markets, Audience Diversity, Empirical Analysis, Experimental Methods, Field Study, User Survey, Misinformation, Content Curation, Beyond Accuracy (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/714/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>TAFA: Two-headed Attention Fused Autoencoder for Context-Aware Recommendations (2020)</h3>
    <p><strong>Authors:</strong> Jin Peng Zhou, Felipe Perez, Maksims Volkovs, Zhaoyue Cheng</p>
    <p>Collaborative filtering with implicit feedback is a ubiquitous class of recommendation problems where only positive interactions such as purchases or clicks are observed. Autoencoder-based recommendation models have shown strong performance on many implicit feedback benchmarks. However, these models tend to suffer from popularity bias making recommendations less personalized. User-generated reviews contain a rich source of preference information, often with specific details that are important to each user, and can help mitigate the popularity bias. Since not all reviews are equally useful, existing work has been exploring various forms of attention to distill relevant information. In the majority of proposed approaches, representations from implicit feedback and review branches are simply concatenated at the end to generate predictions. This can prevent the model from learning deeper correlations between the two modalities and affect prediction accuracy. To address these problems, we propose a novel Two-headed Attention Fused Autoencoder (TAFA) model that jointly learns representations from user reviews and implicit feedback to make recommendations. We apply early and late modality fusion which allows the model to fully correlate and extract relevant information from both input sources. To further combat popularity bias, we leverage the Noise Contrastive Estimation (NCE) objective to “de-popularize” the fused user representation via a two-headed decoder architecture. Empirically, we show that TAFA outperforms leading baselines on multiple real-world benchmarks. Moreover, by tracing attention weights back to reviews we can provide explanations for the generated recommendations and gain further insights into user preferences. Full code for this work is available here: https://github.com/layer6ai-labs/TAFA.</p>
    <p><strong>Categories:</strong> Collaborative Filtering, Implicit Feedback, Autoencoder, Popularity Bias, User Reviews, Attention Mechanisms, Early and Late Fusion, Noise Contrastive Estimation (NCE), Real-World Applications, Interpretability/Explainability, Recommendation Systems, Context-Aware Recommendations (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/555/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>