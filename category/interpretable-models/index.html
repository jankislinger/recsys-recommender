<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui primary button" style="margin: 5px;"
             href="/recsys-recommender/">Interpretable Models</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/offline-evaluation/">Offline Evaluation</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/bias-mitigation/">Bias Mitigation</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/e-commerce/">E-commerce</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Interpretable User Retention Modeling in Recommendation (2023)</h3>
    <p><strong>Authors:</strong> Leyu Lin, Xiaochun Yang, Ruobing Xie, Kaikai Ge, Xu Zhang, Xiaobo Hao, Jie Zhou, Rui Ding</p>
    <p>Recommendation usually focuses on immediate accuracy metrics like CTR as training objectives. User retention rate, which reflects the percentage of today’s users that will return to the recommender system in the next few days, should be paid more attention to in real-world systems. User retention is the most intuitive and accurate reflection of user long-term satisfaction. However, most existing recommender systems are not focused on user retention-related objectives, since their complexity and uncertainty make it extremely hard to discover why a user will or will not return to a system and which behaviors affect user retention. In this work, we conduct a series of preliminary explorations on discovering and making full use of the reasons for user retention in recommendation. Specifically, we make a first attempt to design a rationale contrastive multi-instance learning framework to explore the rationale and improve the interpretability of user retention. Extensive offline and online evaluations with detailed analyses of a real-world recommender system verify the effectiveness of our user retention modeling. We further reveal the real-world interpretable factors of user retention from both user surveys and explicit negative feedback quantitative analyses to facilitate future model designs.</p>
    <p><strong>Categories:</strong> User Retention, Recommendation Systems, Interpretable Models, Model Interpretability, Multi-Instance Learning, A/B Testing, Offline Evaluation, Online Evaluation, Real-World Applications, User Surveys, Explicit Negative Feedback, Long-term User Satisfaction (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/931/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>An Interpretable Neural Network Model for Bundle Recommendations (2022)</h3>
    <p><strong>Authors:</strong> Edward C. Malthouse, Xinyi Li</p>
    <p>A users’ preference for a bundle – a set of items that can be purchased together – can be expressed by the utility of this bundle to the user. The multi-attribute utility theory motivate us to characterize the utility of a bundle using its attributes to improve the personalized bundle recommendation systems. This extended abstract for the Doctoral Symposium describes my PhD project for studying the utility of a bundle using its attributes. The steps taken and some preliminary results are presented, with an outline of the future plans.</p>
    <p><strong>Categories:</strong> Bundle Recommendations, Neural Networks in Recommendations, Interpretable Models, Explainable AI (XAI), Personalization, Beyond Accuracy, Preliminary Results, Theoretical Frameworks, User Preference Modeling, Doctoral Research (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/804/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>An Interpretable Recommendation Model for Gerontological Care (2021)</h3>
    <p><strong>Authors:</strong> Paula Castro, Andre Paulino de Lima, Maria Pimentel, Brunela Orlandi, Laurentino Augusto Dantas, Marcelo Garcia Manzato</p>
    <p>Recommender systems have been successfully applied to diverse areas, but their use in the healthcare domain is still rare. One challenge of applying recommender systems to this domain is related to legal concerns about the consequences of provided recommendations. In this work, we advance an expert-in-the-loop, explanation-first approach to tackle this challenge in a specific healthcare niche: gerontological care. A key aspect of the proposed approach is that both recommendations and explanations reflect the structured questionnaire employed by the practitioner to identify patient needs. Another key aspect is that a clinical dataset of patient assessments and respective assigned interventions is used to estimate effects of alternative interventions during the recommendation process. To evaluate the feasibility of this modelling approach, an explanation style was designed with help of practitioners, and a recommendation model was devised and evaluated against a clinical dataset, which was collected by a partner research group working on gerontological primary care. When compared to other traditional recommendation models, the attained precision was competitive across several evaluation conditions. The results suggest that the proposed approach is feasible and may point new ways of adapting recommender systems to play an assistive role in health care.</p>
    <p><strong>Categories:</strong> Interpretable Models, Healthcare, Gerontology, Regulatory Concerns, Expert Collaboration, Patient Needs, Clinical Data, User-Centered Design, Model Evaluation, Feasibility Studies, Method Comparison, Explainable AI (XAI) (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/680/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>