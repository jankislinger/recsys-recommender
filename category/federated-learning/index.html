<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui primary button" style="margin: 5px;"
             href="/recsys-recommender/">Federated Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/bias-mitigation/">Bias Mitigation</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reproducibility/">Reproducibility</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reinforcement-learning/">Reinforcement Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/cold-start/">Cold Start</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Stalactite: toolbox for fast prototyping of vertical federated learning systems (2024)</h3>
    <p><strong>Authors:</strong> Maria Khodorchenko, Anastasiia Zakharova, Dmitriy Alexandrov, Alexey Vasilev, Maxim Savchenko, Nikolay Butakov, Alexander Grigorievskiy</p>
    <p>Machine learning (ML) models trained on datasets owned by different organizations and physically located in remote databases offer benefits in many real-world use cases. State regulations or business requirements often prevent data transfer to a central location, making it difficult to utilize standard machine learning algorithms. Federated Learning (FL) is a technique that enables models to learn from distributed datasets without revealing the original data. Vertical Federated learning (VFL) is a type of FL where data samples are divided by features across several data owners. For instance, in a recommendation task, a user can interact with various sets of items, and the logs of these interactions are stored by different organizations. In this demo paper, we present Stalactite – an open-source framework for VFL that provides the necessary functionality for building prototypes of VFL systems. It has several advantages over the existing frameworks. In particular, it allows researchers to focus on the algorithmic side rather than engineering and to easily deploy learning in a distributed environment. It implements several VFL algorithms and has a built-in homomorphic encryption layer. We demonstrate its use on a real-world recommendation datasets.</p>
    <p><strong>Categories:</strong> Federated Learning, Vertical Federated Learning (VFL), Recommendation Systems, Machine Learning Frameworks, Algorithm Implementation, Homomorphic Encryption, Security and Privacy, Distributed Systems, Multi-Party Computation, Rapid Prototyping, Real-World Applications, Data Privacy, Open Source Tools (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1208/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Privacy Preserving Conversion Modeling in Data Clean Room (2024)</h3>
    <p><strong>Authors:</strong> Behnam Rezaei, Xiangyi Chen, Ling Leng, Jiajing Xu, Jiankai Sun, Kungang Li</p>
    <p>In the realm of online advertising, accurately predicting the conversion rates (CVR) is crucial for enhancing advertising efficiency and user satisfaction. However, it faces the challenge that due to user privacy choices and advertiser requirements, the advertising platform cannot get the conversion data from some advertisers, making accurate CVR predictions difficult. Although current methods like split learning or vertical federated learning do not share label information directly, they still exchange sample-level gradients, which introduces a privacy risk as adversaries might infer label information through the shared gradients. To address these challenges, our proposed model training framework incorporates several innovative techniques. Firstly, we employ batch-level aggregated gradients instead of sample-level gradients to enhance privacy. Secondly, to minimize communication costs, we utilize adapter-based parameter-efficient fine-tuning methods such as Low-Rank Adaptation (LoRA) and gradient compression in conversion models. These methods allow for efficient collaboration between different parties while reducing the amount of data transferred. Lastly, we incorporate label differential privacy to protect model privacy. Given that this privacy protection alters the data distribution and can result in significant calibration error, we propose a de-biasing technique to ensure accurate model predictions even with perturbed label information. Our experimental results on industrial datasets demonstrate that our method achieves competitive performance while significantly reducing the communication overhead and complying with advertisers’ privacy requirements and user privacy choice. This framework establishes a new benchmark for privacy-preserving and high-performance CVR prediction in the digital advertising industry.</p>
    <p><strong>Categories:</strong> Privacy Preservation, Conversion Rate Prediction, Online Advertising, Machine Learning, Federated Learning, Differential Privacy, Optimization Methods, Data Sharing Challenges, Low-Rank Adaptation (LoRA), Gradient Compression, Advertising Technology, Real-World Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1181/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>FedLoCA: Low-Rank Coordinated Adaptation with Knowledge Decoupling for Federated Recommendations (2024)</h3>
    <p><strong>Authors:</strong> Yong Liao, Boyu Fan, Pengyuan Zhou, Siqing Zhang, Yuchen Ding, Wei Sun</p>
    <p>Privacy protection in recommendation systems is gaining increasing attention, for which federated learning has emerged as a promising solution. Current federated recommendation systems grapple with high communication overhead due to sharing dense global embeddings, and also poorly reflect user preferences due to data heterogeneity. To overcome these challenges, we propose a two-stage Federated Low-rank Coordinated Adaptation (FedLoCA) framework to decouple global and client-specific knowledge into low-rank embeddings, which significantly reduces communication overhead while enhancing the system’s ability to capture individual user preferences amidst data heterogeneity. Further, to tackle gradient estimation inaccuracies stemming from data sparsity in federated recommendation systems, we introduce an adversarial gradient projected descent approach in low-rank spaces, which significantly boosts model performance while maintaining robustness. Remarkably, FedLoCA also alleviates performance loss even under the stringent constraints of differential privacy. Extensive experiments on various real-world datasets demonstrate that FedLoCA significantly outperforms existing methods in both recommendation accuracy and communication efficiency.</p>
    <p><strong>Categories:</strong> Federated Learning, Privacy Protection, Recommendation Systems, Communication Efficiency, Low-Rank Embeddings, Personalization, Gradient Estimation, Optimization, Differential Privacy, Data Heterogeneity, Cold Start, Evaluation Metrics (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1037/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Toward Fair Federated Recommendation Learning: Characterizing the Inter-Dependence of System and Data Heterogeneity (2022)</h3>
    <p><strong>Authors:</strong> John Nguyen, Luca Melis, Kiwan Maeng, Carole-Jean Wu, Haiyu Lu, Mike Rabbat</p>
    <p>Federated learning (FL) is an effective mechanism for data privacy in recommender systems that runs machine learning model training on-device. While prior FL optimizations tackled the data and system heterogeneity challenges, they assume the two are independent of each other. This fundamental assumption is not reflective of real-world, large-scale recommender systems — data and system heterogeneity are tightly intertwined. This paper takes a data-driven approach to show the inter-dependence of data and system heterogeneity in real-world data and quantifies its impact on the overall model quality and fairness. We design a framework, RF2, to model the inter-dependence and evaluate its impact on state-of-the-art model optimization techniques for federated recommendation tasks. We demonstrate that the impact on fairness can be severe under realistic heterogeneity scenarios, by up to 15.8–41 × compared to a simple setup assumed in most (if not all) prior work. The result shows that modeling realistic system-induced data heterogeneity is essential to achieving fair federated recommendation learning.</p>
    <p><strong>Categories:</strong> Federated Learning, Recommender Systems, Fairness in Recommendations, Data Heterogeneity, System Heterogeneity, Inter-Domain Interactions, Model Quality Evaluation, Real-World Applications, Privacy in Machine Learning, Algorithm Design and Optimization (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/779/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Fairness-aware Federated Matrix Factorization (2022)</h3>
    <p><strong>Authors:</strong> Yingqiang Ge, Yongfeng Zhang, Shuchang Liu, Shuyuan Xu, Amelie Marian</p>
    <p>Achieving fairness over different user groups in recommender systems is an important problem. The majority of existing works achieve fairness through constrained optimization that combines the recommendation loss and the fairness constraint. To achieve fairness, the algorithm usually needs to know each user’s group affiliation feature such as gender or race. However, such involved user group feature is usually sensitive and requires protection. In this work, we seek a federated learning solution for the fair recommendation problem and identify the main challenge as an algorithmic conflict between the global fairness objective and the localized federated optimization process. On one hand, the fairness objective usually requires access to all users’ group information. On the other hand, the federated learning systems restrain the personal data in each user’s local space. As a resolution, we propose to communicate group statistics during federated optimization and use differential privacy techniques to avoid exposure of users’ group information when users require privacy protection. We illustrate the theoretical bounds of the noisy signal used in our method that aims to enforce privacy without overwhelming the aggregated statistics. Empirical results show that federated learning may naturally improve user group fairness and the proposed framework can effectively control this fairness with low communication overheads.</p>
    <p><strong>Categories:</strong> Matrix Factorization, Fairness, Federated Learning, Recommendation Systems, Algorithm Design, Differential Privacy, Evaluation Methods, Cold Start, Web Systems, Scalability, User Group Fairness (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/761/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Stronger Privacy for Federated Collaborative Filtering With Implicit Feedback (2021)</h3>
    <p><strong>Authors:</strong> Ben Livshits, Lorenzo Minto, Hamed Haddadi, Moritz Haller</p>
    <p>Recommender systems are commonly trained on centrally-collected user interaction data like views or clicks. This practice however raises serious privacy concerns regarding the recommender’s collection and handling of potentially sensitive data. Several privacy-aware recommender systems have been proposed in recent literature, but comparatively little attention has been given to systems at the intersection of implicit feedback and privacy. To address this shortcoming, we propose a practical federated recommender system for implicit data under user-level local differential privacy (LDP). The privacy-utility trade-off is controlled by parameters ϵ and k, regulating the per-update privacy budget and the number of ϵ-LDP gradient updates sent by each user, respectively. To further protect the user’s privacy, we introduce a proxy network to reduce the fingerprinting surface by anonymizing and shuffling the reports before forwarding them to the recommender. We empirically demonstrate the effectiveness of our framework on the MovieLens dataset, achieving up to Hit Ratio with K=10 (HR@10) 0.68 on 50,000 users with 5,000 items. Even on the full dataset, we show that it is possible to achieve reasonable utility with HR@10>0.5 without compromising user privacy.</p>
    <p><strong>Categories:</strong> Privacy in Recommendation Systems, Federated Collaborative Filtering, Implicit Feedback, Local Differential Privacy (LDP), Federated Learning, Recommendation Algorithms, Privacy-Preserving Machine Learning, User Privacy, Collaborative Filtering, Data Anonymization (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/666/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>A Payload Optimization Method for Federated Recommender Systems (2021)</h3>
    <p><strong>Authors:</strong> Kuan Eeik Tan, Zareen Alamgir, Muhammad Ammad-ud-din, Farwa K. Khan, Adrian Flanagan</p>
    <p>In this study, we introduce the payload optimization method for federated recommender systems (FRS). In federated learning (FL), the global model payload that is moved between the server and users depends on the number of items to recommend. The model payload grows when there is an increasing number of items. This becomes challenging for FRS if it is running in production mode. To tackle the payload challenge, we formulated a multi-arm bandit solution that selected part of the global model and transmitted it to all users. The selection process was guided by a novel reward function suitable for FL systems. So far as we are aware, this is the first optimization method that seeks to address item dependent payloads. The method was evaluated using three benchmark recommendation datasets. The empirical validation confirmed that the proposed method outperforms the simpler methods that do not benefit from the bandits for the purpose of item selection. In addition, we have demonstrated the usefulness of our proposed method by rigorously evaluating the effects of a payload reduction on the recommendation performance degradation. Our method achieved up to a 90% reduction in model payload, yielding only a ∼ 4% - 8% loss in the recommendation performance for highly sparse datasets.</p>
    <p><strong>Categories:</strong> Federated Learning, Recommendation Systems, Payload Optimization, Multi-Armed Bandits, Model Compression, Federated Recommender Systems, Scalability, Recommendation Payloads, Model Selection, Empirical Evaluation (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/621/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>FR-FMSS: Federated Recommendation via Fake Marks and Secret Sharing (2021)</h3>
    <p><strong>Authors:</strong> Zhaohao Lin, Weike Pan, Zhong Ming</p>
    <p>With the implementation of privacy protection laws such as GDPR, it is increasingly difficult for organizations to legally collect user data. However, a typical recommendation algorithm based on machine learning requires user data to learn user preferences. In order to protect user privacy, a lot of recent works turn to develop federated learning-based recommendation algorithms. However, some of these works can only protect the users’ rating values, some can only protect the users’ rating behavior (i.e., the engaged items), and only a few works can protect the both types of privacy at the same time. Moreover, most of them can only be applied to a specific algorithm or a class of similar algorithms. In this paper, we propose a generic cross-user federated recommendation framework called FR-FMSS. Our FR-FMSS can not only protect the two types of user privacy, but can also be applied to most recommendation algorithms for rating prediction, item ranking, and sequential recommendation. Specifically, we use fake marks and secret sharing to modify the data uploaded by the clients to the server, which protects user privacy without loss of model accuracy. We take three representative recommendation algorithms, i.e., MF-MPC, eALS, and Fossil, as examples to show how to apply our FR-FMSS to a specific algorithm.</p>
    <p><strong>Categories:</strong> Federated Learning, Matrix Factorization, Recommendation Systems, Privacy Preservation, Cross-User Federated Recommendations, Fake Marks, Secret Sharing, User Privacy Protection, Model Accuracy, A/B Testing, Data Privacy, Cold Start, User-Centric (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/688/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Horizontal Cross-Silo Federated Recommender Systems (2021)</h3>
    <p><strong>Authors:</strong> Saikishore Kalloori</p>
    <p>Recommender systems (RSs) completely rely on the knowledge of training information to generate recommendations. However, due to privacy, ownership, and protection of users’ information, such training information is not easily accessible or shared with an RS. Moreover, with recent regulations in privacy laws (e.g, GDPR), collecting user preferences and perform centralized training may not be feasible. Federated Learning (FL) is a form of machine learning technique where the goal is to learn a high-quality recommendation model without never directly accessing raw training data. In this work, we specifically focus on situations where multiple stakeholders (referred to as corporate companies like e-commerce business partners, hospitals, banks, news media publishers) participate in federated learning to build a shared recommendation model. We performed offline experiments by simulating a real federated learning setup and investigated the benefits federated learning brings to stakeholders in terms of ranking compared to an RS model trained without participating in federated learning. Our experimental results reveal that stakeholders can significantly benefit from federated learning to generate accurate recommendations. Moreover, we also study the use and benefits of federated learning in situations when there are not enough preferences available for users.</p>
    <p><strong>Categories:</strong> Federated Learning, Recommender Systems, Privacy-Preserving Techniques, Cross-Silo Collaboration, Horizontal Federated Learning, Stakeholder Benefits, Decentralized Recommendation, User Privacy Protection, Multi-Party Collaboration (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/687/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>A Federated Recommender System for Online Services (2020)</h3>
    <p><strong>Authors:</strong> Ben Tan, Qiang Yang, Vincent Zheng, Bo Liu</p>
    <p>Due to privacy and security constraints, directly sharing user data between parties is undesired. Such decentralized data silo issues commonly exist in recommender systems. In general, recommender systems are data-driven. The more data it uses, the better performance it obtains. The data silo issues is a severe limitation of the recommender’s performance. Federated learning is an emerging technology, which bridges the data silos and builds machine learning models without compromising user privacy and data security. We design a recommender system based on federated learning. It is known as the federated recommender system. The system implements plenty of popular algorithms to support various online recommendation services. The algorithm implementation is open-sourced. We also deploy the system on a real-world content recommendation application, achieving significant performance improvement. In this demonstration, we present the architecture of the federated recommender system and give an online demo to show its detailed working procedures and results in content recommendations.</p>
    <p><strong>Categories:</strong> Federated Learning, Recommender Systems, Online Services, Data Silos, Privacy, Algorithm Implementation, Open Source, Real-World Applications, Evaluation Methods, Performance Analysis, Content Recommendations, System Demonstrations (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/596/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>