<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/user-behavior/">User Behavior</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reproducibility/">Reproducibility</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/explainability/">Explainability</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/scalability/">Scalability</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>OutRank: Speeding up AutoML-based Model Search for Large Sparse Data sets with Cardinality-aware Feature Ranking (2023)</h3>
    <p><strong>Authors:</strong> Blaž Škrlj, Blaž Mramor</p>
    <p>The design of modern recommender systems relies on understanding which parts of the feature space are relevant for solving a given recommendation task. However, real-world data sets in this domain are often characterized by their large size, sparsity, and noise, making it challenging to identify meaningful signals. Feature ranking represents an efficient branch of algorithms that can help address these challenges by identifying the most informative features and facilitating the automated search for more compact and better-performing models (AutoML). We introduce OutRank, a system for versatile feature ranking and data quality-related anomaly detection. OutRank was built with categorical data in mind, utilizing a variant of mutual information that is normalized with regard to the noise produced by features of the same cardinality. We further extend the similarity measure by incorporating information on feature similarity and combined relevance. The proposed approach’s feasibility is demonstrated by speeding up the state-of-the-art AutoML system on a synthetic data set with no performance loss. Furthermore, we considered a real-life click-through-rate prediction data set where it outperformed strong baselines such as random forest-based approaches. The proposed approach enables exploration of up to 300% larger feature spaces compared to AutoML-only approaches, enabling faster search for better models on off-the-shelf hardware.</p>
    <p><strong>Categories:</strong> Recommendation Algorithms, Feature Ranking, AutoML, Large Data Sets, Sparse Data, Categorical Data, Cardinality-aware Methods, Anomaly Detection, Information Theory, Synthetic Data, Real-world Applications, Computational Efficiency, Model Search (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/965/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Gradient Matching for Categorical Data Distillation in CTR Prediction (2023)</h3>
    <p><strong>Authors:</strong> Ruixuan Li, Zhenhua Dong, Jiacheng Sun, Cheng Wang, Rui Zhang</p>
    <p>The cost of hardware and energy consumption on training a click-through rate (CTR) model is highly prohibitive. A recent promising direction for reducing such costs is data distillation with gradient matching, which aims to synthesize a small distilled dataset to guide the model to a similar parameter space as those trained on real data. However, there are two main challenges to implementing such a method in the recommendation field: (1) The categorical recommended data are high dimensional and sparse one- or multi-hot data which will block the gradient flow, causing backpropagation-based data distillation invalid. (2) The data distillation process with gradient matching is computationally expensive due to the bi-level optimization. To this end, we investigate efficient data distillation tailored for recommendation data with plenty of side information where we formulate the discrete data to the dense and continuous data format. Then, we further introduce a one-step gradient matching scheme, which performs gradient matching for only a single step to overcome the inefficient training process. The overall proposed method is called Categorical data distillation with Gradient Matching (CGM), which is capable of distilling a large dataset into a small of informative synthetic data for training CTR models from scratch. Experimental results show that our proposed method not only outperforms the state-of-the-art coreset selection and data distillation methods but also has remarkable cross-architecture performance. Moreover, we explore the application of CGM on continual updating and mitigate the effect of different random seeds on the training results.</p>
    <p><strong>Categories:</strong> Categorical Data, Gradient Matching, Click-Through Rate (CTR), Recommendation Systems, Data Distillation, High Dimensional Data, Sparse Data, Dense Representation, Bi-Level Optimization, Continual Learning, Practical Applications, Efficiency, Scalability, Data Transformation. (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/870/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Personalized Recommendations using Knowledge Graphs: A Probabilistic Logic Programming Approach (2016)</h3>
    <p><strong>Authors:</strong> William Cohen, Rose Catherine</p>
    <p>Improving the performance of recommender systems using knowledge graphs is an important task. There have been many hybrid systems proposed in the past that use a mix of content-based and collaborative filtering techniques to boost the performance. More recently, some work has focused on recommendations that use external knowledge graphs (KGs) to supplement content-based recommendation. In this paper, we investigate three methods for making KG based recommendations using a general-purpose probabilistic logic system called ProPPR. The simplest of the models, EntitySim, uses only the links of the graph. We then extend the model to TypeSim that also uses the types of the entities to boost its generalization capabilities. Next, we develop a graph based latent factor model, GraphLF, which combines the strengths of latent factorization with graphs. We compare our approaches to a recently proposed state-of-the-art graph recommendation method on two large datasets, Yelp and MovieLens-100K. The experiments illustrate that our approaches can give large performance improvements. Additionally, we demonstrate that knowledge graphs give maximum advantage when the dataset is sparse, and gradually become redundant as more training data becomes available, and hence are most useful in cold-start settings.</p>
    <p><strong>Categories:</strong> Personalized Recommendations, Knowledge Graphs, Probabilistic Logic Programming, Content-Based Filtering, Collaborative Filtering, Knowledge Graph Recommendations, Real World Applications, Experiments, Evaluation Methods, Cold Start, Sparse Data, Recommendation Techniques, Latent Factor Models (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/190/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Risk-Hedged Venture Capital Investment Recommendation (2015)</h3>
    <p><strong>Authors:</strong> Jun Wang, Xiaoxue Zhao, Weinan Zhang</p>
    <p>With the increasing accessibility of transactional data in venture finance, venture capital (VC) firms face great challenges in developing quantitative tools to identify new investment opportunities. Recommendation techniques have the possibility of helping VCs making data-driven investment decisions by providing an automatic screening process of the large number of startups across different domains on the basis of their past investment data. A previous study has shown the potential advantage of using collaborative filtering to catch and predict the VCs’ investment behaviours. However, two fundamental challenges in venture finance make conventional recommendation techniques difficult to apply. First, risk factors should be cautiously considered when making investments: for a potential startup, a VC needs to specifically estimate how well this new investment can fit into its investment portfolio in such a way that investment risk can be . Second, The investment behaviours are much sparser than conventional recommendation applications and a VC’s investments are usually limited to a few industry categories, making it impossible to use a topic-diversification method to hedge the risk. In this paper, we solve the startup recommendation problem from a risk management perspective. We propose 5 risk-aware startup selection and ranking algorithms to catch the VCs’ investment behaviours and predict their new investments. Apart from the contribution on the new risk-aware recommendation model, our experiments on the collected CrunchBase dataset show significant performance improvements over strong baselines.</p>
    <p><strong>Categories:</strong> Financial Investment, Venture Capital, Quantitative Analysis, Risk Management, Recommendation Systems, Algorithmic Solutions, Real-World Application, Risk Hedging, Portfolio Management, Domain-Specific Recommendations, Sparse Data, Diversification Challenges, Investment Behavior Analysis, Risk-Aware Models, Venture Finance, Research Contribution (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/104/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>