<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reinforcement-learning/">Reinforcement Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reproducibility/">Reproducibility</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/evaluation-methods/">Evaluation Methods</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/explainability/">Explainability</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>KGGLM: A Generative Language Model for Generalizable Knowledge Graph Representation Learning in Recommendation (2024)</h3>
    <p><strong>Authors:</strong> Alessandro Soccol, Giacomo Balloccu, Gianni Fenu, Mirko Marras, Ludovico Boratto</p>
    <p>Current recommendation methods based on knowledge graphs rely on entity and relation representations for several steps along the pipeline, with knowledge completion and path reasoning being the most influential. Despite their similarities, the most effective representation methods for these steps differ, leading to inefficiencies, limited representativeness, and reduced interpretability. In this paper, we introduce KGGLM, a decoder-only Transformer model designed for generalizable knowledge representation learning to support recommendation. The model is trained on generic paths sampled from the knowledge graph to capture foundational patterns, and then fine-tuned on paths specific of the downstream step (knowledge completion and path reasoning in our case). Experiments on ML1M and LFM1M show that KGGLM beats twenty-two baselines in effectiveness under both knowledge completion and recommendation. Source code and pre-processed data sets are available at https://github.com/mirkomarras/kgglm.</p>
    <p><strong>Categories:</strong> Recommendation Algorithms, Knowledge Graphs, Generative Models, Transformer Models, Representation Learning, Knowledge Completion, Path Reasoning, Evaluation Methods, Effectiveness in Recommendations, Scalability (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1195/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Comparative Analysis of Pretrained Audio Representations in Music Recommender Systems (2024)</h3>
    <p><strong>Authors:</strong> Yan-Martin Tamm, Anna Aljanaki</p>
    <p>Over the years, Music Information Retrieval (MIR) has proposed various foundation models pretrained on large amounts of music data. Transfer learning showcases proven effectiveness of foundation models with a broad spectrum of downstream tasks, including auto-tagging and genre classification. However, MIR papers generally do not explore the efficiency of foundation models for Music Recommender Systems (MRS). In addition, the Recommender Systems (RS) community tends to favour traditional end-to-end neural network learning over these models. Our research addresses this gap and evaluates the applicability of six pretrained foundation models (MusicFM, Music2Vec, MERT, EncodecMAE, Jukebox, and MusiCNN) in the context of MRS. We assess their performance using three recommendation models: K-nearest neighbours (KNN), shallow neural network, and BERT4Rec. Our findings suggest that these models exhibit significant performance variability between traditional MIR tasks and MRS, indicating that valuable aspects of musical information captured by foundation models may differ depending on the task. This study establishes a foundation for further exploration of pretrained foundation models to enhance music recommendation systems.</p>
    <p><strong>Categories:</strong> Pretrained Models, Music Recommender Systems, Transfer Learning, Evaluation Methods, Music Information Retrieval, Neural Networks, Recommendation Algorithms, Audio Representations (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1084/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Fairness and Transparency in Music Recommender Systems: Improvements for Artists (2024)</h3>
    <p><strong>Authors:</strong> Karlijn Dinnissen</p>
    <p>Music streaming services have become one of the main sources of music consumption in the last decade, with recommender systems as an important component. As those systems partially decide the songs that music consumers listen to, the systems greatly impact the artists who created the songs. However, when evaluating performance and fairness of these music recommending systems (MRSs), the perspective of the item providers or other music industry professionals is often not considered. Additionally, artists indicate they would appreciate more transparency – both towards and users and the artists themselves – regarding why certain items are recommended and others are not. This research project takes a multi-stakeholder approach to bridge the gap between music systems and their item providers. We first establish artists’ and music industry professionals’ perspective on MRSs through interviews and questionnaires. Based on those insights, we then aim to increase matching between end users and lesser-known artists by generating rich item and user representations. Results will be evaluated both quantitatively and qualitatively. Lastly, we plan to effectively communicate MRS fairness by increasing transparency for both end users and artists.</p>
    <p><strong>Categories:</strong> Fairness, Transparency, Music Recommender Systems (MRS), Artist Perspective, Stakeholder Approach, Evaluation Methods, Recommendation Algorithms, Representation Learning, Multi-Stakeholder Systems, User-Centric Design, Algorithmic Transparency, Diversity in Recommendations (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1136/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Unified Denoising Training for Recommendation (2024)</h3>
    <p><strong>Authors:</strong> Yingpeng Du, Ziyan Wang, Haoyan Chua, Zhu Sun, Jie Zhang, Yew-Soon Ong</p>
    <p>Most existing denoising recommendation methods mainly alleviate noisy implicit feedback (user behaviors) through empirical studies. However, such studies may lack theoretical explainability and fail to model comprehensive noise patterns, which hinders understanding and capturing different noise patterns that show distinct effects on users’ behaviors. Thus, we propose to capture comprehensive noise patterns through a holistic theoretical analysis for more effective denoising, whereby users’ behaviors are divided into the willingness (to interact with) and action (to interact with) phases to disentangle the independent noise patterns. Our analysis unveils that (1) in the willingness phase, the high uncertainty of the user’s willingness to interact with the item can lead to high expectation loss, unifying explainability for existing denoising methods; and (2) in the action phase, higher user-specific inconsistency between willingness and action can not only lead to more noise in the user’s overall behaviors but also make it harder to distinguish between her true and noisy behaviors. All these findings are also aligned with our empirical observations. Inspired by these findings, we propose a Unified Denoising Training (UDT) method for recommendation. To alleviate uncertainty in the willingness phase, we lower the importance of the user-item interaction with high willingness uncertainty recognized by high loss. To ease the inconsistency in the action phase, we lower the overall importance for users with high user-specific inconsistency as it may lead to more noisy behaviors, and then increase the importance gap between recognized true and noisy behaviors for users with low user-specific inconsistency as their behaviors are more distinguishable. Extensive experiments on three real-world datasets show that our proposed UDT outperforms state-of-the-art denoising recommendation methods.</p>
    <p><strong>Categories:</strong> Recommendation Algorithms, Implicit Feedback, User Behavior Modeling, Noise Handling, Real-World Applications, Theoretical Analysis, Unified Approach, Willingness-Action Phases, Recommendation Quality, Denoising Methods (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1072/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Putting Popularity Bias Mitigation to the Test: A User-Centric Evaluation in Music Recommenders (2024)</h3>
    <p><strong>Authors:</strong> Robin Ungruh, Karlijn Dinnissen, Maria Soledad Pera, Hanna Hauptmann, Anja Volk</p>
    <p>Popularity bias is a prominent phenomenon in recommender systems (RS), especially in the music domain. Although popularity bias mitigation techniques are known to enhance the fairness of RS while maintaining their high performance, there is a lack of understanding regarding users’ actual perception of the suggested music. To address this gap, we conducted a user study (n=40) exploring user satisfaction and perception of personalized music recommendations generated by algorithms that explicitly mitigate popularity bias. Specifically, we investigate item-centered and user-centered bias mitigation techniques, aiming to ensure fairness for artists or users, respectively. Results show that neither mitigation technique harms the users’ satisfaction with the recommendation lists despite promoting underrepresented items. However, the item-centered mitigation technique impacts user perception; by promoting less popular items, it reduces users’ familiarity with the items. Lower familiarity evokes discovery—the feeling that the recommendations enrich the user’s taste. We demonstrate that this  can ultimately lead to higher satisfaction, highlighting the potential of less-popular recommendations to improve the user experience.</p>
    <p><strong>Categories:</strong> Recommendation Algorithms, Music Recommendations, Popularity Bias, User-Centric Evaluation, Bias Mitigation, Recommender Systems Evaluation, Personalization, User Perception, Fairness in Recommendations, Discovery (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1056/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>MMGCL: Meta Knowledge-Enhanced Multi-view Graph Contrastive Learning for Recommendations (2024)</h3>
    <p><strong>Authors:</strong> Wentao Zhang, Peng Jiang, Gaode Chen, Qi Zhang, Jingjian Lin, Changyu Li, Yuezihan Jiang, Peiyi Li, Fei Sun</p>
    <p>Multi-view Graph Learning is popular in recommendations due to its ability to capture relationships and connections across multiple views. Existing multi-view graph learning methods generally involve constructing graphs of views and performing information aggregation on view representations. Despite their effectiveness, they face two data limitations: Multi-focal Multi-source data noise and multi-source Data Sparsity. The former arises from the combination of noise from individual views and conflicting edges between views when information from all views is combined. The latter occurs because multi-view learning exacerbate the negative influence of data sparsity because these methods require more model parameters to learn more view information. Motivated by these issues, we propose MMGCL, a meta knowledge-enhanced multi-view graph contrastive learning framework for recommendations. To tackle the data noise issue, MMGCL extract meta knowledge to preserve important information from all views to form a meta view representation. It then rectifies every view in multi-learning frameworks, thus simultaneously removing the view-private noisy edges and conflicting edges across different views. To address the data sparsity issue, MMGCL performs meta knowledge transfer contrastive learning optimization on all views to reduce the searching space for model parameters and add more supervised signal. Besides, we have deployed MMGCL in a real industrial recommender system in China, and we further evaluate it on four benchmark datasets and a practical industry online application. Extensive experiments on these datasets demonstrate the state-of-the-art recommendation performance of MMGCL.</p>
    <p><strong>Categories:</strong> Recommendation Algorithms, Multi-View Graph Learning, Meta Knowledge Enhancement, Data Noise, Data Sparsity, Recommendations Domain, Challenges in Recommendations, Multi-View Learning, Real-World Applications, Industrial Applications, Unsupervised Learning, Beyond Accuracy (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1050/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>It’s Not You, It’s Me: The Impact of Choice Models and Ranking Strategies on Gender Imbalance in Music Recommendation (2024)</h3>
    <p><strong>Authors:</strong> Michael Ekstrand, Andres Ferraro, Christine Bauer</p>
    <p>As recommender systems are prone to various biases, mitigation approaches are needed to ensure that recommendations are fair to various stakeholders. One particular concern in music recommendation is artist gender fairness. Recent work has shown that the gender imbalance in the sector translates to the output of music recommender systems, creating a feedback loop that can reinforce gender biases over time. In this work, we examine whether algorithmic strategies or user behavior are a greater contributor to ongoing improvement (or loss) in fairness as models are repeatedly re-trained on new user feedback data. We simulate this repeated process to investigate the effects of ranking strategies and user choice models on gender fairness metrics. We find re-ranking strategies have a greater effect than user choice models on recommendation fairness over time</p>
    <p><strong>Categories:</strong> Re-ranking, Recommendation Algorithms, Music, Gender Imbalance, Bias Mitigation, Fairness Metrics, Algorithmic Bias, Feedback Loops, Evaluation of Algorithms, Model Retraining (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1094/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>The MovieLens Beliefs Dataset: Collecting Pre-Choice Data for Online Recommender Systems (2024)</h3>
    <p><strong>Authors:</strong> Guy Aridor, Duarte Goncalves, Daniel Kluver, Ruoyan Kong, Joseph Konstan</p>
    <p>An increasingly important aspect of designing recommender systems involves considering how recommendations will influence consumer choices. This paper addresses this issue by introducing a method for collecting user beliefs about un-experienced items – a critical predictor of choice behavior. We implemented this method on the MovieLens platform, resulting in a rich dataset that combines user ratings, beliefs, and observed recommendations. We document challenges to such data collection, including selection bias in response and limited coverage of the product space. This unique resource empowers researchers to delve deeper into user behavior and analyze user choices absent recommendations, measure the effectiveness of recommendations, and prototype algorithms that leverage user belief data, ultimately leading to more impactful recommender systems.</p>
    <p><strong>Categories:</strong> User Behavior, Pre-Choice Data, Recommender Systems, MovieLens, Dataset, User Feedback, Recommendation Algorithms, Research Methods, Movies, Data Collection Challenges, Recommender Systems Design, Evaluation Metrics, Algorithm Development, Belief Modeling, User Choices, Cold Start (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1106/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Multiple Connectivity Views for Session-based Recommendation (2023)</h3>
    <p><strong>Authors:</strong> Zheng Miao, Yujing Wang, Yaming Yang, Jieyu Zhang, Yunhai Tong</p>
    <p>Session-based recommendation (SBR), which makes the next-item recommendation based on previous anonymous actions, has drawn increasing attention. The last decade has seen multiple deep learning-based modeling choices applied on SBR successfully, e.g., recurrent neural networks (RNNs), convolutional neural networks (CNNs), graph neural networks (GNNs), and each modeling choice has its intrinsic superiority and limitation. We argue that these modeling choices differentiate from each other by (1) the way they capture the interactions between items within a session and (2) the operators they adopt for composing the neural network, e.g., convolutional operator or self-attention operator. In this work, we dive deep into the former as it is relatively unique to the SBR scenario, while the latter is shared by general neural network modeling techniques. We first introduce the concept of connectivity view to describe the different item interaction patterns at the input level. Then, we develop the Multiple Connectivity Views for Session-based Recommendation (MCV-SBR), a unified framework that incorporates different modeling choices in a single model through the lens of connectivity view. In addition, MCV-SBR allows us to effectively and efficiently explore the search space of the combinations of connectivity views by the Tree-structured Parzen Estimator Approach (TPE) algorithm. Finally, on three widely used SBR datasets, we verify the superiority of MCV-SBR by comparing the searched models with state-of-the-art baselines. We also conduct a series of studies to demonstrate the efficacy and practicability of the proposed connectivity view search algorithm, as well as other components in MCV-SBR.</p>
    <p><strong>Categories:</strong> Session-based Recommendation, Neural Networks, Connectivity Views, Modeling Choices in SBR, Tree-structured Parzen Estimator (TPE), Deep Learning, Unsupervised Learning, Evaluation Studies, Recommendation Algorithms (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/938/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Alleviating the Long-Tail Problem in Conversational Recommender Systems (2023)</h3>
    <p><strong>Authors:</strong> Zhao Cao, Kun Zhou, Fan Pan, Zhipeng Zhao, Xiaolei Wang, Wayne Xin Zhao, Ji-Rong Wen</p>
    <p>Conversational recommender systems (CRS) aim to provide the recommendation service via natural language conversations. To develop an effective CRS, high-quality CRS datasets are very crucial. However, existing CRS datasets suffer from the long-tail issue, \ie a large proportion of items are rarely (or even never) mentioned in the conversations, which are called long-tail items. As a result, the CRSs trained on these datasets tend to recommend frequent items,  and the diversity of the recommended items would be largely reduced, making users easier to get bored. To address this issue, this paper presents <b>LOT-CRS</b>, a novel framework that focuses on simulating and utilizing a balanced CRS dataset (\ie covering all the items evenly) for improving <b>LO</b>ng-<b>T</b>ail recommendation performance of CRSs. In our approach, we design two pre-training tasks to enhance the understanding of simulated conversation for long-tail items, and adopt retrieval-augmented fine-tuning with label smoothness strategy to further improve the recommendation of long-tail items. Extensive experiments on two public CRS datasets have demonstrated the effectiveness and extensibility of our approach, especially on long-tail recommendation. All the experimental codes will be released after the review period.</p>
    <p><strong>Categories:</strong> Conversational Recommender Systems, Long-Tail Problem, Deep Learning, Natural Language Processing (NLP), Personalization, Recommendation Algorithms, Diversity of Recommendations, Beyond Accuracy Evaluation, Data Simulation, Coverage, Real-World Applications, Recommendation Improvement. (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/851/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Reproducibility Analysis of Recommender Systems relying on Visual Features: traps, pitfalls, and countermeasures (2023)</h3>
    <p><strong>Authors:</strong> Elio Musacchio, Marco Polignano, Antonio Silletti, Pasquale Lops, Giovanni Semeraro, Cataldo Musto</p>
    <p>Reproducibility is an important requirement for scientific progress, and the lack of reproducibility for a large amount of published research can hinder the progress over the state-of-the-art. This concerns several research areas, and recommender systems are witnessing the same reproducibility crisis. Even solid works published at prestigious venues might not be reproducible for several reasons: data might not be public, source code for recommendation algorithms might not be available or well documented, and evaluation metrics might be computed using parameters not explicitly provided. In addition, recommendation pipelines are becoming increasingly complex due to the use of deep neural architectures or representations for multimodal side information involving text, images, audio, or video. This makes the reproducibility of experiments even more challenging. In this work, we describe an extension of an already existing open-source recommendation framework, called ClayRS, with the aim of providing the foundation for future reproducibility of recommendation processes involving images as side information. This extension, called ClayRS Can See, is the starting point for reproducing state-of-the-art recommendation algorithms exploiting images. We have provided our implementation of one of these algorithms, namely VBPR – Visual Bayesian Personalized Ranking from Implicit Feedback, and we have discussed all the issues related to the reproducibility of the study to deeply understand the main traps and pitfalls, along with solutions to deal with such complex environments. We conclude the work by proposing a checklist for recommender systems reproducibility as a guide for the research community.</p>
    <p><strong>Categories:</strong> Reproducibility, Recommendation Algorithms, Visual Features, Open Source, Recommendation Systems, Image Processing, Evaluation Metrics, Implementation, Challenges in Reproduducibility, Guidelines, Implicit Feedback, Multimodal Data (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/943/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>On the Consistency, Discriminative Power and Robustness of Sampled Metrics in Offline Top-N Recommender System Evaluation (2023)</h3>
    <p><strong>Authors:</strong> Dorota Glowacka, Yang Liu, Alan Medlar</p>
    <p>Negative item sampling in offline top-n recommendation evaluation has become increasingly wide-spread, but remains controversial. While several studies have warned against using sampled evaluation metrics on the basis of being a poor approximation of the full ranking (i.e.~using all negative items), others have highlighted their improved discriminative power and potential to make evaluation more robust. Unfortunately, empirical studies on negative item sampling are based on relatively few methods (between 3-12) and, therefore, lack the statistical power to assess the impact of negative item sampling in practice. In this article, we present preliminary findings from a comprehensive benchmarking study of negative item sampling based on 52 recommendation algorithms and 3 benchmark data sets. We show how the number of sampled negative items and different sampling strategies affect the consistency and discriminative power of sampled evaluation metrics. Furthermore, we investigate the impact of sparsity bias and popularity bias on the robustness of these metrics. In brief, we show that the optimal parameterizations for negative item sampling are dependent on data set characteristics and the goals of the investigator, suggesting a need for greater transparency in related experimental design decisions.</p>
    <p><strong>Categories:</strong> Evaluation Metrics, Offline Evaluation, Negative Item Sampling, Recommendation Algorithms, Consistency in Metrics, Discriminative Power, Robustness of Metrics, Sparsity Bias, Popularity Bias (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/961/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Ti-DC-GNN: Incorporating Time-Interval Dual Graphs for Recommender Systems (2023)</h3>
    <p><strong>Authors:</strong> Maria Ivanova, Nikita Severin, Ivan Kireev, Ilya Makarov, Andrey Savchenko, Dmitrii Kiselev</p>
    <p>Recommender systems are essential for personalized content delivery and have become increasingly popular in recent years. However, traditional recommender systems are limited in their ability to capture complex relationships between users and items. Recently, dynamic graph neural networks (DGNNs) have emerged as a promising solution for improving recommender systems by incorporating temporal and sequential information in dynamic graphs. In this paper, we propose a novel method, “Ti-DC-GNN” (Time-Interval Dual Causal Graph Neural Networks), based on an intermediate representation of graph evolution as a sequence of time-interval graphs. The main parts of the method are the novel forms of interval graphs: graph of causality and graph of consequence that explicitly preserve inter-relationships between edges (user-items interactions). The local and global message passing are developed based on edge memory to identify both short-term and long-term dependencies. Experiments on several well-known datasets show that our method consistently outperforms modern temporal GNNs with node memory alone in dynamic edge prediction tasks.</p>
    <p><strong>Categories:</strong> Recommender Systems, Graph Neural Networks, Temporal Dynamics, Recommendation Algorithms, Personalization, User-Item Interactions, Dynamic Graph Neural Networks, Evaluation Metrics, Algorithmic Advances, Time Interval Analysis (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/928/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Contrastive Learning with Frequency-Domain Interest Trends for Sequential Recommendation (2023)</h3>
    <p><strong>Authors:</strong> Guisheng Yin, Yuxin Dong, Yichi Zhang</p>
    <p>Recently, contrastive learning for sequential recommendation has demonstrated its powerful ability to learn high-quality user representations. However, constructing augmented samples in the time domain poses challenges due to various reasons, such as fast-evolving trends, interest shifts, and system factors. Furthermore, the F-principle indicates that deep learning preferentially fits the low-frequency part, resulting in poor performance on high-frequency tasks. The complexity of time series and the low-frequency preference limit the utility of sequence encoders. To address these challenges, we need to construct augmented samples from the frequency domain, thus improving the ability to accommodate events of different frequency sizes. To this end, we propose a novel Contrastive Learning with Frequency-Domain Interest Trends for Sequential Recommendation (CFIT4SRec). We treat the embedding representations of historical interactions as “images” and introduce the second-order Fourier transform to construct augmented samples. The components of different frequency sizes reflect the interest trends between attributes and their surroundings in the hidden space. We introduce three data augmentation operations to accommodate events of different frequency sizes: low-pass augmentation, high-pass augmentation, and band-stop augmentation. Extensive experiments on four public benchmark datasets demonstrate the superiority of CFIT4SRec over the state-of-the-art baselines. The implementation code is available at https://github.com/zhangyichi1Z/CFIT4SRec.</p>
    <p><strong>Categories:</strong> Contrastive Learning, Sequential Recommendation, Frequency-Domain Analysis, Data Augmentation, User Representation Learning, Recommendation Algorithms, Time Series Analysis, Deep Learning, Signal Processing Techniques, Interest Evolution Modeling (<i>deepseek-r1:70b</i>)</p>
    <p><a href="/recsys-recommender/response/855/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>What We Evaluate When We Evaluate Recommender Systems: Understanding Recommender Systems’ Performance using Item Response Theory (2023)</h3>
    <p><strong>Authors:</strong> Yang Liu, Alan Medlar, Dorota Glowacka</p>
    <p>Current practices in offline evaluation use rank-based metrics to measure the quality of recommendation lists. This approach has practical benefits as it centers assessment on the output of the recommender system and, therefore, measures performance from the perspective of end-users. However, this methodology neglects how recommender systems more broadly model user preferences, which is not captured by only considering the top-n recommendations. In this article, we use item response theory (IRT), a family of latent variable models used in psychometric assessment, to gain a comprehensive understanding of offline evaluation. We used IRT to jointly estimate the latent abilities of 51 recommendation algorithms and the characteristics of 3 commonly used benchmark data sets. For all data sets, the latent abilities estimated by IRT suggest that higher scores from traditional rank-based metrics do not reflect improvements in modeling user preferences. Furthermore, we show the top-n recommendations with the most discriminatory power are biased towards lower difficulty items, leaving much room for improvement. Lastly, we highlight the role of popularity in evaluation by investigating how user engagement and item popularity influence recommendation difficulty.</p>
    <p><strong>Categories:</strong> Evaluation Metrics, Item Response Theory, Recommendation Algorithms, Multi-Algorithm Analysis, User Modeling, Latent Variable Models, Offline Evaluation, Beyond Accuracy, Benchmark Datasets, Popularity Bias, Difficulty Modeling, User Engagement (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/889/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Delivery Hero Recommendation Dataset: A Novel Dataset for Benchmarking Recommendation Algorithms (2023)</h3>
    <p><strong>Authors:</strong> Christian Klaue, Raghav Bali, Luke Bovard, Yernat Assylbekov</p>
    <p>In this paper, we propose a new dataset, Delivery Hero Recommendation Dataset (DHRD), which provides a diverse real-world dataset for researchers. DHRD comprises over a million food delivery orders from three distinct cities, encompassing thousands of vendors and an extensive range of dishes, serving a combined customer base of over a million individuals. We discuss the challenges associated with such real-world datasets. By releasing DHRD, researchers are empowered with a valuable resource for building and evaluating recommender systems, paving the way for advancements in this domain.</p>
    <p><strong>Categories:</strong> Recommendation Algorithms, Food/Restaurants, Benchmarking Datasets, Research Resources, Real-World Applications, Dataset Challenges (Data Quality Issues), Evaluation Metrics, User Behavior Analysis, Implicit Feedback, Data Collection (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/992/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>