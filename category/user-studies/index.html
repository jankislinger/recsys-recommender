<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/real-world-applications/">Real-world Applications</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/bias-mitigation/">Bias Mitigation</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reinforcement-learning/">Reinforcement Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reproducibility/">Reproducibility</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Less is More: Towards Sustainability-Aware Persuasive Explanations in Recommender Systems (2024)</h3>
    <p><strong>Authors:</strong> Seda Polat Erdeniz, Viet-Man Le, Sebastian Lubos, Alexander Felfernig, Merfat El Mansi, Thi Ngoc Trang Tran</p>
    <p>Recommender systems play an important role in supporting the achievement of the United Nations sustainable development goals (SDGs). In recommender systems, explanations can support different goals, such as increasing a user’s trust in a recommendation, persuading a user to purchase specific items, or increasing the understanding of the reasons behind a recommendation. In this paper, we discuss the concept of “sustainability-aware persuasive explanations” which we regard as a major concept to support the achievement of the mentioned SDGs. Such explanations are orthogonal to most existing explanation approaches since they focus on a “less is more” principle, which per se is not included in existing e-commerce platforms. Based on a user study in three item domains, we analyze the potential impacts of sustainability-aware persuasive explanations. The study results are promising regarding user acceptance and the potential impacts of such explanations.</p>
    <p><strong>Categories:</strong> Sustainability, Recommender Systems, User Trust, Persuasion, Explanation Methods, User Studies, Ethical Considerations, Sustainable Development Goals (SDGs), Human-Computer Interaction, Impact Analysis (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1202/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>EasyStudy: Framework for Easy Deployment of User Studies on Recommender Systems (2023)</h3>
    <p><strong>Authors:</strong> Ladislav Peska, Patrik Dokoupil</p>
    <p>Improvements in the recommender systems (RS) domain are not possible without a thorough way to evaluate and compare newly proposed approaches. User studies represent a viable alternative to online and offline evaluation schemes, but despite their numerous benefits, they are only rarely used. One of the main reasons behind this fact is that preparing a user study from scratch involves a lot of extra work on top of a simple algorithm proposal.  To simplify this task, we propose \textsc{EasyStudy}, a modular framework built on the credo “<i>Make simple things fast and hard things possible</i>”. It features ready-to-use datasets, preference elicitation methods, incrementally tuned baseline algorithms, study flow plugins, and evaluation metrics. As a result, a simple study comparing several RS can be deployed with just a few clicks, while more complex study designs can still benefit from a range of reusable components, such as preference elicitation. Overall, \textsc{EasyStudy} dramatically decreases the gap between the laboriousness of offline evaluation vs. user studies and, therefore, may contribute towards the more reliable and insightful user-centric evaluation of next-generation RS.</p>
    <p><strong>Categories:</strong> Recommender Systems, User-Centric Evaluation, Evaluation Methods, User Studies, Preference Elicitation, Framework Development, Baseline Algorithms, Beyond Accuracy Evaluation, Scalability, Modular Frameworks (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/962/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Measuring and Mitigating Bias and Harm in Personalized Advertising (2021)</h3>
    <p><strong>Authors:</strong> Muhammad Ali</p>
    <p>Online personalized advertising is often very effective in identifying relevant audiences for each piece of content, which has led to its widespread adoption. In today’s internet, however, these advertising systems are used not only to market products, but also consequential life opportunities such as employment or housing, as well as socially important political messaging. This has led to increasing concerns about the presence of algorithmic bias and possible discrimination in these important domains — with results showing problematic biases along gender, race, and political affiliation, even when the advertiser might have targeted broadly.<br>A growing body of work focuses on measuring and characterizing these biases, as well as finding ways to mitigate these effects and building responsible systems. However, these results often emerge from different scientific communities and are often disconnected in the literature. In this paper, I attempt at bridging the gap between isolated efforts to either measure these biases, or to mitigate them. I discuss how the need to measure bias in advertising, and the efforts to mitigate it, despite being distant in the literature, are complementary problems that need to center their methodolgy around user studies.<br>This paper presents a research agenda that focuses on the need for user-centric measurements of bias, by collecting real ads from users, and using surveys to understand user perceptions for these ads. My approach also calls for incorporating user sentiments into the mitigation efforts, by constraining optimization on user values that emerge from surveys. Finally, I also emphasize the need for involving users in the evaluation of responsible advertising systems; efforts to mitigate bias eventually need to be contextualized in terms of benefits to users instead of simple performance tradeoffs. My focus on the users is motivated by the fact that they are stakeholders in personalized advertising, vulnerable at the hand of algorithmic bias and harm, and therefore crucial in both efforts to measure and mitigate these effects.</p>
    <p><strong>Categories:</strong> Bias in Algorithms, Discrimination, Personalized Advertising, User-Centric Design, Stakeholder Analysis, Measurement Tools, Mitigation Strategies, Responsible AI, Ethics, Harm Reduction, Real-World Applications, Fairness in Algorithms, Cross-Disciplinary Approaches, Algorithmic Justice, User Studies (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/719/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Impact of Item Consumption on Assessment of Recommendations in User Studies (2018)</h3>
    <p><strong>Authors:</strong> Jürgen Ziegler, Tim Donkers, Benedikt Loepp, Timm Kleemann</p>
    <p>In user studies of recommender systems, participants typically cannot consume the recommended items. Still, they are asked to assess recommendation quality and other aspects related to user experience by means of questionnaires. Without having listened to recommended songs or watched suggested movies, however, this might be an error-prone task, possibly limiting validity of results obtained in these studies. In this paper, we investigate the effect of actually consuming the recommended items. We present two user studies conducted in different domains showing that in some cases, differences in the assessment of recommendations and in questionnaire results occur. Apparently, it is not always possible to adequately measure user experience without allowing users to consume items. On the other hand, depending on domain and provided information, participants sometimes seem to approximate the actual value of recommendations reasonably well.</p>
    <p><strong>Categories:</strong> Recommendation Systems, User Behavior, Human Factors, Evaluation Methods, Measurement Validity, Domain Analysis, User Experience, Contextual Factors, Assessment Accuracy, User Studies (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/380/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Effective User Interface Designs to Increase Energy-efficient Behavior in a Rasch-based Energy Recommender System (2017)</h3>
    <p><strong>Authors:</strong> Alain Starke, Chris Snijders, Martijn Willemsen</p>
    <p>People often struggle to find appropriate energy-saving measures to take in the household. Although recommender studies show that tailoring a system’s interaction method to the domain knowledge of the user can increase energy savings, they did not actually tailor the conservation advice itself. We present two large user studies in which we support users to make an energy-efficient behavioral change by presenting tailored energy-saving advice. Both systems use a one-dimensional, ordinal Rasch scale, which orders 79 energy-saving measures on their behavioral difficulty and link this to a user’s energy-saving ability for tailored advice. We established that recommending Rasch-based advice can reduce a user’s effort, increase system support and, in turn, increase choice satisfaction and lead to the adoption of more energy-saving measures. Moreover, follow-up surveys four weeks later point out that tailoring advice on its feasibility can lead to behavioral change.</p>
    <p><strong>Categories:</strong> User Interface Design, Energy Efficiency, Recommender Systems, User Studies, Behavioral Change, Personalization, Evaluation, Sustainability (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/264/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Exploring the Semantic Gap for Movie Recommendations (2017)</h3>
    <p><strong>Authors:</strong> Mehdi Elahi, Stefano Cereda, Paolo Cremonesi, Yashar Deldjoo, Farshad Bakhshandegan, Leonardo Cella</p>
    <p>In the last years, we have seen much attention given to the semantic gap problem in multimedia recommender systems. Much effort has been devoted to bridge this gap by building tools for the extraction of high-level, semantics-based features from multimedia content, as low-level features are not considered useful because they deal primarily with representing the perceived content rather than the semantics of it. In this paper, we explore a different point of view, by leveraging the gap between low-level and high-level features. We experiment with a recent approach for movie recommendations that extract low-level mise-en-scene features from multimedia content and combine it with high-level features provided by the wisdom of the crowd. For our purposes, we first designed an empirical study involving 100 subjects and implemented a movie recommender system with three different versions of the same algorithm, respectively based on (i) conventional movie attributes, (ii) mise-en-scene features, and (iii) a combination of mise-en-scene features and movie attributes. We collected data regarding the quality perceived by the users. In another study, we compared users’ perceived utility of recommendation with offline quality measures. Results from both studies show that the introduction of mise-en-scene features in conjunction with traditional attributes improves both offline and online quality of recommendations.</p>
    <p><strong>Categories:</strong> Movies, Recommender Systems, Content-Based Filtering, Semantic Gap, Feature Combination, Algorithm Design, Evaluation Metrics, User Studies, Online vs Offline Quality, Mise-en-Scène Features, Wisdom of the Crowd (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/292/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Item Familiarity Effects in User-Centric Evaluations of Recommender Systems (2015)</h3>
    <p><strong>Authors:</strong> Michael Jugovac, Dietmar Jannach, Lukas Lerche</p>
    <p>Laboratory studies are a common way of comparing recommendation approaches with respect to different quality dimensions that might be relevant for real users. One typical experimental setup is to first present the participants with recommendation lists that were created with different algorithms and then ask the participants to assess these recommendations individually or to compare two item lists. The cognitive effort required by the participants for the evaluation of item recommendations in such settings depends on whether or not they already know the (features of the) recommended items. Furthermore, lists containing popular and broadly known items are correspondingly easier to evaluate. In this paper we report the results of a user study in which participants recruited on a crowdsourcing platform assessed system-provided recommendations in a between-subjects experimental design. The results surprisingly showed that . An analysis revealed a measurable correlation between item familiarity and user acceptance. Overall, the observations indicate that item familiarity can be a potential confounding factor in such studies and should be considered in experimental designs.</p>
    <p><strong>Categories:</strong> Recommender Systems, User-Centric Evaluation, Evaluation Methodology, Crowdsourcing, Human Factors in Recommendation, Item Familiarity, Experimental Design, User Studies, Behavioral Analysis, Confounding Factors (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/151/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Social Influence Bias in Recommender Systems: A Methodology for Learning, Analyzing, and Mitigating Bias in Ratings (2014)</h3>
    <p><strong>Authors:</strong> Jay Patel, Sanjay Krishnan, Michael Franklin, Ken Goldberg</p>
    <p>To facilitate browsing and selection, almost all recommender systems display an aggregate statistic (the average/mean or median rating value) for each item. This value has potential to influence a participant’s individual rating for an item due to what is known in the survey and psychology literature as Social Influence Bias; the tendency for individuals to conform to what they perceive as the norm in a community. As a result, ratings can be closer to the average and less diverse than they would be otherwise. We propose a methodology to 1) learn, 2) analyze, and 3) mitigate the effect of social influence bias in recommender systems. In the Learning phase, a baseline dataset is established with an initial set of participants by allowing them to rate items twice: before seeing the median rating, and again after seeing it. In the Analysis phase, a new non-parametric significance test based on the Wilcoxon statistic can quantify the extent of social influence bias in this data. If this bias is significant, we propose a Mitigation phase where mathematical models are constructed from this data using polynomial regression and the Bayesian Information Criterion (BIC) and then inverted to produce a filter that can reduce the effect of social influence bias. As a case study, we apply this methodology to the California Report Card (CRC), a new recommender system that encourages political engagement. After the Learning phase collected 9390 ratings, the non-parametric test in the Analysis phase rejected the null hypothesis, identifying significant social influence bias: ratings after display of the median were on average 19.3% closer to the median value. In the Mitigating phase, the learned polynomial models were able to predict changed ratings with a normalized RMSE of 12.8% and reduce bias by 76.3%. Results suggest that social influence bias can be significant in recommender systems and that this bias can be substantially reduced with machine learning.</p>
    <p><strong>Categories:</strong> Social Influence Bias, Recommender Systems, User Behavior, Machine Learning, Governance/POLitics, Statistical Methods, Fairness, A/B Testing, User Studies, Bayesian Methods, Polynomial Regression, Evaluation Metrics, System Design, Diversity of Recommendations, Beyond Accuracy, Bias Mitigation. (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/24/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>