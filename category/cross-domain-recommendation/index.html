<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/real-world-applications/">Real-world Applications</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reinforcement-learning/">Reinforcement Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reproducibility/">Reproducibility</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/scalability/">Scalability</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>A Pre-trained Zero-shot Sequential Recommendation Framework via Popularity Dynamics (2024)</h3>
    <p><strong>Authors:</strong> Hari Sundaram, Junting Wang, Praneet Rathi</p>
    <p>This paper proposes a novel pre-trained framework for zero-shot cross-domain  sequential recommendation without auxiliary information. While using auxiliary information (e.g., item descriptions) seems promising for cross-domain transfer, a cross-domain adaptation of sequential recommenders can be challenging when the target domain differs from the source domain—item descriptions are in different languages; metadata modalities (e.g., audio, image, and text) differ across source and target domains. If we can learn universal item representations independent of the domain type (e.g., groceries, movies), we can achieve zero-shot cross-domain transfer without auxiliary information. Our critical insight is that user interaction sequences highlight shifting user preferences via the popularity dynamics of interacted items. We present a pre-trained sequential recommendation framework: PrepRec, which utilizes a novel popularity dynamics-aware transformer architecture. Through extensive experiments on five real-world datasets, we show that PrepRec, without any auxiliary information, can zero-shot adapt to new application domains and achieve competitive performance compared to state-of-the-art sequential recommender models. In addition, we show that PrepRec complements existing sequential recommenders. With a simple post-hoc interpolation, PrepRec improves the performance of existing sequential recommenders on average by 11.8% in Recall@10 and 22% in NDCG@10. We provide an anonymized implementation of PrepRec at \url{https://anonymous.4open.science/r/PrepRec–128E/}.</p>
    <p><strong>Categories:</strong> Zero-shot Recommendation, Cross-domain Recommendation, Sequential Recommendation, Transformer Architecture, Popularity Dynamics, User Interaction Sequences, Pre-trained Models, Real-world Applications, Cold Start, Recommendation Frameworks, User Preferences, Evaluation Metrics (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1022/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Discerning Canonical User Representation for Cross-Domain Recommendation (2024)</h3>
    <p><strong>Authors:</strong> Sherry Sahebi, Siqian Zhao</p>
    <p>Cross-domain recommender systems have emerged, to address the cold-start problem and enhance recommendation outcomes by leveraging information transfer across different domains. Existing cross-domain recommender systems have investigated the learning of both domain-specific and domain-shared user preferences to enhance recommendation performance. However, these models typically allow the disparities between shared and distinct user preferences to emerge freely in any space, lacking sufficient constraints to identify differences between two domains and ensure that both domains are considered simultaneously. Canonical Correlation Analysis (CCA) has shown promise for transferring information between domains, by mapping their user representations into the same space. But, CCA only models domain similarities, and fails to capture the potential differences between user preferences in different domains. In this paper, we propose Discerning Canonical User Representation Learning for Cross-Domain Recommendation (DICUCDR), a generative adversarial networks (GAN) based method that learns both domain-shared and domain-specific user representations. DICUCDR introduces Discerning Canonical Correlation User Representation Learning (DCCRL), a novel design of non-linear Canonical Correlation mappings that creates a shared transformation for simultaneously mapping similarities between different domains and separating domain differences from domains. We compare DICUCDR against several state-of-the-art approaches using two real-world datasets. Our extensive experiments demonstrate the superiority of separately learning shared and specific user representations via DCCRL.</p>
    <p><strong>Categories:</strong> Cross-Domain Recommendation, Cold Start Problem, Transfer Learning, Multi-Domain, Canonical Correlation Analysis (CCA), Generative Adversarial Networks (GANs), Deep Learning, Representation Learning, Domain Adaptation, Real-World Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1033/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Overcoming Recommendation Limitations with Neuro-Symbolic Integration (2023)</h3>
    <p><strong>Authors:</strong> Tommaso Carraro</p>
    <p>Despite being studied for over twenty years, Recommender Systems (RSs) still suffer from important issues that limit their applicability in real-world scenarios. Data sparsity, cold start, and explainability are some of the most impacting problems. Intuitively, these historical limitations can be mitigated by injecting prior knowledge into recommendation models. Neuro-Symbolic (NeSy) approaches are suitable candidates for achieving this goal. Specifically, they aim to integrate learning (e.g., neural networks) with symbolic reasoning (e.g., logical reasoning). Generally, the integration lets a neural model interact with a logical knowledge base, enabling reasoning capabilities. In particular, NeSy approaches have been shown to deal well with poor training data, and their symbolic component could enhance model transparency. This gives insights that NeSy systems could potentially mitigate the aforementioned RSs limitations. However, the application of such systems to RSs is still in its early stages, and most of the proposed architectures do not really exploit the advantages of a NeSy approach. To this end, we conducted preliminary experiments with a Logic Tensor Network (LTN), a novel NeSy framework. We used the LTN to train a vanilla Matrix Factorization model using a First-Order Logic knowledge base as an objective. In particular, we encoded facts to enable the regularization of the latent factors using content information, obtaining promising results. In this paper, we review existing NeSy recommenders, argue about their limitations, show our preliminary results with the LTN, and propose interesting future works in this novel research area. In particular, we show how the LTN can be intuitively used to regularize models, perform cross-domain recommendation, ensemble learning, and explainable recommendation, reduce popularity bias, and easily define the loss function of a model.</p>
    <p><strong>Categories:</strong> Neuro-Symbolic Integration, Recommender Systems, Data Sparsity, Cold Start Problem, Explainability, Neural Networks, Symbolic Reasoning, Logic Tensor Networks (LTN), Matrix Factorization, Content-Based Recommendations, Model Transparency, Regularization, Cross-Domain Recommendation, Ensemble Learning, Popularity Bias (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/986/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Domain Disentanglement with Interpolative Data Augmentation for Dual-Target Cross-Domain Recommendation (2023)</h3>
    <p><strong>Authors:</strong> Feng Zhu, Zhu Sun, Yan Wang, Jiajie Zhu</p>
    <p>The conventional single-target Cross-Domain Recommendation (CDR) aims to improve the recommendation performance on a sparser target domain by transferring the knowledge from a source domain that contains relatively richer information. By contrast, in recent years, dual-target CDR has been proposed to improve the recommendation performance on both domains simultaneously. However, to this end, there are two challenges in dual-target CDR: (1) how to generate both relevant and diverse augmented user representations, and (2) how to effectively decouple domain-independent information from domain-specific information, in addition to domain-shared information, to capture comprehensive user preferences. To address the above two challenges, we propose a Disentanglement-based framework with Interpolative Data Augmentation for dual-target Cross-Domain Recommendation, called DIDA-CDR. In DIDA-CDR, we first propose an interpolative data augmentation approach to generating both relevant and diverse augmented user representations to augment sparser domain and explore potential user preferences. We then propose a disentanglement module to effectively decouple domain-specific and domain-independent information to capture comprehensive user preferences. Both steps significantly contribute to capturing more comprehensive user preferences, thereby improving the recommendation performance on each domain. Extensive experiments conducted on five real-world datasets show the significant superiority of DIDA-CDR over the state-of-the-art methods.</p>
    <p><strong>Categories:</strong> Cross-Domain Recommendation, Dual-Target CDR, Data Augmentation, Disentanglement Module, User Representation, Comprehensive User Preferences, Matrix Factorization, Evaluation on Real Datasets (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/857/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>TALLRec: An Effective and Efficient Tuning Framework to Align Large Language Model with Recommendation (2023)</h3>
    <p><strong>Authors:</strong> Keqin Bao, Jizhi Zhang, Xiangnan He, Fuli Feng, Wenjie Wang, Yang Zhang</p>
    <p>The impressive performance of Large Language Models (LLMs) across various fields has encouraged researchers to investigate their potential in recommendation tasks. To harness the LLMs’ extensive knowledge and powerful generalization abilities, initial efforts have tried to design instructions for recommendation tasks through In-context Learning. However, the recommendation performance of LLMs remains limited due to (i) significant differences between LLMs’ language-related pre-training tasks and recommendation tasks, and (ii) inadequate recommendation data during the LLMs’ pre-training. To fill the gap, we consider further tuning LLMs for recommendation tasks. To this end, we propose a lightweight tuning framework for LLMs-based recommendation, namely LLM4Rec, which constructs the recommendation data as tuning samples and utilizes LoRA for lightweight tuning. We conduct experiments on two datasets, validating that LLM4Rec is highly efficient w.r.t. computing costs (e.g., a single RTX 3090 is sufficient for tuning LLaMA-7B), and meanwhile, it can significantly enhance the recommendation capabilities of LLMs in the movie and book domains, even with limited tuning samples (< 100 samples). Furthermore, LLM4Rec exhibits strong generalization ability in cross-domain recommendation. Our code and data are available at https://anonymous.4open.science/r/LLM4rec.</p>
    <p><strong>Categories:</strong> Large Language Models, LoRA (Low-Rank Adaptation), Movies, Books, In-Context Learning, Cross-Domain Recommendation, Computational Efficiency, Dataset Evaluation, Recommendation Systems, Tuning Frameworks, Lightweight Fine-Tuning, Generalization Ability, Open-Source Implementation (<i>deepseek-r1:70b</i>)</p>
    <p><a href="/recsys-recommender/response/936/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Heterogeneous Graph Representation Learning for multi-target Cross-Domain Recommendation (2022)</h3>
    <p><strong>Authors:</strong> Tendai Mukande</p>
    <p>This paper discusses the current challenges in modeling real world recommendation scenarios and proposes the development of a unified Heterogeneous Graph Representation Learning framework for multi-target Cross-Domain recommendation (HGRL4CDR). A shared graph with user-item interactions from multiple domains is proposed as a way to provide an effective representation learning layer and unify the modelling of various heterogeneous data. A heterogeneous graph transformer network will be integrated to the representation learning model to prioritize the most important neighbours, and the proposed model would be able to capture complex information as well as adapt to dynamic changes in the data using matrix perturbation. Using the real world Amazon Review dataset, experiments would be conducted on multi-target cross domain recommendation.</p>
    <p><strong>Categories:</strong> Graph Representation Learning, Cross-Domain Recommendation, Heterogeneous Data, Transformer Networks, Multi-Target Recommendations, Real-World Applications, Unified Framework, Recommendation Systems, Matrix Perturbation, Heterogeneous Information Networks (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/813/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Towards Source-Aligned Variational Models for Cross-Domain Recommendation (2021)</h3>
    <p><strong>Authors:</strong> Aghiles Salah, Hady Lauw, Thanh Binh Tran</p>
    <p>Data sparsity is a long-standing challenge in recommender systems. Among existing approaches to alleviate this problem, cross-domain recommendation consists in leveraging knowledge from a source domain or category (e.g., Movies) to improve item recommendation in a target domain (e.g., Books). In this work, we advocate a probabilistic approach to cross-domain recommendation and rely on variational autoencoders (VAEs) as our latent variable models. More precisely, we assume that we have access to a VAE trained on the source domain that we seek to leverage to improve preference modeling in the target domain. To this end, we propose a model which learns to fit the target observations and align its hidden space with the source latent space jointly. Since we model the latent spaces by the variational posteriors, we operate at this level, and in particular, we investigate two approaches, namely rigid and soft alignments. In the former scenario, the variational model in the target domain is set equal to the source variational model. That is, we only learn a generative model in the target domain. In the soft-alignment scenario, the target VAE has its variational model, but which is encouraged to look like its source counterpart. We analyze the proposed objectives theoretically and conduct extensive experiments to illustrate the benefit of our contribution. Empirical results on six real-world datasets show that the proposed models outperform several comparable cross-domain recommendation models.</p>
    <p><strong>Categories:</strong> Cross-Domain Recommendation, Variational Autoencoder, Probabilistic Models, Data Sparsity, Model Adaptation, Latent Space Alignment, Recommendation Systems, Movies, Books, Model Development, Theoretical Analysis (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/674/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Representation Learning for Image-based Music Recommendation (2018)</h3>
    <p><strong>Authors:</strong> Yian Chen, Ming-Feng Tsai, Kwei-Herng Lai, Chuan-Ju Wang, Chih-Chun Hsia</p>
    <p>Image perception is one of the most direct ways to provide contextual information about a user concerning his/her surrounding environment; hence images are a suitable proxy for contextual recommendation. We propose a novel representation learning framework for image-based music recommendation that bridges the heterogeneity gap between music and image data; the proposed method is a key component for various contextual recommendation tasks. Preliminary experiments show that for an image-to-song retrieval task, the proposed method retrieves relevant or conceptually similar songs for input images.</p>
    <p><strong>Categories:</strong> Representation Learning, Multi-modal Recommendation, Contextual Recommendation, Music Recommendations, Content-based Recommendation, Cross-domain Recommendation, Multi-media Systems, Recommendation Algorithms (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/413/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>