<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui primary button" style="margin: 5px;"
             href="/recsys-recommender/">Noise Handling</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/offline-evaluation/">Offline Evaluation</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/bias-mitigation/">Bias Mitigation</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/recommendation-quality/">Recommendation Quality</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/user-centric-design/">User-Centric Design</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reproducibility/">Reproducibility</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Self-Auxiliary Distillation for Sample Efficient Learning in Google-Scale Recommenders (2024)</h3>
    <p><strong>Authors:</strong> Ruoxi Wang, Tiansheng Yao, Ed H. Chi, Andrew Evdokimov, Yuan Gao, Jerry Zhang, Evan Ettinger, Derek Zhiyuan Cheng, Yin Zhang, Jonathan Valverde, Xiang Li</p>
    <p>Industrial recommendation systems process billions of daily user feedback which are complex and noisy. Efficiently uncovering user preference from these signals becomes crucial for high-quality recommendation. We argue that those signals are not inherently equal in terms of their informative value and training ability, which is particularly salient in industrial applications with multi-stage processes (e.g., augmentation, retrieval, ranking). Considering that, in this work, we propose a novel self-auxiliary distillation framework that prioritizes training on high-quality labels, and improves the resolution of low-quality labels through distillation by adding a bilateral branch-based auxiliary task. This approach enables flexible learning from diverse labels without additional computational costs, making it highly scalable and effective for Google-scale recommenders. Our framework consistently improved both offline and online key business metrics across three Google major products. Notably, self-auxiliary distillation proves to be highly effective in addressing the severe signal loss challenge posed by changes such as Apple iOS policy. It further delivered significant improvements in both offline (+17\% AUC) and online metrics for a Google Apps recommendation system. This highlights the opportunities of addressing real-world signal loss problems through self-auxiliary distillation techniques.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Self-Auxiliary Distillation, Large Scale Recommenders, Sample Efficient Learning, Noise Handling, Signal Loss Problems, Offline Evaluation, Online Evaluation, A/B Test, Scalability, User Feedback (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1179/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Unified Denoising Training for Recommendation (2024)</h3>
    <p><strong>Authors:</strong> Yingpeng Du, Ziyan Wang, Haoyan Chua, Zhu Sun, Jie Zhang, Yew-Soon Ong</p>
    <p>Most existing denoising recommendation methods mainly alleviate noisy implicit feedback (user behaviors) through empirical studies. However, such studies may lack theoretical explainability and fail to model comprehensive noise patterns, which hinders understanding and capturing different noise patterns that show distinct effects on users’ behaviors. Thus, we propose to capture comprehensive noise patterns through a holistic theoretical analysis for more effective denoising, whereby users’ behaviors are divided into the willingness (to interact with) and action (to interact with) phases to disentangle the independent noise patterns. Our analysis unveils that (1) in the willingness phase, the high uncertainty of the user’s willingness to interact with the item can lead to high expectation loss, unifying explainability for existing denoising methods; and (2) in the action phase, higher user-specific inconsistency between willingness and action can not only lead to more noise in the user’s overall behaviors but also make it harder to distinguish between her true and noisy behaviors. All these findings are also aligned with our empirical observations. Inspired by these findings, we propose a Unified Denoising Training (UDT) method for recommendation. To alleviate uncertainty in the willingness phase, we lower the importance of the user-item interaction with high willingness uncertainty recognized by high loss. To ease the inconsistency in the action phase, we lower the overall importance for users with high user-specific inconsistency as it may lead to more noisy behaviors, and then increase the importance gap between recognized true and noisy behaviors for users with low user-specific inconsistency as their behaviors are more distinguishable. Extensive experiments on three real-world datasets show that our proposed UDT outperforms state-of-the-art denoising recommendation methods.</p>
    <p><strong>Categories:</strong> Recommendation Algorithms, Implicit Feedback, User Behavior Modeling, Noise Handling, Real-World Applications, Theoretical Analysis, Unified Approach, Willingness-Action Phases, Recommendation Quality, Denoising Methods (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1072/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Adversarial Collaborative Filtering for Free (2023)</h3>
    <p><strong>Authors:</strong> Chin-Chia Michael Yeh, Vivian Lai, Yan Zheng, Hao Yang, Mahashweta Das, Yujie Fan, Xiaoting Li, Huiyuan Chen</p>
    <p>Collaborative Filtering (CF) has been successfully applied to help users discover the items of interest. Nevertheless, existing CF methods suffer from noisy data issue, which negatively impacts the quality of personalized recommendation. To tackle this problem, many  prior studies leverage the adversarial learning principle to regularize the representations of users and items, which  has shown great ability in improving both generalizability and robustness. Generally, those methods  learn adversarial perturbations and model parameters using min-max optimization framework. However, there still have two major limitations: 1) Existing methods lack theoretical guarantees of why adding perturbations improve the model generalizability and robustness since noisy data is naturally different from adversarial attacks; 2)  Solving min-max optimization is time-consuming.  In addition to updating the model parameters, each iteration requires additional computations to update the perturbations, making them not scalable for industry-scale datasets. In this paper, we present Sharpness-aware Matrix Factorization (SharpMF), a simple yet effective method that conducts adversarial training without extra computational cost over the base optimizer. To achieve this goal, we first revisit the existing adversarial collaborative filtering and discuss its connection with recent Sharpness-aware Minimization. This analysis shows that adversarial training actually seeks model parameters that lie in neighborhoods having uniformly low loss values, resulting in better generalizability. To reduce the computational overhead, SharpMF introduces a novel trajectory loss to measure sharpness between current weights and past weights. Experimental results on real-world datasets demonstrate that our SharpMF achieves superior performance with almost zero additional computational cost comparing to adversarial training.</p>
    <p><strong>Categories:</strong> Adversarial Training, Collaborative Filtering, Matrix Factorization, Recommendation Systems, Noise Handling, Generalizability, Robustness, Computational Efficiency, Optimization Techniques, Real-World Applications, User-Centric Design, Scalability, Robustness in Machine Learning (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/848/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Discovering What You’re Known For: A Contextual Poisson Factorization Approach (2016)</h3>
    <p><strong>Authors:</strong> Haokai Lu, James Caverlee, Wei Niu</p>
    <p>Discovering what people are known for is valuable to many important applications such as recommender systems. Unlike an individual’s personal interests, what a user is known for is reflected by the views of others, and is often not easily discerned for a long-tail of the vast majority of users. In this paper, we tackle the problem of discovering what users are known for through a probabilistic model called Bayesian Contextual Poisson Factorization. Moving beyond just modeling user’s content, it naturally models and integrates additional contextual factors, concretely, user’s geo-spatial footprints and social influence, to overcome noisy online activities and social relations. Through GPS-tagged social media datasets, we find that the proposed method can improve known-for prediction performance by 17.5% in precision and 20.9% in recall on average, and that it can capture the implicit relationships between a user’s known-for profile and her content, geo-spatial and social influence.</p>
    <p><strong>Categories:</strong> Recommender Systems, Matrix Factorization, Context-Aware Recommendations, Social Influence, Geo-Spatial Data, Noise Handling, Recommendation Accuracy, Evaluation Metrics, Real-World Applications, Multi-Factor Models (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/177/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>