<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reinforcement-learning/">Reinforcement Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reproducibility/">Reproducibility</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/beyond-accuracy/">Beyond Accuracy</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/explainability/">Explainability</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Towards Empathetic Conversational Recommender Systems (2024)</h3>
    <p><strong>Authors:</strong> Mingfei Liang, Yougang Lyu, Zhaochun Ren, Zhanhui Kang, Pengjie Ren, Xin Xin, Xiaoyu Zhang, Bo Zhang, Maarten de Rijke, Ruobing Xie</p>
    <p>Conversational recommender systems (CRSs) are able to elicit user preferences through multi-turn dialogues. They typically incorporate external knowledge and pre-trained language models to capture the dialogue context. Most CRS approaches, trained on benchmark datasets, assume that the standard items and responses in these benchmarks are optimal. However, they overlook that users may express negative emotions with the standard items and may not feel emotionally engaged by the standard responses. This issue leads to a tendency to replicate the logic of recommenders in the dataset instead of aligning with user needs. To remedy this misalignment, we introduce empathy within a CRS. With empathy we refer to a system’s ability to capture and express emotions. We propose an empathetic conversational recommender (ECR) framework. ECR contains two main modules: emotion-aware item recommendation and emotion-aligned response generation. Specifically, we employ user emotions to refine user preference modeling for accurate recommendations. To generate human-like emotional responses, ECR applies retrieval-augmented prompts to fine-tune a pre-trained language model aligning with emotions and mitigating hallucination. To address the challenge of insufficient supervision labels, we enlarge our empathetic data using emotion labels annotated by large language models and emotional reviews collected from external resources. We propose novel evaluation metrics to capture user satisfaction in real-world CRS scenarios. Our experiments on the ReDial dataset validate the efficacy of our framework in enhancing recommendation accuracy and improving user satisfaction.</p>
    <p><strong>Categories:</strong> Conversational Recommender Systems, Empathy, Emotion-Aware Recommendation, Natural Language Processing, Multi-Turn Dialogues, User Experience, Emotional Responses Generation, Human-Centered AI, Sentiment Analysis, User Preference Modeling (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1070/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Neighborhood-Based Collaborative Filtering for Conversational Recommendation (2024)</h3>
    <p><strong>Authors:</strong> Julian Mcauley, Zhouhang Xie, Nathan Kallus, Dawen Liang, Rahul Jha, Hyunsik Jeon, Zhankui He, Harald Steck, Junda Wu</p>
    <p>Conversational recommender systems (CRS) should understand users’ expressed interests that are frequently semantically rich and knowledge intensive. Prior works attempt to address this challenge by making use of external knowledge bases or parametric knowledge in large language models (LLMs). In this paper, we study a complementary solution, exploiting item knowledge in the training data. We hypothesise that many inference-time user requests can be answered via reusing popular crowd-written answers associated with similar training queries. Following this intuition, we define a class of neighborhood-based CRS that make recommendations by identifying popular items associated with similar training dialogue contexts. Experiments on Inspired, Redial, and Reddit benchmarks show that despite its simplicity, our method achieves comparable to better performance than state-of-the-art LLM-based methods with over 200 times more parameters. We also show neighborhood and model-based predictions can be combined to achieve further performance improvements over both components.</p>
    <p><strong>Categories:</strong> Collaborative Filtering, Conversational Recommender Systems, Neighborhood-Based Methods, Similarity-Based Recommendations, Hybrid Recommendations, Performance Evaluation, Recommendation Quality, Crowd-Written Answers, Item Knowledge Utilization, Beyond Accuracy, Efficiency, Recommendation Systems (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1100/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>What to compare? Towards understanding user sessions on price comparison platforms (2024)</h3>
    <p><strong>Authors:</strong> Julia Neidhardt, Ahmadou Wagne</p>
    <p>E-commerce and online shopping have become integral to the lives of many, with various user behavior types historically identified. Beyond deciding what to buy, determining where to make a purchase has led to the importance of price comparison platforms. However, user behavior on these platforms remains underexplored. Furthermore, web analytics often struggle with tracking users over time and deriving meaningful user types from data. This paper addresses these gaps by defining session types through the analysis and clustering of user logs from a major price comparison platform. The study identifies six distinct session clusters: quick peek, major purchase, constraint-based browsing, knowledge seeking, search and browse and heavy browsing. These findings are intended to inform the design and development of a conversational recommender system (CRS). Often, CRS development occurs without adequate consideration of the existing system into which it will be integrated. The study’s findings, derived from both quantitative analysis and expert interviews, provide valuable contributions, including identified session clusters, their interpretation and indicators on which users might benefit from a CRS on these platforms.</p>
    <p><strong>Categories:</strong> E-commerce and Online Shopping, User Behavior, Clustering Algorithms, Recommender Systems, Conversational Recommender Systems, Long-term User Behavior Analysis, Data Analysis Methods, Price Comparison Platforms, Recommender System Design, System Integration, Real-World Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1204/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>User-Centric Conversational Recommendation: Adapting the Need of User with Large Language Models (2023)</h3>
    <p><strong>Authors:</strong> Gangyi Zhang</p>
    <p>Conversational recommender systems (CRS) promise to provide a more natural user experience for exploring and discovering items of interest through ongoing conversation. However, effectively modeling user preferences during conversations and generating personalized recommendations in real time remain challenging problems. Users often express their needs in a vague and evolving manner, and CRS must adapt to capture the dynamics and uncertainty in user preferences to have productive interactions. This research develops user-centric methods for building conversational recommendation system that can understand complex and changing user needs. We propose a graph-based conversational recommendation framework that represents multi-turn conversations as reasoning over a user-item-attribute graph. Enhanced conversational path reasoning incorporates graph neural networks to improve representation learning in this framework. To address uncertainty and dynamics in user preferences, we present the vague preference multi-round conversational recommendation scenario and an adaptive vague preference policy learning solution that employs reinforcement learning to determine recommendation and preference elicitation strategies tailored to the user. Looking to the future, large language models offer promising opportunities to enhance various aspects of CRS, including user modeling, policy learning, response generation.  Overall, this research takes a user-centered perspective in designing conversational agents that can adapt to the inherent ambiguity involved in natural language dialogues with people.</p>
    <p><strong>Categories:</strong> Conversational Recommender Systems, Large Language Models, Graph Neural Networks, Reinforcement Learning, User Dynamics, Conversational Agents, Personalization, Real-Time Recommendations, Multi-Round Dialogue, AI/ML in Recommendations, User-Centered Design (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/983/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Alleviating the Long-Tail Problem in Conversational Recommender Systems (2023)</h3>
    <p><strong>Authors:</strong> Zhao Cao, Kun Zhou, Fan Pan, Zhipeng Zhao, Xiaolei Wang, Wayne Xin Zhao, Ji-Rong Wen</p>
    <p>Conversational recommender systems (CRS) aim to provide the recommendation service via natural language conversations. To develop an effective CRS, high-quality CRS datasets are very crucial. However, existing CRS datasets suffer from the long-tail issue, \ie a large proportion of items are rarely (or even never) mentioned in the conversations, which are called long-tail items. As a result, the CRSs trained on these datasets tend to recommend frequent items,  and the diversity of the recommended items would be largely reduced, making users easier to get bored. To address this issue, this paper presents <b>LOT-CRS</b>, a novel framework that focuses on simulating and utilizing a balanced CRS dataset (\ie covering all the items evenly) for improving <b>LO</b>ng-<b>T</b>ail recommendation performance of CRSs. In our approach, we design two pre-training tasks to enhance the understanding of simulated conversation for long-tail items, and adopt retrieval-augmented fine-tuning with label smoothness strategy to further improve the recommendation of long-tail items. Extensive experiments on two public CRS datasets have demonstrated the effectiveness and extensibility of our approach, especially on long-tail recommendation. All the experimental codes will be released after the review period.</p>
    <p><strong>Categories:</strong> Conversational Recommender Systems, Long-Tail Problem, Deep Learning, Natural Language Processing (NLP), Personalization, Recommendation Algorithms, Diversity of Recommendations, Beyond Accuracy Evaluation, Data Simulation, Coverage, Real-World Applications, Recommendation Improvement. (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/851/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Bundle MCR: Towards Conversational Bundle Recommendation (2022)</h3>
    <p><strong>Authors:</strong> Zhankui He, Sungchul Kim, Handong Zhao, Fan Du, Tong Yu, Julian McAuley</p>
    <p>Bundle recommender systems recommend sets of items (e.g., pants, shirt, and shoes) to users, but they often suffer from two issues: significant interaction sparsity and a large output space. In this work, we extend multi-round conversational recommendation (MCR) to alleviate these issues. MCR—which uses a conversational paradigm to elicit user interests by asking user preferences on tags (e.g., categories or attributes) and handling user feedback across multiple rounds—is an emerging recommendation setting to acquire user feedback and narrow down the output space, but has not been explored in the context of bundle recommendation. In this work, we propose a novel recommendation task named Bundle MCR. Unlike traditional bundle recommendation (a bundle-aware user model and bundle generation), Bundle MCR studies how to encode user feedback as conversation states and how to post questions to users. Unlike existing MCR in which agents recommend individual items only, Bundle MCR handles more complicated user feedback on multiple items and related tags. To support this, we first propose a new framework to formulate Bundle MCR as Markov Decision Processes (MDPs) with multiple agents, for user modeling, consultation and feedback handling in bundle contexts. Under this framework, we propose a model architecture, called Bundle Bert (Bunt) to (1) recommend items, (2) post questions and (3) manage conversations based on bundle-aware conversation states. Moreover, to train Bunt effectively, we propose a two-stage training strategy. In an offline pre-training stage, Bunt is trained using multiple cloze tasks to mimic bundle interactions in conversations. Then in an online fine-tuning stage, Bunt agents are enhanced by user interactions. Our experiments on multiple offline datasets as well as the human evaluation show the value of extending MCR frameworks to bundle settings and the effectiveness of our Bunt design.</p>
    <p><strong>Categories:</strong> Bundle Recommendation, Conversational Recommender Systems, Multi-Round Conversational Recommendation (MCR), User Feedback Handling, Recommender Systems, Markov Decision Processes (MDPs), Multi-Agent Systems, Conversation State Management, Cold Start, Human Evaluation, Tag-Based Recommendations, Scalability (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/751/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Self-Supervised Bot Play for Transcript-Free Conversational Recommendation with Rationales (2022)</h3>
    <p><strong>Authors:</strong> Julian McAuley, Bodhisattwa Prasad Majumder, Shuyang Li</p>
    <p>Conversational recommender systems offer a way for users to engage in multi-turn conversations to find items they enjoy. For users to trust an agent and give effective feedback, the recommender system must be able to explain its suggestions and rationales. We develop a two-part framework for training multi-turn conversational recommenders that provide recommendation rationales that users can effectively interact with to receive better recommendations. First, we train a recommender system to jointly suggest items and explain its reasoning via subjective rationales. We then fine-tune this model to incorporate iterative user feedback via self-supervised bot-play. Experiments on three real-world datasets demonstrate that our system can be applied to different recommendation models across diverse domains to achieve state-of-the-art performance in multi-turn recommendation. Human studies show that systems trained with our framework provide more useful, helpful, and knowledgeable suggestions in warm- and cold-start settings. Our framework allows us to use only product reviews during training, avoiding the need for expensive dialog transcript datasets that limit the applicability of previous conversational recommender agents.</p>
    <p><strong>Categories:</strong> Conversational Recommender Systems, Self-Supervised Learning, Multi-Turn Conversations, Recommendation Rationales, Transparency, Cold Start, Human Studies, Beyond Accuracy, Data Efficiency, Bot Play (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/778/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Soliciting User Preferences in Conversational Recommender Systems via Usage-related Questions (2021)</h3>
    <p><strong>Authors:</strong> Ivica Kostric, Filip Radlinski, Krisztian Balog</p>
    <p>A key distinguishing feature of conversational recommender systems over traditional recommender systems is their ability to elicit user preferences using natural language. Currently, the predominant approach to preference elicitation is to ask questions directly about items or item attributes. These strategies do not perform well in cases where the user does not have sufficient knowledge of the target domain to answer such questions. Conversely, in a shopping setting, talking about the planned use of items does not present any difficulties, even for those that are new to a domain. In this paper, we propose a novel approach to preference elicitation by asking implicit questions based on item usage. Our approach consists of two main steps. First, we identify the sentences from a large review corpus that contain information about item usage. Then, we generate implicit preference elicitation questions from those sentences using a neural text-to-text model. The main contributions of this work also include a multi-stage data annotation protocol using crowdsourcing for collecting high-quality labeled training data for the neural model. We show that out approach is effective in selecting review sentences and transforming them to elicitation questions, even with limited training data.</p>
    <p><strong>Categories:</strong> Conversational Recommender Systems, Natural Language Processing, Preference Elicitation, Implicit Feedback, Neural Models, Text Generation, Data Annotation, Crowdsourcing, Recommendation Systems, Review Mining, User Interaction, Usage-Based Recommendations (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/703/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Large-scale Interactive Conversational Recommendation System (2021)</h3>
    <p><strong>Authors:</strong> James Allan, Ali Montazeralghaem, Philip S. Thomas</p>
    <p>We propose AC-CRS, a novel conversational recommendation system based on reinforcement learning that better models user interaction compared to prior work. Interactive recommender systems expect an initial request from a user and then iterate by asking questions or recommending potential matching items, continuing until some stopping criterion is achieved. Unlike most existing works that stop as soon as an item is recommended, we model the more realistic expectation that the interaction will continue if the item is not appropriate. Using this process, AC-CRS is able to support a more flexible conversation with users. Unlike existing models, AC-CRS is able to estimate a value for each question in the conversation to make sure that questions asked by the agent are relevant to the target item (i.e., user needs). We also model the possibility that the system could suggest more than one item in a given turn, allowing it to take advantage of screen space if it is present. AC-CRS also better accommodates the massive space of items that a real-world recommender system must handle. Experiments on real-world user purchasing data show the effectiveness of our model in terms of standard evaluation measures such as NDCG.</p>
    <p><strong>Categories:</strong> Conversational Recommender Systems, Reinforcement Learning, Large-scale Recommendation, Interactive Recommender Systems, User Interaction Modeling, Real-time Interaction, Multi-item Recommendations, Evaluation Metrics, Real-world Applications, Methodology Improvements (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/642/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>A Ranking Optimization Approach to Latent Linear Critiquing in Conversational Recommender System (2020)</h3>
    <p><strong>Authors:</strong> Scott Sanner, Kai Luo, Ga Wu, Hanze Li</p>
    <p>Critiquing is a method for conversational recommendation that incrementally adapts recommendations in response to user preference feedback. Specifically, a user is iteratively provided with item recommendations and attribute descriptions for those items; the user may then either accept the recommendation or choose to critique an attribute to generate a new recommendation. A recent direction known as latent linear critiquing (LLC) takes a modern embedding-based approach that seeks to optimize the combination of user preference embeddings with embeddings of critiques based on subjective item descriptions (i.e., keyphrases from user reviews); LLC does so by exploiting the linear structure of the embeddings to efficiently optimize their weights in a linear programming (LP) formulation. In this paper, we revisit LLC and note that it’s score-based optimization approach inherently encourages extreme weightings in order to maximize predicted score gaps between preferred and non-preferred items. Noting that the overall end task objective in critiquing is to re-rank rather than re-score, in this paper we take a ranking optimization approach that seeks to optimize embedding weights based on observed rank violations from earlier critiquing iterations. We evaluate the proposed framework on two recommendation datasets containing user reviews. Empirical results demonstrate that ranking-based LLC generally outperforms scoring-based LLC and other baselines across a variety of datasets, critiquing styles, and both satisfaction and session-length performance metrics.</p>
    <p><strong>Categories:</strong> Ranking Optimization, Conversational Recommender Systems, User Feedback Mechanisms, Preference Learning, Critiquing, Re-ranking, Embeddings, Linear Programming, Session-Based Recommendations, Satisfaction Metrics, Session Length, Optimization Techniques, User Reviews, Evaluation in Real-World Settings. (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/519/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>What does BERT know about books, movies and music? Probing BERT for Conversational Recommendation (2020)</h3>
    <p><strong>Authors:</strong> Claudia Hauff, Gustavo Penha</p>
    <p>Heavily pre-trained transformer models such as BERT have recently shown to be remarkably powerful at language modelling, achieving impressive results on numerous downstream tasks. It has also been shown that they implicitly store factual knowledge in their parameters after pre-training. Understanding what the pre-training procedure of LMs actually learns is a crucial step for using and improving them for Conversational Recommender Systems (CRS). We first study how much off-the-shelf pre-trained BERT “knows” about recommendation items such as books, movies and music. In order to analyze the knowledge stored in BERT’s parameters, we use different probes (i.e., tasks to examine a trained model regarding certain properties) that require different types of knowledge to solve, namely content-based and collaborative-based. Content-based knowledge is knowledge that requires the model to match the titles of items with their content information, such as textual descriptions and genres. In contrast, collaborative-based knowledge requires the model to match items with similar ones, according to community interactions such as ratings. We resort to BERT’s Masked Language Modelling (MLM) head to probe its knowledge about the genre of items, with cloze style prompts. In addition, we employ BERT’s Next Sentence Prediction (NSP) head and representations’ similarity (SIM) to compare relevant and non-relevant search and recommendation query-document inputs to explore whether BERT can, without any fine-tuning, rank relevant items first. Finally, we study how BERT performs in a conversational recommendation downstream task. To this end, we fine-tune BERT to act as a retrieval-based CRS. Overall, our experiments show that: (i) BERT has knowledge stored in its parameters about the content of books, movies and music; (ii) it has more content-based knowledge than collaborative-based knowledge; and (iii) fails on conversational recommendation when faced with adversarial data.</p>
    <p><strong>Categories:</strong> BERT, Transformer Models, Conversational Recommender Systems, Books, Movies, Music, Probing Methods, Content-Based Knowledge, Collaborative-Based Knowledge, Masked Language Modeling (MLM), Next Sentence Prediction (NSP), Similarity (SIM) (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/564/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Towards a Taxonomy of User Feedback Intents for Conversational Recommendations (2019)</h3>
    <p><strong>Authors:</strong> Li Chen, Wanling Cai</p>
    <p>Understanding users’ feedback on recommendation in natural language is crucially important for assisting the system to refine its understanding of the user’s preferences and provide more accurate recommendations in the subsequent interactions. In this paper, we report the results of an exploratory study on a human-human dialogue dataset centered around movie recommendations. In particular, we manually labeled a set of over 200 dialogues at the utterance level, and then conducted descriptive analysis on them from both seekers’ and recommenders’ perspectives. The results reveal not only seekers’ feedback intents as well as the types of preferences they have expressed, but also the reactions of human recommenders that have finally led to successful recommendation. A taxonomy for feedback intents is established along with the results, which could be constructive for improving conversational recommender systems.</p>
    <p><strong>Categories:</strong> Feedback Handling, User Interaction, Natural Language Processing (NLP), Conversational Recommender Systems, Movie Recommendations, User Preferences, Taxonomy Development, Human-Computer Interaction (HCI), Dialogue Analysis, Recommendation Systems, Preference Elicitation, Evaluation Methods (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/520/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Picture-based Navigation for Diagnosing Post-Harvest Diseases of Apple (2018)</h3>
    <p><strong>Authors:</strong> Gabriele Sottocornola, Markus Zanker</p>
    <p>This demo presents a conversational navigation approach for a diagnostic application of postharvest diseases of apple with the goal to educate users on the diagnosed diseases as well as to recommend consequences for the storage facility and what action to take for the next growing period. It thus builds on earlier works on picture-based navigation for conversational recommender systems and provides evidence for its usability based on a first small-scale comparative usability study.</p>
    <p><strong>Categories:</strong> Picture-Based Navigation, Conversational Recommender Systems, Disease Diagnosis, Agricultural Applications, Educational Applications, Recommendation Systems, User Study, Image-Based Recommendations, Usability Testing, Conversational Interfaces (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/398/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>