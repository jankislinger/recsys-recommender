<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui primary button" style="margin: 5px;"
             href="/recsys-recommender/">Session-Based Recommendation</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reinforcement-learning/">Reinforcement Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reproducibility/">Reproducibility</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/deep-learning/">Deep Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/e-commerce/">E-commerce</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Enhancing Sequential Music Recommendation with Negative Feedback-informed Contrastive Learning (2024)</h3>
    <p><strong>Authors:</strong> Shahrzad Shashaani, Pavan Seshadri, Peter Knees</p>
    <p>Modern music streaming services are heavily based on recommen- dation engines to serve continuous content to users. Sequential recommendation—continuously providing new items within a sin- gle session in a contextually coherent manner—has been an emerg- ing topic in current literature. User feedback—a positive or negative response to the item presented—is used to drive content recom- mendations by learning user preferences. We extend this idea to the session-based recommendation domain to improve learning of context-coherent music recommendations by modelling negative user feedback, i.e., skips, in the loss function. To this end, we propose a sequence-aware contrastive sub-task to structure item embeddings in session-based music recommen- dation, such that true next-positive items (ignoring skipped items) are structured closer in the embedding space, while skipped tracks are structured farther away from all items in the session. Since this causes skipped item embeddings in a session to be farther than unskipped items in the learned space, this directly affects item rankings using a K-nearest-neighbors search for next-item recom- mendations, while also promoting the rank of the true next item. Experiments incorporating this task into SoTA methods for sequen- tial item recommendation show consistent performance gains in terms of next-item hit rate, item ranking, and skip down-ranking on three music recommendation datasets, strongly benefiting from increasing presence of user feedback.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Music Recommendation, Sequential Recommendations, Negative Feedback, Contrastive Learning, User Feedback, Session-Based Recommendation, Evaluation Metrics, Embeddings, Music Streaming Services (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1088/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Multiple Connectivity Views for Session-based Recommendation (2023)</h3>
    <p><strong>Authors:</strong> Zheng Miao, Yujing Wang, Yaming Yang, Jieyu Zhang, Yunhai Tong</p>
    <p>Session-based recommendation (SBR), which makes the next-item recommendation based on previous anonymous actions, has drawn increasing attention. The last decade has seen multiple deep learning-based modeling choices applied on SBR successfully, e.g., recurrent neural networks (RNNs), convolutional neural networks (CNNs), graph neural networks (GNNs), and each modeling choice has its intrinsic superiority and limitation. We argue that these modeling choices differentiate from each other by (1) the way they capture the interactions between items within a session and (2) the operators they adopt for composing the neural network, e.g., convolutional operator or self-attention operator. In this work, we dive deep into the former as it is relatively unique to the SBR scenario, while the latter is shared by general neural network modeling techniques. We first introduce the concept of connectivity view to describe the different item interaction patterns at the input level. Then, we develop the Multiple Connectivity Views for Session-based Recommendation (MCV-SBR), a unified framework that incorporates different modeling choices in a single model through the lens of connectivity view. In addition, MCV-SBR allows us to effectively and efficiently explore the search space of the combinations of connectivity views by the Tree-structured Parzen Estimator Approach (TPE) algorithm. Finally, on three widely used SBR datasets, we verify the superiority of MCV-SBR by comparing the searched models with state-of-the-art baselines. We also conduct a series of studies to demonstrate the efficacy and practicability of the proposed connectivity view search algorithm, as well as other components in MCV-SBR.</p>
    <p><strong>Categories:</strong> Session-based Recommendation, Neural Networks, Connectivity Views, Modeling Choices in SBR, Tree-structured Parzen Estimator (TPE), Deep Learning, Unsupervised Learning, Evaluation Studies, Recommendation Algorithms (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/938/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Transformers4Rec: Bridging the Gap between NLP and Sequential / Session-Based Recommendation (2021)</h3>
    <p><strong>Authors:</strong> Ronay Ak, Even Oldridge, Sara Rabhi, Gabriel de Souza Pereira Moreira, Jeong Min Lee</p>
    <p>Much of the recent progress in sequential and session-based recommendation has been driven by improvements in model architecture and pretraining techniques originating in the field of Natural Language Processing. Transformer architectures in particular have facilitated building higher-capacity models and provided data augmentation and training techniques which demonstrably improve the effectiveness of sequential recommendation. But with a thousandfold more research going on in NLP, the application of transformers for recommendation understandably lags behind. To remedy this we introduce Transformers4Rec, an open-source library built upon HuggingFace’s Transformers library with a similar goal of opening up the advances of NLP based Transformers to the recommender system community and making these advancements immediately accessible for the tasks of sequential and session-based recommendation. Like its core dependency, Transformers4Rec is designed to be extensible by researchers, simple for practitioners, and fast and robust in industrial deployments.<br>In order to demonstrate the usefulness of the library and the applicability of Transformer architectures in next-click prediction for user sessions, where sequence lengths are much shorter than those commonly found in NLP, we have leveraged Transformers4Rec to win two recent session-based recommendation competitions. In addition, we present in this paper the first comprehensive empirical analysis comparing many Transformer architectures and training approaches for the task of session-based recommendation. We demonstrate that the best Transformer architectures have superior performance across two e-commerce datasets while performing similarly to the baselines on two news datasets. We further evaluate in isolation the effectiveness of the different training techniques used in causal language modeling, masked language modeling, permutation language modeling and replacement token detection for a single Transformer architecture, XLNet. We establish that training XLNet with replacement token detection performs well across all datasets. Finally, we explore techniques to include side information such as item and user context features in order to establish best practices and show that the inclusion of side information uniformly improves recommendation performance. Transformers4Rec library is available at https://github.com/NVIDIA-Merlin/Transformers4Rec/</p>
    <p><strong>Categories:</strong> Transformers, Session-based Recommendation, Sequential Recommendation, Open Source Libraries, Empirical Analysis, Model Comparison, Language Modeling Techniques, E-commerce, News, Side Information, Industrial Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/668/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Long-tail Session-based Recommendation (2020)</h3>
    <p><strong>Authors:</strong> Siyi Liu, Yujia Zheng</p>
    <p>Session-based recommendation focuses on the prediction of user actions based on anonymous sessions and is a necessary method in the lack of user historical data. However, none of the existing session-based recommendation methods explicitly takes the long-tail recommendation into consideration, which plays an important role in improving the diversity of recommendation and producing the serendipity. As the distribution of items with long-tail is prevalent in session-based recommendation scenarios (e.g., e-commerce, music, and TV program recommendations), more attention should be put on the long-tail session-based recommendation. In this paper, we propose a novel network architecture, namely TailNet, to improve long-tail recommendation performance, while maintaining competitive accuracy performance compared with other methods. We start by classifying items into short-head (popular) and long-tail (niche) items based on click frequency. Then a novel preference mechanism is proposed and applied in TailNet to determine user preference between two types of items, so as to softly adjust and personalize recommendations. Extensive experiments on two real-world datasets verify the superiority of our method compared with state-of-the-art works.</p>
    <p><strong>Categories:</strong> Session-based Recommendation, Long-tail Recommendations, Recommendation Systems, Item Popularity, Personalized Recommendations, Diversity (Recommendations), Serendipity, E-commerce, Music, TV/Media, Recommendation Performance, Experiments (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/579/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>ADER: Adaptively Distilled Exemplar Replay Towards Continual Learning for Session-based Recommendation (2020)</h3>
    <p><strong>Authors:</strong> Xiaoyu Lin, Boi Faltings, Fei Mi</p>
    <p>Session-based recommendation has received growing attention recently due to the increasing privacy concern. Despite the recent success of neural session-based recommenders, they are typically developed in an offline manner using a static dataset. However, recommendation requires continual adaptation to take into account new and obsolete items and users, and requires “continual learning” in real-life applications. In this case, the recommender is updated continually and periodically with new data that arrives in each update cycle, and the updated model needs to provide recommendations for user activities before the next model update. A major challenge for continual learning with neural models is catastrophic forgetting, in which a continually trained model forgets user preference patterns it has learned before. To deal with this challenge, we propose a method called Adaptively Distilled Exemplar Replay (ADER) by periodically replaying previous training samples (i.e., exemplars) to the current model with an adaptive distillation loss. Experiments are conducted based on the state-of-the-art SASRec model using two widely used datasets to benchmark ADER with several well-known continual learning techniques. We empirically demonstrate that ADER consistently outperforms other baselines, and it even outperforms the method using all historical data at every update cycle. This result reveals that ADER is a promising solution to mitigate the catastrophic forgetting issue towards building more realistic and scalable session-based recommenders.</p>
    <p><strong>Categories:</strong> Session-based Recommendation, Continual Learning, Catastrophic Forgetting, Exemplar Replay, Adaptive Distillation Loss, Neural Recommenders, Real-world Applications, Recommendation Systems, Evaluation of Recommendations, Scalability, Model Updates, User Behavior Modeling (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/560/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Predictability Limits in Session-based Next Item Recommendation (2019)</h3>
    <p><strong>Authors:</strong> Priit Järv</p>
    <p>Session-based recommendations are based on the user’s recent actions, for example, the items they have viewed during the current browsing session or the sightseeing places they have just visited. Closely related is sequence-aware recommendation, where the choice of the next item should follow from the sequence of previous actions. We study seven benchmarks for session-based recommendation, covering retail, music and news domains to investigate how accurately user behavior can be predicted from the session histories. We measure the entropy rate of the data and estimate the limit of predictability to be between 44% and 73% in the included datasets. We establish some algorithm-specific limits on prediction accuracy for Markov chains, association rules and k-nearest neighbors methods. With most of the analyzed methods, the algorithm design limits their performance with sparse training data. The session based k-nearest neighbors are least restricted in comparison and have room for improvement across all of the analyzed datasets.</p>
    <p><strong>Categories:</strong> Session-Based Recommendation, Next Item Prediction, Sequence-Aware Recommendation, Retail Domain, Music Domain, News Domain, Markov Chains, Association Rules, k-Nearest Neighbors, Predictability Limits, Entropy Rate Analysis, Algorithm Design Limits (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/485/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Explicit Elimination of Similarity Blocking for Session-based Recommendation (2016)</h3>
    <p><strong>Authors:</strong> Martha Larson, Mattia Brusamento, Paolo Cremonesi, Roberto Pagano</p>
    <p>A single `odd’ interaction can cause two user interaction sessions to diverge in similarity, and stand in the way of generalization. The sensitivity of session-based recommenders to session similarity motivates us to explicitly identify and remove such `similarity blockers’. Specifically, we leverage huge amounts of data, which allow us to identify blockers in the form of non-co-occurring items. Other blockers can be identified using content-based similarity. Our experiments reveal that explicitly eliminating relatively few blockers improves performance.</p>
    <p><strong>Categories:</strong> Session-Based Recommendation, Similarity Blocking, Recommendation Algorithms, Data Utilization, Content-Based Methods, Performance Improvement, User Interaction Analysis, Generalization in ML (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/221/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>