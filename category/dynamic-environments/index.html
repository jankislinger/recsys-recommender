<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui primary button" style="margin: 5px;"
             href="/recsys-recommender/">Dynamic Environments</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reinforcement-learning/">Reinforcement Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reproducibility/">Reproducibility</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/real-world-applications/">Real-world Applications</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Recommender Systems for Personalized User Experience: Lessons learned at Booking.com (2021)</h3>
    <p><strong>Authors:</strong> Ioannis Kangas</p>
    <p>Booking.com is the world’s leading online travel platform where users make many decisions supported by our recommendations, such as destinations, travel dates, facilities, etc. This leads to a complex User Interface (UI) containing many widgets of different relevance for different users. We address the problem of constructing an optimal UI, a non-trivial problem, mainly due to user preferences evolving over time and multiple independent teams collaboratively building the UI. Our goal is to provide a personalized User Experience (UX) which adapts to changes in the environment and ensures governable, collaborative product development. The solution relies on a Multi Armed Bandits (MAB) framework currently allowing product teams to collaborate on the construction of UIs and serving millions of users every day. We present examples of our solution and lessons learned during their implementation.</p>
    <p><strong>Categories:</strong> Recommender Systems, Travel, User Interface/Experience, Multi-Armed Bandits, Personalization, Adaptive Systems, Collaborative Development, Real-World Applications, Implementation Strategies, Product Development, Dynamic Environments, UI Construction (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/742/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Recommending in changing times (2020)</h3>
    <p><strong>Authors:</strong> Manoj Nambiar, Amey Pandit, Rekha Singhal, Shruti Kunde, Shashank Gupta, Mayank Mishra, Gautam Shroff</p>
    <p>Recommender systems today face major challenges in keeping up with dynamic customer preferences. Disruptions or sudden changes in the environment affect customer preferences drastically and render historical data ineffective for modeling. With businesses relying heavily on Machine Learning(ML) based recommender systems for catering to customer preferences, the accuracy of timely recommendations gains prime significance. To address these challenges, we propose a novel concept, LDT (Labeled Data Threshold), a newly defined parameter to determine the sufficiency of available labeled training data. Our proposed scheme, using LDT leads to a significant reduction (  50X) in the training time for a model, thus enabling recommender systems to adapt quickly to disruptions. We illustrate the efficacy of our proposed scheme, by conducting extensive experimental analysis on six well known, structured data sets from various public domains.</p>
    <p><strong>Categories:</strong> Machine Learning, Recommendation Systems, Dynamic Environments, Adaptability, Scalability, Empirical Evaluation, Training Efficiency, Novel Concepts (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/613/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Contextual Meta-Bandit for Recommender Systems Selection (2020)</h3>
    <p><strong>Authors:</strong> Sandor Caetano, Renan M. de Oliveira, Anderson Soares, Luckeciano C. Melo, Marlesson R. O. de Santana, Fernando H. F. Camargo, Bruno Brandão</p>
    <p>Recommendation systems operate in a highly stochastic and non-stationary environment. As the amount of user-specific information varies, the users’ interests themselves also change. This combination creates a dynamic setting where a single solution will rarely be optimal unless it can keep up with these transformations. One system may perform better than others depending on the situation at hand, thus making the choice of which system to deploy, even more difficult. We address these problems by using the Hierarchical Reinforcement Learning framework. Our proposed meta-bandit acts as a policy over options, where each option maps to a pre-trained, independent recommender system. This meta-bandit learns online and selects a recommender accordingly to the context, adjusting to the situation. We conducted experiments on real data and found that our approach manages to address the dynamics within the user’s changing interests. We also show that it outperforms any of the recommenders separately, as well as an ensemble of them.</p>
    <p><strong>Categories:</strong> Contextual Meta-Bandit, Multi-Armed Bandits, Hierarchical Reinforcement Learning, Recommendation Systems, Online Learning, Real-World Applications, Dynamic Environments, User Behavior, Algorithm Selection (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/574/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Efficient Similarity Computation for Collaborative Filtering in Dynamic Environments (2019)</h3>
    <p><strong>Authors:</strong> Olivier Jeunen, Bart Goethals, Koen Verstrepen</p>
    <p>The problem of computing all pairwise similarities in a large collection of vectors is a well-known and common data mining task. As the number and dimensionality of these vectors keeps increasing, however, currently existing approaches are often unable to meet the strict efficiency requirements imposed by the environments they need to perform in. Real-time neighbourhood-based collaborative filtering (CF) is one example of such an environment in which performance is critical. In this work, we present a novel algorithm for efficient and exact similarity computation between sparse, high-dimensional vectors. Our approach exploits the sparsity that is inherent to implicit feedback data-streams, entailing significant gains compared to other methods. Furthermore, as our model learns incrementally, it is naturally suited for dynamic real-time CF environments. We propose a MapReduce-inspired parallellisation procedure along with our method, and show how even more speed-up can be achieved. Additionally, in many real-world systems, many items are actually not recommendable at any given time, due to recency, stock, seasonality, or enforced business rules. We exploit this fact to further improve the computational efficiency of our approach. Experimental evaluation on both real-world and publicly available datasets shows that our approach scales up to millions of processed user-item interactions per second, and well advances the state-of-the-art. ,</p>
    <p><strong>Categories:</strong> Collaborative Filtering, Recommendation Systems, Algorithm Efficiency, High-Dimensional Data, Dynamic Environments, Distributed Computing, Real-World Applications, Performance Evaluation (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/443/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>