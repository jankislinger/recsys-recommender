<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/evaluation-methods/">Evaluation Methods</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/benchmarking/">Benchmarking</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reinforcement-learning/">Reinforcement Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/explainability/">Explainability</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/beyond-accuracy/">Beyond Accuracy</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Evaluating the Pros and Cons of Recommender Systems Explanations (2024)</h3>
    <p><strong>Authors:</strong> Kathrin Wardatzky</p>
    <p>Despite the growing interest in explainable AI in the RecSys community, the evaluation of explanations is still an open research topic. Typically, explanations are evaluated using offline metrics, with a case study, or through a user study. In my research, I will have a closer look at the evaluation of the effects of explanations on users. I investigate two possible factors that can impact the effects reported in recent publications, namely the explanation design and content as well as the users themselves. I further address the problem of determining promising explanations for an application scenario from a seemingly endless pool of options. Lastly, I propose a user study to close some of the research gaps established in the surveys and investigate how recommender systems explanations impact the understanding of users with different backgrounds.</p>
    <p><strong>Categories:</strong> Explainable AI, Recommender Systems (RecSys), Evaluation Methods, User Study, Explanation Design, User-Centered Design, Offline Metrics, Case Study (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1140/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Analyzing Accuracy versus Diversity in a Health Recommender System for Physical Activities: a Longitudinal User Study (2023)</h3>
    <p><strong>Authors:</strong> Luc Martens, Toon De Pessemier, Ine Coppens</p>
    <p>As personalization has great potential to improve mobile health apps, analyzing the effect of different recommender algorithms in the health domain is still in its infancy. As such, this paper investigates whether more accurate recommendations from a content-based recommender or more diverse recommendations from a user-based collaborative filtering recommender will lead to more motivation to move. An eight-week longitudinal between-subject user study is being conducted with an Android app in which participants receive personalized recommendations for physical activities and tips to reduce sedentary behavior. The objective manipulation check confirmed that the group with collaborative filtering received significantly more diverse recommendations. The subjective manipulation check showed that the content-based group assigned more positive feedback for perceived accuracy and star rating to the recommendations they chose and executed. However, perceived diversity and inspiringness was significantly higher in the content-based group, suggesting that users might experience the recommendations differently. Lastly, momentary motivation for the executed activities and tips was significantly higher in the content-based group. As such, the preliminary results of this longitudinal study suggest that more accurate and less diverse recommendations have better effects on motivating users to move more.</p>
    <p><strong>Categories:</strong> Recommender Systems, Healthcare, Accuracy, Diversity of Recommendations, Collaborative Filtering, Content-Based Filtering, Longitudinal Study, User Study, Perceived Accuracy, Beyond Accuracy, Real-World Applications, Inspiringness (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/948/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>A User-Centered Investigation of Personal Music Tours (2022)</h3>
    <p><strong>Authors:</strong> Giovanni Gabbolini, Derek Bridge</p>
    <p>Streaming services use recommender systems to surface the right music to users. Playlists are a popular way to present music in a list-like fashion, i.e. as a plain list of songs. An alternative are tours, where the songs alternate with segues, which explain the connections between consecutive songs. Tours address the user need of seeking background information about songs, and are found to be superior to playlists, given the right user context. In this work, we provide, for the first time, a user-centered evaluation of two tour-generation algorithms (Greedy and Optimal) using semi-structured interviews. We assess the algorithms, we discuss attributes of the tours that the algorithms produce, we identify which attributes are desirable and which are not, and we enumerate several possible improvements to the algorithms, along with practical suggestions on how to implement the improvements. Our main findings are that Greedy generates more likeable tours than Optimal, and that three important attributes of tours are segue diversity, song arrangement and song familiarity. More generally, we provide insights into how to present music to users, which could inform the design of user-centered recommender systems.</p>
    <p><strong>Categories:</strong> Greedy Algorithm, Optimal Algorithm, Music Recommendations, Streaming Services, Tour Generation, User-Centered Evaluation, Segue Diversity, Song Arrangement, Song Familiarity, User Study, User Preferences, Presentation of Recommendations, Algorithm Improvement (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/747/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>The role of preference consistency, defaults and musical expertise in users’ exploration behavior in a genre exploration recommender (2021)</h3>
    <p><strong>Authors:</strong> Yu Liang, Martijn C. Willemsen</p>
    <p>Recommender systems are efficient at predicting users’ current preferences, but how users’ preferences develop over time is still under-explored. In this work, we study the development of users’ musical preferences. Exploring musical preference consistency between short-term and long-term preferences in data from earlier studies, we find that users with higher musical expertise have more consistent preferences at their top-listened artists and tags than those with lower musical expertise. Users typically chose to explore genres that were close to their current preferences, and this effect was stronger for expert users. Based on these findings we conducted a user study on genre exploration to investigate (1) whether it is possible to nudge users to explore more distant genres, and (2) how users’ exploration behaviors within a genre are influenced by default recommendation settings that balance personalization with genre representativeness in different ways. Our results show that users were more likely to select the more distant genres if these were presented at the top of the list. However, users with high musical expertise were less likely to do so, consistent with our earlier findings. When given a representative or mixed (balanced) default for exploration within a genre, users selected less personalized recommendation settings and explored further away from their current preferences, than with a personalized default. However, this effect was moderated by users’ slider usage behaviors. Overall, our results suggest that (personalized) defaults can nudge users to explore new, more distant genres and songs. However, the effect is smaller for those with higher musical expertise levels.</p>
    <p><strong>Categories:</strong> Recommendation Systems, User Behavior, Preference Consistency, Genre Exploration, Musical Expertise, Defaults and Defaults Impact, Personalization vs Representativeness, User Study, Slider Usage, Exploration vs Exploitation, Default Settings Impact (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/665/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Local Factor Models for Large-Scale Inductive Recommendation (2021)</h3>
    <p><strong>Authors:</strong> Longqi Yang, Tobias Schnabel, Susan Dumais, Paul N. Bennett</p>
    <p>In many domains, user preferences are similar locally within like-minded subgroups of users, but typically differ globally between those subgroups. Local recommendation models were shown to substantially improve top-K recommendation performance in such settings. However, existing local models do not scale to large-scale datasets with an increasing number of subgroups and do not support inductive recommendations for users not appearing in the training set. Key reasons for this are that subgroup detection and recommendation get implemented as separate steps in the model or that local models are explicitly instantiated for each subgroup. In this paper, we propose an End-to-end Local Factor Model (Elfm) which overcomes these limitations by combining both steps and incorporating local structures through an inductive bias. Our model can be optimized end-to-end and supports incremental inference, does not require a full separate model for each subgroup, and has overall small memory and computational costs for incorporating local structures. Empirical results show that our method substantially improves recommendation performance on large-scale datasets with millions of users and items with considerably smaller model size. Our user study also shows that our approach produces coherent item subgroups which could aid in the generation of explainable recommendations.</p>
    <p><strong>Categories:</strong> Recommendation Algorithms, Factor Models, Large-Scale Recommendations, Subgroup Detection, Cold Start, Scalability, Top-K Performance, Explainable Recommendations, Incremental Inference, User Study. (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/652/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>ClusterExplorer: Enable User Control over Related Recommendations via Collaborative Filtering and Clustering (2020)</h3>
    <p><strong>Authors:</strong> Kati Launis, Denis Kotkov, Mats Neovius, Qian Zhao</p>
    <p>Related item recommendations have a long history in recommender systems, but they tend to be a static list of similar items with respect to a target item of interest without any support of user control. In this paper, we propose ClusterExplorer, a novel approach for enabling user control over related recommendations. The approach allows users to explore the latent space of user-item interactions through controlling related recommendations. We evaluated ClusterExplorer in the book domain with 42 participants recruited in a public library and found that our approach has higher user satisfaction of browsing items and is more helpful in finding interesting items compared to traditional related item recommendations.</p>
    <p><strong>Categories:</strong> Related Item Recommendations, Collaborative Filtering, User Control, Clustering, Books, User Study, Latent Space, Browsing Experience (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/561/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>User-Centered Evaluation of Strategies for Recommending Sequences of Points of Interest to Groups (2019)</h3>
    <p><strong>Authors:</strong> Wolfgang Wörndl, Daniel Herzog</p>
    <p>Most recommender systems (RSs) predict the preferences of individual users; however, in certain scenarios, recommendations need to be made for a group of users. Tourism is a popular domain for group recommendations because people often travel in groups and look for point of interest (POI) sequences for their visits during a trip. In this study, we present different strategies that can be used to recommend POI sequences for groups. In addition, we introduce novel approaches, including a strategy called Split Group, which allows groups to split into smaller groups during a trip. We compared all strategies in a user study with 40 real groups. Our results proved that there was a significant difference in the quality of recommendations generated by using the different strategies. Most groups were willing to split temporarily during a trip, even when they were traveling with persons close to them. In this case, Split Group generated the best recommendations for different evaluation criteria. We use these findings to propose improvements for group recommendation strategies in the tourism domain.</p>
    <p><strong>Categories:</strong> Tourism, Group Recommendations, Point of Interest (POI) Recommendations, User-Centered Evaluation, Quality of Recommendations, Personalized Recommendations, Travel Planning, Sequence Recommendations, Split Group Strategy, Real-World Applications, User Study (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/502/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Designing for the Better by Taking Users into Account: A Qualitative Evaluation of User Control Mechanisms in (News) Recommender Systems (2019)</h3>
    <p><strong>Authors:</strong> Jaron Harambam, Mykola Makhortykh, Dimitrios Bountouridis, Joris van Hoboken</p>
    <p>Recommender systems (RS) are on the rise in many domains. While they offer great promises, they also raise concerns: lack of transparency, reduction of diversity, little to no user control. In this paper, we align with the normative turn in computer science which scrutinizes the ethical and societal implications of RS. We focus and elaborate on the concept of user control because that mitigates multiple problems at once. Taking the news industry as our domain, we conducted four focus groups, or moderated think-aloud sessions, with Dutch news readers (N=21) to systematically study how people evaluate different control mechanisms (at the input, process, and output phase) in a News Recommender Prototype (NRP). While these mechanisms are sometimes met with distrust about the actual control they offer, we found that an intelligible user profile (including reading history and flexible preferences settings), coupled with possibilities to influence the recommendation algorithms is highly valued, especially when these control mechanisms can be operated in relation to achieving personal goals. By bringing (future) users’ perspectives to the fore, this paper contributes to a  richer understanding of why and how to design for user control in recommender systems.</p>
    <p><strong>Categories:</strong> Recommender Systems, News Domain, User Control Mechanisms, Qualitative Evaluation, Ethical Considerations, Societal Implications, User Study, Input Control Mechanisms, Process Control Mechanisms, Output Control Mechanisms, Transparency, Personalization, News Recommender Systems, User-Centered Design, Usability (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/438/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>User-Centric Evaluation of Session-Based Recommendations for an Automated Radio Station (2019)</h3>
    <p><strong>Authors:</strong> Dietmar Jannach, Malte Ludewig</p>
    <p>The creation of an automated and virtually endless playlist given a start item is a common feature of modern media streaming services. When no past information about the user’s preferences is available, the creation of such playlists can be done using session-based recommendation techniques. In this case, the recommendations only depend on the start item and the user’s interactions in the current listening session, such as ‘liking’ or skipping an item. In recent years, various novel session-based techniques were proposed, often based on deep learning. The evaluation of such approaches is in most cases solely based on offline experimentation and abstract accuracy measures. However, such evaluations cannot inform us about the quality as perceived by users. To close this research gap, we have conducted a user study (N=250), where the participants interacted with an automated online radio station. Each treatment group received recommendations that were generated by one of five different algorithms. Our results show that comparably simple techniques led to quality perceptions that are similar or even better than when a complex deep learning mechanism or Spotify’s recommendations are used. The simple mechanisms, however, often tend to recommend comparably popular tracks, which can lead to lower discovery effects. i>Presentation: Wednesday Poster Lunch</i</p>
    <p><strong>Categories:</strong> Session-Based Recommendations, User-Centric Evaluation, Recommendation Systems, Media Streaming, Automated Radio, Deep Learning, Algorithm Comparison, A/B Testing, User Study, Real-World Applications, Perceived Quality, Discovery Effects, Beyond Accuracy (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/499/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Combining Text Summarization and Aspect-based Sentiment Analysis of Users’ Reviews to Justify Recommendations (2019)</h3>
    <p><strong>Authors:</strong> Pasquale Lops, Giovanni Semeraro, Marco de Gemmis, Cataldo Musto, Gaetano Rossiello</p>
    <p>In this paper we present a methodology to justify recommendations that relies on the information extracted from users’ reviews discussing the available items. The intuition behind the approach is to conceive the justification as a summary of the most relevant and distinguishing aspects ofthe item, automatically obtained by analyzing the available reviews. To this end, we designed a pipeline of natural language processing techniques based on aspect extraction, sentiment analysis and text summarization to gather the reviews, process the relevant excerpts,and generate a unique synthesis presenting the main characteristics of the item. Such a summary is finally presented to the target user as justification of the recommendation she received. In the experimental evaluation we carried out a user study in the movie domain (N=141) and the results showed that our approach is able to make the recommendation process more transparent, engaging and trustful for the users. Moreover, the proposed method also beat another review-based explanation technique, thus confirming the validity of our intuition. i>Presentation: Monday Poster Lunch</i</p>
    <p><strong>Categories:</strong> Recommendation Systems, Natural Language Processing, Text Summarization, Aspect-Based Sentiment Analysis, Movie Domain, User Study, Explainability, Trust, Experimental Results, Evaluation Methodology, Pipeline Design, Transparency in AI, User Feedback, Sentiment Analysis, Aspect Extraction, User-Centered Design (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/469/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Picture-based Navigation for Diagnosing Post-Harvest Diseases of Apple (2018)</h3>
    <p><strong>Authors:</strong> Gabriele Sottocornola, Markus Zanker</p>
    <p>This demo presents a conversational navigation approach for a diagnostic application of postharvest diseases of apple with the goal to educate users on the diagnosed diseases as well as to recommend consequences for the storage facility and what action to take for the next growing period. It thus builds on earlier works on picture-based navigation for conversational recommender systems and provides evidence for its usability based on a first small-scale comparative usability study.</p>
    <p><strong>Categories:</strong> Picture-Based Navigation, Conversational Recommender Systems, Disease Diagnosis, Agricultural Applications, Educational Applications, Recommendation Systems, User Study, Image-Based Recommendations, Usability Testing, Conversational Interfaces (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/398/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Understanding Latent Factors Using a GWAP (2018)</h3>
    <p><strong>Authors:</strong> Jürgen Ziegler, Johannes Kunkel, Benedikt Loepp</p>
    <p>Recommender systems relying on latent factor models often appear as black boxes to their users. Semantic descriptions for the factors might help to mitigate this problem. Achieving this automatically is, however, a non-straightforward task due to the models’ statistical nature. We present an output-agreement game that represents factors by means of sample items and motivates players to create such descriptions. A user study shows that the collected output actually reflects real-world characteristics of the factors.</p>
    <p><strong>Categories:</strong> Algorithm Family (Latent Factor Models), User Study, Games with a Purpose (GWAP), Real-World Applications, Transparency/Interpretability in Recommendations, Explainability, Human-Readable Descriptions, Recommendation Systems, Social Aspects, Crowdsourcing, Methodology (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/420/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Users’ Choices About Hotel Booking: Cues for Personalizing the Presentation of Recommendations (2017)</h3>
    <p><strong>Authors:</strong> Catalin-Mihai Barbu, Jürgen Ziegler</p>
    <p>Personalization in recommender systems has typically been applied to the underlying algorithms. In contrast, the presentation of individual recommendations—specifically, the various ways in which it can be adapted to suit the user’s needs in a more effective manner—has received relatively little attention by comparison. We present the results of an exploratory survey about users’ choices regarding hotel recommendations and draw preliminary conclusions about whether these choices can influence the presentation of recommendations.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Travel, Hospitality, Personalization, User Behavior, Presentation, Adaptation, Evaluation Methods, User Study, Survey Methodology, Data Collection (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/334/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Surveying User Reactions to Recommendations Based on Inferences Made by Face Detection Technology (2017)</h3>
    <p><strong>Authors:</strong> Jason Wiese, Jennifer Marlow</p>
    <p>It is increasingly possible to use cameras and sensors to detect and analyze human appearance for the purposes of personalizing user experiences. Such systems are already deployed in some public places to personalize advertisements and recommend items. However, since these technologies are not yet widespread, we do not have a good sense of the perceived benefits and drawbacks of public display systems that use face detection as an input for personalized recommendations. We conducted a user study with a system that inferred a user’s gender and age from a facial detection and analysis algorithm and used this to present recommendations in two scenarios (finding stores to visit in a mall and finding a pair of sunglasses to buy).  This work provides an initial step towards understanding user reactions to a new and emerging form of implicit recommendation based on physical appearance.</p>
    <p><strong>Categories:</strong> Face Detection, Personalized Recommendations, Retail, User Perception, Privacy Concerns, Beyond Accuracy, User Study, Computer Vision, Implicit Feedback (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/297/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>ExpLOD: A Framework for Explaining Recommendations based on the Linked Open Data Cloud (2016)</h3>
    <p><strong>Authors:</strong> Fedelucio Narducci, Pasquale Lops, Marco De Gemmis, Giovanni Semeraro, Cataldo Musto</p>
    <p>In this paper we present ExpLOD, a framework which exploits the information available in the Linked Open Data (LOD) cloud to generate a natural language explanation of the suggestions produced by a recommendation algorithm. The methodology is based on building a graph in which the items liked by a user are connected to the items recommended through the properties available in the LOD cloud. Next, given this graph, we implemented some techniques to rank those properties and we used the most relevant ones to feed a module for generating explanations in natural language. In the experimental evaluation we performed a user study with 308 subjects aiming to investigate to what extent our explanation framework can lead to more transparent, trustful and engaging recommendations. The preliminary results provided us with encouraging findings, since our algorithm performed better than both a non-personalized explanation baseline and a popularity-based one.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Explanation Generation, Linked Open Data (LOD), Natural Language Processing (NLP), User Study, Trust in Recommendations, Explainable AI (XAI), Transparency in Recommendations, Graph-Based Methods, Evaluation Techniques, Framework Design (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/204/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Contrasting Offline and Online Results when Evaluating Recommendation Algorithms (2016)</h3>
    <p><strong>Authors:</strong> Marco Rossetti, Fabio Stella, Markus Zanker</p>
    <p>Most evaluations of novel algorithmic contributions assess their accuracy in predicting what was withheld in an offline evaluation scenario. However, several doubts have been raised that standard offline evaluation practices are not appropriate to select the best algorithm for field deployment. The goal of this work is therefore to compare the offline and the online evaluation methodology with the same study participants, i.e. a within users experimental design. This paper presents empirical evidence that the ranking of algorithms based on offline accuracy measurements clearly contradicts the results from the online study with the same set of users. Thus the external validity of the most commonly applied evaluation methodology is not guaranteed.</p>
    <p><strong>Categories:</strong> Offline Evaluation, Online Evaluation, Algorithmic Evaluation Methods, Recommendation Algorithms, External Validity, User-Centered Evaluation, Evaluation Methodology, Algorithm Selection, Empirical Evidence, Deployment Considerations, User Study, Recommendation Systems (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/199/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>