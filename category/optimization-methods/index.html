<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui primary button" style="margin: 5px;"
             href="/recsys-recommender/">Optimization Methods</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/bias-mitigation/">Bias Mitigation</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/multi-armed-bandits/">Multi-Armed Bandits</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reproducibility/">Reproducibility</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Calibrating the Predictions for Top-N Recommendations (2024)</h3>
    <p><strong>Authors:</strong> Masahiro Sato</p>
    <p>Well-calibrated predictions of user preferences are essential for many applications. Since recommender systems typically select the top-N items for users, calibration for those top-N items, rather than for all items, is important.  We show that previous calibration methods result in miscalibrated predictions for the top-N items, despite their excellent calibration performance when evaluated on all items.  In this work, we address the miscalibration in the top-N recommended items. We first define evaluation metrics for this objective and then propose a generic method to optimize calibration models focusing on the top-N items. It groups the top-N items by their ranks and optimizes distinct calibration models for each group with rank-dependent training weights.  We verify the effectiveness of the proposed method for both explicit and implicit feedback datasets, using diverse classes of recommender models.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Top-N Recommendations, Calibration of Predictions, Evaluation Metrics, Optimization Methods, Explicit Feedback, Implicit Feedback, Diverse Recommenders, Accuracy of Recommendations, Matrix Factorization, Multi-Armed Bandits, Algorithm Evaluation, Item Ranking (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1082/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Δ-OPE: Off-Policy Estimation with Pairs of Policies (2024)</h3>
    <p><strong>Authors:</strong> Aleksei Ustimenko, Olivier Jeunen</p>
    <p>The off-policy paradigm casts recommendation as a counterfactual decision-making task, allowing practitioners to unbiasedly estimate online metrics using offline data. This leads to effective evaluation metrics, as well as learning procedures that directly optimise online success. Nevertheless, the high variance that comes with unbiased- ness is typically the crux that complicates practical applications. An important insight is that the difference between policy values can often be estimated with significantly reduced variance, if said policies have positive covariance. This allows us to formulate a pairwise off-policy estimation task: Δ-OPE. Δ-OPE subsumes the common use-case of estimating improve- ments of a learnt policy over a production policy, using data col- lected by a stochastic logging policy. We introduce Δ-OPE methods based on the widely used Inverse Propensity Scoring estimator and its extensions. Moreover, we characterise a variance-optimal additive control variate that further enhances efficiency. Simulated, offline, and online experiments show that our methods significantly improve performance for both evaluation and learning tasks.</p>
    <p><strong>Categories:</strong> Off-Policy Estimation, Inverse Propensity Scoring, A/B Testing, Recommendation Evaluation, Variance Reduction, Experimental Methods, Multi-Policy Evaluation, Domain-Specific Applications, Optimization Methods. (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1117/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Privacy Preserving Conversion Modeling in Data Clean Room (2024)</h3>
    <p><strong>Authors:</strong> Behnam Rezaei, Xiangyi Chen, Ling Leng, Jiajing Xu, Jiankai Sun, Kungang Li</p>
    <p>In the realm of online advertising, accurately predicting the conversion rates (CVR) is crucial for enhancing advertising efficiency and user satisfaction. However, it faces the challenge that due to user privacy choices and advertiser requirements, the advertising platform cannot get the conversion data from some advertisers, making accurate CVR predictions difficult. Although current methods like split learning or vertical federated learning do not share label information directly, they still exchange sample-level gradients, which introduces a privacy risk as adversaries might infer label information through the shared gradients. To address these challenges, our proposed model training framework incorporates several innovative techniques. Firstly, we employ batch-level aggregated gradients instead of sample-level gradients to enhance privacy. Secondly, to minimize communication costs, we utilize adapter-based parameter-efficient fine-tuning methods such as Low-Rank Adaptation (LoRA) and gradient compression in conversion models. These methods allow for efficient collaboration between different parties while reducing the amount of data transferred. Lastly, we incorporate label differential privacy to protect model privacy. Given that this privacy protection alters the data distribution and can result in significant calibration error, we propose a de-biasing technique to ensure accurate model predictions even with perturbed label information. Our experimental results on industrial datasets demonstrate that our method achieves competitive performance while significantly reducing the communication overhead and complying with advertisers’ privacy requirements and user privacy choice. This framework establishes a new benchmark for privacy-preserving and high-performance CVR prediction in the digital advertising industry.</p>
    <p><strong>Categories:</strong> Privacy Preservation, Conversion Rate Prediction, Online Advertising, Machine Learning, Federated Learning, Differential Privacy, Optimization Methods, Data Sharing Challenges, Low-Rank Adaptation (LoRA), Gradient Compression, Advertising Technology, Real-World Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1181/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Performance of Hyperbolic Geometry Models in Top-N Recommendation Tasks (2020)</h3>
    <p><strong>Authors:</strong> Alexander Tuzhilin, Evgeny Frolov, Leyla Mirvakhabova, Valentin Khrulkov, Ivan Oseledets</p>
    <p>We introduce a simple autoencoder based on hyperbolic geometry for solving standard collaborative filtering problem. In contrast to many modern deep learning techniques, we build our solution using only a single hidden layer. Remarkably, even with such a minimalistic approach, we not only outperform the Euclidean counterpart but also achieve a competitive performance with respect to the current state-of-the-art. We additionally explore the effects of space curvature on the quality of hyperbolic models and propose an efficient data-driven method for estimating its optimal value.</p>
    <p><strong>Categories:</strong> Hyperbolic Geometry, Recommendation Systems, Collaborative Filtering, Autoencoder, Deep Learning Techniques, Top-N Recommendations, Algorithm Performance, Space Curvature, Optimization Methods, Performance Evaluation, Matrix Factorization, Real-World Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/580/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Uplift-based Evaluation and Optimization of Recommenders (2019)</h3>
    <p><strong>Authors:</strong> Sho Takemori, Qian Zhang, Masahiro Sato, Takashi Sonoda, Janmajay Singh, Tomoko Ohkuma</p>
    <p>Recommender systems aim to increase user actions such as clicks and purchases. Typical evaluations of recommenders regard the purchase of a recommended item as a success. However, the item may have been purchased even without the recommendation. An uplift is defined as an increase in user actions caused by recommendations. Situations with and without a recommendation cannot both be observed for a specific user-item pair at a given time instance, making uplift-based evaluation and optimization challenging. This paper proposes new evaluation metrics and optimization methods for the uplift in a recommender system. We apply a causal inference framework to estimate the average uplift for the offline evaluation of recommenders. Our evaluation protocol leverages both purchase and recommendation logs under a currently deployed recommender system, to simulate the cases both with and without recommendations. This enables the offline evaluation of the uplift for newly generated recommendation lists. For optimization, we need to define positive and negative samples that are specific to an uplift-based approach. For this purpose, we deduce four classes of items by observing purchase and recommendation logs. We derive the relative priorities among these four classes in terms of the uplift and use them to construct both pointwise and pairwise sampling methods for uplift optimization. Through dedicated experiments with three public datasets, we demonstrate the effectiveness of our optimization methods in improving the uplift.</p>
    <p><strong>Categories:</strong> Uplift Modeling, Causal Inference, Recommendation Systems, Evaluation Metrics, Offline Evaluation, Beyond Accuracy, Optimization Methods, Real World Data (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/457/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>