<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/bias-mitigation/">Bias Mitigation</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reproducibility/">Reproducibility</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reinforcement-learning/">Reinforcement Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/real-world-applications/">Real-world Applications</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Transfer Learning in Collaborative Recommendation for Bias Reduction (2021)</h3>
    <p><strong>Authors:</strong> Weike Pan, Dugang Liu, Zinan Lin, Zhong Ming</p>
    <p>In a recommender system, a user’s interaction is often biased by the items’ displaying positions and popularity, as well as the user’s self-selection. Most existing recommendation models are built using such a biased user-system interaction data. In this paper, we first additionally introduce a specially collected unbiased data and then propose a novel transfer learning solution, i.e., transfer via joint reconstruction (TJR), to achieve knowledge transfer and sharing between the biased data and unbiased data. Specifically, in our TJR, we refine the prediction via the latent features containing bias information in order to obtain a more accurate and unbiased prediction. Moreover, we integrate the two data by reconstructing their interaction in a joint learning manner. We then adopt three representative methods as the backbone models of our TJR and conduct extensive empirical studies on two public datasets, showcasing the effectiveness of our transfer learning solution over some very competitive baselines.</p>
    <p><strong>Categories:</strong> Transfer Learning, Recommender Systems, Collaborative Filtering, Bias Reduction, Transfer Learning Techniques, Data Integration, Evaluation, Cross-Domain Learning, Latent Factor Models, Empirical Evaluation, General Recommendation, Data Collection, Quality Improvement (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/693/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Combining Rating and Review Data by Initializing Latent Factor Models with Topic Models for Top-N Recommendation (2020)</h3>
    <p><strong>Authors:</strong> Barry Smyth, Aonghus Lawlor, Francisco J. Peña, Diarmuid O’Reilly-Morgan, Elias Z. Tragos, Erika Duriakova, Neil Hurley</p>
    <p>Nowadays we commonly have multiple sources of data associated with items. Users may provide numerical ratings, or implicit interactions, but may also provide textual reviews. Although many algorithms have been proposed to jointly learn a model over both interactions and textual data, there is room to improve the many factorization models that are proven to work well on interactions data, but are not designed to exploit textual information. Our focus in this work is to propose a simple, yet easily applicable and effective, method to incorporate review data into such factorization models. In particular, we propose to build the user and item embeddings within the topic space of a topic model learned from the review data. This has several advantages: we observe that initializing the user and item embeddings in topic space leads to faster convergence of the factorization algorithm to a model that out-performs models initialized randomly, or with other state-of-the-art initialization strategies. Moreover, constraining user and item factors to topic space allows for the learning of an interpretable model that users can visualise.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Explicit Feedback, Implicit Feedback, Latent Factor Models, Topic Models, User/Item Embeddings, Textual Data, Initialization Strategies, Model Convergence, Model Interpretability, Hybrid Models, Top-N Recommendations (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/575/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Latent Factor Models and Aggregation Operators for Collaborative Filtering in Reciprocal Recommender Systems (2019)</h3>
    <p><strong>Authors:</strong> James Neve, Ivan Palomares</p>
    <p>Online dating platforms help to connect people who might potentially be a good match for each other. They have exerted a significant societal impact over the last decade, such that about one third of new relationships in the US are now started online, for instance. Recommender Systems are widely utilized in online platforms that connect people to people in e.g. online dating and recruitment sites. These recommender approaches are fundamentally different from traditional user-item approaches (such as those operating on movie and shopping sites), in that they must consider the interests of both parties jointly. Latent factor models have been notably successful in the area of user-item recommendation, however they have not been investigated within user-to-user domains as of yet. In this study, we present a novel method for reciprocal recommendation using latent factor models. We also provide a first analysis of the use of different preference aggregation strategies, thereby demonstrating that the aggregation function used to combine user preference scores has a significant impact on the outcome of the recommender system. Our evaluation results report significant improvements over previous nearest-neighbour and content-based methods for reciprocal recommendation, and show that the latent factor model can be used effectively on much larger datasets than previous state-of-the-art reciprocal recommender systems.</p>
    <p><strong>Categories:</strong> Latent Factor Models, Collaborative Filtering, Reciprocal Recommender Systems, Dating/Online Dating, Recommendation Quality, Aggregation Operators, Preference Aggregation, Scalability, Nearest Neighbor Methods, Content-Based Filtering, Evaluation Metrics (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/445/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Latent Modeling of Unexpectedness for Recommendations (2019)</h3>
    <p><strong>Authors:</strong> Pan Li, Alexander Tuzhilin</p>
    <p>Unexpectedness constitutes an important factor for recommender system to improve user satisfaction and avoid filter bubble issues. Previous methods model unexpectedness in the feature space, making them difficult to capture the latent, complex and heterogeneous interactions between users and items. In this paper, we propose to model unexpectedness in the latent space and utilize a latent convex hull structure to provide unexpected recommendations, as illustrated in Figure 1. Extensive experiments on two real-world datasets demonstrate effectiveness of latent unexpectedness over explicit unexpectedness and show that the proposed model significantly outperforms baseline models in terms of unexpectedness measures while achieving the same level of accuracy.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Unexpectedness, Latent Factor Models, Matrix Factorization, User Satisfaction, Addressing Filter Bubbles, Real-World Applications, Recommender System Quality, Evaluation Metrics, User-Centered Design, Machine Learning Techniques,凸 Hull Method (Latent) (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/515/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Preference Elicitation as an Optimization Problem (2018)</h3>
    <p><strong>Authors:</strong> Filip Radlinski, Maarten de Rijke, Julia Kiseleva, Anna Sepliarskaia</p>
    <p>The new user cold-start problem arises when a recommender system does not yet have any information about a user. A common solution to this problem is to generate a user profile as part of the sign-up process, by asking the user to rate several items. We propose a new elicitation method to generate a static preference questionnaire (SPQ) that asks a new user to make pairwise comparisons between items by posing relative preference questions. Using a latent factor model, SPQ improves personalized recommendations by choosing a minimal and diverse set of static preference questions to ask any new user. We are the first to rigorously prove which optimization task should be solved in order to select the next preference question for static questionnaires. Our theoretical results are confirmed by extensive experimentation. We test the performance of SPQ on two real-world datasets, under two experimental conditions: simulated, when users behave according to LFM, and real, in which there is no user rating model. SPQ reduces the questionnaire length that is necessary to make accurate recommendations for new users by up to a factor of three compared to state-of-the-art preference elicitation methods. Moreover, solving the right optimization task, SPQ shows better performance than baselines with dynamically generated questions.</p>
    <p><strong>Categories:</strong> Cold Start, Recommendation Systems, User Profiling, Preference Elicitation, Optimization, Latent Factor Models, Real-World Applications, Experiments, Datasets, Evaluation Metrics, Performance Comparison, Efficiency, Pairwise Comparisons (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/357/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Towards Large Scale Training Of AutoEncoders For Collaborative Filtering (2018)</h3>
    <p><strong>Authors:</strong> Abdallah Moussawi</p>
    <p>In this paper, we apply a mini-batch based negative sampling method to efficiently train a latent factor autoencoder model on large scale and sparse data for implicit feedback collaborative filtering. We compare our work against a state-of-the-art baseline model on different experimental datasets and show that this method can lead to a good and fast approximation of the baseline model performance.</p>
    <p><strong>Categories:</strong> Collaborative Filtering, Autoencoders, Large Scale, Implicit Feedback, Mini-Batch Training, Negative Sampling, Performance Metrics, Latent Factor Models (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/412/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Learning to Rank with Trust and Distrust in Recommender Systems (2017)</h3>
    <p><strong>Authors:</strong> Dimitrios Rafailidis, Fabio Crestani</p>
    <p>The sparsity of users’ preferences can significantly degrade the quality of recommendations in the collaborative filtering strategy. To account for the fact that the selections of social friends and foes may improve the recommendation accuracy, we propose a learning to rank model that exploits users’ trust and distrust relationships. Our learning to rank model focusses on the performance at the top of the list, with the recommended items that end-users will actually see. In our model, we try to push the relevant items of users and their friends at the top of the list, while ranking low those of their foes. Furthermore, we propose a weighting strategy to capture the correlations of users’ preferences with friends’ trust and foes’ distrust degrees in two intermediate trust- and distrust-preference user latent spaces, respectively. Our experiments on the Epinions dataset show that the proposed learning to rank model significantly outperforms other state-of-the-art methods in the presence of sparsity in users’ preferences and when a part of trust and distrust relationships is not available. Furthermore, we demonstrate the crucial role of our weighting strategy in our model, to balance well the influences of friends and foes on users’ preferences.</p>
    <p><strong>Categories:</strong> Learning to Rank, Recommender Systems, Trust and Distrust, Collaborative Filtering, Sparsity Handling, Top-N Recommendations, Beyond Accuracy, Social Networks, Latent Factor Models (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/269/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Modeling the Assimilation-Contrast Effects in Online Product Rating Systems: Debiasing and Recommendations (2017)</h3>
    <p><strong>Authors:</strong> Junzhou Zhao, Xiaoying Zhang, John C.S. Lui</p>
    <p>The unbiasedness of online product ratings, an important property to ensure that users’ ratings indeed reflect their true evaluations to products, is vital both in shaping consumer purchase decisions and providing reliable recommendations. Recent experimental studies showed that distortions from historical ratings would ruin the unbiasedness of subsequent ratings. How to “discover” the distortions from historical ratings in each single rating (or at the micro-level), and perform the “de-biasing operations” in real rating systems are the main objectives of this work. Using 42 million real customer ratings, we first show that users either “assimilate” or “contrast” to historical ratings under different scenarios: users conform to historical ratings if historical ratings are not far from the product quality (assimilation), while users deviate from historical ratings if they are significantly different from the product quality (contrast). This phenomenon can be explained by the well-known psychological argument: the “Assimilate-Contrast” theory. However, none of the existing works on modeling historical ratings’ influence have taken this into account, and this motivates us to propose the Historical Influence Aware Latent Factor Model (HIALF), the first model for real rating systems to capture and mitigate historical distortions in each single rating. HIALF also allows us to study the influence patterns of historical ratings from a modeling perspective, and it perfectly matches the assimilation and contrast effects we previously observed. Also, HIALF achieves significant improvements in predicting subsequent ratings, and accurately predicts the relationships revealed in previous empirical measurements on real ratings. Finally, we show that HIALF can contribute to better recommendations by decoupling users’ real preference from distorted ratings, and reveal the intrinsic product quality for wiser consumer purchase decisions.</p>
    <p><strong>Categories:</strong> Latent Factor Models, Online Product Ratings, Recommendation Systems, Debiasing Methods, Psychological Models, Assimilation-Contrast Effects, E-commerce, Consumer Behavior, User Behavior Dynamics, Evaluation of Recommendations, Prediction Accuracy, Large Datasets, Algorithmic Improvements (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/267/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Fewer Flops at the Top: Accuracy, Diversity, and Regularization in Two-Class Collaborative Filtering (2017)</h3>
    <p><strong>Authors:</strong> Bibek Paudel, Thilo Haas, Abraham Bernstein</p>
    <p>In most existing recommender systems, implicit or explicit interactions are treated as positive links and all unknown interactions are treated as negative links. The goal is to suggest new links that will be perceived as positive links. However, as signed social networks and newer content services become common, it is important to distinguish between positive and negative preferences. Even in existing applications, the cost of a negative recommendation could be high when people are looking for new jobs, friends, or places to live. In this work, we develop novel probabilistic latent factor models to recommend positive links and compare with existing methods on five different openly available datasets. Our models are able to produce better ranking lists and are effective in the task of ranking positive links at the top and negative links at the bottom. Moreover, we find that modeling signed social networks and user preferences this way has the advantage of increasing diversity of recommendations. We also investigate the effect of regularization on the quality of recommendations, a matter that has not received enough attention in the literature. We find that regularization parameter heavily affects the quality of recommendations in terms of both accuracy and diversity.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Collaborative Filtering, User Preferences, Matrix Factorization, Social Networks, Accuracy of Recommendations, Diversity of Recommendations, Evaluation Methods, Regularization Techniques, Probabilistic Models, Latent Factor Models. (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/259/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Recommending Product Sizes to Customers (2017)</h3>
    <p><strong>Authors:</strong> Vivek Varadarajan Sembium, Atul Saroop, Srujana Merugu, Rajeev Rastogi</p>
    <p>We propose a novel latent factor model for recommending product size fits {Small, Fit, Large} to customers. Latent factors for customers and products in our model correspond to their physical true size, and are learnt from past product purchase and returns data. The outcome for a customer, product pair is predicted based on the difference between customer and product true sizes, and efficient algorithms are proposed for computing customer and product true size values that minimize two loss function variants. In experiments with Amazon shoe datasets, we show that our latent factor models incorporating personas, and leveraging return codes show a 17-21% AUC improvement compared to baselines. In an online A/B test, recommendations produced by our algorithms show an improvement of 33 basis points in percentage of Fit transactions over control.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Latent Factor Models, E-commerce, Product Size Recommendations, Customer Behavior Analysis, AUC Improvement, Real-World Applications, Online Experiments, Personalization, Beyond Accuracy Metrics, Scalability, User Experience. (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/276/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Factorization Meets the Item Embedding: Regularizing Matrix Factorization with Item Co-occurrence (2016)</h3>
    <p><strong>Authors:</strong> David M. Blei, Dawen Liang, Jaan Altosaar, Laurent Charlin</p>
    <p>Matrix factorization (MF) models and their extensions are standard in modern recommender systems. MF models decompose the observed user-item interaction matrix into user and item latent factors. In this paper, we propose a co-factorization model, CoFactor, which jointly decomposes the user-item interaction matrix and the item-item co-occurrence matrix with shared item latent factors. For each pair of items, the co-occurrence matrix encodes the number of users that have consumed both items. CoFactor is inspired by the recent success of word embedding models (e.g., word2vec) which can be interpreted as factorizing the word co-occurrence matrix. We show that this model significantly improves the performance over MF models on several datasets with little additional computational overhead. We provide qualitative results that explain how CoFactor improves the quality of the inferred factors and characterize the circumstances where it provides the most significant improvements.</p>
    <p><strong>Categories:</strong> Matrix Factorization, Recommendation Systems, Item Embeddings, Co-Occurrence Analysis, Latent Factor Models, Regularization Techniques, Word Embeddings Inspiration, Scalability (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/173/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Personalized Recommendations using Knowledge Graphs: A Probabilistic Logic Programming Approach (2016)</h3>
    <p><strong>Authors:</strong> William Cohen, Rose Catherine</p>
    <p>Improving the performance of recommender systems using knowledge graphs is an important task. There have been many hybrid systems proposed in the past that use a mix of content-based and collaborative filtering techniques to boost the performance. More recently, some work has focused on recommendations that use external knowledge graphs (KGs) to supplement content-based recommendation. In this paper, we investigate three methods for making KG based recommendations using a general-purpose probabilistic logic system called ProPPR. The simplest of the models, EntitySim, uses only the links of the graph. We then extend the model to TypeSim that also uses the types of the entities to boost its generalization capabilities. Next, we develop a graph based latent factor model, GraphLF, which combines the strengths of latent factorization with graphs. We compare our approaches to a recently proposed state-of-the-art graph recommendation method on two large datasets, Yelp and MovieLens-100K. The experiments illustrate that our approaches can give large performance improvements. Additionally, we demonstrate that knowledge graphs give maximum advantage when the dataset is sparse, and gradually become redundant as more training data becomes available, and hence are most useful in cold-start settings.</p>
    <p><strong>Categories:</strong> Personalized Recommendations, Knowledge Graphs, Probabilistic Logic Programming, Content-Based Filtering, Collaborative Filtering, Knowledge Graph Recommendations, Real World Applications, Experiments, Evaluation Methods, Cold Start, Sparse Data, Recommendation Techniques, Latent Factor Models (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/190/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Towards Improving Top-N Recommendation by Generalization of SLIM (2015)</h3>
    <p><strong>Authors:</strong> Alvaro Soto, Denis Parra, Santiago Larrain</p>
    <p>Sparse Linear Methods (SLIM) are state-of-the-art recommendation approaches based on matrix factorization, which rely on a regularized l1-norm and l2-norm optimization — an alternative optimization problem to the traditional Frobenious norm. Although they have shown outstanding performance in Top-N recommendation, existent works have not yet analyzed some inherent assumptions that can have an important effect on the performance of these algorithms. In this paper, we attempt to improve the performance of SLIM by proposing a generalized formulation of the aforementioned assumptions. Instead of directly learning a sparse representation of the user-item matrix, we (i) learn the latent factors’ matrix of the users and the items via a traditional matrix factorization approach, and then (ii) reconstruct the latent user or item matrix via prototypes which are learned using sparse coding, an alternative SLIM commonly used in the image processing domain. The results show that by tuning the parameters of our generalized model we are able to outperform SLIM in several Top-N recommendation experiments conducted on two different datasets, using both nDCG and nDCG@10 as evaluation metrics. These preliminary results, although not conclusive, indicate a promising line of research to improve the performance of SLIM recommendation.</p>
    <p><strong>Categories:</strong> Sparse Linear Methods (SLIM), Matrix Factorization, Optimization Techniques, Top-N Recommendations, Recommendation Algorithms, Evaluation Metrics, Latent Factor Models, Sparse Coding, Generalization, Algorithm Generalization. (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/166/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Exploiting Latent Social Listening Representations for Music Recommendations (2015)</h3>
    <p><strong>Authors:</strong> Yi-Hsuan Yang, Ming-Feng Tsai, Yu-Ching Lin, Chih-Ming Chen, Po-Chuan Chien</p>
    <p>Music listening can be regarded as a social activity, in which people can listen together and make friends with one other. Therefore, social relationships may imply multiple facets of the users, such as their listening behaviors and tastes. In this light, it is considered that social relationships hold abundant valuable information that can be utilized for music recommendation. However, utilizing the information for recommendation could be difficult, because such information is usually sparse. To address this issue, we propose to learn the latent social listening representations by the DeepWalk method, and then integrate the learned representations into Factorization Machines to construct better recommendation models. With the DeepWalk method, user social relationships can be transformed from the sparse and independent and identically distributed ( ) form into a dense and non- form. In addition, the latent representations can also capture the spatial locality among users and items, therefore benefiting the constructed recommendation models.</p>
    <p><strong>Categories:</strong> Social Network Analysis, User Behavior, Graph-Based Methods, Matrix Factorization, Representation Learning, Music, Recommendation Algorithms, Evaluation Metrics, Feature Integration, Latent Factor Models (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/147/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>User Churn Migration Analysis with DEDICOM (2015)</h3>
    <p><strong>Authors:</strong> Christian Bauckhage, César Ojeda, Rafet Sifa</p>
    <p>Time plays an important role regarding user preferences for products. It introduces asymmetries into the adoption of products which should be considered the context of recommender systems and business intelligence. We therefore investigate how temporally asymmetric user preferences can be analyzed using a latent factor model called Decomposition Into Directional Components (DEDICOM). We introduce a new scalable hybrid algorithm that combines projected gradient descent and alternating least squares updates to compute DEDICOM and imposes semi-nonnegativity constraints to better interpret the resulting factors. We apply our model to analyze user churn and migration between different computer games in a social gaming environment.</p>
    <p><strong>Categories:</strong> User Churn, User Migration, Temporal Analysis, Recommendation Systems, Latent Factor Models, Algorithm Scalability, Hybrid Algorithms, Social Gaming, User Behavior Analysis, Data Mining, Matrix Factorization, Business Intelligence (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/132/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Towards a Dynamic Top-N Recommendation Framework (2014)</h3>
    <p><strong>Authors:</strong> Xin Liu</p>
    <p>Real world large-scale recommender systems are always dynamic: new users and items continuously enter the system, and the status of old ones (e.g., users’ preference and items’ popularity) evolve over time. In order to handle such dynamics, we propose a recommendation framework consisting of an online component and an offline component, where the newly arrived items are processed by the online component such that users are able to get suggestions for fresh information, and the influence of longstanding items is captured by the offline component. Based on individual users’ past rating behavior, recommendations from the two components are combined to provide top-N recommendation. We formulate recommendation problem as a ranking problem where learning to rank is applied to extend upon a latent factor model to optimize recommendation rankings by minimizing a pairwise loss function. Furthermore, to more accurately model interactions between users and items, Latent Dirichlet Allocation is incorporated to fuse rating information and textual information. Real data based experiments demonstrate that our approach outperforms the state-of-the-art models by at least 61.21% and 50.27% in terms of mean average precision (MAP) and normalized discounted cumulative gain (NDCG) respectively.</p>
    <p><strong>Categories:</strong> Dynamic Recommendations, Top-N Recommendations, Online Algorithms, Offline Processing, Latent Factor Models, Learning to Rank, Textual Information Fusion, Mean Average Precision (MAP), Normalized Discounted Cumulative Gain (NDCG), Real Data Experiments (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/36/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>