<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui primary button" style="margin: 5px;"
             href="/recsys-recommender/">Bias in Algorithms</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reproducibility/">Reproducibility</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/evaluation-methods/">Evaluation Methods</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/e-commerce/">E-commerce</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Measuring and Mitigating Bias and Harm in Personalized Advertising (2021)</h3>
    <p><strong>Authors:</strong> Muhammad Ali</p>
    <p>Online personalized advertising is often very effective in identifying relevant audiences for each piece of content, which has led to its widespread adoption. In today’s internet, however, these advertising systems are used not only to market products, but also consequential life opportunities such as employment or housing, as well as socially important political messaging. This has led to increasing concerns about the presence of algorithmic bias and possible discrimination in these important domains — with results showing problematic biases along gender, race, and political affiliation, even when the advertiser might have targeted broadly.<br>A growing body of work focuses on measuring and characterizing these biases, as well as finding ways to mitigate these effects and building responsible systems. However, these results often emerge from different scientific communities and are often disconnected in the literature. In this paper, I attempt at bridging the gap between isolated efforts to either measure these biases, or to mitigate them. I discuss how the need to measure bias in advertising, and the efforts to mitigate it, despite being distant in the literature, are complementary problems that need to center their methodolgy around user studies.<br>This paper presents a research agenda that focuses on the need for user-centric measurements of bias, by collecting real ads from users, and using surveys to understand user perceptions for these ads. My approach also calls for incorporating user sentiments into the mitigation efforts, by constraining optimization on user values that emerge from surveys. Finally, I also emphasize the need for involving users in the evaluation of responsible advertising systems; efforts to mitigate bias eventually need to be contextualized in terms of benefits to users instead of simple performance tradeoffs. My focus on the users is motivated by the fact that they are stakeholders in personalized advertising, vulnerable at the hand of algorithmic bias and harm, and therefore crucial in both efforts to measure and mitigate these effects.</p>
    <p><strong>Categories:</strong> Bias in Algorithms, Discrimination, Personalized Advertising, User-Centric Design, Stakeholder Analysis, Measurement Tools, Mitigation Strategies, Responsible AI, Ethics, Harm Reduction, Real-World Applications, Fairness in Algorithms, Cross-Disciplinary Approaches, Algorithmic Justice, User Studies (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/719/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Biases in Recommendation System (2021)</h3>
    <p><strong>Authors:</strong> Saumya Bhadani</p>
    <p>Recommendation systems shape what people consume and experience online, which makes it critical to assess their effect on society and whether they are affected by any potential source of bias. My research focuses on a specific source of bias — popularity — that is especially relevant in two online contexts: news consumption, and cultural markets. Social media newsfeeds, which are designed to optimize the engagement of users, may inadvertently promote inaccurate and partisan news domains, since these are often popular among like-minded and polarized audiences. More generally, in any type of cultural market, popularity bias may lead to the suppression of niche quality products, which may not attract enough attention. In the context of online newsfeeds, I am investigating whether the political diversity of the audience of a news website can be used as signal of journalistic quality. In an analysis of a comprehensive dataset of news source reliability ratings and web browsing histories, I have shown that the diversity of the audience of a news website is a valuable signal to counter popularity bias and to promote journalistic quality. To further validate these results experimentally, I propose to have direct interactions with social media users through surveys. Here, I provide the details of a field study that I am planning to undertake using an experimental social media platform. More generally, in the context of any online cultural market, political audience diversity may not be applicable but the idea of diversity as a signal for higher quality might still be useful. For example, movies which are liked by an “age diverse” population or books which are read by racially diverse audience may have better quality than other items. However, in this research I have explored audience diversity in the context of social media newsfeeds only. For any online cultural market, I propose a method to quantify the popularity bias through an empirical analysis, using data from several existing markets. Accurately estimating the impact of popularity bias can help us advance our understanding of machine biases and also lead to the development of more robust recommendation systems.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Bias in Algorithms, Popularity Bias, News Consumption, Cultural Markets, Audience Diversity, Empirical Analysis, Experimental Methods, Field Study, User Survey, Misinformation, Content Curation, Beyond Accuracy (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/714/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>