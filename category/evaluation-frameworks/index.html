<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui primary button" style="margin: 5px;"
             href="/recsys-recommender/">Evaluation Frameworks</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/real-world-applications/">Real-world Applications</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/bias-mitigation/">Bias Mitigation</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reproducibility/">Reproducibility</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>RepSys: Framework for Interactive Evaluation of Recommender Systems (2022)</h3>
    <p><strong>Authors:</strong> Pavel Kordík, Jan Šafařík, Vojtěch Vančura</p>
    <p>Making recommender systems more transparent and auditable is crucial for the future adoption of these systems. Available tools typically present mostly errors of models aggregated over all test users, which is often insufficient to uncover hidden biases and problems. Moreover, the emphasis is primarily on the accuracy of recommendations but less on other important metrics, such as the diversity of recommended items, the extent of catalog coverage, or the opportunity to discover novel items at bestsellers’ expense. In this work, we propose RepSys, a framework for evaluating recommender systems. Our work offers a set of highly interactive approaches for investigating various scenario recommendations, analyzing a dataset, and evaluating distributions of various metrics that combine visualization techniques with existing offline evaluation methods. RepSys framework is available under an open-source license to other researchers.</p>
    <p><strong>Categories:</strong> Recommender Systems, Evaluation Frameworks, Beyond Accuracy, Diversity of Recommendations, Catalog Coverage, Visualization Techniques, Interactive Evaluation, Open Source (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/805/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Evaluation Framework for Cold-Start Techniques in Large-Scale Production Settings (2022)</h3>
    <p><strong>Authors:</strong> Moran Haham</p>
    <p>In recommender systems, cold-start issues are situations where no previous events (e.g., ratings), are known for certain users or items. Mitigating cold-start situations is a fundamental problem in almost any recommender system [3, 5]. In real-life, large-scale production systems, the challenge of optimizing the cold-start strategy is even greater. We present an end-to-end framework for evaluating and comparing different cold-start strategies. By applying this framework in Outbrain’s recommender system, we were able to reduce our cold-start costs by half, while supporting both offline and online settings. Our framework solves the pain of benchmarking numerous cold-start techniques using surrogate accuracy metrics on offline datasets - coupled with an extensive, cost-controlled online A/B test. In this abstract, We’ll start with a short introduction to the cold-start challenge in recommender systems. Next, we will explain the motivation for a framework for cold-start techniques. Lastly, we will then describe - step by step - how we used the framework to reduce our exploration by more than 50%.</p>
    <p><strong>Categories:</strong> Cold Start, Recommender Systems, Evaluation Frameworks, Large-Scale Production, Real-World Applications, Case Studies, Cost Optimization, Offline vs Online, Surrogate Metrics, Optimization of Exploration, Recommendation Strategies, Controlled Online Experiments (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/819/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>RADio – Rank-Aware Divergence Metrics to Measure Normative Diversity in News Recommendations (2022)</h3>
    <p><strong>Authors:</strong> Mateo Gutierrez Granada, Sanne Vrijenhoek, Maarten de Rijke, Gabriel Bénédict, Daan Odijk</p>
    <p>In traditional recommender system literature, diversity is often seen as the opposite of similarity, and typically defined as the distance between identified topics, categories or word models. However, this is not expressive of the social science’s interpretation of diversity, which accounts for a news organization’s norms and values and which we here refer to as normative diversity. We introduce RADio, a versatile metrics framework to evaluate recommendations according to these normative goals. RADio introduces a rank-aware Jensen Shannon (JS) divergence. This combination accounts for (i) a user’s decreasing propensity to observe items further down a list and (ii) full distributional shifts as opposed to point estimates. We evaluate RADio’s ability to reflect five normative concepts in news recommendations on the Microsoft News Dataset and six (neural) recommendation algorithms, with the help of our metadata enrichment pipeline. We find that RADio provides insightful estimates that can potentially be used to inform news recommender system design.</p>
    <p><strong>Categories:</strong> Normative Diversity, News Recommendations, Divergence Metrics, Rank-Aware Methods, Metadata Enrichment, Recommender Systems Evaluation, Algorithm Design, Real-World Applications, Neural Recommendation Algorithms, Social Science Aspects, Evaluation Frameworks, Diversity in Recommendations (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/775/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>T-RecS: A Framework for a Temporal Semantic Analysis of the ACM Recommender Systems Conference (2016)</h3>
    <p><strong>Authors:</strong> Pasquale Lops, Fedelucio Narducci, Marco De Gemmis, Giovanni Semeraro, Pierpaolo Basile</p>
    <p>This paper presents T-RecS (Temporal analysis of Recommender Systems conference proceedings), a framework that supplies services to analyze the Recommender Systems Conference proceedings from the first edition, held in 2007, to the last one, held in 2015, under a temporal point of view. The idea behind T-RecS is to identify linguistic phenomena that reflect some interesting variations for the research community, such as topic drift, or how the correlation between two terms changed over time, or how similarity between two authors evolved over time. The implemented framework can be easily adapted for the analysis of different corpora and domains.</p>
    <p><strong>Categories:</strong> Temporal Analysis, Recommender Systems, Semantic Analysis, Research Methods, Academic Conferences, Corpus Analysis, Text Mining, Evaluation Frameworks, Domain Adaptation, Research Tools (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/237/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>RiVal — A Toolkit to Foster Reproducibility in Recommender System Evaluation (2014)</h3>
    <p><strong>Authors:</strong> Alejandro Bellogin, Alan Said</p>
    <p>Currently, it is difficult to put in context and compare the results from a given evaluation of a recommender system, mainly because too many alternatives exist when designing and implementing an evaluation strategy. Furthermore, the actual implementation of a recommendation algorithm sometimes diverges considerably from the well-known ideal formulation due to manual tuning and modifications observed to work better in some situations. RiVal - a recommender system evaluation toolkit - allows for complete control of the different evaluation dimensions that take place in any experimental evaluation of a recommender system: data splitting, definition of evaluation strategies, and computation of evaluation metrics. In this demo we present some of the functionality of RiVal and show step-by-step how RiVal can be used to evaluate the results from any recommendation framework and make sure that the results are comparable and reproducible.</p>
    <p><strong>Categories:</strong> Reproducibility, Evaluation Frameworks, Recommendation Systems Evaluation, Recommender Systems Tools, Research Methods, Data Splitting, Evaluation Metrics, Experimental Design (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/60/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>