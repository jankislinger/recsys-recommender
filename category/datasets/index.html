<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reinforcement-learning/">Reinforcement Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reproducibility/">Reproducibility</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/evaluation-methods/">Evaluation Methods</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/e-commerce/">E-commerce</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Leveraging Large Language Models for Sequential Recommendation (2023)</h3>
    <p><strong>Authors:</strong> Panos Louridas, Dietmar Jannach, Marios Fragkoulis, Wouter Zorgdrager, Jesse Harte, Asterios Katsifodimos</p>
    <p>Sequential recommendation problems have received increasing attention in research during the past few years, leading to the inception of a large variety of algorithmic approaches. In this work, we explore how large language models (LLMs), which are nowadays introducing disruptive effects in many AI-based applications, can be used to build or improve sequential recommendation approaches. Specifically, we devise and evaluate three approaches to leverage the power of LLMs in different ways. Our results from experiments on two datasets show that initializing the state-of-the-art sequential recommendation model BERT4Rec with embeddings obtained from an LLM improves NDCG by 15-20% compared to the vanilla BERT4Rec model. Furthermore, we find that a simple approach that leverages LLM embeddings for producing recommendations, can provide competitive performance by highlighting semantically related items. We publicly share the code and data of our experiments to ensure reproducibility.</p>
    <p><strong>Categories:</strong> Large Language Models, Sequential Recommendation, Algorithmic Approaches, Recommendation Systems, Evaluation Methods, Natural Language Processing, Performance Improvement, Embeddings, Reproducibility, Datasets, Research Methods (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/956/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>PyRecGym: A Reinforcement Learning Gym for Recommender Systems (2019)</h3>
    <p><strong>Authors:</strong> Barry Smyth, Elias Z. Tragos, Bichen Shi, Aonghus Lawlor, Makbule Gulcin Ozsoy, James Geraci, Neil Hurley</p>
    <p>Recommender systems (RS) share many features and objectives with reinforcement learning (RL) systems. The former aim to maximise user satisfaction by recommending the right items to the right users at the right time, the latter maximise future rewards by selecting state-changing actions in some environment. The concept of an RL gym has become increasingly important when it comes to supporting the development of RL models. A gym provides a simulation environment in which to test and develop RL agents, providing a state model, actions, rewards/penalties etc. In this paper we describe and demonstrate the PyRecGym gym, which is specifi- cally designed for the needs of recommender systems research, by supporting standard test datasets (MovieLens, Yelp etc.), common input types (text, numeric etc.), and thereby offering researchers a reproducible research environment to accelerate experimentation and development of RL in RS. i>Presentation: Wednesday Poster Lunch</i</p>
    <p><strong>Categories:</strong> Reinforcement Learning, Recommender Systems, Tools/Frameworks, Research Tools, Reproducibility, Evaluation Methods, Controlled Experiment, Machine Learning, Research Environment, Datasets (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/494/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Preference Elicitation as an Optimization Problem (2018)</h3>
    <p><strong>Authors:</strong> Filip Radlinski, Maarten de Rijke, Julia Kiseleva, Anna Sepliarskaia</p>
    <p>The new user cold-start problem arises when a recommender system does not yet have any information about a user. A common solution to this problem is to generate a user profile as part of the sign-up process, by asking the user to rate several items. We propose a new elicitation method to generate a static preference questionnaire (SPQ) that asks a new user to make pairwise comparisons between items by posing relative preference questions. Using a latent factor model, SPQ improves personalized recommendations by choosing a minimal and diverse set of static preference questions to ask any new user. We are the first to rigorously prove which optimization task should be solved in order to select the next preference question for static questionnaires. Our theoretical results are confirmed by extensive experimentation. We test the performance of SPQ on two real-world datasets, under two experimental conditions: simulated, when users behave according to LFM, and real, in which there is no user rating model. SPQ reduces the questionnaire length that is necessary to make accurate recommendations for new users by up to a factor of three compared to state-of-the-art preference elicitation methods. Moreover, solving the right optimization task, SPQ shows better performance than baselines with dynamically generated questions.</p>
    <p><strong>Categories:</strong> Cold Start, Recommendation Systems, User Profiling, Preference Elicitation, Optimization, Latent Factor Models, Real-World Applications, Experiments, Datasets, Evaluation Metrics, Performance Comparison, Efficiency, Pairwise Comparisons (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/357/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>