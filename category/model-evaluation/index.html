<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reproducibility/">Reproducibility</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/user-engagement/">User Engagement</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/explainability/">Explainability</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/multi-task-learning/">Multi-Task Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reinforcement-learning/">Reinforcement Learning</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>AMBAR: A dataset for Assessing Multiple Beyond-Accuracy Recommenders (2024)</h3>
    <p><strong>Authors:</strong> David Contreras, Ludovico Boratto, Elizabeth Gómez, Maria Salamo</p>
    <p>Nowadays a recommendation model should exploit additional information from both the user and item perspectives, in addition to utilizing user-item interaction data. Datasets are central in offering the required information for evaluating new models or algorithms. Although there are many datasets in the literature with user and item properties, there are several issues not covered yet: (i) it is difficult to perform cross-analysis of properties at user and item level as they are not related in most cases; and (ii) on top of that, in many occasions datasets do not allow analysis at different granularity levels. In this paper, we propose a new dataset in the music domain, named AMBAR, that includes the above-mentioned issues. Besides detailing in depth the structure of the new dataset, we also show its application in contexts (i.e., multi-objective, fair, and calibrated recommendations) where both the effectiveness and the beyond-accuracy perspectives of recommendation are assessed.</p>
    <p><strong>Categories:</strong> Beyond Accuracy, Recommendation Systems, Dataset Construction, Music Domain, Multi-Objective Optimization, Fairness, Model Evaluation, Data Granularity, Ethics in ML, Evaluation Metrics. (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1105/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Evaluation and simplification of text difficulty using LLMs in the context of recommending texts in French to facilitate language learning (2024)</h3>
    <p><strong>Authors:</strong> Michalis Vlachos, Yash Raj Shrestha, Henri Jamet, Maxime Manderlier</p>
    <p>We develop a recommendation system for foreign language learning. This recommends text or video content. It ranks digital content considering both the content’s difficulty and how the topic aligns to the learners’ interests. To achieve this, we automatically apply the following operations to any text: a. Classify its subject. b. Evaluate its linguistic difficulty. c. Potentially simplify its language level, while preserving its semantic content for adaptation to the reader’s language level. Once these three operations have produced a set of texts adapted to the reader’s interests and level, they are ranked by relevance using a recommendation system based on the reading and satisfaction of other users. In this paper, we focus on using Large Language Models (LLMs) to automatically perform these tasks on any set of texts. We present an approach for training and evaluation and compare both zero-shot and fine-tuned performance of state-of-the-art models. Our findings indicate a marked improvement in the prediction of French content difficulty (improvement range of 18-56%), a 27% enhancement in topic prediction accuracy with fine-tuned models compared to zero-shot models, and up to an 18% increase in NDCG in recommendation performance.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Language Learning, Text Simplification, Large Language Models (LLMs), Natural Language Processing, Education, French Language, Difficulty Evaluation, Automatic Content Adaptation, User Personalization, Model Evaluation, Recommendation Metrics, User Satisfaction (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1091/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Track Mix Generation on Music Streaming Services using Transformers (2023)</h3>
    <p><strong>Authors:</strong> Thomas Bouabça, Walid Bendada, Benjamin Chapus, Thibault Cador, Théo Bontempelli, Mathieu Morlon, Guillaume Salha-Galvan</p>
    <p>This paper introduces Track Mix, a personalized playlist generation system released in 2022 on the music streaming service Deezer. Track Mix automatically generates “mix” playlists inspired by initial music tracks, allowing users to discover music similar to their favorite content. To generate these mixes, we consider a Transformer model trained on millions of track sequences from user playlists. In light of the growing popularity of Transformers in recent years, we analyze the advantages, drawbacks, and technical challenges of using such a model for mix generation on the service, compared to a more traditional collaborative filtering approach. Since its release, Track Mix has been generating playlists for millions of users daily, enhancing their music discovery experience on Deezer.</p>
    <p><strong>Categories:</strong> Transformer Models, Music Streaming, Recommendation Systems, Deep Learning, Personalization, Language Modeling, Collaborative Filtering, Real-World Applications, User Engagement, Playlist Generation, Neural Networks, Music Domain, Scalability, Model Evaluation (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1016/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Everyone’s a Winner! On Hyperparameter Tuning of Recommendation Models (2023)</h3>
    <p><strong>Authors:</strong> Dietmar Jannach, Faisal Shehzad</p>
    <p>The performance of a recommender system algorithm in terms of common offline accuracy measures often strongly depends on the chosen hyperparameters. Therefore, when comparing algorithms in offline experiments, we can obtain reliable insights regarding the effectiveness of a newly proposed algorithm only if we compare it to a number of state-of-the-art baselines that are carefully tuned for each of the considered datasets. While this fundamental principle of any area of applied machine learning is undisputed, we find that the tuning process for the baselines in the current literature is barely documented in much of today’s published research. Ultimately, in case the baselines are actually not carefully tuned, progress may remain unclear. In this paper, we showcase how every method in such an unsound comparison can be reported to be outperforming the state-of-the-art. Finally, we iterate appropriate research practices to avoid unreliable algorithm comparisons in the future.</p>
    <p><strong>Categories:</strong> Algorithm Comparison, Hyperparameter Tuning, Reproducibility, Research Methodology, Model Evaluation, Experimental Design, Best Practices, Recommendation Systems, Research Practices (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/942/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Investigating the effects of incremental training on neural ranking models (2023)</h3>
    <p><strong>Authors:</strong> Wenzhe Shi, Gilberto Titericz, Kazuki Onodera, Gabriel de Souza Pereira Moreira, Praveen Dhinwa, Chris Deotte, Even Oldridge, Vishal Agrawal, Chris Green, Benedikt Schifferer</p>
    <p>Recommender systems are an essential component of online systems, providing users with a personalized experience. Some recommendation scenarios such as social networks or news are very dynamic, with new items added continuously and the interest of users changing over time due to breaking news or popular events. Incremental training is a popular technique to keep recommender models up-to-date in those dynamic platforms. In this paper, we provide an empirical analysis of a large industry dataset from the Sharechat app MOJ, a social media platform for short videos, to answer relevant questions like – how often should I retrain the model? – do different models, features and dataset sizes benefit from incremental training? – Do all users and items benefit the same from incremental training?</p>
    <p><strong>Categories:</strong> Neural Networks, Incremental Training, Recommendation Systems, Model Evaluation, Dynamic Data, Social Media, Online Learning, Industry Dataset, User Behavior Analysis, Short Videos (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1001/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Learning Recommendations from User Actions in the Item-poor Insurance Domain (2022)</h3>
    <p><strong>Authors:</strong> Simone Borg Bruun, Christina Lioma, Maria Maistro</p>
    <p>While personalised recommendations are successful in domains like retail, where large volumes of user feedback on items are available, the generation of automatic recommendations in data-sparse domains, like insurance purchasing, is an open problem. The insurance domain is notoriously data-sparse because the number of products is typically low (compared to retail) and they are usually purchased to last for a long time. Also, many users still prefer the telephone over the web for purchasing products, reducing the amount of web-logged user interactions. To address this, we present a recurrent neural network recommendation model that uses past user sessions as signals for learning recommendations. Learning from past user sessions allows dealing with the data scarcity of the insurance domain. Specifically, our model learns from several types of user actions that are not always associated with items, and unlike all prior session-based recommendation models, it models relationships between input sessions and a target action (purchasing insurance) that does not take place within the input sessions. Evaluation on a real-world dataset from the insurance domain (ca. 44K users, 16 items, 54K purchases, and 117K sessions) against several state-of-the-art baselines shows that our model outperforms the baselines notably. Ablation analysis shows that this is mainly due to the learning of dependencies across sessions in our model. We contribute the first ever session-based model for insurance recommendation, and make available our dataset to the research community.</p>
    <p><strong>Categories:</strong> Recurrent Neural Networks, Session-Based Recommendations, Insurance Domain, Data-Sparse Domains, User Actions as Signals, Cross-Session Dependencies, Real-World Applications, Ablation Analysis, Recommendation Algorithms, Model Evaluation. (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/765/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>An Interpretable Recommendation Model for Gerontological Care (2021)</h3>
    <p><strong>Authors:</strong> Paula Castro, Andre Paulino de Lima, Maria Pimentel, Brunela Orlandi, Laurentino Augusto Dantas, Marcelo Garcia Manzato</p>
    <p>Recommender systems have been successfully applied to diverse areas, but their use in the healthcare domain is still rare. One challenge of applying recommender systems to this domain is related to legal concerns about the consequences of provided recommendations. In this work, we advance an expert-in-the-loop, explanation-first approach to tackle this challenge in a specific healthcare niche: gerontological care. A key aspect of the proposed approach is that both recommendations and explanations reflect the structured questionnaire employed by the practitioner to identify patient needs. Another key aspect is that a clinical dataset of patient assessments and respective assigned interventions is used to estimate effects of alternative interventions during the recommendation process. To evaluate the feasibility of this modelling approach, an explanation style was designed with help of practitioners, and a recommendation model was devised and evaluated against a clinical dataset, which was collected by a partner research group working on gerontological primary care. When compared to other traditional recommendation models, the attained precision was competitive across several evaluation conditions. The results suggest that the proposed approach is feasible and may point new ways of adapting recommender systems to play an assistive role in health care.</p>
    <p><strong>Categories:</strong> Interpretable Models, Healthcare, Gerontology, Regulatory Concerns, Expert Collaboration, Patient Needs, Clinical Data, User-Centered Design, Model Evaluation, Feasibility Studies, Method Comparison, Explainable AI (XAI) (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/680/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Recommendation on Live-Streaming Platforms: Dynamic Availability and Repeat Consumption (2021)</h3>
    <p><strong>Authors:</strong> Karl Aberer, Jeremie Rappaz, Julian McAuley</p>
    <p>Live-streaming platforms broadcast user-generated video in real-time. Recommendation on these platforms shares similarities with traditional settings, such as a large volume of heterogeneous content and highly skewed interaction distributions. However, several challenges must be overcome to adapt recommendation algorithms to live-streaming platforms: first, content availability is dynamic which restricts users to choose from only a subset of items at any given time; during training and inference we must carefully handle this factor in order to properly account for such signals, where ‘non-interactions’ reflect availability as much as implicit preference. Streamers are also fundamentally different from ‘items’ in traditional settings: repeat consumption of specific channels plays a significant role, though the content itself is fundamentally ephemeral. In this work, we study recommendation in this setting of a dynamically evolving set of available items. We propose LiveRec, a self-attentive model that personalizes item ranking based on both historical interactions and current availability. We also show that carefully modelling repeat consumption plays a significant role in model performance. To validate our approach, and to inspire further research on this setting, we release a dataset containing 475M user interactions on Twitch over a 43-day period. We evaluate our approach on a recommendation task and show our method to outperform various strong baselines in ranking the currently available content.</p>
    <p><strong>Categories:</strong> Dynamic Availability, Live Streaming, Repeat Consumption, Recommendation Systems, Self-Attention Models, Real World Application, User Interaction Data, Model Evaluation, Ephemeral Content, Twitch, Live-Streaming Platforms, Video Streaming (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/656/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Predicting Musical Sophistication from Music Listening Behaviors: A Preliminary Study (2018)</h3>
    <p><strong>Authors:</strong> Mark Graus, Bruce Ferwerda</p>
    <p>Psychological models are increasingly being used to explain online behavioral traces. Aside from the commonly used personality traits as a general user model, more domain dependent models are gaining attention. The use of domain dependent psychological models allows for more fine-grained identification of behaviors and provide a deeper understanding behind the occurrence of those behaviors. Understanding behaviors based on psychological models can provide an advantage over data-driven approaches. For example, relying on psychological models allow for ways to personalize when data is scarce. In this preliminary work we look at the relation between users’ musical sophistication and their online music listening behaviors and to what extent we can successfully predict musical sophistication. An analysis of data from a study with 61 participants shows that listening behaviors can successfully be used to infer users’ musical sophistication.</p>
    <p><strong>Categories:</strong> Psychological Modeling, User Behavior Analysis, Music Domain, Prediction Methods, Domain-Specific Models, Online Behavior, Personalization, Model Evaluation, Participant Behavior, Data Analysis (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/419/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Gaze Prediction for Recommender Systems (2016)</h3>
    <p><strong>Authors:</strong> Qian Zhao, F. Maxwell Harper, Shuo Chang, Joseph A. Konstan</p>
    <p>As users browse a recommender system, they systematically consider or skip over much of the displayed content. It seems obvious that these eye gaze patterns contain a rich signal concerning these users’ preferences. However, because eye tracking data is not available to most recommender systems, these signals are not widely incorporated into personalization models. In this work, we show that it is possible to predict gaze by combining easily-collected user browsing data with eye tracking data from a small number of users in a grid-based recommender interface. Our technique is able to leverage a small amount of eye tracking data to infer gaze patterns for other users. We evaluate our prediction models in MovieLens — an online movie recommender system. Our results show that incorporating eye tracking data from a small number of users significantly boosts accuracy as compared with only using browsing data, even though the eye-tracked users are different from the testing users (e.g. AUC=0.823 vs. 0.693 in predicting whether a user will fixate on an item). We also demonstrate that Hidden Markov Models (HMMs) can be applied in this setting; they are better than linear models in predicting fixation probability and capturing the interface regularity through Bayesian inference (AUC=0.823 vs. 0.757).</p>
    <p><strong>Categories:</strong> Hidden Markov Models, Recommender Systems, Eye Tracking, Personalization, Fixation Prediction, Machine Learning Algorithms, MovieLens, Model Evaluation, Accuracy Improvement, Beyond Accuracy, Bayesian Inference, Data Fusion (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/175/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Recommendation from Intransitive Pairwise Comparisons (2016)</h3>
    <p><strong>Authors:</strong> Elja Arjas, Marta Crispino, Arnoldo Frigessi, Valeria Vitelli</p>
    <p>In this poster we propose a full Bayesian probabilistic method to learn preferences from non-transitive pairwise comparison data. Such lack of transitivity easily arises when the number of pairwise comparisons is large, and they are given sequentially without allowing for consistency check. We develop a Bayesian Mallows model able to handle such data through a latent layer of uncertainty which captures the generation of preference misreporting. We then construct an MCMC algorithm, and test the procedure on simulated data.</p>
    <p><strong>Categories:</strong> Bayesian Methods, Mallows Model, Probabilistic Models, Markov Chain Monte Carlo (MCMC), Recommendation Systems, Preference Modeling, Intransitive Preferences, Machine Learning, Non-Transitive Data, Model Evaluation. (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/244/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Top-N Recommendation with Missing Implicit Feedback (2015)</h3>
    <p><strong>Authors:</strong> Gert Lanckriet, Daryl Lim, Julian McAuley</p>
    <p>In implicit feedback datasets, non-interaction of a user with an item does not necessarily indicate that an item is irrelevant for the user. Thus, evaluation measures computed on the observed feedback may not accurately reflect performance on the complete data. In this paper, we discuss a missing data model for implicit feedback and propose a novel evaluation measure oriented towards Top-N recommendation. Our evaluation measure admits unbiased estimation under our missing data model, unlike the popular Normalized Discounted Cumulative Gain (NDCG) measure. We also derive an efficient algorithm to optimize the measure on the training data. We run several experiments which demonstrate the utility of our proposed measure.</p>
    <p><strong>Categories:</strong> Top-N Recommendation, Implicit Feedback, Evaluation Metrics, Algorithm Optimization, Missing Data, Machine Learning, Model Evaluation, Recommendation Systems, Diversity of Recommendations, Real-World Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/138/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>