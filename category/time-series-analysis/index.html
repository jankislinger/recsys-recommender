<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui primary button" style="margin: 5px;"
             href="/recsys-recommender/">Time Series Analysis</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/explainability/">Explainability</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/evaluation-metrics/">Evaluation Metrics</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reproducibility/">Reproducibility</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reinforcement-learning/">Reinforcement Learning</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Sliding Window Training – Utilizing Historical Recommender Systems Data for Foundation Models (2024)</h3>
    <p><strong>Authors:</strong> Ko-Jen Hsiao, Yesu Feng, Sudarshan Lamkhede, Swanand Joshi, Zhe Zhang</p>
    <p>Long-lived recommender systems (RecSys) often encounter lengthy user-item interaction histories that span many years. To effectively learn long term user preferences, Large RecSys foundation models (FM) need to encode this information in pretraining. Usually, this is done by either generating a long enough sequence length to take all history sequences as input at the cost of large model input dimension or by dropping some parts of the user history to accommodate model size and latency requirements on the production serving side. In this paper, we introduce a sliding window training technique to incorporate long user history sequences during training time without increasing the model input dimension. We show the quantitative \& qualitative improvements this technique brings to the RecSys FM in learning user long term preferences. We additionally show that the average quality of items in the catalog learnt in pretraining also improves.</p>
    <p><strong>Categories:</strong> Recommender Systems (RecSys), Foundation Models, Training Techniques, Sliding Window, Historical Data Utilization, Model Optimization, User Preferences Learning, Catalog Quality, Pretraining Methods, Scalability, Time Series Analysis, Model Efficiency, Evaluation Metrics, Real-World Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1176/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Personalized Category Frequency prediction for Buy It Again recommendations (2023)</h3>
    <p><strong>Authors:</strong> Kunal Ghosh, Rankyung Park, Amit Pande</p>
    <p>Buy It Again (BIA) recommendations are crucial to retailers to help improve user experience and site engagement by suggest- ing items that customers are likely to buy again based on their own repeat purchasing patterns. Most existing BIA studies analyze guests’ personalized behaviour at item granularity. This finer level of granularity might be appropriate for small businesses or small datasets for search purposes. However, this approach can be infea- sible for big retailers like Amazon, Walmart, or Target which have hundreds of millions of guests and tens of millions of items. For such data sets, it is more practical to have a coarse-grained model that captures customer behaviour at the item category level. In addition, customers commonly explore variants of items within the same categories, e.g., trying different brands or flavors of yogurt. A category-based model may be more appropriate in such scenarios. We propose a recommendation system called a hierarchical PCIC model that consists of a personalized category model (PC model) and a personalized item model within categories (IC model). PC model generates a personalized list of categories that customers are likely to purchase again. IC model ranks items within categories that guests are likely to reconsume within a category. The hierarchical PCIC model captures the general consumption rate of products using survival models. Trends in consumption are captured using time series models. Features derived from these models are used in training a category-grained neural network. We compare PCIC to twelve existing baselines on four standard open datasets. PCIC improves NDCG up to 16% while improving recall by around 2%. We were able to scale and train (over 8 hours) PCIC on a large dataset of 100M guests and 3M items where repeat categories of a guest outnumber repeat items. PCIC was deployed and A/B tested on the site of a major retailer, leading to significant gains in guest engagement.</p>
    <p><strong>Categories:</strong> Buy It Again, Hierarchical Models, Scalability, Survival Models, Time Series Analysis, Large Scale Retail, Evaluation Metrics, Real World Applications, A/B Testing. (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/905/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Contrastive Learning with Frequency-Domain Interest Trends for Sequential Recommendation (2023)</h3>
    <p><strong>Authors:</strong> Guisheng Yin, Yuxin Dong, Yichi Zhang</p>
    <p>Recently, contrastive learning for sequential recommendation has demonstrated its powerful ability to learn high-quality user representations. However, constructing augmented samples in the time domain poses challenges due to various reasons, such as fast-evolving trends, interest shifts, and system factors. Furthermore, the F-principle indicates that deep learning preferentially fits the low-frequency part, resulting in poor performance on high-frequency tasks. The complexity of time series and the low-frequency preference limit the utility of sequence encoders. To address these challenges, we need to construct augmented samples from the frequency domain, thus improving the ability to accommodate events of different frequency sizes. To this end, we propose a novel Contrastive Learning with Frequency-Domain Interest Trends for Sequential Recommendation (CFIT4SRec). We treat the embedding representations of historical interactions as “images” and introduce the second-order Fourier transform to construct augmented samples. The components of different frequency sizes reflect the interest trends between attributes and their surroundings in the hidden space. We introduce three data augmentation operations to accommodate events of different frequency sizes: low-pass augmentation, high-pass augmentation, and band-stop augmentation. Extensive experiments on four public benchmark datasets demonstrate the superiority of CFIT4SRec over the state-of-the-art baselines. The implementation code is available at https://github.com/zhangyichi1Z/CFIT4SRec.</p>
    <p><strong>Categories:</strong> Contrastive Learning, Sequential Recommendation, Frequency-Domain Analysis, Data Augmentation, User Representation Learning, Recommendation Algorithms, Time Series Analysis, Deep Learning, Signal Processing Techniques, Interest Evolution Modeling (<i>deepseek-r1:70b</i>)</p>
    <p><a href="/recsys-recommender/response/855/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Investigating the Impact of Audio States in Music Streaming Sessions (2020)</h3>
    <p><strong>Authors:</strong> Rishabh Mehrotra, Aaron Ng</p>
    <p>Music streaming is inherently sequential in nature, with track sequence information playing a key role in user satisfaction with recommended music. In this work, we investigate the role audio characteristics of music content play in understanding music streaming sessions. Focusing on 18 audio attributes (e.g. dancability, acousticness, energy), we formulate audio transitioning in a session as a multiple changepoint detection problem, and extract latent states of different audio attributes within each session. Based on insights from large scale music streaming data from a popular music streaming platform, we investigate questions around the extent to which audio characteristics fluctuate within streaming sessions, the heterogeneity across different audio attributes and their impact on user satisfaction. Furthermore, we demonstrate the promise of such audio-based characterizing of sessions in better sequencing tracks in a session, and highlight the potential gains in user satisfaction on offer. We discuss implications on the design of track sequencing models, and identify important prediction tasks to further research on the topic.</p>
    <p><strong>Categories:</strong> Music Recommendation, Audio Features, Changepoint Detection, Time Series Analysis, User Satisfaction, Real-World Application, Track Sequencing, Beyond Accuracy, Diversity of Recommendations, Personalization (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/612/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Predicting User Routines with Masked Dilated Convolutions (2019)</h3>
    <p><strong>Authors:</strong> Dragomir Yankov, Senthil Palanisamy, Renzhong Wang, Wei Wu, Siddhartha Arora, Michael R. Evans</p>
    <p>Predicting users daily location visits – when and where they will go, and how long they will stay – is key for making effective location-based recommendations. Knowledge of an upcoming day allows the suggestion of relevant alternatives (e.g., a new coffee shop on the way to work) in advance, prior to a visit. This helps users make informed decisions and plan accordingly. People’s visit routines, or just routines, can vary significantly from day to day, and visits from earlier in the day, week, or month may affect subsequent choices. Traditionally, routine prediction has been modeled with sequence methods, such as HMMs or more recently with RNN-based architectures. However, the problem with such architectures is that their predictive performance degrades when increasing the number of historical observations in the routine sequence. In this paper, we propose Masked-TCN (MTCN), a novel method based on time-dilated convolutional networks. The method implements custom dilations and masking which can process effectively long routine sequences, identifying recurring patterns at different resolution – hourly, daily, weekly, monthly. We demonstrate that MTCN achieves 8% improvement in accuracy over current state-of-the-art solutions on a large data set of visit routines. i>Presentation: Wednesday Poster Lunch</i</p>
    <p><strong>Categories:</strong> Masked Dilated Convolutions, User Behavior Prediction, Recommendation Systems, Activity Prediction, Time Series Analysis, Geolocation, Spatial Recommendations, Temporal Pattern Recognition, Sequence Modeling, Model Performance Evaluation, Innovation in Algorithms, Location-Based Recommendations, User Routine Modeling, Long-Term Dependencies, Custom Dilation Techniques, Masking Techniques, Sequential Decision-Making, Accuracy Improvement (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/492/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Genre Prediction to Inform the Recommendation Process (2016)</h3>
    <p><strong>Authors:</strong> Maria Soledad Pera, Nevena Dragovic</p>
    <p>In this paper we present a time-based genre prediction strategy that can inform the book recommendation process. To explicitly consider time in predicting genres of interest, we rely on a popular time series forecasting model as well as reading patterns of each individual reader or group of readers (in case of libraries or publishing companies). Based on a conducted initial assessment using the Amazon dataset, we demonstrate our strategy outperforms its baseline counterpart.</p>
    <p><strong>Categories:</strong> Books, Genre Prediction, Recommendation Systems, Time Series Analysis, Temporal Recommendation, User Modeling, Time Series Forecasting, E-commerce Applications, Performance Metrics, Beyond Accuracy, Amazon Dataset Usage, Baseline Evaluation, Reading Patterns, Forecasting Models (<i>deepseek-r1:70b</i>)</p>
    <p><a href="/recsys-recommender/response/228/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>