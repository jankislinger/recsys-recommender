<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui primary button" style="margin: 5px;"
             href="/recsys-recommender/">Representation Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/explainability/">Explainability</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/real-world-applications/">Real-world Applications</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reinforcement-learning/">Reinforcement Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reproducibility/">Reproducibility</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Information-Controllable Graph Contrastive Learning for Recommendation (2024)</h3>
    <p><strong>Authors:</strong> Zixuan Yang, Zirui Guo, Yanhua Yu, Liang Pang, Tat-Seng Chua, Kangkang Lu, Yuling Wang</p>
    <p>In the evolving landscape of recommender systems, Graph Contrastive Learning (GCL) has become a prominent method for enhancing recommendation performance by alleviating the issue of data sparsity. However, existing GCL-based recommendations often overlook the control of shared information between the contrastive views. In this paper, we initially analyze and experimentally demonstrate these methods often lead to the issue of augmented representation collapse, where the representations between views become excessively similar, diminishing their distinctiveness. To address this issue, we propose the Information-Controllable Graph Contrastive Learning (IGCL) framework, a novel approach that focuses on optimizing the shared information between views to include as much relevant information for the recommendation task as possible while maintaining an appropriate level. In particular, we design the Collaborative Signals Enhanced Augmentation module to infuse the augmented representation with rich, task-relevant collaborative signals. Furthermore, the Information-Controllable Contrastive Learning module is designed to direct control over the magnitude of shared information between the contrastive views to avoid over-similarity. Extensive experiments on three public datasets demonstrate the effectiveness of IGCL, showcasing significant improvements in performance and the capability to alleviate augmented representation collapse.</p>
    <p><strong>Categories:</strong> Graph Contrastive Learning, Recommendation Systems, Collaborative Filtering, Machine Learning, Representation Learning, Feature Engineering, Information Theory, Evaluation Metrics, Collaborative Signals, Information Flow Control, Data Sparsity, Empirical Study (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1047/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Towards Open-World Recommendation with Knowledge Augmentation from Large Language Models (2024)</h3>
    <p><strong>Authors:</strong> Weiwen Liu, Bo Chen, Yong Yu, Hong Zhu, Yunjia Xi, Weinan Zhang, Jianghao Lin, Xiaoling Cai, Jieming Zhu, Ruiming Tang</p>
    <p>Recommender system plays a vital role in various online services. However, its insulated nature of training and deploying separately within a specific closed domain limits its access to open-world knowledge. Recently, the emergence of large language models (LLMs) has shown promise in bridging this gap by encoding extensive world knowledge and demonstrating reasoning capabilities. Nevertheless, previous attempts to directly use LLMs as recommenders cannot meet the inference latency demand of industrial recommender systems. In this work, we propose an Open-World Knowledge Augmented Recommendation Framework with Large Language Models, dubbed KAR, to acquire two types of external knowledge from LLMs — the reasoning knowledge on user preferences and the factual knowledge on items. We introduce factorization prompting to elicit accurate reasoning on user preferences. The generated reasoning and factual knowledge are effectively transformed and condensed into augmented vectors by a hybrid-expert adaptor in order to be compatible with the recommendation task. The obtained vectors can then be directly used to enhance the performance of any recommendation model. We also ensure efficient inference by preprocessing and prestoring the knowledge from the LLM. Extensive experiments show that KAR significantly outperforms the state-of-the-art baselines and is compatible with a wide range of recommendation algorithms. We deploy KAR to Huawei’s news and music recommendation platforms and gain a 7% and 1.7% improvement in the online A/B test, respectively.</p>
    <p><strong>Categories:</strong> Large Language Models (LLMs), Knowledge Augmentation, Recommender Systems, Open-World Recommendation, Knowledge Graphs, User Preference Modeling, Factorization Prompting, Feature Extraction, Representation Learning, Hybrid Models, Efficiency Optimization, Scalability, State-of-the-Art Methods, Real-World Applications, A/B Testing, News, Music, Beyond Accuracy, Compatibility (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1071/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>KGGLM: A Generative Language Model for Generalizable Knowledge Graph Representation Learning in Recommendation (2024)</h3>
    <p><strong>Authors:</strong> Alessandro Soccol, Giacomo Balloccu, Gianni Fenu, Mirko Marras, Ludovico Boratto</p>
    <p>Current recommendation methods based on knowledge graphs rely on entity and relation representations for several steps along the pipeline, with knowledge completion and path reasoning being the most influential. Despite their similarities, the most effective representation methods for these steps differ, leading to inefficiencies, limited representativeness, and reduced interpretability. In this paper, we introduce KGGLM, a decoder-only Transformer model designed for generalizable knowledge representation learning to support recommendation. The model is trained on generic paths sampled from the knowledge graph to capture foundational patterns, and then fine-tuned on paths specific of the downstream step (knowledge completion and path reasoning in our case). Experiments on ML1M and LFM1M show that KGGLM beats twenty-two baselines in effectiveness under both knowledge completion and recommendation. Source code and pre-processed data sets are available at https://github.com/mirkomarras/kgglm.</p>
    <p><strong>Categories:</strong> Recommendation Algorithms, Knowledge Graphs, Generative Models, Transformer Models, Representation Learning, Knowledge Completion, Path Reasoning, Evaluation Methods, Effectiveness in Recommendations, Scalability (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1195/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Discerning Canonical User Representation for Cross-Domain Recommendation (2024)</h3>
    <p><strong>Authors:</strong> Sherry Sahebi, Siqian Zhao</p>
    <p>Cross-domain recommender systems have emerged, to address the cold-start problem and enhance recommendation outcomes by leveraging information transfer across different domains. Existing cross-domain recommender systems have investigated the learning of both domain-specific and domain-shared user preferences to enhance recommendation performance. However, these models typically allow the disparities between shared and distinct user preferences to emerge freely in any space, lacking sufficient constraints to identify differences between two domains and ensure that both domains are considered simultaneously. Canonical Correlation Analysis (CCA) has shown promise for transferring information between domains, by mapping their user representations into the same space. But, CCA only models domain similarities, and fails to capture the potential differences between user preferences in different domains. In this paper, we propose Discerning Canonical User Representation Learning for Cross-Domain Recommendation (DICUCDR), a generative adversarial networks (GAN) based method that learns both domain-shared and domain-specific user representations. DICUCDR introduces Discerning Canonical Correlation User Representation Learning (DCCRL), a novel design of non-linear Canonical Correlation mappings that creates a shared transformation for simultaneously mapping similarities between different domains and separating domain differences from domains. We compare DICUCDR against several state-of-the-art approaches using two real-world datasets. Our extensive experiments demonstrate the superiority of separately learning shared and specific user representations via DCCRL.</p>
    <p><strong>Categories:</strong> Cross-Domain Recommendation, Cold Start Problem, Transfer Learning, Multi-Domain, Canonical Correlation Analysis (CCA), Generative Adversarial Networks (GANs), Deep Learning, Representation Learning, Domain Adaptation, Real-World Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1033/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Self-Attentive Sequential Recommendations with Hyperbolic Representations (2024)</h3>
    <p><strong>Authors:</strong> Tatyana Matveeva, Evgeny Frolov, Ivan Oseledets, Leyla Mirvakhabova</p>
    <p>In recent years, self-attentive sequential learning models have surpassed conventional collaborative filtering techniques in next-item recommendation tasks. However, Euclidean geometry utilized in these models may not be optimal for capturing a complex structure of behavioral data. Building on recent advances in the application of hyperbolic geometry to collaborative filtering tasks, we propose a novel approach that leverages hyperbolic geometry in the sequential learning setting. Our approach replaces final output of the Euclidean models with a linear predictor in the non-linear hyperbolic space, which increases the representational capacity and improves recommendation quality.</p>
    <p><strong>Categories:</strong> Self-Attention, Transformer-Based Models, Hyperbolic Geometry, Sequential Recommendations, Recommendation Systems, Model Architecture, Representation Learning, Geometric Deep Learning, Output Layer Design, Recommendation Quality (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1113/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Fairness and Transparency in Music Recommender Systems: Improvements for Artists (2024)</h3>
    <p><strong>Authors:</strong> Karlijn Dinnissen</p>
    <p>Music streaming services have become one of the main sources of music consumption in the last decade, with recommender systems as an important component. As those systems partially decide the songs that music consumers listen to, the systems greatly impact the artists who created the songs. However, when evaluating performance and fairness of these music recommending systems (MRSs), the perspective of the item providers or other music industry professionals is often not considered. Additionally, artists indicate they would appreciate more transparency – both towards and users and the artists themselves – regarding why certain items are recommended and others are not. This research project takes a multi-stakeholder approach to bridge the gap between music systems and their item providers. We first establish artists’ and music industry professionals’ perspective on MRSs through interviews and questionnaires. Based on those insights, we then aim to increase matching between end users and lesser-known artists by generating rich item and user representations. Results will be evaluated both quantitatively and qualitatively. Lastly, we plan to effectively communicate MRS fairness by increasing transparency for both end users and artists.</p>
    <p><strong>Categories:</strong> Fairness, Transparency, Music Recommender Systems (MRS), Artist Perspective, Stakeholder Approach, Evaluation Methods, Recommendation Algorithms, Representation Learning, Multi-Stakeholder Systems, User-Centric Design, Algorithmic Transparency, Diversity in Recommendations (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1136/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Incorporating Time in Sequential Recommendation Models (2023)</h3>
    <p><strong>Authors:</strong> James Caverlee, Mostafa Rahmani, Fei Wang</p>
    <p>Sequential models are designed to learn sequential patterns in data based on the chronological order of user interactions. However, they often ignore the timestamps of these interactions. Incorporating time is crucial because many sequential patterns are time-dependent, and the model cannot make time-aware recommendations without considering time. This article demonstrates that providing a rich representation of time can significantly improve the performance of sequential models. The existing literature treats time as a one-dimensional time-series obtained by quantizing time. In this study, we propose treating time as a multi-dimensional time-series and explore representation learning methods, including  a kernel based method and an embedding-based algorithm. Experiments on multiple datasets show that the inclusion of time significantly enhances the model’s performance, and multi-dimensional methods outperform the one-dimensional method by a substantial margin.</p>
    <p><strong>Categories:</strong> Sequential Models, Time Series, Kernel-based Methods, Embedding-based Algorithms, Sequential Recommendations, Temporal Dynamics, Recommendation Systems, Model Enhancement, Representation Learning, Performance Analysis, Methodological Innovations, Applied Research, User Interaction Patterns, Multi-dimensional Time Series, Data Analysis Techniques, Experimental Evaluation, Scalability, Cold Start, Diversity of Recommendations, Beyond Accuracy (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/907/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Rethinking Multi-Interest Learning for Candidate Matching in Recommender Systems (2023)</h3>
    <p><strong>Authors:</strong> Peilin Zhou, Fangzhao Wu, Jingqi Gao, Jae Boum Kim, Yueqi Xie, Yining Hua, Sunghun Kim, Qichen Ye</p>
    <p>Existing research efforts for multi-interest candidate matching in recommender systems mainly focus on improving model architecture or incorporating additional information, neglecting the importance of training schemes. This work revisits the training framework and uncovers two major problems hindering the expressiveness of learned multi-interest representations. First, the current training objective (i.e., uniformly sampled softmax) fails to effectively train discriminative representations in a multi-interest learning scenario due to the severe increase in easy negative samples. Second, a routing collapse problem is observed where each learned interest may collapse to express information only from a single item, resulting in information loss. To address these issues, we propose the REMI framework, consisting of an Interest-aware Hard Negative mining strategy (IHN) and a Routing Regularization (RR) method. IHN emphasizes interest-aware hard negatives by proposing an ideal sampling distribution and developing a Monte-Carlo strategy for efficient approximation. RR prevents routing collapse by introducing a novel regularization term on the item-to-interest routing matrices. These two components enhance the learned multi-interest representations from both the optimization objective and the composition information. REMI is a general framework that can be readily applied to various existing multi-interest candidate matching methods. Experiments on three real-world datasets show our method can significantly improve state-of-the-art methods with easy implementation and negligible computational overhead. The source code is available at https://anonymous.4open.science/r/ReMIRec-B64C/.</p>
    <p><strong>Categories:</strong> Multi-Interest Learning, Candidate Matching, Training Strategies, Hard Negative Mining, Routing Regularization, Optimization Objectives, Representation Learning, Real-World Applications, General Frameworks, Problem Analysis, Model Enhancement, Recommendation Systems, Interest Representation (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/878/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>An Exploration of Sentence-Pair Classification for Algorithmic Recruiting (2023)</h3>
    <p><strong>Authors:</strong> Toine Bogers, Mesut Kaya</p>
    <p>Recent years have seen a rapid increase in the application of computational approaches to different HR tasks, such as algorithmic hiring, skill extraction, and monitoring of employee satisfaction. Much of the recent work on estimating the fit between a person and a job has used representation learning to represent both resumes and job vacancies computationally and determine the degree to which they match. A common approach to this task is Sentence-BERT, which uses a Siamese network to encode resumes and job descriptions into fixed-length vectors and estimates how well they match based on the similarity between those vectors. In our paper, we adapt BERT’s next-sentence prediction task—predicting whether one sentence is likely to follow another in a given context—to the task of matching resumes with job descriptions. Using historical data on past (mis)matches between job-resume pairs, we fine-tune BERT for this downstream task. Through a combination of offline and online experiments on data from a large Scandinavian job portal, we show that this approach performs significantly better than Sentence-BERT and other state-of-the-art approaches for determining person-job fit.</p>
    <p><strong>Categories:</strong> BERT, Sentence-BERT, Representation Learning, Fine-Tuning, Next-Sentence Prediction, Recruitment, Job Matching, Text Matching, Sentence-Pair Classification, Person-Job Fit, Candidate-Position Matching, Performance Comparison (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/950/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Neural Basket Embedding for Sequential Recommendation (2021)</h3>
    <p><strong>Authors:</strong> Vojtěch Vančura</p>
    <p>Next basket prediction from historical purchases is quite a complex task, even for e-commerce datasets with a low number of items that are being purchased repeatedly. Neural approaches are not much better in predicting next purchases than simple heuristics. This paper focuses on the challenge of how to encode baskets into efficient neural embedding with low reconstruction error while maintaining the similarity of baskets in the latent space. In our representation, replacing a product with a similar product or increasing quantity will not change the embedding of the basket much. We believe that good basket representation is critical for subsequent prediction. Our analysis shows that state-of-the-art next basket prediction approaches have limitations in their representation of baskets. We would like to focus on this aspect in our future research.</p>
    <p><strong>Categories:</strong> Neural Networks, Recommendation Systems, Sequential Data, Representation Learning, E-Commerce, Products, Next Purchase Prediction, Basket Embedding, Similarity Measures, Basket Representation, Efficient Embeddings (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/716/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Shared Neural Item Representations for Completely Cold Start Problem (2021)</h3>
    <p><strong>Authors:</strong> Guannan Liang, Young-joo Chung, Ramin Raziperchikolaei</p>
    <p>Neural networks have become popular recently in recommendation systems to extract user and item representations. Most previous works follow a two-branch setting, where user and item networks learn user and item representations in the first and second branches, respectively. In the item cold-start problem, where the usage patterns of the items do not exist, the user network uses ID/interaction vector as the input and the item network uses the item side information (content) as the input. In this paper, we will show that by using this structure, two representations are learned for each item in the training set; one is the output of the item network and the other one is hidden inside the user network and is used for learning user representations. Learning two representations makes training slower and optimization more difficult. We propose to unify the two representations and only use the one generated by the item network. Also, we will show how attention mechanisms fit in our setting and how they can improve the quality of the representations. Our results on public and real-world datasets show that our approach converges faster, achieves higher recall in fewer iterations, and is more robust to the changes in the number of training samples compared to the previous works.</p>
    <p><strong>Categories:</strong> Cold Start, Item Cold Start, Representation Learning, Neural Networks, Recommendation Systems, Optimization, Attention Mechanisms, Evaluation Metrics, Deep Learning, Real-World Applications, Performance Improvements (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/662/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Learning to Represent Human Motives for Goal-directed Web Browsing (2021)</h3>
    <p><strong>Authors:</strong> Longqi Yang, Jyun-Yu Jiang, Bahareh Sarrafzadeh, Brent Hecht, Jaime Teevan, Chia-Jung Lee</p>
    <p>Motives or goals are recognized in psychology literature as the most fundamental drive that explains and predicts why people do what they do, including when they browse the web. Although providing enormous value, these higher-ordered goals are often unobserved, and little is known about how to leverage such goals to assist people’s browsing activities. This paper proposes to take a new approach to address this problem, which is fulfilled through a novel neural framework, Goal-directed Web Browsing  (GoWeB). We adopt a psychologically-sound taxonomy of higher-ordered goals and learn to build their representations in a structure-preserving manner. Then we incorporate the resulting representations for enhancing the experiences of common activities people perform on the web. Experiments on large-scale data from Microsoft Edge web browser show that GoWeB significantly outperforms competitive baselines for in-session web page recommendation, re-visitation classification, and goal-based web page grouping. A follow-up analysis further characterizes how the variety of human motives can affect the difference observed in human behavioral patterns.</p>
    <p><strong>Categories:</strong> Neural Frameworks, Psychological Models, Web Browsing, Recommendation Systems, Goal-Oriented Behavior, Real-World Applications, Representation Learning, Evaluation Beyond Accuracy, Large-Scale Data Analysis, Human Behavior Analysis, Innovation in Frameworks, User Experience (UX) Optimization (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/643/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Learning Representations of Hierarchical Slates in Collaborative Filtering (2020)</h3>
    <p><strong>Authors:</strong> Ashok Chandrashekar, Ehtsham Elahi</p>
    <p>We are interested in building collaborative filtering models for recommendation systems where users interact with slates instead of individual items. These slates can be hierarchical in nature. The central idea of our approach is to learn low dimensional embeddings of these slates. We present a novel way to learn these embeddings by making use of the (unknown) statistics of the underlying distribution generating the hierarchical data. Our representation learning algorithm can be viewed as a simple composition rule that can be applied recursively in a bottom-up fashion to represent arbitrarily complex hierarchical structures in terms of the representations of its constituent components. We demonstrate our ideas on two real world recommendation systems datasets including the one used for the RecSys 2019 challenge. For that dataset, we improve upon the performance achieved by the winning team’s model by incorporating embeddings as features generated by our approach in their solution.</p>
    <p><strong>Categories:</strong> Representation Learning, Collaborative Filtering, Hierarchical Data Processing, Recommendation Systems, Slate Recommendations, Evaluation Metrics, Performance Analysis, Case Studies, Recursive Algorithms (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/610/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Improving One-class Recommendation with Multi-tasking on Various Preference Intensities (2020)</h3>
    <p><strong>Authors:</strong> Chu-Jen Shao, Hao-Ming Fu, Pu-Jen Cheng</p>
    <p>In the one-class recommendation problem, it’s required to make recommendations basing on users’ implicit feedback, which is inferred from their action and inaction. Existing works obtain representations of users and items by encoding positive and negative interactions observed from training data. However, these efforts assume that all positive signals from implicit feedback reflect a fixed preference intensity, which is not realistic. Consequently, representations learned with these methods usually fail to capture informative entity features that reflect various preference intensities.<br>In this paper, we propose a multi-tasking framework taking various preference intensities of each signal from implicit feedback into consideration. Representations of entities are required to satisfy the objective of each subtask simultaneously, making them more robust and generalizable. Furthermore, we incorporate attentive graph convolutional layers to explore high-order relationships in the user-item bipartite graph and dynamically capture the latent tendencies of users toward the items they interact with. Experimental results show that our method performs better than state-of-the-art methods by a large margin on three large-scale real-world benchmark datasets.</p>
    <p><strong>Categories:</strong> One-class Recommendation, Implicit Feedback, Multi-task Learning, Graph Convolutional Networks, User-Item Bipartite Graphs, Preference Intensity Modeling, Representation Learning, High-order Relationships, Performance Evaluation, Scalability (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/577/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Representation Learning for Image-based Music Recommendation (2018)</h3>
    <p><strong>Authors:</strong> Yian Chen, Ming-Feng Tsai, Kwei-Herng Lai, Chuan-Ju Wang, Chih-Chun Hsia</p>
    <p>Image perception is one of the most direct ways to provide contextual information about a user concerning his/her surrounding environment; hence images are a suitable proxy for contextual recommendation. We propose a novel representation learning framework for image-based music recommendation that bridges the heterogeneity gap between music and image data; the proposed method is a key component for various contextual recommendation tasks. Preliminary experiments show that for an image-to-song retrieval task, the proposed method retrieves relevant or conceptually similar songs for input images.</p>
    <p><strong>Categories:</strong> Representation Learning, Multi-modal Recommendation, Contextual Recommendation, Music Recommendations, Content-based Recommendation, Cross-domain Recommendation, Multi-media Systems, Recommendation Algorithms (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/413/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Select and Predict: Multitask Learning for Recommender Systems (2018)</h3>
    <p><strong>Authors:</strong> Guy Hadash, Rita Osadchy, Oren Sar Shalom</p>
    <p>The two main tasks in the Recommender Systems domain are the selection and prediction tasks. The prediction task aims at predicting to what extent a user would like any given item, which would enable to recommend the items with the highest predicted scores. The selection task on the other hand directly aims at recommending the most valuable items for the user. Several Multitask Learning approaches have been proposed to learn user and item representations that optimize both tasks simultaneously. In this work, we propose a novel framework that exploits the fact that a user first decides to interact with an item (selection task) and afterward to rate it (prediction task). We evaluated our framework on 2 benchmark datasets, on 2 different configurations and show its superiority over state-of-the-art methods.</p>
    <p><strong>Categories:</strong> Multitask Learning, Recommender Systems, Selection Task, Prediction Task, Sequential Recommendations, User-Item Interaction, Representation Learning, Evaluation Metrics (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/392/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>