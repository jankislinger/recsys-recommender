<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/explainability/">Explainability</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/evaluation-methods/">Evaluation Methods</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reinforcement-learning/">Reinforcement Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/e-commerce/">E-commerce</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/performance-evaluation/">Performance Evaluation</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Bridging Search and Recommendation in Generative Retrieval: Does One Task Help the Other? (2024)</h3>
    <p><strong>Authors:</strong> Marco De Nadai, Ali Vardasbi, Enrico Palumbo, Hugues Bouchard, Gustavo Penha</p>
    <p>Generative retrieval for search and recommendation is a promising paradigm for retrieving items, offering an alternative to traditional methods that depend on external indexes and nearest-neighbor searches. Instead, generative models directly associate inputs with item IDs. Given the impressive capabilities of Large Language Models (LLMs), these generative systems play a crucial role in centralizing a variety of Information Retrieval (IR) tasks in a single model that performs tasks such as query understanding, retrieval, recommendation, explanation, re-ranking, and response generation. Despite the growing interest in such a unified generative approach for IR systems, the advantages of using a single, multi-task model over multiple specialized models are not well established in the literature. This paper investigates whether and when such a unified approach can outperform task-specific models in the IR tasks of search and recommendation, broadly co-existing in multiple industrial online platforms, such as Spotify, YouTube, and Netflix. Previous work shows that (1) the latent representations of items, learned by generative recommenders, are biased towards popularity, and (2) content-based and collaborative-filtering-based information can improve an item’s representations. Motivated by this, our study is guided by two hypotheses: [H1] the joint training regularizes the estimation of each item’s popularity, and [H2] the joint training regularizes the item’s latent representations, where search captures content-based aspects of an item and recommendation captures collaborative-filtering aspects. Our extensive experiments with both simulated and real-world data support both [H1] and [H2] as key contributors to the effectiveness improvements observed in the unified search and recommendation generative models over the single-task approaches.</p>
    <p><strong>Categories:</strong> Generative Models, Large Language Models (LLMs), Information Retrieval (IR), Search Systems, Recommendation Systems, Multi-Task Learning, Real-World Applications, Evaluation Metrics, Latent Representations, Popularity Bias, Collaborative Filtering, Content-Based Filtering, Explanation Generation, Industrial Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1030/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>KGGLM: A Generative Language Model for Generalizable Knowledge Graph Representation Learning in Recommendation (2024)</h3>
    <p><strong>Authors:</strong> Alessandro Soccol, Giacomo Balloccu, Gianni Fenu, Mirko Marras, Ludovico Boratto</p>
    <p>Current recommendation methods based on knowledge graphs rely on entity and relation representations for several steps along the pipeline, with knowledge completion and path reasoning being the most influential. Despite their similarities, the most effective representation methods for these steps differ, leading to inefficiencies, limited representativeness, and reduced interpretability. In this paper, we introduce KGGLM, a decoder-only Transformer model designed for generalizable knowledge representation learning to support recommendation. The model is trained on generic paths sampled from the knowledge graph to capture foundational patterns, and then fine-tuned on paths specific of the downstream step (knowledge completion and path reasoning in our case). Experiments on ML1M and LFM1M show that KGGLM beats twenty-two baselines in effectiveness under both knowledge completion and recommendation. Source code and pre-processed data sets are available at https://github.com/mirkomarras/kgglm.</p>
    <p><strong>Categories:</strong> Recommendation Algorithms, Knowledge Graphs, Generative Models, Transformer Models, Representation Learning, Knowledge Completion, Path Reasoning, Evaluation Methods, Effectiveness in Recommendations, Scalability (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1195/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Generative Next-Basket Recommendation (2023)</h3>
    <p><strong>Authors:</strong> Wenqi Sun, Ji-Rong Wen, Ruobing Xie, Junjie Zhang, Leyu Lin, Wayne Xin Zhao</p>
    <p>Next-basket Recommendation (NBR) refers to the task of predicting a set of items that a user will purchase in the next basket. However, most of existing works merely focus on the relevance between user preferences and predicted items, ignoring the essential relationships among items in the next basket, which often results in over-homogenization of items. In this work, we presents a novel Generative next-basket Recommendation model (GeRec), a new NBR paradigm that generates the recommended items one by one to form the next basket via an autoregressive decoder. This generative NBR paradigm contributes to capturing and considering item relationships inside each baskets in both training and serving. Moreover, we jointly consider user’s both item- and basket-level contextual information to better capture user’s multi-granularity preferences. Extensive experiments on three real-world datasets demonstrate the effectiveness of our model.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Generative Models, E-commerce, Autoregressive Techniques, Item Relationships, Multi-Granularity Preferences, Basket Recommendations, Real-World Applications, Improvement Over Existing Methods, Next-Basket Prediction, Contextual Information, Item Relationships in Baskets (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/902/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>A Generative Model for Review-Based Recommendations (2019)</h3>
    <p><strong>Authors:</strong> Guy Uziel, Amir Kantor, Oren Sar Shalom</p>
    <p>User generated reviews is a highly informative source of information, that has recently gained lots of attention in the recommender systems community. In this work we propose a generative latent variable model that explains both observed ratings and textual reviews. This latent variable model allows to combine any traditional collaborative filtering method, together with any deep learning architecture for text processing. Experimental results on four benchmark datasets demonstrate its superiority comparing to all baseline recommender systems. Furthermore, a running time analysis shows that this approach is in order of magnitude faster that relevant baselines. i>Presentation: Tuesday Poster Lunch</i</p>
    <p><strong>Categories:</strong> Generative Models, Recommender Systems, Collaborative Filtering, Text Processing, Reviews, Evaluation Metrics, Latent Variable Models, Multimodal Data, Recommendation Accuracy, Efficiency (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/459/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Deep Generative Ranking for Personalized Recommendation (2019)</h3>
    <p><strong>Authors:</strong> Huafeng Liu, Jingxuan Wen, Jian Yu, Liping Jing</p>
    <p>Recommender systems offer critical services in the age of mass information. Personalized ranking have been attractive both for content providers and customers due to its ability of creating a user-specific ranking on the item set. Although the powerful factor-analysis methods including latent factor model and deep neural network models have achieved promising results, they still suffer from the challenging issues, such as sparsity of recommendation data, uncertainty of optimization, and etc. To enhance the accuracy and generalization of recommender system, in this paper, we propose a deep generative ranking (DGR) model under the Wasserstein auto-encoder framework. Specifically, DGR simultaneously generates the pointwise implicit feedback data (via a Beta-Bernoulli distribution) and creates the pairwise ranking list by sufficient exploiting both interacted and non-interacted items for each user. DGR can be efficiently inferred by minimizing its penalized evidence lower bound. Meanwhile, we theoretically analyze the generalization error bounds of DGR model to guarantee its performance in extremely sparse feedback data. A series of experiments on four large-scale datasets (Movielens (20M), Netflix, Epinions and Yelp in movie, product and business domains) have been conducted. By comparing with the state-of-the-art methods, the experimental results demonstrate that DGR consistently benefit the recommendation system in ranking estimation task, especially for the near-cold-start-users (with less than five interacted items).</p>
    <p><strong>Categories:</strong> Recommendation Systems, Deep Learning, Generative Models, Personalization, Implicit Feedback, Cold Start Problem, Matrix Factorization, Large-Scale Datasets, Theoretical Analysis, Cross-Domain Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/434/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>