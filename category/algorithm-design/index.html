<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui primary button" style="margin: 5px;"
             href="/recsys-recommender/">Algorithm Design</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/bias-mitigation/">Bias Mitigation</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reproducibility/">Reproducibility</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/evaluation-methods/">Evaluation Methods</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>AIE: Auction Information Enhanced Framework for CTR Prediction in Online Advertising (2024)</h3>
    <p><strong>Authors:</strong> Chenxu Zhu, Muyu Zhang, Yang Yang, Huifeng Guo, Menghui Zhu, Bo Chen, Ruiming Tang, Zhenhua Dong, Xinyi Dai</p>
    <p>Click-Through Rate (CTR) prediction is a fundamental technique for online advertising recommendation and the complex online competitive auction process also brings many difficulties to CTR optimization. Recent studies have shown that introducing posterior auction information contributes to the performance of CTR prediction. However, existing work doesn’t fully capitalize on the benefits of auction information and overlooks the data bias brought by the auction, leading to biased and suboptimal results. To address these limitations, we propose Auction Information Enhanced Framework (AIE) for CTR prediction in online advertising, which delves into the problem of insufficient utilization of auction signals and first reveals the auction bias. Specifically, AIE introduces two pluggable modules, namely Adaptive Market-price AuxiliaryModule (AM2) and Bid Calibration Module (BCM), which work collaboratively to excavate the posterior auction signals better and enhance the performance of CTR prediction. Furthermore, the two proposed modules are lightweight, model-agnostic and friendly to inference latency. Extensive experiments are conducted on a public dataset and an industrial dataset to demonstrate the effectiveness and compatibility of AIE. Besides, a one-month online A/B test in a large-scale advertising platform shows that AIE improves the base model by 5.76% and 2.44% in terms of eCPM and CTR, respectively.</p>
    <p><strong>Categories:</strong> Algorithm Design, Online Advertising, Recommendation Systems, Auction Mechanisms, CTR Prediction, Model Performance, Bias Mitigation, A/B Test, Evaluation Metrics, Scalability, Real-World Applications, Beyond Accuracy (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1021/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Revisiting LightGCN: Unexpected Inflexibility, Inconsistency, and A Remedy Towards Improved Recommendation (2024)</h3>
    <p><strong>Authors:</strong> Geon Lee, Kijung Shin, Kyungho Kim</p>
    <p>Graph Neural Networks (GNNs) have emerged as effective tools in recommender systems. Among various GNN models, LightGCN is distinguished by its simplicity and outstanding performance. Its efficiency has led to widespread adoption across different domains, including social, bundle, and multimedia recommendations. In this paper, we thoroughly examine the mechanisms of LightGCN, focusing on its strategies for scaling embeddings, aggregating neighbors, and pooling embeddings across layers. Our analysis reveals that, contrary to expectations based on its design, LightGCN suffers from inflexibility and inconsistency when applied to real-world data. We introduce LightGCN++, an enhanced version of LightGCN designed to address the identified limitations. LightGCN++ incorporates flexible scaling of embedding norms and neighbor weighting, along with a tailored approach for pooling layer-wise embeddings to resolve the identified inconsistencies. Despite its remarkably simple remedy, extensive experimental results demonstrate that LightGCN++ significantly outperforms LightGCN, achieving an improvement of up to 17.81% in terms of NDCG@20. Furthermore, state-of-the-art models utilizing LightGCN as a backbone for item, bundle, multimedia, and knowledge-graph-based recommendations exhibit improved performance when equipped with LightGCN++.</p>
    <p><strong>Categories:</strong> Graph Neural Networks (GNNs), Recommendation Systems, LightGCN, Algorithm Design, Evaluation Metrics, Embedding Techniques, Social Recommendations, Bundle Recommendations, Multimedia Recommendations, Model Limitations, Algorithm Optimization, Recommendation Quality (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1110/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Scale-Invariant Learning-to-Rank (2024)</h3>
    <p><strong>Authors:</strong> Ye-Sheen Lim, Alessio Petrozziello, Xiaoke Liu, Christian Sommeregger</p>
    <p>At Expedia, learning-to-rank (LTR) models plays a key role on our website in sorting and presenting information more relevant to users, such as search filters, property rooms, amenities, and images. A major challenge in deploying these models is ensuring consistent feature scaling between training and production data, as discrepancies can lead to unreliable rankings when deployed. Normalization techniques like feature standardization and batch normalization could address these issues but are impractical in production due to latency impacts and the difficulty of distributed real-time inference. To address consistent feature scaling issue, we introduce a scale-invariant LTR framework which combines a deep and a wide neural network to mathematically guarantee scale-invariance in the model at both training and prediction time.</p>
    <p><strong>Categories:</strong> Learning-to-Rank, E-commerce, Travel, Model Scaling, Feature Engineering, Production Systems, Scale-Invariant Methods, Ranking Algorithms, Web Systems, Real-World Applications, Model Robustness, Algorithm Design (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1174/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>One-class recommendation systems  with  the hinge pairwise distance loss and orthogonal representations (2024)</h3>
    <p><strong>Authors:</strong> Ramin Raziperchikolaei, Young-joo Chung</p>
    <p>In one-class recommendation systems, the goal is to learn a model from a small set of interacted users and items and then identify the positively-related (i.e., similar) user-item pairs among a large number of pairs with unknown interactions. Most loss functions in the literature rely on dissimilar pairs of users and items, which are selected from the ones with unknown interactions, to obtain better prediction performance. The main issue of this strategy is that it needs a large number of dissimilar pairs, which increases the training time significantly. In this paper, the goal is to only use the similar set to train the models and discard the dissimilar set.  We highlight three trivial solutions that the models converge to when they are trained only on similar pairs: collapsed, dimensional collapsed, and shrinking solutions. We propose a hinge pairwise loss and an orthogonality term that can be added to the objective functions in the literature to avoid these trivial solutions. We conduct experiments on various tasks on public and real-world datasets, which show that our approach using only similar pairs can be trained several times faster than the state-of-the-art methods while achieving competitive results.</p>
    <p><strong>Categories:</strong> Recommendation Systems, One-class Learning, Algorithm Design, Loss Function Design, Optimization Techniques, User-Item Interaction, Similarity-based Recommendations, Cold Start Problem, Efficiency, Real-world Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1102/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>RPAF: A Reinforcement Prediction-Allocation Framework for Cache Allocation in Large-Scale Recommender Systems (2024)</h3>
    <p><strong>Authors:</strong> Kaiqiao Zhan, Kun Gai, Xiaoshuang Chen, Yao Wang, Ziqiang Zhang, Ben Wang, Yulin Wu, Shuo Su</p>
    <p>Modern recommender systems are built upon computation-intensive infrastructure, and it is challenging to perform real-time computation for each request, especially in peak periods, due to the limited computational resources. Recommending by user-wise result caches is widely used when the system cannot afford a real-time recommendation. However, it is challenging to allocate real-time and cached recommendations to maximize the users’ overall engagement. This paper shows two key challenges to cache allocation, i.e., the temporal dependency and the streaming allocation. Then, we propose a reinforcement prediction-allocation framework (RPAF) to address these issues. RPAF is a reinforcement-learning-based two-stage framework containing prediction and allocation stages. The prediction stage estimates the values of the cache choices considering the strategy and value dependencies, while the allocation stage determines the cache choices for each request. We show that the challenge of training RPAF includes globality and the strictness of budget constraints, and a relaxed local allocator (RLA) is proposed to address this issue. Moreover, a PoolRank algorithm is used in the allocation stage to deal with the streaming allocation problem. Experiments show that RPAF significantly improves users’ engagement under computational budget constraints.</p>
    <p><strong>Categories:</strong> Reinforcement Learning, Cache Management, Recommender Systems, Real-time Recommendations, Scalability, Streaming Allocation, Optimization, Computational Constraints, Algorithm Design, Evaluation Metrics, Temporal Dependency, Recommendation Strategies (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1058/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Generative Learning Plan Recommendation for Employees: A Performance-aware Reinforcement Learning Approach (2023)</h3>
    <p><strong>Authors:</strong> Ying Sun, Xin Song, Hengshu Zhu, Hui Xiong, Zhi Zheng</p>
    <p>With the rapid development of enterprise Learning Management Systems (LMS), more and more companies are trying to build enterprise training and course learning platforms for promoting the career development of employees. Indeed, through course learning, many employees have the opportunity to improve their knowledge and skills. For these systems, a major issue is how to recommend learning plans, i.e., a set of courses arranged in the order they should be learned, that can help employees improve their work performance. Existing studies mainly focus on recommending courses that users are most likely to click on by capturing their learning preferences. However, the learning preference of employees may not be the right fit for their career development, and thus it may not necessarily mean their work performance can be improved accordingly. Furthermore, how to capture the mutual correlation and sequential effects between courses, and ensure the rationality of the generated results, is also a major challenge. To this end, in this paper, we propose the Generative Learning plAn recommenDation (GLAD) framework, which can generate personalized learning plans for employees to help them improve their work performance. Specifically, we first design a performance predictor and a rationality discriminator, which have the same transformer-based model architecture, but with totally different parameters and functionalities. In particular, the performance predictor is trained for predicting the work performance of employees based on their work profiles and historical learning records, while the rationality discriminator aims to evaluate the rationality of the generated results. Then, we design a learning plan generator based on the gated transformer and the cross-attention mechanism for learning plan generation. We calculate the weighted sum of the output from the performance predictor and the rationality discriminator as the reward, and we use Self-Critical Sequence Training (SCST) based policy gradient methods to train the generator following the Generative Adversarial Network (GAN) paradigm. Finally, extensive experiments on real-world data clearly validate the effectiveness of our GLAD framework compared with state-of-the-art baseline methods and reveal some interesting findings for talent management</p>
    <p><strong>Categories:</strong> Employee Training, Career Development, Learning Plan Generation, Reinforcement Learning, Sequence Modeling, Performance Prediction, Rationality Evaluation, Dual-Model Framework, Algorithm Design, Policy Gradient Methods, GAN-based Models, Practical Applications, Performance Comparison (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/868/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Learning the True Objectives of Multiple Tasks in Sequential Behavior Modeling (2023)</h3>
    <p><strong>Authors:</strong> Jiawei Zhang</p>
    <p>Multi-task optimization is an emerging research field in recommender systems that focuses on improving the recommendation performance of multiple tasks. Various methods have been proposed in the past to address task weight balancing, gradient conflict resolution, Pareto optimality, etc, yielding promising results in specific contexts. However, when it comes to real-world scenarios involving user sequential behaviors, these methods are not well suited. To address this gap, we propose AcouRec, a novel and effective approach for sequential behavior modeling in multi-task recommender systems inspired by acoustic attenuation. Specifically, AcouRec introduces an impact attenuation mechanism to mitigate the uncertain task interference in multi-task optimization. Extensive experiments on public datasets demonstrate the effectiveness of AcouRec.</p>
    <p><strong>Categories:</strong> Acoustic Attenuation, Algorithm Design, Multi-Task Optimization, Recommender Systems, Sequential Behavior Modeling, Task Interference Handling, Multi-Objective Optimization, User Sequential Behavior, Real World Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/957/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Translating the Public Service Media Remit into Metrics and Algorithms (2022)</h3>
    <p><strong>Authors:</strong> Andreas Grün, Xenija Neufeld</p>
    <p>After multiple years of providing automated video recommendations in the ZDFmediathek, ZDF has established a solid ground for the usage of recommender systems. Being a Public Service Media (PSM) provider, our most important driver on this journey is our Public Service Media Remit (PSMR). We are committed to cultivate PSM values such as diversity, fairness, and transparency while providing fresh and relevant content. Therefore, it is important for us to not only measure the success of our recommender systems in terms of basic business Key Performance Indicators (KPIs) such as clicks and viewing minutes but also to ensure and to measure the achievement of PSM values. While speaking about PSM values, however, it is important to keep in mind that there is no easy way to directly measure values as such. In order to be able to measure their extent in a recommender system, we need to translate these values into public value metrics. However, not only the final results are essential for the PSMR. Additionally, it is highly important to establish transparency while working towards these results, that is, while defining the data, the algorithms, and the pipelines used in recommender systems. In our talk we will provide a deeper insight into how we approach this task with Model Cards and give an overview of some models, their Model Cards, and metrics that we are currently using for ZDFmediathek.</p>
    <p><strong>Categories:</strong> Public Service Media, Metrics for Public Value, Fairness in Recommendations, Model Transparency, Recommendation Algorithms, Algorithm Design, Diversity of Recommendations, Beyond Accuracy Evaluation, Public Service Values, Metrics Design, Recommendation System Design, Transparency in Machine Learning (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/830/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Solving Diversity-Aware Maximum Inner Product Search Efficiently and Effectively (2022)</h3>
    <p><strong>Authors:</strong> Sumio Fujita, Kohei Hirata, Daichi Amagata, Takahiro Hara</p>
    <p>Maximum inner product search (or k-MIPS) is a fundamental operation in recommender systems that infer preferable items for users. To support large-scale recommender systems, existing studies designed scalable k-MIPS algorithms. However, these studies do not consider diversity, although recommending diverse items is important to improve user satisfaction. We therefore formulate a new problem, namely diversity-aware k-MIPS. In this problem, users can control the degree of diversity in their recommendation lists through a parameter. However, exactly solving this problem is unfortunately NP-hard, so it is challenging to devise an efficient, effective, and practical algorithm for the diversity-aware k-MIPS problem. This paper overcomes this challenge and proposes IP-Greedy, which incorporates new early termination and skipping techniques into a greedy algorithm. We conduct extensive experiments on real datasets, and the results demonstrate the efficiency and effectiveness of our algorithm. Also, we conduct a case study of the diversity-aware k-MIPS problem on a real dataset. We confirm that this problem can make recommendation lists diverse while preserving high inner products of user and item vectors in the lists.</p>
    <p><strong>Categories:</strong> Diversity of Recommendations, Recommendation Algorithms, Maximum Inner Product Search, Algorithm Design, User Satisfaction, Scalable Algorithms, Real-World Applications, Evaluation Metrics, Customizable Parameters, Beyond Accuracy, Efficiency Optimization (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/777/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Aspect Re-distribution for Learning Better Item Embeddings in Sequential Recommendation (2022)</h3>
    <p><strong>Authors:</strong> Wei Cai, Jingwen Mao, Weike Pan, Zhechao Yu, Congfu Xu</p>
    <p>Sequential recommendation has attracted a lot of attention from both academia and industry. Since item embeddings directly affect the recommendation results, their learning process is very important. However, most existing sequential models may introduce bias when updating the item embeddings. For example, in a sequence where all items are endorsed by a same celebrity, the co-occurrence of two items only indicates their similarity in terms of endorser, and is independent of the other aspects such as category and color. The existing models often update the entire item as a whole or update different aspects of the item without distinction, which fails to capture the contributions of different aspects to the co-occurrence pattern. To overcome the above limitations, we propose aspect re-distribution (ARD) to focus on updating the aspects that are important for co-occurrence. Specifically, we represent an item using several aspect embeddings with the same initial importance. We then re-calculate the importance of each aspect according to the other items in the sequence. Finally, we aggregate these aspect embeddings into a single aspect-aware embedding according to their importance. The aspect-aware embedding can be provided as input to a successor sequential model. Updates of the aspect-aware embedding are passed back to the aspect embeddings based on their importance. Therefore, different from the existing models, our method pays more attention to updating the important aspects. In our experiments, we choose self-attention networks as the successor model. The experimental results on four real-world datasets indicate that our method achieves very promising performance in comparison with seven state-of-the-art models.</p>
    <p><strong>Categories:</strong> Aspect Re-distribution, Item Embeddings, Sequential Recommendation, Algorithm Design, Model Optimization, Recommendation Quality, Attribute-Based Recommendations, Self-Attention Networks, Bias Correction, Dynamic Embedding Updates, Domain-Agnostic (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/745/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Recommendations: They’re in fashion (2022)</h3>
    <p><strong>Authors:</strong> Tiago Lacerda, Diogo Gonçalves, Carlos Carvalheira</p>
    <p>Farfetch, the leading online platform for luxury fashion, has spent several years developing a recommender system. In fact, recommendations have been quite successful in improving both the user experience and the company’s own business metrics [3 – 9]. In this talk we will shed some light on how we built our recommender system at Farfetch, the main obstacles we faced, and some plans for the future. Recommendations started their journey at Farfetch somewhere around 2015. At the time, we had a single model that trained once per day that updated the users’ recommendations with the same frequency. Currently, we have around 20 models in production and the majority of them are designed to handle streaming data from the users and adapt in realtime to user actions. How can we balance training and improving existing models, creating new models, serving them in real time and still keep our code in check, our tests up to date and our pipelines moving? We will discuss the three main components that we created in order to tackle our real world issue of providing ever-improving recommendations to our customers: The Gym, The Recommenders and The API. The Gym (Fig. 1) is the place where model training takes place. Inspired by the gyms from Open-AI and Criteo [ 1, 2], it mixes Spark and Python according to what we need to process. It has three main goals. Process the data that is going to feed the models, train the models, and evaluate the models. The Gym is equipped to handle every model from deep neural networks to simple collaborative models. It provides a fluid platform for multi model creation. The Recommenders (Fig. 2) define the common structure and interface for each recommender model. From applying the literature and our own experience, we found a predetermined behaviour that every recommendation follows, even though the models can be quite different from one another. It’s the individual components of a specific recommender that change. The components determine which products or brands are the candidates for a recommendation, what the right context for the recommendation is and how to score the candidates in light of the context. We can then mix and match these components to achieve the right recommender model. The Recommenders define these components and the common path that uses them. It’s Strategy Pattern all the way down. The API (Fig. 3), which we call Precog, loads and serves the models previously trained in The Gym and defined in The Recommenders. Every request made to this application triggers an execution for the particular context of the request, which means we can deliver highly personalized and context-aware recommendations. Since every recommender model is defined as implementing a recommend method, the API is simultaneously flexible in the variety of models it handles, but also quite unconcerned with the specific implementation of a recommender model and the libraries/packages needed to train it. Finally, with this presentation, we aim to give an overview and understanding of our recommendations cycle, going in detail about how these three components communicate among them. The final goal is to give a personalised experience to our customers, which given the luxury ecosystem in which Farfetch is involved, has high demands and expectations associated with it.</p>
    <p><strong>Categories:</strong> Luxury Fashion, Recommendation Systems, Real-Time Processing, Scalability, Software Engineering, Model Training Infrastructure, Real-Time Recommendations, Microservices, Architecture Patterns, Strategy Pattern, Algorithm Design, Personalization, DevOps, System Evolution, Model Serving (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/845/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Recommender Systems and Algorithmic Hate (2022)</h3>
    <p><strong>Authors:</strong> Robin Burke, Lucia Jayne, Jessie Smith</p>
    <p>Despite increasing reliance on personalization in digital platforms, many algorithms that curate content or information for users have been met with resistance. When users feel dissatisfied or harmed by recommendations, this can lead users to hate, or feel negatively towards these personalized systems. Algorithmic hate detrimentally impacts both users and the system, and can result in various forms of algorithmic harm, or in extreme cases can lead to public protests against “the algorithm” in question. In this work, we summarize some of the most common causes of algorithmic hate and their negative consequences through various case studies of personalized recommender systems. We explore promising future directions for the RecSys research community that could help alleviate algorithmic hate and improve the relationship between recommender systems and their users.</p>
    <p><strong>Categories:</strong> Algorithm Design, User Experience (UX), Ethics in AI/ML, Trust Issues, Algorithmic Harm, Case Studies, Public Perception, User Trust, Ethical Considerations, Personalization Issues (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/798/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Automate Page Template Optimization: An Offline Deep Q-Learning Approach (2022)</h3>
    <p><strong>Authors:</strong> Wenyang Liu, Zhou Qin</p>
    <p>The modern e-commerce web pages have brought better customer experience and more profitable services by whole page optimization at different granularity, e.g., page layout optimization, item ranking optimization, etc. Generating the proper page layout per customer’s request is one of the vital tasks during the web page rendering process, which can directly impact customers’ shopping experience and their decision-making. In this paper, we formulate the request-rendering interactions as a Markov decision process (MDP) and solve it by deep reinforcement learning (RL). Specifically, we present the design and implementation of applying offline Deep Q-Learning (DQN) to the contextual page layout optimization problem. Through the offline evaluation method, we demonstrate the effectiveness of the proposed framework, i.e., the RL agent has the potential to perform better than the baseline ranker by learning from the offline data set, e.g., the RL agent can improve the average cumulative rewards up to 36.69% comparing to the baseline ranker.</p>
    <p><strong>Categories:</strong> Reinforcement Learning, Deep Learning, E-commerce Optimization, Web Page Layout Optimization, Markov Decision Process (MDP), Offline Deep Q-Learning, Customer Experience, Performance Improvement, Profitability Optimization, Algorithm Design, Offline Evaluation Methods, Machine Learning Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/832/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Fairness-aware Federated Matrix Factorization (2022)</h3>
    <p><strong>Authors:</strong> Yingqiang Ge, Yongfeng Zhang, Shuchang Liu, Shuyuan Xu, Amelie Marian</p>
    <p>Achieving fairness over different user groups in recommender systems is an important problem. The majority of existing works achieve fairness through constrained optimization that combines the recommendation loss and the fairness constraint. To achieve fairness, the algorithm usually needs to know each user’s group affiliation feature such as gender or race. However, such involved user group feature is usually sensitive and requires protection. In this work, we seek a federated learning solution for the fair recommendation problem and identify the main challenge as an algorithmic conflict between the global fairness objective and the localized federated optimization process. On one hand, the fairness objective usually requires access to all users’ group information. On the other hand, the federated learning systems restrain the personal data in each user’s local space. As a resolution, we propose to communicate group statistics during federated optimization and use differential privacy techniques to avoid exposure of users’ group information when users require privacy protection. We illustrate the theoretical bounds of the noisy signal used in our method that aims to enforce privacy without overwhelming the aggregated statistics. Empirical results show that federated learning may naturally improve user group fairness and the proposed framework can effectively control this fairness with low communication overheads.</p>
    <p><strong>Categories:</strong> Matrix Factorization, Fairness, Federated Learning, Recommendation Systems, Algorithm Design, Differential Privacy, Evaluation Methods, Cold Start, Web Systems, Scalability, User Group Fairness (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/761/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>RADio – Rank-Aware Divergence Metrics to Measure Normative Diversity in News Recommendations (2022)</h3>
    <p><strong>Authors:</strong> Mateo Gutierrez Granada, Sanne Vrijenhoek, Maarten de Rijke, Gabriel Bénédict, Daan Odijk</p>
    <p>In traditional recommender system literature, diversity is often seen as the opposite of similarity, and typically defined as the distance between identified topics, categories or word models. However, this is not expressive of the social science’s interpretation of diversity, which accounts for a news organization’s norms and values and which we here refer to as normative diversity. We introduce RADio, a versatile metrics framework to evaluate recommendations according to these normative goals. RADio introduces a rank-aware Jensen Shannon (JS) divergence. This combination accounts for (i) a user’s decreasing propensity to observe items further down a list and (ii) full distributional shifts as opposed to point estimates. We evaluate RADio’s ability to reflect five normative concepts in news recommendations on the Microsoft News Dataset and six (neural) recommendation algorithms, with the help of our metadata enrichment pipeline. We find that RADio provides insightful estimates that can potentially be used to inform news recommender system design.</p>
    <p><strong>Categories:</strong> Normative Diversity, News Recommendations, Divergence Metrics, Rank-Aware Methods, Metadata Enrichment, Recommender Systems Evaluation, Algorithm Design, Real-World Applications, Neural Recommendation Algorithms, Social Science Aspects, Evaluation Frameworks, Diversity in Recommendations (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/775/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Don’t recommend the obvious: estimate probability ratios (2022)</h3>
    <p><strong>Authors:</strong> Wenjie Zhao, Roberto Pellegrini, Iain Murray</p>
    <p>Sequential recommender systems are becoming widespread in the online retail and streaming industry. These systems are often trained to predict the next item given a sequence of a user’s recent actions, and standard evaluation metrics reward systems that can identify the most probable items that might appear next. However, some recent papers instead evaluate recommendation systems with popularity-sampled metrics, which measure how well the model can find a user’s next item when hidden amongst generally-popular items. We argue that these popularity-sampled metrics are more appropriate for recommender systems, because the most probable items for a user often include generally-popular items. If the probability that a customer will watch Toy Story is not much more probable than for the average customer, then the movie isn’t especially relevant for them and we should not recommend it. This paper shows that optimizing popularity-sampled metrics is closely related to estimating point-wise mutual information (PMI). We propose and compare two techniques to fit PMI directly, which both improve popularity-sampled metrics for state-of-the-art recommender systems. The improvements are large compared to differences between recently-proposed model architectures.</p>
    <p><strong>Categories:</strong> Recommender Systems, Sequential Recommender Systems, Evaluation Metrics, Popularity-Sampled Metrics, Point-wise Mutual Information (PMI), Recommendation Algorithms, Algorithm Design, Beyond Accuracy (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/754/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>