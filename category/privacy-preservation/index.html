<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui primary button" style="margin: 5px;"
             href="/recsys-recommender/">Privacy Preservation</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reinforcement-learning/">Reinforcement Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reproducibility/">Reproducibility</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/user-centric-design/">User-Centric Design</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Privacy Preserving Conversion Modeling in Data Clean Room (2024)</h3>
    <p><strong>Authors:</strong> Behnam Rezaei, Xiangyi Chen, Ling Leng, Jiajing Xu, Jiankai Sun, Kungang Li</p>
    <p>In the realm of online advertising, accurately predicting the conversion rates (CVR) is crucial for enhancing advertising efficiency and user satisfaction. However, it faces the challenge that due to user privacy choices and advertiser requirements, the advertising platform cannot get the conversion data from some advertisers, making accurate CVR predictions difficult. Although current methods like split learning or vertical federated learning do not share label information directly, they still exchange sample-level gradients, which introduces a privacy risk as adversaries might infer label information through the shared gradients. To address these challenges, our proposed model training framework incorporates several innovative techniques. Firstly, we employ batch-level aggregated gradients instead of sample-level gradients to enhance privacy. Secondly, to minimize communication costs, we utilize adapter-based parameter-efficient fine-tuning methods such as Low-Rank Adaptation (LoRA) and gradient compression in conversion models. These methods allow for efficient collaboration between different parties while reducing the amount of data transferred. Lastly, we incorporate label differential privacy to protect model privacy. Given that this privacy protection alters the data distribution and can result in significant calibration error, we propose a de-biasing technique to ensure accurate model predictions even with perturbed label information. Our experimental results on industrial datasets demonstrate that our method achieves competitive performance while significantly reducing the communication overhead and complying with advertisers’ privacy requirements and user privacy choice. This framework establishes a new benchmark for privacy-preserving and high-performance CVR prediction in the digital advertising industry.</p>
    <p><strong>Categories:</strong> Privacy Preservation, Conversion Rate Prediction, Online Advertising, Machine Learning, Federated Learning, Differential Privacy, Optimization Methods, Data Sharing Challenges, Low-Rank Adaptation (LoRA), Gradient Compression, Advertising Technology, Real-World Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1181/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Enhancing Privacy in Recommender Systems through Differential Privacy Techniques (2024)</h3>
    <p><strong>Authors:</strong> Angela Di Fazio</p>
    <p>Recommender systems have become essential tools for addressing information overload in the digital age. However, the collection and usage of user data for personalized recommendations raise significant privacy concerns. This research focuses on enhancing privacy in recommender systems through the application of differential privacy techniques, particularly in the domain of privacy-preserving data publishing. Our study aims to address three key research questions: (1) developing standardized metrics to characterize and compare recommendation datasets in the context of privacy-preserving data publishing, (2) designing differential privacy algorithms for private data publishing that preserve recommendation quality, and (3) examining the impact of differential privacy on beyond-accuracy objectives in recommender systems. We propose to develop domain-specific metrics for evaluating the similarity between recommendation datasets, analogous to those used in other domains such as trajectory data publication. Additionally, we will investigate methods to balance the trade-off between privacy guarantees and recommendation accuracy, considering the potential disparate impacts on different user subgroups. Finally, we aim to assess the broader implications of implementing differential privacy on beyond-accuracy objectives such as diversity, popularity bias, and fairness. By addressing these challenges, our research seeks to contribute to the advancement of privacy-preserving techniques in recommender systems, facilitating the responsible and secure use of recommendation data while maintaining the utility of personalized suggestions. The outcomes of this study have the potential to significantly benefit the field by enabling the reuse of existing algorithms with minimal adjustments while ensuring robust privacy guarantees.</p>
    <p><strong>Categories:</strong> Privacy Preservation, Differential Privacy, Recommender Systems, Metrics Evaluation, Beyond Accuracy Objectives, Domain-Specific Metrics, Privacy-Preserving Data Publishing, Trade-Off Analysis, User Subgroup Impacts, Diversity, Popularity Bias, Fairness, Responsible Data Use (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1139/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Enhanced Privacy Preservation for Recommender Systems (2023)</h3>
    <p><strong>Authors:</strong> Ziqing Wu</p>
    <p>My research focuses on privacy preservation for recommender systems specifically in the following aspects: first, how to better address users’ realistic privacy concerns and offer enhanced privacy control by considering what and with whom to share sensitive information for decentralized recommender systems; second, how to enhance the privacy preservation capability of LLM-based recommender systems; last, how to formulate uniform metrics to compare the privacy-preservation efficacy of the recommender system.</p>
    <p><strong>Categories:</strong> Privacy Preservation, Recommender Systems, User-Centric Design, Decentralized Systems, Large Language Models, Machine Learning, Deep Learning, Evaluation Metrics, Performance Measurement, Algorithm Evaluation, Data Security, Trust (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/976/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Challenges for Anonymous Session-Based Recommender Systems in Indoor Environments (2023)</h3>
    <p><strong>Authors:</strong> Alessio Ferrato</p>
    <p>Recommender Systems (RSs) have gained widespread popularity for providing personalized recommendations in manifold domains. However, considering the growing user privacy concerns, the development of recommender systems that prioritize data protection has become increasingly important. In indoor environments, RSs face unique challenges, and ongoing research is being conducted to address them. Anonymous Session-Based Recommender Systems (ASBRSs) can represent a possible solution to address these challenges while ensuring user privacy. This paper aims to bridge the gap between existing RS research and the demand for privacy-preserving recommender systems, especially in indoor settings, where significant research efforts are underway. Therefore, it proposes three research questions: How does user modeling based on implicit feedback impact on ASBRSs, considering different embedding extraction networks? How can short sessions be leveraged to start the recommendation process in ASBRSs? To what extent can ASBRSs generate fair recommendations? By investigating these questions, this study establishes the foundations for applying ASBRSs in indoor environments, safeguarding user privacy, and contributing to the ongoing research in this field.</p>
    <p><strong>Categories:</strong> Recommender Systems, Privacy Preservation, Session-Based Recommenders, Indoor Environments, Implicit Feedback, User Modeling, Short Sessions Handling, Real-World Applications, Data Protection, Methodology, Fairness in Recommendations, Review/Foundational Research (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/979/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>FR-FMSS: Federated Recommendation via Fake Marks and Secret Sharing (2021)</h3>
    <p><strong>Authors:</strong> Zhaohao Lin, Weike Pan, Zhong Ming</p>
    <p>With the implementation of privacy protection laws such as GDPR, it is increasingly difficult for organizations to legally collect user data. However, a typical recommendation algorithm based on machine learning requires user data to learn user preferences. In order to protect user privacy, a lot of recent works turn to develop federated learning-based recommendation algorithms. However, some of these works can only protect the users’ rating values, some can only protect the users’ rating behavior (i.e., the engaged items), and only a few works can protect the both types of privacy at the same time. Moreover, most of them can only be applied to a specific algorithm or a class of similar algorithms. In this paper, we propose a generic cross-user federated recommendation framework called FR-FMSS. Our FR-FMSS can not only protect the two types of user privacy, but can also be applied to most recommendation algorithms for rating prediction, item ranking, and sequential recommendation. Specifically, we use fake marks and secret sharing to modify the data uploaded by the clients to the server, which protects user privacy without loss of model accuracy. We take three representative recommendation algorithms, i.e., MF-MPC, eALS, and Fossil, as examples to show how to apply our FR-FMSS to a specific algorithm.</p>
    <p><strong>Categories:</strong> Federated Learning, Matrix Factorization, Recommendation Systems, Privacy Preservation, Cross-User Federated Recommendations, Fake Marks, Secret Sharing, User Privacy Protection, Model Accuracy, A/B Testing, Data Privacy, Cold Start, User-Centric (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/688/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Privacy Preserving Collaborative Filtering by Distributed Mediation (2021)</h3>
    <p><strong>Authors:</strong> Tamir Tassa, Alon Ben Horin</p>
    <p>Recommender systems have become very influential in our everyday decision making, e.g., helping us choose a movie from a content platform, or offering us suitable products on e-commerce websites. While most vendors who utilize recommender systems rely exclusively on training data consisting of past transactions that took place through them, the accuracy of recommendations can be improved if several vendors conjoin their datasets. Alas, such data sharing poses grave privacy concerns for both the vendors and the users. In this study we present secure multi-party protocols that enable several vendors to share their data, in a privacy-preserving manner, in order to allow more accurate Collaborative Filtering (CF). Shmueli and Tassa (RecSys 2017) introduced privacy-preserving CF protocols that rely on a mediator; namely, a third party that assists in performing the computations. They demonstrated the significant advantages of mediation in that context. We take here the mediation approach into the next level by using several independent mediators. Such distributed mediation maintains all of the advantages that were identified by Shmueli and Tassa, and offers additional ones, in comparison with the single-mediator protocols: stronger security and dramatically shorter runtimes. In addition, while all prior art assumed limited and unrealistic settings, in which each user can purchase any given item through only one vendor, we consider here a general and more realistic setting, which encompasses all previously considered settings, where users can choose between different competing vendors. We demonstrate the appealing performance of our protocols through extensive experimentation.</p>
    <p><strong>Categories:</strong> Privacy Preservation, Collaborative Filtering, Recommendation Systems, Multi-Vendor Recommendations, Secure Multi-party Computation, Distributed Mediation, Scalability, Security, Evaluation Metrics, Real-World Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/655/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>PDMFRec: A Decentralised Matrix Factorisation with Tunable User-centric Privacy (2019)</h3>
    <p><strong>Authors:</strong> James Geraci, Aonghus Lawlor, Francisco J. Peña, Panagiotis Symeonidis, Barry Smyth, Elias Z. Tragos, Erika Duriakova, Neil Hurley</p>
    <p>Conventional approaches to matrix factorisation (MF) typically rely on a centralised collection of user data for building a MF model. This approach introduces an increased risk when it comes to user privacy. In this short paper we propose an alternative, user-centric, privacy enhanced, decentralised approach to MF. Our method pushes the computation of the recommendation model to the user’s device, and eliminates the need to exchange sensitive personal information; instead only the loss gradients of local device-based) MF models need to be shared. Moreover, users can select the amount and type of information to be shared, for enhanced privacy. We demonstrate the effectiveness of this approach by considering different levels of user privacy in comparison with state-of-the-art alternatives. i>Presentation: Tuesday Poster Lunch</i</p>
    <p><strong>Categories:</strong> Matrix Factorisation, Recommendation Systems, Decentralised Computing, Privacy Preservation, Data Privacy, Edge Computing, Secure Communication, User-Centric Design, Evaluation Methods, Benchmarking, Privacy-Preserving Machine Learning (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/489/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>PrivateJobMatch: A Privacy-Oriented Deferred Multi-Match Recommender System for Stable Employment (2019)</h3>
    <p><strong>Authors:</strong> Amar Saini, Florin Rusu, Andrew Johnston</p>
    <p>Coordination failure reduces match quality among employers and candidates in the job market, resulting in a large number of unfilled positions and/or unstable, short-term employment. Centralized job search engines provide a platform that connects directly employers with job-seekers. However, they require users to disclose a significant amount of personal data, i.e., build a user profile, in order to provide meaningful recommendations. In this paper, we present PrivateJobMatch — a privacy-oriented deferred multi-match recommender system — which generates stable pairings while requiring users to provide only a partial ranking of their preferences. PrivateJobMatch explores a series of adaptations of the game-theoretic Gale-Shapley deferred acceptance algorithm which combine the flexibility of decentralized markets with the intelligence of centralized matching. We identify the shortcomings of the original algorithm when applied to a job market and propose novel solutions that rely on machine learning techniques. Experimental results on real and synthetic data confirm the benefits of the proposed algorithms across several quality measures. Over the past year, we have implemented a PrivateJobMatch prototype and deployed it in an active job market economy. Using the gathered real-user preference data, we find that the match recommendations are superior to a typical decentralized job market—while requiring only a partial ranking of the user preferences.</p>
    <p><strong>Categories:</strong> Deferred Acceptance Algorithm, Machine Learning, Job Market, Employment Matching, Recommendation Systems, Privacy Preservation, Real-World Applications, Beyond Accuracy, Diversity of Recommendations, Stability in Recommendations, Privacy-Preserving Recommenders, Game-Theoretic Approaches (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/456/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>