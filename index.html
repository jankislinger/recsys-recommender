<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/bias-mitigation/">Bias Mitigation</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reinforcement-learning/">Reinforcement Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/real-world-applications/">Real-world Applications</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/ab-testing/">A/B Testing</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/evaluation-metrics/">Evaluation Metrics</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reproducibility/">Reproducibility</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/knowledge-graphs/">Knowledge Graphs</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>The Elephant in the Room: Rethinking the Usage of Pre-trained Language Model in Sequential Recommendation (2024)</h3>
    <p><strong>Authors:</strong> Zekai Qu, Chaojun Xiao, Zhanhui Kang, Ruobing Xie, Xingwu Sun</p>
    <p>Sequential recommendation (SR) has seen significant advancements with the help of Pre-trained Language Models (PLMs). Some PLM-based SR models directly use PLM to encode user historical behavior’s text sequences to learn user representations, while there is seldom an in-depth exploration of the capability and suitability of PLM in behavior sequence modeling. In this work, we first conduct extensive model analyses between PLMs and PLM-based SR models, discovering great underutilization and parameter redundancy of PLMs in behavior sequence modeling. Inspired by this, we explore different lightweight usages of PLMs in SR, aiming to maximally stimulate the ability of PLMs for SR while satisfying the efficiency and usability demands of practical systems. We discover that adopting behavior-tuned PLMs for item initializations of conventional ID-based SR models is the most economical framework of PLM-based SR, which would not bring in any additional inference cost but could achieve a dramatic performance boost compared with the original version. Extensive experiments on five datasets show that our simple and universal framework leads to significant improvement compared to classical SR and SOTA PLM-based SR models without additional inference costs.</p>
    <p><strong>Categories:</strong> Pre-trained Language Models, Sequential Recommendation, Model Analysis, Behavior Sequence Modeling, Efficiency in Recommendations, Lightweight Usage of PLMs, Parameter Redundancy, Model Adaptation (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1064/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Toward 100TB Recommendation Models with Embedding Offloading (2024)</h3>
    <p><strong>Authors:</strong> Sarunya Pumma, Levy Zhao, Joshua Deng, Dennis Van Der Staay, Jian He, Intaik Park, Ehsan Ardestani, Damian Reeves, Yu Guo, Paul Zhang, Henry Tsang</p>
    <p>Training recommendation models become memory-bound with large embedding tables, and fast GPU memory is scarce. In this paper, we explore embedding caches and prefetch pipelines to effectively leverage large but slow host memory for embedding tables. We introduce Locality-Aware Sharding and iterative planning that automatically size caches optimally and produce effective sharding plans. Embedding Offloading, a system that combines all of these components and techniques, is implemented on top of Meta’s open-source libraries, FBGEMM GPU and TorchRec, and it is used to improve scalability and efficiency of industry-scale production models. Embedding Offloading achieved 37x model scale to 100TB model size with only 26% training speed regression.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Embedding, Scalability, Memory Optimization, System Design, Cache Management, Sharding, Production Systems, Industry Applications, System Performance, GPU Memory, Resource Management (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1178/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Enhancing Cross-Domain Recommender Systems with LLMs: Evaluating Bias and Beyond-Accuracy Measures (2024)</h3>
    <p><strong>Authors:</strong> Thomas Elmar Kolb</p>
    <p>The research domain of recommender systems is rapidly evolving. Initially, optimization efforts focused primarily on accuracy. However, recent research has highlighted the importance of addressing bias and beyond-accuracy measures such as novelty, diversity, and serendipity. With the rise of multi-domain recommender systems, the need to re-examine bias and beyond-accuracy measures in cross-domain settings has become crucial. Traditional methods face challenges such as cold-start problems, which can potentially be mitigated by leveraging LLMs. This proposed work investigates how LLM-based recommendation methods can enhance cross-domain recommender systems, focusing on identifying, measuring, and mitigating bias while evaluating the impact of beyond-accuracy measures. We aim to provide new insights by comparing traditional and LLM-based systems within a real-world environment encompassing the domains of news, books, and various lifestyle areas. Our research seeks to address the outlined gaps and develop effective evaluation strategies for the unique challenges posed by LLMs in cross-domain recommender systems.</p>
    <p><strong>Categories:</strong> Cross-Domain Recommender Systems, Large Language Models (LLMs), Bias, Novelty, Diversity, Serendipity, Beyond Accuracy, Cold Start Problem, News Domain, Books Domain, Lifestyle Domain, Real-World Applications, Traditional Recommenders, Neural Networks, Multi-Domain Evaluation, Enhancing Recommender Systems (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1137/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Effective Off-Policy Evaluation and Learning in Contextual Combinatorial Bandits (2024)</h3>
    <p><strong>Authors:</strong> Yuta Saito, Tatsuhiro Shimizu, Ren Kishimoto, Masahiro Nomura, Koichi Tanaka, Haruka Kiyohara</p>
    <p>We explore off-policy evaluation and learning in contextual combinatorial bandits (CCB), where a policy selects a subset in the action space. For example, it might choose a set of furniture pieces (a bed and a drawer) from available items (bed, drawer, chair, etc.) for interior design sales. This setting is widespread in fields such as recommender systems and healthcare, yet OPE/L of CCB remains unexplored in the relevant literature. Standard OPE methods typically employ regression and importance sampling in the action subset space. However, they often face significant challenges due to high bias or variance, exacerbated by the exponential growth in the number of available subsets. To address these challenges, we introduce a concept of factored action space, which allows us to decompose each subset into binary indicators. These indicators signify whether each action is included in the selected subset. This formulation allows us to distinguish between the “main effect” derived from the main actions, and the “residual effect”, originating from the supplemental actions, facilitating more effective OPE. Specifically, our estimator, called OPCB, leverages an importance sampling-based approach to unbiasedly estimate the main effect, while employing regression-based approach to deal with the residual effect with low variance. OPCB achieves substantial variance reduction compared to conventional importance sampling methods and bias reduction relative to regression methods under certain conditions, as illustrated in our theoretical analysis. Experiments on both synthetic and real-world datasets demonstrate OPCB’s superior performance over the typical methods, particularly when navigating the complexities of a large action subset space.</p>
    <p><strong>Categories:</strong> Combinatorial Bandits, Contextual Bandits, Off-Policy Evaluation, Importance Sampling, Regression Methods, Recommender Systems, Healthcare, Scalability, Evaluation Metrics, Multi-Armed Bandits, Real-World Applications, Theoretical Analysis. (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1040/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Sliding Window Training – Utilizing Historical Recommender Systems Data for Foundation Models (2024)</h3>
    <p><strong>Authors:</strong> Ko-Jen Hsiao, Yesu Feng, Sudarshan Lamkhede, Swanand Joshi, Zhe Zhang</p>
    <p>Long-lived recommender systems (RecSys) often encounter lengthy user-item interaction histories that span many years. To effectively learn long term user preferences, Large RecSys foundation models (FM) need to encode this information in pretraining. Usually, this is done by either generating a long enough sequence length to take all history sequences as input at the cost of large model input dimension or by dropping some parts of the user history to accommodate model size and latency requirements on the production serving side. In this paper, we introduce a sliding window training technique to incorporate long user history sequences during training time without increasing the model input dimension. We show the quantitative \& qualitative improvements this technique brings to the RecSys FM in learning user long term preferences. We additionally show that the average quality of items in the catalog learnt in pretraining also improves.</p>
    <p><strong>Categories:</strong> Recommender Systems (RecSys), Foundation Models, Training Techniques, Sliding Window, Historical Data Utilization, Model Optimization, User Preferences Learning, Catalog Quality, Pretraining Methods, Scalability, Time Series Analysis, Model Efficiency, Evaluation Metrics, Real-World Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1176/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Playlist Search Reinvented: LLMs Behind the Curtain (2024)</h3>
    <p><strong>Authors:</strong> Tarun Sharma, Siddharth Sharma, Geetha Aluri, Joaquin Delgado</p>
    <p>Improving search functionality poses challenges such as data scarcity for model training, metadata enrichment for comprehensive document indexing, and the labor-intensive manual annotation for evaluation. Traditionally, iterative methods relying on human annotators and customer feedback have been used. However, recent advancements in Large Language Models (LLMs) offer new solutions. This paper focuses on applying LLMs to playlist search in Amazon Music. Leveraging LLMs’ contextual understanding and generative capabilities automates metadata enrichment, reducing manual efforts and expediting training. LLMs also address data scarcity by generating synthetic training data and serve as scalable judges for evaluation, enhancing search performance assessment. We demonstrate how these innovations enhance playlist search, overcoming traditional limitations to improve search result accuracy and relevance.</p>
    <p><strong>Categories:</strong> Large Language Models (LLMs), Music, Entertainment, Search Functionality, Evaluation Methods, Data Generation/Synthesis, Real-World Applications, Automation, Scalability, Metadata Enrichment (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1169/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Explainable and Faithful Educational Recommendations through Causal Language Modelling via Knowledge Graphs (2024)</h3>
    <p><strong>Authors:</strong> Neda Afreen</p>
    <p>The rapid expansion of digital education has significantly increased the need for recommender systems to help learners navigate the extensive variety of available learning resources. Recent advancements in these systems have notably improved the personalization of course recommendations. However, many existing systems fail to provide clear explanations for their recommendations, making it difficult for learners to understand why a particular suggestion was made. This lack of transparency can negatively impact trust and acceptance of the system. Researchers have emphasized the importance of explanations in various other domains such as ecommerce, media, and entertainment, demonstrating how explanations can enhance system transparency, foster user trust, and improve decision-making processes. Despite these insights, such approaches have been rarely applied to the educational domain, and their effectiveness in practical use remains largely unexamined. My research focuses on developing explainable recommender systems for digital education. First, I aim to design knowledge graphs that can support high-quality recommendations in the context of education. Second, I will create models backed by these knowledge graphs that not only deliver accurate recommendations but also provide faithful explanations for each suggestion, helping learners make informed decisions. Third, I will evaluate the effectiveness of these explainable recommender systems in real-world scenarios.</p>
    <p><strong>Categories:</strong> Causal Language Modeling, Knowledge Graphs, Explainable Recommendations, Faithful Explanations, Transparency in Recommendations, Trust in Systems, Real-World Evaluation, Education Domain, User-Centric Design, Personalization (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1138/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Revisiting LightGCN: Unexpected Inflexibility, Inconsistency, and A Remedy Towards Improved Recommendation (2024)</h3>
    <p><strong>Authors:</strong> Geon Lee, Kijung Shin, Kyungho Kim</p>
    <p>Graph Neural Networks (GNNs) have emerged as effective tools in recommender systems. Among various GNN models, LightGCN is distinguished by its simplicity and outstanding performance. Its efficiency has led to widespread adoption across different domains, including social, bundle, and multimedia recommendations. In this paper, we thoroughly examine the mechanisms of LightGCN, focusing on its strategies for scaling embeddings, aggregating neighbors, and pooling embeddings across layers. Our analysis reveals that, contrary to expectations based on its design, LightGCN suffers from inflexibility and inconsistency when applied to real-world data. We introduce LightGCN++, an enhanced version of LightGCN designed to address the identified limitations. LightGCN++ incorporates flexible scaling of embedding norms and neighbor weighting, along with a tailored approach for pooling layer-wise embeddings to resolve the identified inconsistencies. Despite its remarkably simple remedy, extensive experimental results demonstrate that LightGCN++ significantly outperforms LightGCN, achieving an improvement of up to 17.81% in terms of NDCG@20. Furthermore, state-of-the-art models utilizing LightGCN as a backbone for item, bundle, multimedia, and knowledge-graph-based recommendations exhibit improved performance when equipped with LightGCN++.</p>
    <p><strong>Categories:</strong> Graph Neural Networks (GNNs), Recommendation Systems, LightGCN, Algorithm Design, Evaluation Metrics, Embedding Techniques, Social Recommendations, Bundle Recommendations, Multimedia Recommendations, Model Limitations, Algorithm Optimization, Recommendation Quality (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1110/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Is It Really Complementary? Revisiting Behavior-based Labels for Complementary Recommendation (2024)</h3>
    <p><strong>Authors:</strong> Kazushi Okamoto, Kai Sugahara, Chihiro Yamasaki</p>
    <p>Complementary recommendation is a type of item-to-item recommendation that recommends what should be purchased together for an item. Previous studies have traditionally used behavior-based labels (BBLs) that are constructed from the co-purchase logs of users for training and evaluation because rigorous label construction for complements is inefficient. However, the fact that many item pairs in BBLs are not functionally complementary, even though they are frequently co-purchased, has been overlooked. This study aimed to re-evaluate the validity of BBLs through functional relationships and provide directions for their improvement. Quantitative analysis using manually annotated function-based labels (FBLs) as correct labels revealed that the accuracy of the complementary recommendations generated by BBLs was below 50%, suggesting potential functional incompatibility within BBLs. Existing models that were trained on BBLs were similarly inaccurate, indicating the unreliability of the evaluations in existing studies. Finally, we proposed a label correction method for BBLs using a small set of FBLs, thereby providing a direction for reliable complementary recommendations.</p>
    <p><strong>Categories:</strong> Complementary Recommendations, Behavior-based Labels (BBLs), Item-to-Item Recommendations, Functional Relationships, Evaluation Metrics, Label Correction, Data Annotation, Recommendation Systems, E-commerce, Reliability. (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1196/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>A Multimodal Single-Branch Embedding Network for Recommendation in Cold-Start and Missing Modality Scenarios (2024)</h3>
    <p><strong>Authors:</strong> Anna Hausberger, Markus Schedl, Christian Ganhör, Shah Nawaz, Marta Moscati</p>
    <p>Most recommender systems adopt collaborative filtering (CF) and provide recommendations based on past collective interactions. Therefore, the performance of CF algorithms degrades when few or no interactions are available, a scenario referred to as cold-start. To address this issue, previous work relies on models leveraging both collaborative data and side information on the users or items. Similar to multimodal learning, these models aim at combining collaborative and content representations in a shared embedding space. In this work we propose a novel technique for multimodal recommendation, relying on a multimodal Single-Branch embedding network for Recommendation (SiBraR). Leveraging weight-sharing, SiBraR encodes interaction data as well as multimodal side information using the same single-branch embedding network on different modalities. This makes SiBraR effective in scenarios of missing modality, including cold start. Our extensive experiments on large-scale recommendation datasets from three different recommendation domains (music, movie, and e-commerce) and providing multimodal content information (audio, text, image, labels, and interactions) show that SiBraR significantly outperforms CF as well as state-of-the-art content-based RSs in cold-start scenarios, and is competitive in warm scenarios. We show that SiBraR’s recommendations are accurate in missing modality scenarios, and that the model is able to map different modalities to the same region of the shared embedding space, hence reducing the modality gap.</p>
    <p><strong>Categories:</strong> Recommender Systems, Multimodal Learning, Cold Start, Missing Modality, Embedding Networks, Collaborative Filtering, Content-Based Recommendations, Music, Movies, E-commerce, Large-Scale Datasets, Performance Improvement (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1018/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Context-based Entity Recommendation for Knowledge Workers: Establishing a Benchmark on Real-life Data (2024)</h3>
    <p><strong>Authors:</strong> Mahta Bakhshizadeh, Heiko Maus, Andreas Dengel</p>
    <p>In recent decades, recommender systems have undergone significant advancements, particularly in popular domains like movies, music, and product recommendations. Yet, progress has been notably slower in leveraging these systems for personal information management and knowledge assistance. In addition to challenges that complicate the adoption of recommender systems in this domain (such as privacy concerns, heterogeneous recommendation items, and frequent context switching), a significant barrier to progress in this area has been the absence of a standardized benchmark for researchers to evaluate their approaches. In response to this gap, this paper presents a benchmark built upon a publicly available dataset of real-life knowledge work in context (RLKWiC). This benchmark focuses on evaluating context-based entity recommendation, a use case for leveraging recommender systems to support knowledge workers in their daily digital tasks. By providing this benchmark, it is aimed to facilitate and accelerate research efforts in enhancing personal knowledge assistance through recommender systems.</p>
    <p><strong>Categories:</strong> Recommender Systems, Knowledge Management, Information Management, Real-world Applications, Privacy, Heterogeneous Data, Context-based Recommendations, Benchmarking, Evaluation Metrics, Dataset Development, Workflows, User Behavior, Personalization, Knowledge Workers (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1107/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Scaling Law of Large Sequential Recommendation Models (2024)</h3>
    <p><strong>Authors:</strong> Hongyu Lu, Yu Chen, Wayne Xin Zhao, Gaowei Zhang, Yupeng Hou, Ji-Rong Wen</p>
    <p>Scaling of neural networks has recently shown great potential to improve the model capacity in various fields. Specifically, model performance has a power-law relationship with model size or data size, which provides important guidance for the development of large-scale models. However, there is still limited understanding on the scaling effect of user behavior models in recommender systems, where the unique data characteristics (e.g., data scarcity and sparsity) pose new challenges in recommendation tasks. In this work, we focus on investigating the scaling laws in large sequential recommendation models. Specifically, we consider a pure ID-based task formulation, where the interaction history of a user is formatted as a chronological sequence of item IDs. We don’t incorporate any side information (e.g., item text), to delve into the scaling law’s applicability from the perspective of user behavior. We successfully scale up the model size to 0.8B parameters, making it feasible to explore the scaling effect in a diverse range of model sizes. As the major findings, we empirically show that the scaling law still holds for these trained models, even in data-constrained scenarios. We then fit the curve for scaling law, and successfully predict the test loss of the two largest tested model scales. Furthermore, we examine the performance advantage of scaling effect on five challenging recommendation tasks, considering the unique issues (e.g., cold start, robustness, long-term preference) in recommender systems. We find that scaling up the model size can greatly boost the performance on these challenging tasks, which again verifies the benefits of large recommendation models.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Scaling Laws, Sequential Recommendations, Model Scalability, Large-Scale Models, User Behavior Modeling, Cold Start Problem, Evaluation Metrics, Data Sparsity, Model Capacity (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1065/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Accelerating the Surrogate Retraining for Poisoning Attacks against Recommender Systems (2024)</h3>
    <p><strong>Authors:</strong> Yunfan Wu, Shuchang Tao, Qi Cao, Huawei Shen, Fei Sun, Kaike Zhang</p>
    <p>Recent studies have demonstrated the vulnerability of recommender systems to data poisoning attacks, where adversaries inject carefully crafted fake user interactions into the training data to manipulate recommendations for target items.Current attack methods involve iterative retraining a surrogate recommender on the poisoned data with latest fake users to optimize the attack. However, this repetitive retraining is highly time-consuming, hindering the efficient assessment and optimization of fake users. To mitigate this computational bottleneck and develop a more effective attack in an affordable time, we analyze the retraining process and find that a change in the representation of one user/item will cause a cascading effect through the user-item interaction graph. Under theoretical guidance, we introduce Gradient Passing (GP),  a novel technique that explicitly passes gradients between interacted user-item pairs during backpropagation, thereby approximate the cascading effect and accelerating retraining. With just a single training step, GP can achieve effects comparable to multiple original steps. Under the same number of retraining epochs, GP enables a closer approximation of the surrogate recommender to the victim. This improved approximation provides better guidance for optimizing fake users, ultimately leading to enhanced data poisoning attacks. Extensive experiments on real-world datasets demonstrate the efficiency and effectiveness of our proposed GP.</p>
    <p><strong>Categories:</strong> Recommender Systems, Data Poisoning Attacks, Adversarial Machine Learning, Gradient Passing, Surrogate Model Retraining, User/Item Interaction Graphs, Cascading Effects, Backpropagation Optimization (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1024/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Neighborhood-Based Collaborative Filtering for Conversational Recommendation (2024)</h3>
    <p><strong>Authors:</strong> Julian Mcauley, Zhouhang Xie, Nathan Kallus, Dawen Liang, Rahul Jha, Hyunsik Jeon, Zhankui He, Harald Steck, Junda Wu</p>
    <p>Conversational recommender systems (CRS) should understand users’ expressed interests that are frequently semantically rich and knowledge intensive. Prior works attempt to address this challenge by making use of external knowledge bases or parametric knowledge in large language models (LLMs). In this paper, we study a complementary solution, exploiting item knowledge in the training data. We hypothesise that many inference-time user requests can be answered via reusing popular crowd-written answers associated with similar training queries. Following this intuition, we define a class of neighborhood-based CRS that make recommendations by identifying popular items associated with similar training dialogue contexts. Experiments on Inspired, Redial, and Reddit benchmarks show that despite its simplicity, our method achieves comparable to better performance than state-of-the-art LLM-based methods with over 200 times more parameters. We also show neighborhood and model-based predictions can be combined to achieve further performance improvements over both components.</p>
    <p><strong>Categories:</strong> Collaborative Filtering, Conversational Recommender Systems, Neighborhood-Based Methods, Similarity-Based Recommendations, Hybrid Recommendations, Performance Evaluation, Recommendation Quality, Crowd-Written Answers, Item Knowledge Utilization, Beyond Accuracy, Efficiency, Recommendation Systems (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1100/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Bridging Viewpoints in News with Recommender Systems (2024)</h3>
    <p><strong>Authors:</strong> Jia Hua Jeng</p>
    <p>News Recommender systems (NRSs) aid in decision-making in news media. However, undesired effects can emerge. Among these are selective exposures that may contribute to polarization, potentially reinforcing existing attitudes through belief perseverance—discounting contrary evidence due to their opposing attitudinal strength. This can be unsafe for people, making it difficult to accept information objectively. A crucial issue in news recommender system research is how to mitigate these undesired effects by designing recommender interfaces and machine learning models that enable people to consider to be more open to different perspectives. Alongside accurate models, the user experience is an equally important measure. Indeed, the core statistics are based on users’ behaviors and experiences in this research project. Therefore, this research agenda aims to steer the choices of readers’ based on altering their attitudes. The core methods plan to concentrate on the interface design and ML model building involving manipulations of cues, users’ behaviors prediction, NRSs algorithm and changing the nudges. In sum, the project aims to provide insight in the extent to which news recommender systems can be effective in mitigating polarized opinions.</p>
    <p><strong>Categories:</strong> Machine Learning, News Recommender Systems, Bias Mitigation, Personalization, User Experience, Interface Design, Behavior Prediction, Nudge Theory, Selective Exposure, Diversity of Recommendations, Perspective Bridging, Accuracy in Recommendations, Attitude Alteration, Media, Public Opinion, Social Impact (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1135/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Can editorial decisions impair journal recommendations? Analysing the impact of journal characteristics on recommendation systems (2024)</h3>
    <p><strong>Authors:</strong> Elias Entrup, Anett Hoppe, Ralph Ewerth</p>
    <p>Recommendation services for journals help scientists choose appropriate publication venues for their research results. They often use a semantic matching process to compare e.g. an abstract against already published articles. As these services can guide a researcher’s decision, their fairness and neutrality are critical qualities. However, the impact of journal characteristics (such as the abstract length) on recommendations is understudied. In this paper, we investigate whether editorial journal characteristics can lead to biased rankings from recommendation services, i.e. if editorial choices can systematically lead to a better ranking of one’s own journal. The performed experiments show that longer abstracts or a higher number of articles per journal can boost the rank of a journal in the recommendations. We apply these insights to an active, open-source journal recommendation system. The adaptation of the algorithm leads to an increased accuracy for smaller journals.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Journal Publishing, Bias in Recommendations, Editorial Decisions, Algorithm Adaptation, Open-Source Tools, Academic Publishing, Journal Characteristics, Fairness in AI/ML, Semantic Matching, User Impact (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1083/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>