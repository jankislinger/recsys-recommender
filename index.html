<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Flask App</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css">
  <link rel="stylesheet" href="/recsys-recommender/static/custom.css">
</head>

<body>

<div class="ui menu container">
  <div class="header item">
    RecSys Recommender
  </div>
  <a class="item" href="/recsys-recommender/">
    Recommendations
  </a>
  <a class="item" href="/recsys-recommender/embedding/">
    Embedding
  </a>
</div>

<div class="ui inverted main container">
  <div class="ui masthead vertical segment">
    

  <h1 class="ui header">RecSys Articles</h1>

  
  <div class="ui segment center aligned">
    <div class="ui" style="flex-wrap: wrap; margin: 10px 0;">
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/large-language-models-llms/">Large Language Models (LLMs)</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/transfer-learning/">Transfer Learning</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/data-sparsity/">Data Sparsity</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/sequential-recommendations/">Sequential Recommendations</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/bias-mitigation/">Bias Mitigation</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/fairness/">Fairness</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/reproducibility/">Reproducibility</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/cold-start/">Cold Start</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/offline-evaluation/">Offline Evaluation</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/performance-evaluation/">Performance Evaluation</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/scalability/">Scalability</a>
        
      
        
          <a class="ui button" style="margin: 5px;"
             href="/recsys-recommender/category/e-commerce/">E-commerce</a>
        
      
    </div>
  </div>

  
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Improving the Shortest Plank: Vulnerability-Aware Adversarial Training for Robust Recommender System (2024)</h3>
    <p><strong>Authors:</strong> Fei Sun, Qi Cao, Yunfan Wu, Huawei Shen, Xueqi Cheng, Kaike Zhang</p>
    <p>Recommender systems play a pivotal role in mitigating information overload in diverse fields. Nonetheless, the inherent openness of these systems introduces vulnerabilities, allowing attackers to insert fake users to skew the exposure of certain items, known as poisoning attacks. Adversarial training emerges as a notable defense mechanism against such poisoning attacks within recommender systems. Traditional adversarial training methods apply perturbations with the same scale across all users to their embeddings to maintain system robustness against the worst-case attacks. Yet, in reality, attacks often affect only a subset of users who are actually vulnerable to the specific attacks. These indiscriminate perturbations make it difficult to balance effective protection for vulnerable users and avoidance of recommendation quality degradation for those who are not. To address this issue, our research delves into understanding user vulnerability. Considering that poisoning attacks pollutes the training data, we observe that the extent of a recommender system’s fit to users’ training data, particularly when high, correlates with an increased likelihood of users incorporating attack information, thus indicating their vulnerability. Leveraging these insights, we introduce the Vulnerability-aware Adversarial Training (VAT) method, designed to counteract poisoning attacks in recommender systems. VAT employs a novel vulnerability-aware function to estimate users’ vulnerability based on the degree to which they are fitted by the system. Guided by this evaluation, VAT applies user-specific perturbations to embeddings. thereby not only reducing the success rate of attacks but also preserving—and potentially enhancing—the quality of recommendations. Comprehensive experiments confirm VAT’s superior defensive capabilities against various attacks and recommendation models.</p>
    <p><strong>Categories:</strong> Adversarial Training, Poisoning Attacks, Robustness, Security, User Vulnerability Analysis, Defense Mechanisms, Recommender Systems, Machine Learning, Adversarial Machine Learning, Security in Recommender Systems (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1045/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Optimizing for Participation in Recommender System (2024)</h3>
    <p><strong>Authors:</strong> Sourabh Bansod, Yaping Zhang, Bibang Liu, Mingyan Gao, Yuan Shao, Arnab Bhadury</p>
    <p>The traditional recommender system has been designed to mostly optimize for viewer consumption, and with the rise of short form videos, the boundaries between consumption and participation have blurred. This shift presents an opportunity to optimize recommender systems not only for passive consumption, but also for active participation in content creation. In this paper, we document the development of a recommender system that provides inspiration to existing content uploaders and new future content uploaders to encourage participation. Our contributions are two-fold: 1) Inspiration Framework: We present a novel framework for building a recommender system that goes beyond traditional consumption-focused metrics, specifically addressing the need for creative inspiration to lower barriers for participation. This framework is adaptable in the design of large-scale recommender systems in other domains. 2) Empirical Evaluation: We conduct systematic evaluation via live experiments to prove the values of the proposed system in increasing daily participation and participants.</p>
    <p><strong>Categories:</strong> Recommender Systems, Content Creation, Video Recommendation, Beyond Accuracy, User Engagement, Real-World Applications, Cold Start, Framework Design (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1167/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Data Augmentation using Reverse Prompt for Cost-Efficient Cold-Start Recommendation (2024)</h3>
    <p><strong>Authors:</strong> Genki Kusano</p>
    <p>Recommendation systems that use auxiliary information such as product names and categories have been proposed to address the cold-start problem. However, these methods do not perform well when we only have insufficient warm-start training data. On the other hand, large language models (LLMs) can perform as effective cold-start recommendation systems even with limited warm-start data. However, they require numerous API calls for inferences, which leads to high operational costs in terms of time and money. This is a significant concern in industrial applications. In this paper, we introduce a new method, RevAug, which leverages LLMs as a data augmentation to enhance cost-efficient cold-start recommendation systems. To generate pseudo-samples, we have reversed the commonly used prompt for an LLM from “Would this user like this item?” to “What kind of items would this user like?”. Generated outputs by this reverse prompt are pseudo-auxiliary information utilized to enhance recommendation systems in the training phase. In numerical experiments with four real-world datasets, RevAug demonstrated superior performance in cold-start settings with limited warm-start data compared to existing methods. Moreover, RevAug significantly reduced API fees and processing time compared to an LLM-based recommendation method.</p>
    <p><strong>Categories:</strong> Cold Start, Data Augmentation, Large Language Models (LLMs), Recommendation Systems, Reverse Prompt, Cost Efficiency, Methodology, Performance in Cold-Start Settings, Real-World Applications. (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1081/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Short-form Video Needs Long-term Interests: An Industrial Solution for Serving Large User Sequence Models (2024)</h3>
    <p><strong>Authors:</strong> Ben Most, Yuening Li, Qingyun Liu, Liang Liu, Xinyang Yi, Junjie Shan, Shuchao Bi, Lichan Hong, Chuan He, Jiaxi Tang, Diego Uribe, Kaushik Kalyan, Ed Chi</p>
    <p>Sequential models are invaluable for powering personalized recommendation systems. In the context of short-form video (SFV) feeds, where user behavior history is typically longer, there’s a need for a system to handle users’ long-term interests. However, deploying large sequence models to extensive web-scale applications faces challenges due to high serving cost. To address this, we propose an industrial framework designed for efficiently serving large user sequence models. Specifically, the proposed infrastructure decouples the serving of user sequence model and the main recommendation model, with user sequence model served offline (in an asynchronous manner) with periodical refresh. The proposed infrastructure is also model-agnostic; thus, it can be used to support any types of user sequence models (even LLMs) with controllable costs. Empirical results show that large user models deployed with our framework significantly and consistently enhances the quality of the main recommendation model, with minimal serving costs increase.</p>
    <p><strong>Categories:</strong> User Sequence Models, Short-form Video, Recommendation Systems, Long-term Interests, Model Serving, Scalability, Cost Efficiency, Industrial Framework, Offline Serving, Beyond Accuracy (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1175/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Comparative Analysis of Pretrained Audio Representations in Music Recommender Systems (2024)</h3>
    <p><strong>Authors:</strong> Yan-Martin Tamm, Anna Aljanaki</p>
    <p>Over the years, Music Information Retrieval (MIR) has proposed various foundation models pretrained on large amounts of music data. Transfer learning showcases proven effectiveness of foundation models with a broad spectrum of downstream tasks, including auto-tagging and genre classification. However, MIR papers generally do not explore the efficiency of foundation models for Music Recommender Systems (MRS). In addition, the Recommender Systems (RS) community tends to favour traditional end-to-end neural network learning over these models. Our research addresses this gap and evaluates the applicability of six pretrained foundation models (MusicFM, Music2Vec, MERT, EncodecMAE, Jukebox, and MusiCNN) in the context of MRS. We assess their performance using three recommendation models: K-nearest neighbours (KNN), shallow neural network, and BERT4Rec. Our findings suggest that these models exhibit significant performance variability between traditional MIR tasks and MRS, indicating that valuable aspects of musical information captured by foundation models may differ depending on the task. This study establishes a foundation for further exploration of pretrained foundation models to enhance music recommendation systems.</p>
    <p><strong>Categories:</strong> Pretrained Models, Music Recommender Systems, Transfer Learning, Evaluation Methods, Music Information Retrieval, Neural Networks, Recommendation Algorithms, Audio Representations (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1084/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Multi-Behavioral Sequential Recommendation (2024)</h3>
    <p><strong>Authors:</strong> Shereen Elsayed, Lars Schmidt-Thieme, Ahmed Rashed</p>
    <p>Sequential recommendation models are crucial for next-item prediction tasks in various online platforms, yet many focus on a single behavior, neglecting valuable implicit interactions. While multi-behavioral models address this using graph-based approaches, they often fail to capture sequential patterns simultaneously. Our proposed Multi-Behavioral Sequential Recommendation framework (MBSRec) captures the multi-behavior dependencies between the heterogeneous historical interactions via multi-head self-attention. Furthermore, we utilize a weighted binary cross-entropy loss for precise behavior control. Experimental results on four datasets demonstrate MBSRec’s significant outperformance of state-of-the-art approaches. The implementation code is available here (https://drive.google.com/drive/folders/1EGRQutc9xtVYbsbXswUcTb9nvT1Tc9cZ?usp=sharing) during the review and will be added to GitHub upon acceptance.</p>
    <p><strong>Categories:</strong> Multi-Behavioral Models, Sequential Recommendation, Implicit Feedback, Attention Mechanism, Recommender Systems, Loss Function Optimization, Deep Learning, Evaluation Metrics, Implementation Details, Cross-Entropy Loss, Multi-Head Self Attention, Heterogeneous Interactions (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1101/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Explainable and Faithful Educational Recommendations through Causal Language Modelling via Knowledge Graphs (2024)</h3>
    <p><strong>Authors:</strong> Neda Afreen</p>
    <p>The rapid expansion of digital education has significantly increased the need for recommender systems to help learners navigate the extensive variety of available learning resources. Recent advancements in these systems have notably improved the personalization of course recommendations. However, many existing systems fail to provide clear explanations for their recommendations, making it difficult for learners to understand why a particular suggestion was made. This lack of transparency can negatively impact trust and acceptance of the system. Researchers have emphasized the importance of explanations in various other domains such as ecommerce, media, and entertainment, demonstrating how explanations can enhance system transparency, foster user trust, and improve decision-making processes. Despite these insights, such approaches have been rarely applied to the educational domain, and their effectiveness in practical use remains largely unexamined. My research focuses on developing explainable recommender systems for digital education. First, I aim to design knowledge graphs that can support high-quality recommendations in the context of education. Second, I will create models backed by these knowledge graphs that not only deliver accurate recommendations but also provide faithful explanations for each suggestion, helping learners make informed decisions. Third, I will evaluate the effectiveness of these explainable recommender systems in real-world scenarios.</p>
    <p><strong>Categories:</strong> Causal Language Modeling, Knowledge Graphs, Explainable Recommendations, Faithful Explanations, Transparency in Recommendations, Trust in Systems, Real-World Evaluation, Education Domain, User-Centric Design, Personalization (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1138/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>The MovieLens Beliefs Dataset: Collecting Pre-Choice Data for Online Recommender Systems (2024)</h3>
    <p><strong>Authors:</strong> Guy Aridor, Duarte Goncalves, Daniel Kluver, Ruoyan Kong, Joseph Konstan</p>
    <p>An increasingly important aspect of designing recommender systems involves considering how recommendations will influence consumer choices. This paper addresses this issue by introducing a method for collecting user beliefs about un-experienced items – a critical predictor of choice behavior. We implemented this method on the MovieLens platform, resulting in a rich dataset that combines user ratings, beliefs, and observed recommendations. We document challenges to such data collection, including selection bias in response and limited coverage of the product space. This unique resource empowers researchers to delve deeper into user behavior and analyze user choices absent recommendations, measure the effectiveness of recommendations, and prototype algorithms that leverage user belief data, ultimately leading to more impactful recommender systems.</p>
    <p><strong>Categories:</strong> User Behavior, Pre-Choice Data, Recommender Systems, MovieLens, Dataset, User Feedback, Recommendation Algorithms, Research Methods, Movies, Data Collection Challenges, Recommender Systems Design, Evaluation Metrics, Algorithm Development, Belief Modeling, User Choices, Cold Start (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1106/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Cross-Domain Latent Factors Sharing via Implicit Matrix Factorization (2024)</h3>
    <p><strong>Authors:</strong> Alexey Vasilev, Anton Vakhrushev, Evgeny Frolov, Abdulaziz Samra, Alexander Grigorevskiy</p>
    <p>Data sparsity has been one of the long-standing problems for recommender systems. One of the solutions to mitigate this issue is to exploit knowledge available in other source domains. However, many cross-domain recommender systems introduce a complex architecture that makes them less scalable in practice. On the other hand, matrix factorization methods are still considered to be strong baselines for single-domain recommendations. In this paper, we introduce the CDIMF, a model that extends the standard implicit matrix factorization with ALS to cross-domain scenarios. We apply the Alternating Direction Method of Multipliers to learn shared latent factors for overlapped users while factorizing the interaction matrix. In a dual-domain setting, experiments on industrial datasets demonstrate a competing performance of CDIMF for both cold-start and warm-start. The proposed model can outperform most other recent cross-domain and single-domain models.</p>
    <p><strong>Categories:</strong> Matrix Factorization, Cross-Domain, Data Sparsity, Scalability, Cold Start, Recommender Systems, Implicit Feedback, Alternating Least Squares (ALS), Latent Factors, Evaluation Metrics Beyond Accuracy (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1029/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Low Rank Field-Weighted Factorization Machines for Low Latency Item Recommendation (2024)</h3>
    <p><strong>Authors:</strong> Ariel Raviv, Tularam Ban, Alex Shtoff, Oren Somekh, Michael Viderman, Naama Haramaty-Krasne</p>
    <p>Factorization machine (FM) variants are widely used in recommendation systems that operate under strict throughput and latency requirements, such as online advertising systems. FMs have two prominent strengths. First, is their ability to model pairwise feature interactions while being resilient to data sparsity by learning factorized representations. Second, their computational graphs facilitate fast inference and training. Moreover, when items are ranked as a part of a query for each incoming user, these graphs facilitate computing the portion stemming from the user and context fields only once per query.  Thus, the computational cost for each ranked item is proportional only to the number of fields that vary among the ranked items. Consequently, in terms of inference cost, the number of user or context fields is practically unlimited. More advanced variants of FMs, such as field-aware and field-weighted FMs, provide better accuracy by learning a representation of field-wise interactions, but require computing all pairwise interaction terms explicitly. In particular, the computational cost during inference is proportional to the square of the number of fields, including user, context, and item. When the number of fields is large, this is prohibitive in systems with strict latency constraints, and imposes a limit on the number of user and context fields for a given computational budget. To mitigate this caveat, heuristic pruning of low intensity field interactions is commonly used to accelerate inference. In this work we propose an alternative to the pruning heuristic in field-weighted FMs using a diagonal plus symmetric low-rank decomposition. Our technique reduces the computational cost of inference, by allowing it to be proportional to the number of item fields only. Using a set of experiments on real-world datasets, we show that aggressive rank reduction outperforms similarly aggressive pruning, both in terms of accuracy and item recommendation speed. Beyond computational complexity analysis, we corroborate our claim of faster inference experimentally, both via a synthetic test, and by having deployed our solution to a major online advertising system, where we observed significant ranking latency improvements. We made the code to reproduce the results on public datasets and synthetic tests available at https://anonymous.4open.science/r/pytorch-fm-0EC0.</p>
    <p><strong>Categories:</strong> Factorization Machines (FM), Matrix Factorization, Online Advertising, Low Latency, Computational Efficiency, Field-Weighted Factorization Machines, Inference Optimization, Real-World Applications, Performance Evaluation, Low Rank Decomposition (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1048/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>End-to-End Cost-Effective Incentive Recommendation under Budget Constraint with Uplift Modeling (2024)</h3>
    <p><strong>Authors:</strong> Yunpeng Weng, Xiuqiang He, Hao Yang, Dugang Liu, Xing Tang, Zexu Sun</p>
    <p>In modern online platforms, incentive (<i>e.g</i>., discounts, bonus) are essential factors that enhance user engagement and increase platform revenue. Over recent years, uplift modeling has been introduced as a strategic approach to assign incentive to individual customers. Especially, in many real-world applications, online platforms can only incentivize customers with specific budget constraints. This problem can be reformulated as the multi-choice knapsack problem (MCKP). The objective of this optimization is to select the optimal incentive for each customer in order to maximize the return-on-investment (ROI). Recent works in this field frequently tackle the problem of budget allocation using a two-stage approach. %: the first stage utilizes causal inference algorithms to estimate the individual treatment effect or uplift, while the second stage employs integer programming techniques to determine the optimal solution for budget allocation. However, this solution is confronted with the following challenges: (1) The commonly used causal inference methods often ignore the domain knowledge in online marketing, where the expected response curve of a customer should be monotonic and smooth as the incentive increases. (2) There is an optimality gap between the two stages, resulting in inferior sub-optimal allocation performance, which is due to the loss of the incentive recommendation information for the uplift prediction under the limited budget constraint. To address these challenges, we propose a novel <u>E</u>nd-to-<u>E</u>nd Cost-<u>E</u>ffective <u>I</u>ncentive <u>R</u>ecommendation (E$^3$IR) model under the budget constraint. Specifically, our methods consist of two modules: the uplift prediction module and the differentiable allocation module. In the uplift prediction module, we construct prediction heads to capture the incremental improvement between adjacent treatments with the marketing domain constraints (<i>i.e.</i>, monotonic and smooth). %To obtain a monotonic user response curve, we constrain the output of each prediction head to be non-negative. In the differentiable allocation module, we incorporate integer linear programming (ILP) as a differentiable layer input. Furthermore, we conduct extensive experiments on both public and real product datasets, which demonstrate that our E$^3$IR improves allocation performance compared to existing two-stage approaches.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Marketing Strategies, E-commerce, Uplift Modeling, Resource Management, Optimization, Causal Inference, Integer Linear Programming, Real-World Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1038/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Pay Attention to Attention for Sequential Recommendation (2024)</h3>
    <p><strong>Authors:</strong> Xiaojing Liu, Yuli Liu, Min Liu</p>
    <p>Transformer-based approaches have demonstrated remarkable success in various sequence-based tasks. However, traditional self-attention models may not sufficiently capture the intricate dependencies within items in sequential recommendation scenarios. This is due to the lack of explicit emphasis on attention weights, which play a critical role in allocating attention and understanding item-to-item correlations. To better exploit the potential of attention weights and improve the capability of sequential recommendation in learning high-order dependencies, we propose a novel sequential recommendation (SR) approach called attention weight refinement (AWRSR). AWRSR enhances the effectiveness of self-attention by additionally paying attention to attention weights, allowing for more refined attention distributions of correlations among items. We conduct comprehensive experiments on multiple real-world datasets, demonstrating that our approach consistently outperforms state-of-the-art SR models. Moreover, we provide a thorough analysis of AWRSR’s effectiveness in capturing higher-level dependencies. These findings suggest that AWRSR offers a promising new direction for enhancing the performance of self-attention architecture in SR tasks, with potential applications in other sequence-based problems as well.</p>
    <p><strong>Categories:</strong> Sequential Recommendations, Attention Mechanisms, Transformer-Based Models, Recommendation Systems, Higher-Order Dependencies, Model Performance, Experimental Analysis, Item Correlations, Real-World Applications, Novel Methods, Attention Weight Refinement, Self-Attention Architecture, Machine Learning for Recommendations, Potential Applications in Other Domains (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1104/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>DNS-Rec: Data-aware Neural Architecture Search for Recommender Systems (2024)</h3>
    <p><strong>Authors:</strong> Zijian Zhang, Xiangyu Zhao, Ruocheng Guo, Sheng Zhang, Chenyi Zhuang, Jinjie Gu, Yao Zhao, Hongzhi Yin, Maolin Wang</p>
    <p>In the era of data proliferation, efficiently sifting through vast information to extract meaningful insights has become increasingly crucial. This paper addresses the computational and resource inefficiencies prevalent in existing Sequential Recommender Systems (SRSs). However, existing SRSs are often plagued by significant computational overhead and resource inefficiency during the inference stage. To address these challenges, we introduce an innovative approach combining pruning methods with advanced model designs. Furthermore, we delve into resource-constrained Neural Architecture Search (NAS), an emerging technique in recommender systems, to optimize models in terms of FLOPs, latency, and energy consumption while maintaining or enhancing accuracy. Our principal contribution is the development of a Data-aware Neural Architecture Search for Recommender System (DNS-Rec). DNS-Rec is specifically designed to tailor compact network architectures for attention-based SRS models, thereby ensuring accuracy retention. It incorporates data-aware gates to enhance the performance of the recommendation network by learning information from historical user-item interactions. Moreover, DNS-Rec employs a dynamic resource constraint strategy, stabilizing the search process and yielding more suitable architectural solutions. We demonstrate the effectiveness of our approach through rigorous experiments conducted on three benchmark datasets, which highlight the superiority of DNS-Rec in SRSs. Our findings set a new standard for future research in efficient and accurate recommendation systems, marking a significant step forward in this rapidly evolving field.</p>
    <p><strong>Categories:</strong> Neural Architecture Search, Recommender Systems, Sequential Recommender Systems (SRSs), Computational Efficiency, Resource Optimization, Attention-Based Models, Data-Aware Methods, Pruning Techniques, Scalability, Energy Efficiency, Dynamic Resource Allocation, Model Design (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1027/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Scene-wise Adaptive Network for Dynamic Cold-start Scenes Optimization in CTR Prediction (2024)</h3>
    <p><strong>Authors:</strong> Chao Tang, Wenhao Li, Jie Zhou, Shixiong Zhao, Chuan Luo, Kun Zhang</p>
    <p>In the realm of modern mobile E-commerce, providing users with nearby commercial service recommendations through location-based online services has become increasingly vital. While machine learning approaches have shown promise in multi-scene recommendation, existing methodologies often struggle to address cold-start problems in unprecedented scenes: the increasing diversity of commercial choices, along with the short online lifespan of scenes, give rise to the complexity of effective recommendations in online and dynamic scenes. In this work, we propose Scene-wise Adaptive Network (SwAN), a novel approach that emphasizes high-performance cold-start online recommendations for new scenes. Our approach introduces several crucial capabilities, including scene similarity learning, user-specific scene transition cognition, scene-specific information construction for the new scene, and enhancing the diverged logical information between scenes. We demonstrate SwAN’s potential to optimize dynamic multi-scene recommendation problems by effectively online handling cold-start recommendations for any newly arrived scenes. More encouragingly, SwAN has been successfully deployed in Company M’s online catering recommendation service, which serves millions of customers per day, and SwAN has achieved a 5.64% CTR index improvement relative to the baselines and a 5.19% increase in daily order volume proportion.</p>
    <p><strong>Categories:</strong> Scene-wise Adaptive Network (SwAN), Neural Networks, Cold Start, Multi-scene Recommendations, Dynamic Scenarios, Recommendation Systems, Mobile E-commerce, Catering Services, Location-based Services, Evaluation Metrics, Beyond Accuracy, Real-world Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1063/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Leveraging LLM generated labels to reduce bad matches in job recommendations (2024)</h3>
    <p><strong>Authors:</strong> Dheeraj Toshniwal, Yingchi Pei, Yi Wei Pang, Nilanjan Sengupta</p>
    <p>Negative signals are increasingly employed to enhance recommendation quality. However, explicit negative feedback is often sparse and may disproportionately reflect the preferences of more vocal users. Commonly used implicit negative feedback, such as impressions without positive interactions, has the limitation of not accurately capturing users’ true negative preferences because users mainly pursue information they consider interesting. In this work, we present an approach that leverages fine-tuned Large Language Models (LLMs) to evaluate matches and generate negative signals at scale while maintaining cost efficiency. We demonstrate significant improvements in recommendation quality by deploying a traditional classifier trained using LLM-generated labels.</p>
    <p><strong>Categories:</strong> Recommendation Systems, Job Recommendations, Negative Feedback Mechanisms, Large Language Models (LLMs), Implicit Feedback Analysis, Model Fine-Tuning, Scalability in ML Applications (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1171/">See reasoning</a></p>
  </div>

    </div>
  
    <div class="ui segment">
      
  <div class="item">
    <h3>Pareto Front Approximation for Multi-Objective Session-Based Recommender Systems (2024)</h3>
    <p><strong>Authors:</strong> Timo Wilm, Philipp Normann, Felix Stepprath</p>
    <p>This work introduces MultiTRON, an approach that adapts Pareto front approximation techniques to multi-objective session-based recommender systems using a transformer neural network. Our approach optimizes trade-offs between key metrics such as click-through and conversion rates by training on sampled preference vectors. A significant advantage is that after training, a single model can access the entire Pareto front, allowing it to be tailored to meet the specific requirements of different stakeholders by adjusting an additional input vector that weights the objectives. We validate the model’s performance through extensive offline and online evaluation. For broader application and research, the source code is made available. The results confirm the model’s ability to manage multiple recommendation objectives effectively, offering a flexible tool for diverse business needs.</p>
    <p><strong>Categories:</strong> Multi-objective optimization, Session-based recommendations, Pareto front approximation, Transformer neural networks, Offline evaluation, Online evaluation, Recommendation systems, Real-world applications, Evaluation techniques, Deep learning approaches (<i>deepseek-r1:32b</i>)</p>
    <p><a href="/recsys-recommender/response/1166/">See reasoning</a></p>
  </div>

    </div>
  



  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.js"></script>

</body>

</html>